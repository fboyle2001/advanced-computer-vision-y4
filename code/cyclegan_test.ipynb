{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d988e0-06f5-4fbc-8619-bb6230134379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d5985-f272-4c30-9779-463dc8ddb209",
   "metadata": {},
   "source": [
    "Ref: Section 7 (Appendix) from CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba39a9-178f-45c7-9248-d022f4a2109c",
   "metadata": {},
   "source": [
    "## Generator Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f82b81ce-aa8e-4841-9de0-5c9c3a2fc903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CINR = Convolution Instance Norm ReLU\n",
    "# 3x3 convolutions with stride 1/2, 1 or 2 depending on position\n",
    "# Uses reflection padding\n",
    "# In the paper:\n",
    "# dk denotes a k filter stride 2 with 3x3 conv\n",
    "# c7s1-k denotes a k filter stride 1 with 7x7 conv\n",
    "# uk denotes a k filter stride 1/2 with 3x3 conv\n",
    "class CINRLayer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, kernel_size, reflect_pad):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        conv_type = nn.Conv2d if stride >= 1 else nn.ConvTranspose2d\n",
    "        stride = stride if stride >= 1 else int(1 / stride)\n",
    "        \n",
    "        if reflect_pad:\n",
    "            layers.append(nn.ReflectionPad2d(kernel_size // 2))\n",
    "        \n",
    "        layers += [\n",
    "            conv_type(in_ch, out_ch, kernel_size=kernel_size, stride=stride, bias=True),\n",
    "            nn.InstanceNorm2d(out_ch),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "        \n",
    "        self.seq = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.seq(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d2cf237-8620-4f96-8002-c9e7f712e2af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Contains 2 3x3 convolutional layers with the same number of filters on both layers\n",
    "# Use reflect padding in these\n",
    "# Don't use dropout\n",
    "# Use instancenorm\n",
    "class GeneratorResidualBlock(nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(feature_size, feature_size, kernel_size=3, bias=True),\n",
    "            nn.InstanceNorm2d(feature_size),\n",
    "            nn.ReLU(True),\n",
    "            # Dropout would go here if I want it\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(feature_size, feature_size, kernel_size=3, bias=True)\n",
    "        ]\n",
    "        \n",
    "        self.seq = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return batch + self.seq(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3bcdc4-d08f-4ffb-aeb9-005347427016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the 128x128 case:\n",
    "# c7s1-64, d128, d256, R256 x 6, u128, u64, c7s1-3\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [\n",
    "            CINRLayer(in_ch=3, out_ch=64, stride=1, kernel_size=7, reflect_pad=True),\n",
    "            CINRLayer(in_ch=64, out_ch=128, stride=2, kernel_size=3, reflect_pad=False),\n",
    "            CINRLayer(in_ch=128, out_ch=256, stride=2, kernel_size=3, reflect_pad=False),\n",
    "            \n",
    "            # same dim all the way through\n",
    "            GeneratorResidualBlock(feature_size=256),\n",
    "            GeneratorResidualBlock(feature_size=256),\n",
    "            GeneratorResidualBlock(feature_size=256),\n",
    "            GeneratorResidualBlock(feature_size=256),\n",
    "            GeneratorResidualBlock(feature_size=256),\n",
    "            GeneratorResidualBlock(feature_size=256),\n",
    "            \n",
    "            CINRLayer(in_ch=256, out_ch=128, kernel_size=3, stride=0.5, reflect_pad=False),\n",
    "            CINRLayer(in_ch=128, out_ch=64, kernel_size=3, stride=0.5, reflect_pad=False),\n",
    "            CINRLayer(in_ch=64, out_ch=3, stride=1, kernel_size=7, reflect_pad=True)\n",
    "        ]\n",
    "        \n",
    "        self.seq = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        return self.seq(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae37a12-33d5-4b56-9e1c-72910af8c07a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce GTX 1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (seq): Sequential(\n",
       "    (0): CINRLayer(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "        (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): CINRLayer(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): CINRLayer(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): GeneratorResidualBlock(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): GeneratorResidualBlock(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): GeneratorResidualBlock(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): GeneratorResidualBlock(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): GeneratorResidualBlock(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): GeneratorResidualBlock(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): CINRLayer(\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (10): CINRLayer(\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (11): CINRLayer(\n",
       "      (seq): Sequential(\n",
       "        (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "        (1): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if (torch.cuda.device_count()>0):\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    \n",
    "generator_model = Generator().to(device)\n",
    "generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c95b84dd-b2d1-4c7a-8ea7-6e6231b218e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ReflectionPad2d-1          [-1, 3, 134, 134]               0\n",
      "            Conv2d-2         [-1, 64, 128, 128]           9,472\n",
      "    InstanceNorm2d-3         [-1, 64, 128, 128]               0\n",
      "              ReLU-4         [-1, 64, 128, 128]               0\n",
      "         CINRLayer-5         [-1, 64, 128, 128]               0\n",
      "            Conv2d-6          [-1, 128, 63, 63]          73,856\n",
      "    InstanceNorm2d-7          [-1, 128, 63, 63]               0\n",
      "              ReLU-8          [-1, 128, 63, 63]               0\n",
      "         CINRLayer-9          [-1, 128, 63, 63]               0\n",
      "           Conv2d-10          [-1, 256, 31, 31]         295,168\n",
      "   InstanceNorm2d-11          [-1, 256, 31, 31]               0\n",
      "             ReLU-12          [-1, 256, 31, 31]               0\n",
      "        CINRLayer-13          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-14          [-1, 256, 33, 33]               0\n",
      "           Conv2d-15          [-1, 256, 31, 31]         590,080\n",
      "   InstanceNorm2d-16          [-1, 256, 31, 31]               0\n",
      "             ReLU-17          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-18          [-1, 256, 33, 33]               0\n",
      "           Conv2d-19          [-1, 256, 31, 31]         590,080\n",
      "GeneratorResidualBlock-20          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-21          [-1, 256, 33, 33]               0\n",
      "           Conv2d-22          [-1, 256, 31, 31]         590,080\n",
      "   InstanceNorm2d-23          [-1, 256, 31, 31]               0\n",
      "             ReLU-24          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-25          [-1, 256, 33, 33]               0\n",
      "           Conv2d-26          [-1, 256, 31, 31]         590,080\n",
      "GeneratorResidualBlock-27          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-28          [-1, 256, 33, 33]               0\n",
      "           Conv2d-29          [-1, 256, 31, 31]         590,080\n",
      "   InstanceNorm2d-30          [-1, 256, 31, 31]               0\n",
      "             ReLU-31          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-32          [-1, 256, 33, 33]               0\n",
      "           Conv2d-33          [-1, 256, 31, 31]         590,080\n",
      "GeneratorResidualBlock-34          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-35          [-1, 256, 33, 33]               0\n",
      "           Conv2d-36          [-1, 256, 31, 31]         590,080\n",
      "   InstanceNorm2d-37          [-1, 256, 31, 31]               0\n",
      "             ReLU-38          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-39          [-1, 256, 33, 33]               0\n",
      "           Conv2d-40          [-1, 256, 31, 31]         590,080\n",
      "GeneratorResidualBlock-41          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-42          [-1, 256, 33, 33]               0\n",
      "           Conv2d-43          [-1, 256, 31, 31]         590,080\n",
      "   InstanceNorm2d-44          [-1, 256, 31, 31]               0\n",
      "             ReLU-45          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-46          [-1, 256, 33, 33]               0\n",
      "           Conv2d-47          [-1, 256, 31, 31]         590,080\n",
      "GeneratorResidualBlock-48          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-49          [-1, 256, 33, 33]               0\n",
      "           Conv2d-50          [-1, 256, 31, 31]         590,080\n",
      "   InstanceNorm2d-51          [-1, 256, 31, 31]               0\n",
      "             ReLU-52          [-1, 256, 31, 31]               0\n",
      "  ReflectionPad2d-53          [-1, 256, 33, 33]               0\n",
      "           Conv2d-54          [-1, 256, 31, 31]         590,080\n",
      "GeneratorResidualBlock-55          [-1, 256, 31, 31]               0\n",
      "  ConvTranspose2d-56          [-1, 128, 63, 63]         295,040\n",
      "   InstanceNorm2d-57          [-1, 128, 63, 63]               0\n",
      "             ReLU-58          [-1, 128, 63, 63]               0\n",
      "        CINRLayer-59          [-1, 128, 63, 63]               0\n",
      "  ConvTranspose2d-60         [-1, 64, 127, 127]          73,792\n",
      "   InstanceNorm2d-61         [-1, 64, 127, 127]               0\n",
      "             ReLU-62         [-1, 64, 127, 127]               0\n",
      "        CINRLayer-63         [-1, 64, 127, 127]               0\n",
      "  ReflectionPad2d-64         [-1, 64, 133, 133]               0\n",
      "           Conv2d-65          [-1, 3, 127, 127]           9,411\n",
      "   InstanceNorm2d-66          [-1, 3, 127, 127]               0\n",
      "             ReLU-67          [-1, 3, 127, 127]               0\n",
      "        CINRLayer-68          [-1, 3, 127, 127]               0\n",
      "================================================================\n",
      "Total params: 7,837,699\n",
      "Trainable params: 7,837,699\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 194.37\n",
      "Params size (MB): 29.90\n",
      "Estimated Total Size (MB): 224.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(generator_model, input_size=(3, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f35bf-0dfe-404b-9f8d-14001dfa101c",
   "metadata": {},
   "source": [
    "Todo: have a small shrink here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
