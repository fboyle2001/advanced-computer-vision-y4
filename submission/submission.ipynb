{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011db540-76a2-4754-9535-435c968eb1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.models\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c425dcb-98ac-415d-885d-4ad3f7b099cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "if device == \"cpu\":\n",
    "    print(f\"It is highly recommended to use a GPU! This is likely to run extremely slowly otherwise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25821c9c-9e99-4877-bcb4-271b20ec22fd",
   "metadata": {},
   "source": [
    "# Code Acknowledgements\n",
    "I have used multiple open source repositories as references for my implementation:\n",
    "\n",
    "* CycleGAN: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix by Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros\n",
    "* RecycleGAN: https://github.com/aayushbansal/Recycle-GAN/ by Aayush Bansal, Shugao Ma, Deva Ramanan, and Yaser Sheikh\n",
    "* GAN Training Tips: https://github.com/soumith/ganhacks by Soumith Chintala, Emily Denton, Martin Arjovsky, and Michael Mathieu\n",
    "* Transpose Convolution Replacements: https://gist.github.com/bearpelican/a87a6140661ffbc9b97409a12a1cf45b by Andrew Shaw\n",
    "* Practicals on Blackboard from the Advanced Computer Vision course materials \n",
    "\n",
    "My implementation is my own work but I have used these resources, along with the papers cited in my report, to guide my code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5b2fd-9d38-4a0d-ae35-68b280fb9b38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1: Human Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60aba41f-cc58-4164-a5aa-3fc00dca68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skeletal_pose import PoseKeypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d02f9-170e-44fe-9896-7f71b40f5819",
   "metadata": {},
   "source": [
    "General setup instructions:\n",
    "\n",
    "* Please place the original data into a folder called 'original_data' in the same directory as this notebook\n",
    "* Please ensure ffmpeg is available on your system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99938d90-d9a3-497c-b6fb-52cce8f09de7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.1: Human Patch Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5827d8b-0888-40fd-8f32-7bc73f226941",
   "metadata": {},
   "source": [
    "The process I follow to extract the human patches is as follows:\n",
    "\n",
    "1. Extract the frames from the training videos using ffmpeg\n",
    "2. Use a pre-trained MaskR-CNN model to segment and extract the human patches\n",
    "3. Save the human patches for future processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d18a58-7545-483f-9490-ee283bcf85dc",
   "metadata": {},
   "source": [
    "Firstly, I use ffmpeg to extract all frames from the videos and store them for later processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f73f7e3-fa2b-4119-9520-ac8ad9a7d85d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/01.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T16:57:33.000000Z\n",
      "  Duration: 00:02:46.97, start: 0.000000, bitrate: 2738 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2736 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:57:33.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7ffff3a43ba0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_01_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:57:33.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 5004 fps=164 q=2.0 Lsize=N/A time=00:02:46.96 bitrate=N/A speed=5.48x    \n",
      "video:315976kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/02.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T16:59:03.000000Z\n",
      "  Duration: 00:01:01.63, start: 0.000000, bitrate: 2753 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2750 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:59:03.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7ffff0612a60] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_02_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:59:03.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1847 fps=157 q=2.0 Lsize=N/A time=00:01:01.62 bitrate=N/A speed=5.25x    \n",
      "video:143859kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/03.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:00:43.000000Z\n",
      "  Duration: 00:00:39.41, start: 0.000000, bitrate: 2727 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2723 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:00:43.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffec25c7e0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_03_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:00:43.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1181 fps=166 q=2.0 Lsize=N/A time=00:00:39.40 bitrate=N/A speed=5.55x    \n",
      "video:105614kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/04.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:01:59.000000Z\n",
      "  Duration: 00:00:39.87, start: 0.000000, bitrate: 2834 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2830 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:01:59.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7ffff3f6cec0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_04_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:01:59.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1195 fps=158 q=2.0 Lsize=N/A time=00:00:39.87 bitrate=N/A speed=5.26x    \n",
      "video:61894kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/05.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:03:11.000000Z\n",
      "  Duration: 00:00:19.52, start: 0.000000, bitrate: 2915 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2909 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:03:11.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffcd7fc6a0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_05_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:03:11.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame=  585 fps=164 q=2.0 Lsize=N/A time=00:00:19.51 bitrate=N/A speed=5.48x    \n",
      "video:51759kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/06.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:04:29.000000Z\n",
      "  Duration: 00:00:59.19, start: 0.000000, bitrate: 2769 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2766 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:04:29.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffe3b35160] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_06_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:04:29.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1774 fps=157 q=2.0 Lsize=N/A time=00:00:59.19 bitrate=N/A speed=5.24x    \n",
      "video:117139kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/07.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:07:46.000000Z\n",
      "  Duration: 00:01:06.30, start: 0.000000, bitrate: 2764 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2761 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:07:46.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffc07cf8e0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_07_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:07:46.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1987 fps=153 q=2.0 Lsize=N/A time=00:01:06.29 bitrate=N/A speed= 5.1x    \n",
      "video:142919kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/08.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:09:17.000000Z\n",
      "  Duration: 00:01:00.43, start: 0.000000, bitrate: 2752 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2750 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:09:17.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffee9e6bc0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_08_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:09:17.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1811 fps=158 q=2.0 Lsize=N/A time=00:01:00.42 bitrate=N/A speed=5.28x    \n",
      "video:143797kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/09.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:11:32.000000Z\n",
      "  Duration: 00:01:10.44, start: 0.000000, bitrate: 2698 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2696 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:11:32.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffc9d95680] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_09_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:11:32.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 2111 fps=155 q=2.0 Lsize=N/A time=00:01:10.43 bitrate=N/A speed=5.16x    \n",
      "video:211729kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Game/10.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T17:13:16.000000Z\n",
      "  Duration: 00:00:51.08, start: 0.000000, bitrate: 2844 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2841 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:13:16.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7ffff49d83a0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Game/Train_Game_10_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T17:13:16.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1531 fps=163 q=2.0 Lsize=N/A time=00:00:51.08 bitrate=N/A speed=5.43x    \n",
      "video:93406kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Movie/01.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T16:33:40.000000Z\n",
      "  Duration: 00:03:02.88, start: 0.000000, bitrate: 425 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 480x360 [SAR 1:1 DAR 4:3], 424 kb/s, 25 fps, 25 tbr, 25k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:33:40.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffe64fc8a0] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Movie/Train_Movie_01_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 480x360 [SAR 1:1 DAR 4:3], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:33:40.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 4572 fps=234 q=2.0 Lsize=N/A time=00:03:02.88 bitrate=N/A speed=9.35x    \n",
      "video:80388kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Movie/02.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T16:35:44.000000Z\n",
      "  Duration: 00:01:11.20, start: 0.000000, bitrate: 439 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 480x360 [SAR 1:1 DAR 4:3], 437 kb/s, 25 fps, 25 tbr, 25k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:35:44.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffc30fb760] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Movie/Train_Movie_02_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 480x360 [SAR 1:1 DAR 4:3], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:35:44.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1780 fps=234 q=2.0 Lsize=N/A time=00:01:11.20 bitrate=N/A speed=9.36x    \n",
      "video:33779kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Train/Movie/03.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T16:36:29.000000Z\n",
      "  Duration: 00:05:29.00, start: 0.000000, bitrate: 428 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 480x360 [SAR 1:1 DAR 4:3], 427 kb/s, 25 fps, 25 tbr, 25k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:36:29.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffe10e0540] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Train/Movie/Train_Movie_03_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 480x360 [SAR 1:1 DAR 4:3], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:36:29.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 8225 fps=230 q=2.0 Lsize=N/A time=00:05:29.00 bitrate=N/A speed=9.18x    \n",
      "video:170328kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Test/Test Movie.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T16:48:53.000000Z\n",
      "  Duration: 00:01:05.80, start: 0.000000, bitrate: 427 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 480x360 [SAR 1:1 DAR 4:3], 424 kb/s, 25 fps, 25 tbr, 25k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:48:53.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffc59ded60] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './extracted_data/frames/Test/Test_Test Movie_%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 480x360 [SAR 1:1 DAR 4:3], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:48:53.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1645 fps=239 q=2.0 Lsize=N/A time=00:01:05.80 bitrate=N/A speed=9.55x    \n",
      "video:36842kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./frame_extraction.sh ./original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5c0b41-8482-4fdf-8f88-c80736f7aead",
   "metadata": {},
   "source": [
    "Next, I use a pre-trained MaskR-CNN model to extract the human patches.\n",
    "This part is heavily inspired by the practical 'Semantic Segmentation Mask R-CNN.ipynb' on Blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794a10d4-0cfc-456b-b791-fe53c67114a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskrcnn = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "maskrcnn.to(device).eval()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228ff6df-fa85-4e8f-abc5-ffbbb4df4417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 91 COCO class names, directly from Semantic Segmentation Mask R-CNN.ipynb\n",
    "coco_names = ['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94d0a54-d0d7-4e41-8b7f-928a57202193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def batch_loader(input_directory, output_directory, batch_size):\n",
    "    # Get all files in the directory that are frames\n",
    "    file_names = [file_name for file_name in os.listdir(input_directory) if file_name.endswith(\".jpg\")]\n",
    "    \n",
    "    for i in tqdm(range(len(file_names) // batch_size + 1)):\n",
    "        selected = []\n",
    "        start_idx = batch_size * i\n",
    "        limit_idx = batch_size * (i + 1)\n",
    "        \n",
    "        # Get the images to put through the model\n",
    "        if limit_idx > len(file_names):\n",
    "            selected = file_names[start_idx:]\n",
    "        else:\n",
    "            selected = file_names[start_idx:limit_idx]\n",
    "            \n",
    "        if len(selected) == 0:\n",
    "            break\n",
    "        \n",
    "        output_files = []\n",
    "        raw_frames = []\n",
    "        usable_frames = []\n",
    "        \n",
    "        for file_name in selected:\n",
    "            # Pre-determine the save location and load the frame with RGB\n",
    "            output_files.append(f\"{output_directory}/Segmented_{file_name.split('.')[0]}\")\n",
    "            input_file = f\"{input_directory}/{file_name}\"\n",
    "            raw_frame = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "            raw_frames.append(raw_frame)\n",
    "            \n",
    "            usable_frame = cv2.cvtColor(raw_frame, cv2.COLOR_BGR2RGB)\n",
    "            usable_frame = tensor_transform(usable_frame)\n",
    "            usable_frames.append(usable_frame)\n",
    "        \n",
    "        # Return a tensor to use with the model and additional info for cropping and saving\n",
    "        stacked_frames = torch.stack(usable_frames).to(device)\n",
    "        yield stacked_frames, raw_frames, output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac26cdf-8cab-4849-859c-c3f9d9d8d5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_maskrcnn_output(maskrcnn_output, original_frame, save_loc, threshold):\n",
    "    # Get the relevant model output on to the CPU in a usable format\n",
    "    scores = output[\"scores\"].detach().cpu().numpy()\n",
    "    boxes = output[\"boxes\"].detach().cpu().numpy().astype(int)\n",
    "    label_indices = output[\"labels\"].detach().cpu()\n",
    "    \n",
    "    # Process each entry found by the model\n",
    "    for i, (confidence, box, label_idx) in enumerate(zip(scores, boxes, label_indices)):\n",
    "        label = coco_names[label_idx.item()]\n",
    "        \n",
    "        if label != \"person\":\n",
    "            continue\n",
    "        \n",
    "        # The confidences are sorted high to low so stop once we're below the threshold\n",
    "        if confidence < threshold:\n",
    "            break\n",
    "          \n",
    "        # Crop and save the patch using its bounding box\n",
    "        x_0, y_0, x_1, y_1 = box\n",
    "        patch = original_frame.copy()[y_0:y_1, x_0:x_1]\n",
    "        cv2.imwrite(f\"{save_loc}_{i}.jpg\", patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94eee283-6bbe-4416-8bda-96b696af8279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If everything is setup correctly and the frames have been extracted these settings should be fine\n",
    "base_folders = [\"Train/Game\", \"Train/Movie\"]\n",
    "base_frame_folder = \"./extracted_data/frames\"\n",
    "base_output_folder = \"./extracted_data/unclassified_human_patches\"\n",
    "\n",
    "batch_size = 4\n",
    "threshold = 0.965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b56ffa-92a7-4451-99a5-9c7996c10469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process each folder and every frame in them\n",
    "# Takes a few hours to run\n",
    "for base_folder in base_folders:\n",
    "    in_directory = f\"{base_frame_folder}/{base_folder}\"\n",
    "    out_directory = f\"{base_output_folder}/{base_folder}\"\n",
    "    \n",
    "    os.makedirs(out_directory)\n",
    "    \n",
    "    print(f\"{in_directory} -> {out_directory}\")\n",
    "    \n",
    "    batch_generator = batch_loader(in_directory, out_directory, batch_size)\n",
    "\n",
    "    for i, (batch, raw_frames, output_files) in enumerate(batch_generator):\n",
    "        with torch.no_grad():\n",
    "            outputs = maskrcnn(batch)\n",
    "\n",
    "        for output, frame, output_file in zip(outputs, raw_frames, output_files):\n",
    "            process_maskrcnn_output(output, frame, output_file, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff914a2-2095-4728-ac1f-8d0885719cce",
   "metadata": {},
   "source": [
    "In testing, this gave:\n",
    "\n",
    "* 18,454 human patches for the movie clips\n",
    "* 37,530 human patches for the game clips \n",
    "\n",
    "I now sample 50 random images from each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922652c3-5952-4308-9044-eb26a3e3111a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_submission_folder = \"./data_for_submission/1_1_sampled_human_patches\"\n",
    "sample_count = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c956f58-b4f0-408a-a2e1-e125b026cda8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./extracted_data/unclassified_human_patches/Train/Game -> ./data_for_submission/1_1_sampled_human_patches/Train/Game\n",
      "./extracted_data/unclassified_human_patches/Train/Movie -> ./data_for_submission/1_1_sampled_human_patches/Train/Movie\n"
     ]
    }
   ],
   "source": [
    "for base_folder in base_folders:\n",
    "    patch_directory = f\"{base_output_folder}/{base_folder}\"\n",
    "    sampled_directory = f\"{base_submission_folder}/{base_folder}\"\n",
    "    \n",
    "    os.makedirs(sampled_directory) \n",
    "    \n",
    "    print(f\"{patch_directory} -> {sampled_directory}\")\n",
    "    \n",
    "    file_names = [file_name for file_name in os.listdir(patch_directory) if file_name.endswith(\".jpg\")]\n",
    "    sampled_file_names = random.sample(file_names, k=sample_count)\n",
    "    \n",
    "    for sampled in sampled_file_names:\n",
    "        shutil.copy(f\"{patch_directory}/{sampled}\", sampled_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f3ffa-c212-4ebb-92a2-e23b455b8f09",
   "metadata": {},
   "source": [
    "## 1.2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76022d-72a4-4c8a-bb5d-710c8c46a55d",
   "metadata": {},
   "source": [
    "Using the human patches from the previous task, I use the following process to classify them according to pose:\n",
    "1. Use OpenPose to extract the pose keypoints from each human patch\n",
    "2. Load the extracted pose into Python and analyse the data to determine the pose based on joint visibility\n",
    "3. To determine if they are standing or sitting I compute the angle between the hips and knees if they are visible\n",
    "4. Save the images into folders based on their classified pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b1d9e-491e-4641-8b40-f03148222b64",
   "metadata": {},
   "source": [
    "Firstly, I use OpenPose to extract the pose. Depending on your install of OpenPose you may need to adjust the command slightly below to point to the OpenPose executable. I generated normalised keypoints so that image scale is irrelevant for determining the pose and limit the resolution and disable the display to work within my GPU resource constraints. Depending on your operating system use the %%cmd cell for Windows and the %%bash cell for Unix. The Unix one is untested as I am using Windows to run this but something along those lines should work if you want to run it! (May need to play around with directories based on OpenPose installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f3ffe1a-6ffb-4125-aac5-e10ea1427573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19045.2728]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test>mkdir .\\extracted_data\\human_poses\\Train\\Game\n",
      "\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test>mkdir .\\extracted_data\\human_poses\\Train\\Movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .\\extracted_data\\human_poses\\Train\\Game already exists.\n",
      "A subdirectory or file .\\extracted_data\\human_poses\\Train\\Movie already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test>cd .\\openpose\n",
      "\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test\\openpose>.\\bin\\OpenPoseDemo.exe --image_dir ..\\extracted_data\\unclassified_human_patches\\Train\\Game --write_json ..\\extracted_data\\human_poses\\Train\\Game --keypoint_scale 3 --net_resolution \"656x368\" --display 0 --render_pose 0\n",
      "Starting OpenPose demo...\n",
      "Configuring OpenPose...\n",
      "Starting thread(s)...\n",
      "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
      "\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test\\openpose>.\\bin\\OpenPoseDemo.exe --image_dir ..\\extracted_data\\unclassified_human_patches\\Train\\Movie --write_json ..\\extracted_data\\human_poses\\Train\\Movie --keypoint_scale 3 --net_resolution \"656x368\" --display 0 --render_pose 0\n",
      "Starting OpenPose demo...\n",
      "Configuring OpenPose...\n",
      "Starting thread(s)...\n",
      "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
      "\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test\\openpose>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "mkdir .\\extracted_data\\human_poses\\Train\\Game\n",
    "mkdir .\\extracted_data\\human_poses\\Train\\Movie\n",
    "cd .\\openpose\n",
    ".\\bin\\OpenPoseDemo.exe --image_dir ..\\extracted_data\\unclassified_human_patches\\Train\\Game --write_json ..\\extracted_data\\human_poses\\Train\\Game --keypoint_scale 3 --net_resolution \"656x368\" --display 0 --render_pose 0\n",
    ".\\bin\\OpenPoseDemo.exe --image_dir ..\\extracted_data\\unclassified_human_patches\\Train\\Movie --write_json ..\\extracted_data\\human_poses\\Train\\Movie --keypoint_scale 3 --net_resolution \"656x368\" --display 0 --render_pose 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a59a809-f067-4548-96a0-469714bad021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ./extracted_data/human_poses/Train/Game\n",
    "./openpose/build/examples/openpose/openpose.bin --image_dir ./extracted_data/unclassified_human_patches/Train/Game --write_json ./extracted_data/human_poses/Train/Game --keypoint_scale 3 --net_resolution \"656x368\" --display 0 --render_pose 0\n",
    "mkdir -p ./extracted_data/human_poses/Train/Movie\n",
    "./openpose/build/examples/openpose/openpose.bin --image_dir ./extracted_data/unclassified_human_patches/Train/Movie --write_json ./extracted_data/human_poses/Train/Movie --keypoint_scale 3 --net_resolution \"656x368\" --display 0 --render_pose 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bec2a-d860-4aef-a339-852705619ea8",
   "metadata": {},
   "source": [
    "Now that I have the extracted pose data saved as .json files in a one-to-one mapping with each human patch (although there may be multiple humans detected by the pose detector!), I process these using Python. Before this I need to define what I count as each class. In connection with Q1.3 I consider those that are facing away to be in the class 'Other' regardless of all other attributes. I group the joints and measure the visibility of each group, the groups are:\n",
    "\n",
    "* Head: Nose, Left Eye, Left Ear, Right Eye, Right Eye\n",
    "* Torso and Arms: Neck, Left Shoulder, Left Elbow, Left Wrist, Right Shoulder, Right Elbow, Right Wrist\n",
    "* Hips: Mid Hip, Left Hip, Right Hip\n",
    "* Legs: Left Knee, Left Ankle, Right Knee, Right Ankle\n",
    "* Feet: Left Ankle, Left Heel, Left Big Toe, Left Small Toe, Right Ankle, Right Heel, Right Big Toe, Right Small Toe\n",
    "\n",
    "Then to classify by pose:\n",
    "\n",
    "* Head Only: At least 60% of the Head group visible, less than 45% of the Torso and Arms group visible and none of the Hips, Legs or Feet groups visible\n",
    "* Half Body: At least 40% of the Head group visible, at least 50% of the Torso and Arms group visible, any amount of Hips, and none of the Legs or Feet groups visible\n",
    "* Full Body: At least 40% of the Head group visible, at least 70% of the Torso and Arms group visible, at least 50% of the Hips and Legs visible, and any amount of Feet visible\n",
    "\n",
    "Finally, to classify sitting and standing I measure the angle between the knees and hips. If this is less than 50 degrees they are sitting otherwise they are standing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6d0ed4-cbc3-44ca-a12e-d53060ff500f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_folders = [\"Train/Movie\", \"Train/Game\"]\n",
    "base_patch_directory = \"./extracted_data/unclassified_human_patches\"\n",
    "base_pose_directory = \"./extracted_data/human_poses\"\n",
    "base_classification_directory = \"./extracted_data/classified_human_patches\"\n",
    "base_sample_directory = \"./extracted_data/human_patches_validation_set/raw\"\n",
    "base_sample_classified_directory = \"./extracted_data/human_patches_validation_set/hand_classified\"\n",
    "\n",
    "sample_count = 150\n",
    "\n",
    "classes = [\"Full Body Sitting\", \"Full Body Standing\", \"Half Body\", \"Head Only\", \"Other\"]\n",
    "show_skeleton = False\n",
    "enforce_facing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f8ccf-7604-46d6-907c-336000d2c28e",
   "metadata": {},
   "source": [
    "Prior to classifying them, I sample 150 patches from each domain to classify by hand to evaluate the performance of the pose classification process. I put the classified files in the following directory: ./extracted_data/human_patches_validation_set/{base_folder}/{class_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb21c83-390c-42a4-9416-905d28017f29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./extracted_data/unclassified_human_patches/Train/Movie -> ./extracted_data/human_patches_validation_set/raw/Train/Movie\n",
      "./extracted_data/unclassified_human_patches/Train/Game -> ./extracted_data/human_patches_validation_set/raw/Train/Game\n"
     ]
    }
   ],
   "source": [
    "for base_folder in base_folders:\n",
    "    patch_directory = f\"{base_patch_directory}/{base_folder}\"\n",
    "    sampled_directory = f\"{base_sample_directory}/{base_folder}\"\n",
    "    \n",
    "    os.makedirs(sampled_directory) \n",
    "    \n",
    "    print(f\"{patch_directory} -> {sampled_directory}\")\n",
    "    \n",
    "    file_names = [file_name for file_name in os.listdir(patch_directory) if file_name.endswith(\".jpg\")]\n",
    "    sampled_file_names = random.sample(file_names, k=sample_count)\n",
    "    \n",
    "    for sampled in sampled_file_names:\n",
    "        shutil.copy(f\"{patch_directory}/{sampled}\", sampled_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eecbfb-557a-4a82-b8e2-e2fe16865af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for base_folder in base_folders:\n",
    "    patch_directory = f\"{base_patch_directory}/{base_folder}\"\n",
    "    pose_directory = f\"{base_pose_directory}/{base_folder}\"\n",
    "    output_directory = f\"{base_classification_directory}/{base_folder}\"\n",
    "    \n",
    "    for class_name in classes:\n",
    "        os.makedirs(f\"{output_directory}/{class_name}\")\n",
    "    \n",
    "    file_names = [''.join(file_name.split(\".\")[:-1]) for file_name in os.listdir(patch_directory) if file_name.endswith(\".jpg\")]\n",
    "    \n",
    "    for file_name in tqdm(file_names):\n",
    "        patch_loc = f\"{patch_directory}/{file_name}.jpg\"\n",
    "        keypoints_loc = f\"{pose_directory}/{file_name}_keypoints.json\"\n",
    "        \n",
    "        with open(keypoints_loc, \"r\") as fp:\n",
    "            raw_data = json.load(fp)\n",
    "\n",
    "        if len(raw_data[\"people\"]) != 1:\n",
    "            continue\n",
    "        \n",
    "        kps = raw_data[\"people\"][0][\"pose_keypoints_2d\"]\n",
    "        pose = PoseKeypoints.load_keypoints(kps)\n",
    "        \n",
    "        classification = pose.classify(enforce_facing=enforce_facing)\n",
    "        save_loc = f\"{output_directory}/{classification}/{file_name}.jpg\"\n",
    "        \n",
    "        patch = cv2.imread(patch_loc)\n",
    "    \n",
    "        if show_skeleton:\n",
    "            patch = pose.overlay_pose(patch)\n",
    "        \n",
    "        cv2.imwrite(save_loc, patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54778d69-932a-4d80-9945-a6b6591e4b6e",
   "metadata": {},
   "source": [
    "I now evaluate the results using the hand classified set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c068e3b-00c9-478f-b106-11cf0eeee208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Movie Accuracy: 0.7843137254901961\n",
      "Train/Game Accuracy: 0.7474747474747475\n"
     ]
    }
   ],
   "source": [
    "for base_folder in base_folders:\n",
    "    classification_data = {}\n",
    "    hand_classified_folder = f\"{base_sample_classified_directory}/{base_folder}\"\n",
    "    pred_classified_folder = f\"{base_classification_directory}/{base_folder}\"\n",
    "    \n",
    "    for class_name in classes:\n",
    "        for file_name in os.listdir(f\"{hand_classified_folder}/{class_name}\"):\n",
    "            classification_data[file_name] = {\"ground_truth\": class_name, \"predicted\": None}\n",
    "    \n",
    "    for class_name in classes:\n",
    "        classified_files = os.listdir(f\"{pred_classified_folder}/{class_name}\")\n",
    "        \n",
    "        for file_name in classification_data.keys():\n",
    "            if file_name in classified_files:\n",
    "                classification_data[file_name][\"predicted\"] = class_name\n",
    "                \n",
    "    correct = 0\n",
    "    \n",
    "    classification_data_rows = [{\"file\": key, **value} for key, value in classification_data.items() if value[\"predicted\"] is not None]\n",
    "    df = pd.DataFrame(classification_data_rows)\n",
    "    \n",
    "    df[\"match\"] = df.apply(lambda row: row[\"ground_truth\"] == row[\"predicted\"], axis=1)\n",
    "    \n",
    "    print(f\"{base_folder} Accuracy:\", df[\"match\"].sum() / len(df))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cad786-35c6-43c3-9014-7285f09ff347",
   "metadata": {},
   "source": [
    "I now sample 10 images from each class per domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78b5fec4-4314-40ab-b085-1cdb5cd2498f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_submission_folder = \"./data_for_submission/1_2_sampled_pose_classified\"\n",
    "sample_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e929c39-1fbb-4940-a7e0-54ff7e85a785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./extracted_data/classified_human_patches/Train/Movie/Full Body Sitting -> ./data_for_submission/1_2_sampled_pose_classified/Train/Movie/Full Body Sitting\n",
      "./extracted_data/classified_human_patches/Train/Movie/Full Body Standing -> ./data_for_submission/1_2_sampled_pose_classified/Train/Movie/Full Body Standing\n",
      "./extracted_data/classified_human_patches/Train/Movie/Half Body -> ./data_for_submission/1_2_sampled_pose_classified/Train/Movie/Half Body\n",
      "./extracted_data/classified_human_patches/Train/Movie/Head Only -> ./data_for_submission/1_2_sampled_pose_classified/Train/Movie/Head Only\n",
      "./extracted_data/classified_human_patches/Train/Movie/Other -> ./data_for_submission/1_2_sampled_pose_classified/Train/Movie/Other\n",
      "./extracted_data/classified_human_patches/Train/Game/Full Body Sitting -> ./data_for_submission/1_2_sampled_pose_classified/Train/Game/Full Body Sitting\n",
      "./extracted_data/classified_human_patches/Train/Game/Full Body Standing -> ./data_for_submission/1_2_sampled_pose_classified/Train/Game/Full Body Standing\n",
      "./extracted_data/classified_human_patches/Train/Game/Half Body -> ./data_for_submission/1_2_sampled_pose_classified/Train/Game/Half Body\n",
      "./extracted_data/classified_human_patches/Train/Game/Head Only -> ./data_for_submission/1_2_sampled_pose_classified/Train/Game/Head Only\n",
      "./extracted_data/classified_human_patches/Train/Game/Other -> ./data_for_submission/1_2_sampled_pose_classified/Train/Game/Other\n"
     ]
    }
   ],
   "source": [
    "for base_folder in base_folders:\n",
    "    for class_name in classes:\n",
    "        sampled_directory = f\"{base_submission_folder}/{base_folder}/{class_name}\"\n",
    "        os.makedirs(sampled_directory)\n",
    "        \n",
    "        class_folder = f\"{base_classification_directory}/{base_folder}/{class_name}\"\n",
    "        print(f\"{class_folder} -> {sampled_directory}\")\n",
    "        \n",
    "        file_names = [file_name for file_name in os.listdir(class_folder) if file_name.endswith(\".jpg\")]\n",
    "        sampled_file_names = random.sample(file_names, k=min(sample_count, len(file_names)))\n",
    "        \n",
    "        for sampled in sampled_file_names:\n",
    "            shutil.copy(f\"{class_folder}/{sampled}\", sampled_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8199a95-1e43-463e-a842-a1fa7cb9363b",
   "metadata": {},
   "source": [
    "## 1.3: Training Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb33ffd-be8f-455a-ba8d-e98f3751ffc8",
   "metadata": {},
   "source": [
    "Now that I have classified the human patches according to pose, I need to select the most appropriate data for training the model. I will use CycleGAN initially as such I need approximately 1200 images from both domains to form a quality dataset. This needs to be diverse (i.e. not just similar patches a couple of frames apart) and representative of the data. To achieve this I group human patches into sequences to reduce oversampling of extremely similar patches which will degrade the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "584e967c-8393-44e6-adc7-183b1653e898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_similar_images(ordered_dir, cutoff, window):\n",
    "    image_locs = [f\"{ordered_dir}/{file_name}\" for file_name in os.listdir(ordered_dir) if file_name.endswith(\".jpg\")]\n",
    "    groups = [[image_locs[0]]]\n",
    "    \n",
    "    for image_loc in tqdm(image_locs):\n",
    "        img_hash = imagehash.average_hash(Image.open(image_loc))\n",
    "        \n",
    "        closest_group_idx = -1\n",
    "        closest_group_diff = 65\n",
    "        \n",
    "        for offset, group in enumerate(groups[-window:][::-1]):\n",
    "            group_idx = len(groups) - offset - 1\n",
    "            last_hash = imagehash.average_hash(Image.open(group[-1]))\n",
    "            diff = img_hash - last_hash\n",
    "            \n",
    "            if diff < closest_group_diff:\n",
    "                closest_group_idx = group_idx\n",
    "                closest_group_diff = diff\n",
    "        \n",
    "        if closest_group_diff <= cutoff:\n",
    "            groups[closest_group_idx].append(image_loc)\n",
    "        else:\n",
    "            groups.append([image_loc])\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdb54f70-c40b-4e91-8411-cd238fe90c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_classes(base_directory, classes, cutoff, window):\n",
    "    groups = []\n",
    "    \n",
    "    for class_name in classes:\n",
    "        pose_directory = f\"{base_directory}/{class_name}\"\n",
    "        groups += group_similar_images(pose_directory, cutoff, window)\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53507d3a-73e2-45cf-8444-c14c5e4c780c",
   "metadata": {},
   "source": [
    "I discard all images from the 'Other' category as I determine that these will likely not be of use to the model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "185105af-d72e-47ab-a456-a7a9793cd5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [\"Full Body Sitting\", \"Full Body Standing\", \"Half Body\", \"Head Only\"]\n",
    "base_pose_directory = \"./extracted_data/classified_human_patches\"\n",
    "cutoff = 8\n",
    "window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8ac4355-ff6f-4c18-92bf-326d37612334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a71f2f708f42669d699b371e701ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708e57bc77be4382ba4a613e054a2681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4011 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bda795e0ac4fecafd993cf9748dde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464e0564fd694de7bbd0321318be7444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa544e26ce274a29a39572a6577c931a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13b8f16bf234eda8fdead14e40296e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b2a0422eea4bda840a0b891eb2adb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5331 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d3ce3aa5cf4700a835246a7a151da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game_groups = group_classes(f\"{base_pose_directory}/Train/Game\", classes, cutoff, window) \n",
    "movie_groups = group_classes(f\"{base_pose_directory}/Train/Movie\", classes, cutoff, window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d0840-e205-4723-a4d6-f41bfcd6bee6",
   "metadata": {},
   "source": [
    "Now I sample from these sequences of images. I also discard images that are too small, as I will training on 128x128 images for CycleGAN I discard all images that are smaller than 64x64 pixels as they will be too poor quality to be useful when resized to 128x128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09e6fbe-96fe-40a6-911b-785857ded481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_test_count = 250\n",
    "target_train_count = 1200\n",
    "output_size = 128\n",
    "min_size = 64\n",
    "sequence_proportion = 0.05\n",
    "\n",
    "train_output_directory = lambda base: f\"./extracted_data/cyclegan_training_data/{base}/Train\"\n",
    "test_output_directory = lambda base: f\"./extracted_data/cyclegan_training_data/{base}/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "526bf0bd-c47e-4be2-b30d-82b29a44eb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_train_test_split(groups, train_dir, test_dir, train_target, test_target, output_size, min_size, sequence_proportion):\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "    for group_no, group in enumerate(tqdm(groups)):\n",
    "        selected_patches = random.sample(range(len(group)), k=max(1, int(sequence_proportion * len(group))))\n",
    "        \n",
    "        for i in selected_patches:\n",
    "            patch = Image.open(group[i])\n",
    "            \n",
    "            if patch.width < min_size or patch.height < min_size:\n",
    "                continue\n",
    "                \n",
    "            patch = patch.resize((output_size, output_size))\n",
    "            patch.save(f\"{train_dir}/{group_no:05d}_{i:05d}.jpg\")\n",
    "    \n",
    "    valid_train_files = [file_name for file_name in os.listdir(train_dir) if file_name.endswith(\".jpg\")]\n",
    "    \n",
    "    if len(valid_train_files) <= train_target:\n",
    "        print(f\"Only found {len(valid_train_files)} valid files, not able to produce a test set\")\n",
    "        return\n",
    "    \n",
    "    available_for_test = min(len(valid_train_files) - train_target, test_target)\n",
    "    selected_for_test = random.sample(valid_train_files, k=available_for_test)\n",
    "    \n",
    "    for file_name in selected_for_test:\n",
    "        os.rename(f\"{train_dir}/{file_name}\", f\"{test_dir}/{file_name}\")\n",
    "    \n",
    "    print(\"Moved\", len(selected_for_test), \"files to test set\")\n",
    "    \n",
    "    valid_train_files = [file_name for file_name in os.listdir(train_dir) if file_name.endswith(\".jpg\")]\n",
    "    \n",
    "    if len(valid_train_files) > train_target:\n",
    "        selected_for_delete = random.sample(valid_train_files, k=len(valid_train_files) - train_target)\n",
    "    \n",
    "        for file_name in selected_for_delete:\n",
    "            os.remove(f\"{train_dir}/{file_name}\")\n",
    "\n",
    "        print(\"Deleted\", len(selected_for_delete), \"files from the train set\")\n",
    "    \n",
    "    print(\"Train Size:\", len([file_name for file_name in os.listdir(train_dir) if file_name.endswith(\".jpg\")]))\n",
    "    print(\"Test Size:\", len([file_name for file_name in os.listdir(test_dir) if file_name.endswith(\".jpg\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0d4ee0e-52a7-4c6c-9df0-2cd654ae99d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b99fecba864faca1d88b9e34d59325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 250 files to test set\n",
      "Deleted 181 files from the train set\n",
      "Train Size: 1200\n",
      "Test Size: 250\n"
     ]
    }
   ],
   "source": [
    "create_train_test_split(game_groups, train_output_directory(\"Game\"), test_output_directory(\"Game\"), target_train_count, target_test_count, output_size, min_size, sequence_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d4ae863-9d32-4ae0-8a33-74cfb0b873b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94580491b8ea48558278ad025155068a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 104 files to test set\n",
      "Train Size: 1200\n",
      "Test Size: 104\n"
     ]
    }
   ],
   "source": [
    "create_train_test_split(movie_groups, train_output_directory(\"Movie\"), test_output_directory(\"Movie\"), target_train_count, target_test_count, output_size, min_size, sequence_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1beb9e-246f-486c-8258-da8300768d12",
   "metadata": {},
   "source": [
    "Now I sample 50 random images from each training dataset for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4578ac4d-5b07-479b-86f7-a4b3ff9904cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_submission_folder = \"./data_for_submission/1_3_sampled_training_data\"\n",
    "sample_count = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a472cde-0d2c-45e4-867a-41b8e32c30b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./extracted_data/cyclegan_training_data/Game/Train -> ./data_for_submission/1_3_sampled_training_data/Game\n",
      "./extracted_data/cyclegan_training_data/Movie/Train -> ./data_for_submission/1_3_sampled_training_data/Movie\n"
     ]
    }
   ],
   "source": [
    "for base_folder in [\"Game\", \"Movie\"]:\n",
    "    train_directory = train_output_directory(base_folder)\n",
    "    sampled_directory = f\"{base_submission_folder}/{base_folder}\"\n",
    "    \n",
    "    os.makedirs(sampled_directory) \n",
    "    \n",
    "    print(f\"{train_directory} -> {sampled_directory}\")\n",
    "    \n",
    "    file_names = [file_name for file_name in os.listdir(train_directory) if file_name.endswith(\".jpg\")]\n",
    "    sampled_file_names = random.sample(file_names, k=sample_count)\n",
    "    \n",
    "    for sampled in sampled_file_names:\n",
    "        shutil.copy(f\"{train_directory}/{sampled}\", sampled_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41ab59-62ba-465a-8298-5cb4ff6132c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Real-world Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c23dfb06-ff13-4870-9204-3bdb763c9e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joint_dataset import JointDomainImageDataset, JointDomainTripletDataset\n",
    "from generator_model import Generator\n",
    "from cycle_gan import CycleGAN\n",
    "from recycle_gan import RecycleGAN\n",
    "from visdom_utils import MultiLinePlot\n",
    "from image_utils import revert_normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea568e-42df-4803-93fd-100e43829d32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1: Image Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f873d60a-2017-444a-b0b0-d6a65c6ba043",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba5805c7-f918-4c0c-a0f0-2bd1619ff290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using_google_gpus = False\n",
    "\n",
    "train_X_loc = \"./extracted_data/cyclegan_training_data/Game/Train\" \n",
    "test_X_loc = \"./extracted_data/cyclegan_training_data/Game/Test\" \n",
    "\n",
    "train_Y_loc = \"./extracted_data/cyclegan_training_data/Movie/Train\"\n",
    "test_Y_loc = \"./extracted_data/cyclegan_training_data/Movie/Test\"\n",
    "\n",
    "run_data_directory = \"./runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c969af7-5f6e-4c5a-be28-6b7b804d9fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "if using_google_gpus:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    vis = None\n",
    "else:\n",
    "    import visdom\n",
    "    vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de85931a-29ad-4425-9496-fb29bb56aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: 'drive/MyDrive/cyclegan'\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/cyclegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7ff0c67-274c-4e1a-870b-a28a7da84645",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JointDomainImageDataset(train_X_loc, train_Y_loc, train=True, img_size=128)\n",
    "test_dataset = JointDomainImageDataset(test_X_loc, test_Y_loc, train=False, img_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9d81a74-7359-4197-9936-623d4e14ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs = []\n",
    "test_ys = []\n",
    "\n",
    "for i in random.sample(range(0, len(test_dataset)), 16):\n",
    "    x, y = test_dataset[i]\n",
    "    test_xs.append(x)\n",
    "    test_ys.append(y)\n",
    "\n",
    "test_xs = torch.stack(test_xs)\n",
    "test_ys = torch.stack(test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb9538f2-ad81-4828-80e3-71c2a7356078",
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis is not None:\n",
    "    vis.images(torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in test_xs]), nrow=4, opts={\"title\": \"X_test originals\"})\n",
    "    vis.images(torch.stack([revert_normalisation(y).permute(2, 0, 1) for y in test_ys]), nrow=4, opts={\"title\": \"Y_test originals\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12c26f71-e553-41c5-b442-da2a63ede0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_dataset[random.randint(0, len(test_dataset))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bf14622-23f3-4f77-86a7-167e2ac2ac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9608) tensor(0.8431)\n"
     ]
    }
   ],
   "source": [
    "print(test_img.min(), test_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72827ab8-0ef3-41bf-b415-c56f6f7a1de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1755e2dd810>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb2847bf-e756-486a-83e4-a947b9bfc619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1755e3c81c0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(revert_normalisation(test_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a1a63-e7d0-4d5b-9a5c-4b8c795e2358",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0649aa7-7fe1-4600-8297-5e6e45aafb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 100\n",
    "lambda_weight = 10\n",
    "lambda_idt_X = 0.5\n",
    "lambda_idt_Y = 0.5\n",
    "\n",
    "blocks = 6\n",
    "upsample_strategy = [\"upsample\", \"conv_transpose\", \"pixel_shuffle\"][0]\n",
    "pool_size = 50\n",
    "opt_scheduler_type = \"linear_decay_with_warmup\"\n",
    "\n",
    "checkpoint_instance_dir = None\n",
    "checkpoint_epoch_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "917c021f-d634-4c02-a457-8076d2df8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06f30f66-d599-4931-8857-09b481b287a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised weights\n"
     ]
    }
   ],
   "source": [
    "if checkpoint_instance_dir is not None and checkpoint_epoch_dir is not None:\n",
    "    cyclegan = CycleGAN.load(f\"{run_data_directory}/{checkpoint_instance_dir}\", f\"{checkpoint_epoch_dir}\", device, blocks)\n",
    "else:\n",
    "    cyclegan = CycleGAN(blocks, upsample_strategy, device, pool_size, opt_scheduler_type, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63a2304f-045b-421e-a2fd-66221c2a1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{cyclegan.save_folder}/info_{checkpoint_epoch_dir}.json\", \"w+\") as fp:\n",
    "    json.dump({\n",
    "        \"block_count\": cyclegan.resnet_block_count,\n",
    "        \"upsample_strategy\": upsample_strategy,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"opt_scheduler_type\": opt_scheduler_type,\n",
    "        \"data_folders\": {\n",
    "            \"train_X\": train_X_loc,\n",
    "            \"test_X\": test_X_loc,\n",
    "            \"train_Y\": train_Y_loc,\n",
    "            \"test_Y\": test_Y_loc\n",
    "        },\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_epochs\": epochs,\n",
    "        \"start_epoch\": cyclegan.start_epoch,\n",
    "        \"lambda_weight\": lambda_weight,\n",
    "        \"lambda_idt_X\": lambda_idt_X,\n",
    "        \"lambda_idt_Y\": lambda_idt_Y,\n",
    "        \"checkpoint\": {\n",
    "            \"instance\": checkpoint_instance_dir,\n",
    "            \"epoch\": checkpoint_epoch_dir\n",
    "        }\n",
    "    }, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "333e1468-fb3d-4eae-b228-d1c99c545808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could also enable random flipping\n",
    "def generate_noisy_labels(shape, real, device):\n",
    "    # Randomly generated between 0 and 1\n",
    "    labels = torch.rand(shape, device=device)\n",
    "    \n",
    "    if real:\n",
    "        # Now they are between 0.7 and 1.1\n",
    "        labels = (2 * labels / 5) + 0.7\n",
    "    else:\n",
    "        # Now they are between 0 and 0.3\n",
    "        labels = (labels * 3) / 10\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac04939a-dc0e-4dee-9322-653cff0a8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_loss(real, fake, pool, discriminator, loss_func):\n",
    "    # Discriminator should give (1) for a real image and (0) for a fake\n",
    "    real_pred = discriminator(real)\n",
    "    real_loss = loss_func(real_pred, generate_noisy_labels(real_pred.shape, True, device)) # Should dampen?\n",
    "    \n",
    "    # We draw from the history buffer\n",
    "    pool_fake = pool.randomise_existing_batch(fake)\n",
    "    fake_pred = discriminator(pool_fake)\n",
    "    # Fake images should not fool the discriminator\n",
    "    fake_loss = loss_func(fake_pred.detach(), generate_noisy_labels(fake_pred.shape, False, device))\n",
    "    \n",
    "    avg_loss = (real_loss + fake_loss) * 0.5\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e70cd1af-4317-40ec-9a0c-f2eb6342a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch\n",
      "[1:100] Took 16.48s\n",
      "[1:100] loss_idt_x: 0.2597608774155378, G_fool_loss: 0.20890929840505124, cycled_x_loss: 0.2739638955146074, D_X_loss: 0.40991327181458476\n",
      "[1:100] loss_idt_y: 0.3123185461759567, F_fool_loss: 0.14446092285215856, cycled_y_loss: 0.33616753354668616, D_Y_loss: 0.4694626188278198\n",
      "[1:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:200] Took 12.90s\n",
      "[1:200] loss_idt_x: 0.24173177771270274, G_fool_loss: 0.03866207478567958, cycled_x_loss: 0.251174683496356, D_X_loss: 0.3235919590294361\n",
      "[1:200] loss_idt_y: 0.28084933921694755, F_fool_loss: 0.0503176799416542, cycled_y_loss: 0.31133716508746145, D_Y_loss: 0.30655116096138957\n",
      "[1:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:300] Took 12.82s\n",
      "[1:300] loss_idt_x: 0.23150294840335847, G_fool_loss: 0.039426376540213824, cycled_x_loss: 0.2425686191767454, D_X_loss: 0.3317151902616024\n",
      "[1:300] loss_idt_y: 0.257626436650753, F_fool_loss: 0.05897355066612363, cycled_y_loss: 0.2878461642563343, D_Y_loss: 0.3068429531157017\n",
      "[1:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:400] Took 12.84s\n",
      "[1:400] loss_idt_x: 0.2469529577344656, G_fool_loss: 0.035263117589056495, cycled_x_loss: 0.2583701941370964, D_X_loss: 0.3222361208498478\n",
      "[1:400] loss_idt_y: 0.28939087077975273, F_fool_loss: 0.04456143829971552, cycled_y_loss: 0.31709160208702086, D_Y_loss: 0.3020438277721405\n",
      "[1:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:500] Took 12.82s\n",
      "[1:500] loss_idt_x: 0.254449041262269, G_fool_loss: 0.03994557611644268, cycled_x_loss: 0.2669950596988201, D_X_loss: 0.3054521371424198\n",
      "[1:500] loss_idt_y: 0.2800975033640862, F_fool_loss: 0.038575453758239744, cycled_y_loss: 0.2893889062851667, D_Y_loss: 0.3105648815631866\n",
      "[1:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:600] Took 12.82s\n",
      "[1:600] loss_idt_x: 0.2174602574110031, G_fool_loss: 0.04966063382104039, cycled_x_loss: 0.22660838775336742, D_X_loss: 0.31041270166635515\n",
      "[1:600] loss_idt_y: 0.23640185758471488, F_fool_loss: 0.0438453864492476, cycled_y_loss: 0.25648658506572247, D_Y_loss: 0.31762085393071177\n",
      "[1:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:700] Took 12.82s\n",
      "[1:700] loss_idt_x: 0.22223633348941804, G_fool_loss: 0.03561420631594956, cycled_x_loss: 0.23872782573103904, D_X_loss: 0.30222018674016\n",
      "[1:700] loss_idt_y: 0.21601129844784736, F_fool_loss: 0.03377902522683143, cycled_y_loss: 0.2335516255348921, D_Y_loss: 0.30880230888724325\n",
      "[1:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:800] Took 12.82s\n",
      "[1:800] loss_idt_x: 0.20490833409130574, G_fool_loss: 0.02779483943246305, cycled_x_loss: 0.2276850488781929, D_X_loss: 0.3090759174525738\n",
      "[1:800] loss_idt_y: 0.26241401948034765, F_fool_loss: 0.04708035685122013, cycled_y_loss: 0.2772300215065479, D_Y_loss: 0.30078729465603826\n",
      "[1:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:900] Took 12.83s\n",
      "[1:900] loss_idt_x: 0.22100173130631448, G_fool_loss: 0.075459800735116, cycled_x_loss: 0.2396481844037771, D_X_loss: 0.29479112192988394\n",
      "[1:900] loss_idt_y: 0.23698462061583997, F_fool_loss: 0.03267836034297943, cycled_y_loss: 0.2525922255218029, D_Y_loss: 0.33976711973547935\n",
      "[1:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:1000] Took 12.81s\n",
      "[1:1000] loss_idt_x: 0.2267146823555231, G_fool_loss: 0.02710602678358555, cycled_x_loss: 0.2375429880619049, D_X_loss: 0.30711067244410517\n",
      "[1:1000] loss_idt_y: 0.20744791574776172, F_fool_loss: 0.03689966034144163, cycled_y_loss: 0.22026226192712783, D_Y_loss: 0.2987640216946602\n",
      "[1:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:1100] Took 12.95s\n",
      "[1:1100] loss_idt_x: 0.25753330752253534, G_fool_loss: 0.027647966435179114, cycled_x_loss: 0.26540758579969403, D_X_loss: 0.3054529248178005\n",
      "[1:1100] loss_idt_y: 0.22426979780197143, F_fool_loss: 0.032781958943232894, cycled_y_loss: 0.243113494515419, D_Y_loss: 0.3015466000139713\n",
      "[1:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[1:END] Completed epoch in 158.47029829025269s\n",
      "[1:1199] ep_loss_idt_x: 0.233 ep_G_fool_loss: 0.052 ep_cycled_x_loss: 0.247 ep_D_X_loss: 0.319\n",
      "[1:1199] ep_loss_idt_y: 0.252 ep_F_fool_loss: 0.050 ep_cycled_y_loss: 0.271 ep_D_Y_loss: 0.321\n",
      "[1:END] Completed eval in 1.069169044494629s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[1:END] Saving models and training information permanently\n",
      "[2:100] Took 15.06s\n",
      "[2:100] loss_idt_x: 0.20320431858301163, G_fool_loss: 0.023697206638753413, cycled_x_loss: 0.21542699001729487, D_X_loss: 0.30056147307157516\n",
      "[2:100] loss_idt_y: 0.21695592418313026, F_fool_loss: 0.02724084730260074, cycled_y_loss: 0.22823825284838675, D_Y_loss: 0.29691158056259154\n",
      "[2:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:200] Took 12.83s\n",
      "[2:200] loss_idt_x: 0.21910229057073594, G_fool_loss: 0.026054958272725345, cycled_x_loss: 0.227821648940444, D_X_loss: 0.2938228942453861\n",
      "[2:200] loss_idt_y: 0.1940660409629345, F_fool_loss: 0.03222534773871302, cycled_y_loss: 0.20848351910710336, D_Y_loss: 0.29689269214868547\n",
      "[2:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:300] Took 12.83s\n",
      "[2:300] loss_idt_x: 0.216224704682827, G_fool_loss: 0.029438776932656764, cycled_x_loss: 0.22404783263802527, D_X_loss: 0.3044047868251801\n",
      "[2:300] loss_idt_y: 0.18402285642921926, F_fool_loss: 0.03339013512246311, cycled_y_loss: 0.20615234695374965, D_Y_loss: 0.29798883855342867\n",
      "[2:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:400] Took 12.83s\n",
      "[2:400] loss_idt_x: 0.22517717860639094, G_fool_loss: 0.026025693286210298, cycled_x_loss: 0.23459816664457322, D_X_loss: 0.3068646642565727\n",
      "[2:400] loss_idt_y: 0.19189961180090903, F_fool_loss: 0.02938988852314651, cycled_y_loss: 0.2228604953736067, D_Y_loss: 0.292651055008173\n",
      "[2:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:500] Took 13.08s\n",
      "[2:500] loss_idt_x: 0.20768141351640224, G_fool_loss: 0.02943503369577229, cycled_x_loss: 0.21721039839088918, D_X_loss: 0.29340904623270037\n",
      "[2:500] loss_idt_y: 0.2033540989458561, F_fool_loss: 0.029210617393255235, cycled_y_loss: 0.22311093844473362, D_Y_loss: 0.29835282891988757\n",
      "[2:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:600] Took 12.84s\n",
      "[2:600] loss_idt_x: 0.2248960242420435, G_fool_loss: 0.028503958564251662, cycled_x_loss: 0.2297344461083412, D_X_loss: 0.3012805806100369\n",
      "[2:600] loss_idt_y: 0.20365748699754477, F_fool_loss: 0.03036877952516079, cycled_y_loss: 0.2213181383907795, D_Y_loss: 0.2955026005208492\n",
      "[2:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:700] Took 12.81s\n",
      "[2:700] loss_idt_x: 0.22622402235865594, G_fool_loss: 0.03425854272209108, cycled_x_loss: 0.23124188013374805, D_X_loss: 0.2988608059287071\n",
      "[2:700] loss_idt_y: 0.1990303586423397, F_fool_loss: 0.03139621937647462, cycled_y_loss: 0.21748350568115712, D_Y_loss: 0.3084842087328434\n",
      "[2:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:800] Took 12.82s\n",
      "[2:800] loss_idt_x: 0.20945537000894546, G_fool_loss: 0.02924242405220866, cycled_x_loss: 0.21047543473541735, D_X_loss: 0.2965243981778622\n",
      "[2:800] loss_idt_y: 0.18196650244295598, F_fool_loss: 0.033630501665174964, cycled_y_loss: 0.20624375350773336, D_Y_loss: 0.30081793904304505\n",
      "[2:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:900] Took 12.82s\n",
      "[2:900] loss_idt_x: 0.2068535888940096, G_fool_loss: 0.02882789185270667, cycled_x_loss: 0.2094681005179882, D_X_loss: 0.29847550809383394\n",
      "[2:900] loss_idt_y: 0.1736562141031027, F_fool_loss: 0.03171682402491569, cycled_y_loss: 0.18295966751873494, D_Y_loss: 0.2973830416798592\n",
      "[2:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:1000] Took 12.82s\n",
      "[2:1000] loss_idt_x: 0.20619806565344334, G_fool_loss: 0.033684920985251665, cycled_x_loss: 0.21831984736025334, D_X_loss: 0.29116989150643346\n",
      "[2:1000] loss_idt_y: 0.22602179750800133, F_fool_loss: 0.032348400168120864, cycled_y_loss: 0.22331521421670913, D_Y_loss: 0.31396605640649794\n",
      "[2:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:1100] Took 12.82s\n",
      "[2:1100] loss_idt_x: 0.19701206766068935, G_fool_loss: 0.028857017513364554, cycled_x_loss: 0.2126704892516136, D_X_loss: 0.2938718643784523\n",
      "[2:1100] loss_idt_y: 0.1819768834859133, F_fool_loss: 0.02529634727165103, cycled_y_loss: 0.18571121983230113, D_Y_loss: 0.30304056987166406\n",
      "[2:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[2:END] Completed epoch in 157.12111568450928s\n",
      "[2:1199] ep_loss_idt_x: 0.213 ep_G_fool_loss: 0.028 ep_cycled_x_loss: 0.221 ep_D_X_loss: 0.297\n",
      "[2:1199] ep_loss_idt_y: 0.196 ep_F_fool_loss: 0.030 ep_cycled_y_loss: 0.210 ep_D_Y_loss: 0.300\n",
      "[2:END] Completed eval in 1.014289379119873s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[2:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[3:100] Took 14.75s\n",
      "[3:100] loss_idt_x: 0.2167845945060253, G_fool_loss: 0.02682795879431069, cycled_x_loss: 0.23204508990049363, D_X_loss: 0.2972933158278465\n",
      "[3:100] loss_idt_y: 0.17845461145043373, F_fool_loss: 0.02734350411221385, cycled_y_loss: 0.1862927170842886, D_Y_loss: 0.2998406374454498\n",
      "[3:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:200] Took 12.82s\n",
      "[3:200] loss_idt_x: 0.2063612364977598, G_fool_loss: 0.023579486021772025, cycled_x_loss: 0.21539092674851418, D_X_loss: 0.2960995414853096\n",
      "[3:200] loss_idt_y: 0.18903000883758067, F_fool_loss: 0.024239401780068875, cycled_y_loss: 0.19690265536308288, D_Y_loss: 0.2967524865269661\n",
      "[3:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:300] Took 12.84s\n",
      "[3:300] loss_idt_x: 0.21870479926466943, G_fool_loss: 0.03000218726694584, cycled_x_loss: 0.22824873633682727, D_X_loss: 0.2993171063065529\n",
      "[3:300] loss_idt_y: 0.18679053477942945, F_fool_loss: 0.03020461106672883, cycled_y_loss: 0.2021378018707037, D_Y_loss: 0.30144007474184037\n",
      "[3:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:400] Took 12.82s\n",
      "[3:400] loss_idt_x: 0.20521040886640549, G_fool_loss: 0.03187692169100046, cycled_x_loss: 0.21708117201924323, D_X_loss: 0.30062201872468\n",
      "[3:400] loss_idt_y: 0.16701624870300294, F_fool_loss: 0.034021119372919205, cycled_y_loss: 0.18787003725767135, D_Y_loss: 0.30650843501091\n",
      "[3:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:500] Took 12.86s\n",
      "[3:500] loss_idt_x: 0.20260859183967114, G_fool_loss: 0.027823225948959588, cycled_x_loss: 0.2106984670460224, D_X_loss: 0.3041208089888096\n",
      "[3:500] loss_idt_y: 0.1884918762743473, F_fool_loss: 0.0279004776943475, cycled_y_loss: 0.2108701604604721, D_Y_loss: 0.3027456276118755\n",
      "[3:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:600] Took 12.83s\n",
      "[3:600] loss_idt_x: 0.19767521306872368, G_fool_loss: 0.02380666334182024, cycled_x_loss: 0.2063682958483696, D_X_loss: 0.29467050194740296\n",
      "[3:600] loss_idt_y: 0.18996314890682697, F_fool_loss: 0.024360823864117264, cycled_y_loss: 0.19983831390738488, D_Y_loss: 0.29686779469251634\n",
      "[3:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:700] Took 12.82s\n",
      "[3:700] loss_idt_x: 0.20677389711141586, G_fool_loss: 0.027994383787736297, cycled_x_loss: 0.20866448037326335, D_X_loss: 0.2916597421467304\n",
      "[3:700] loss_idt_y: 0.16566611222922803, F_fool_loss: 0.027244470622390507, cycled_y_loss: 0.18701894633471966, D_Y_loss: 0.2935054421424866\n",
      "[3:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:800] Took 12.82s\n",
      "[3:800] loss_idt_x: 0.20620632953941823, G_fool_loss: 0.026051234668120742, cycled_x_loss: 0.21574500247836112, D_X_loss: 0.30226844996213914\n",
      "[3:800] loss_idt_y: 0.16740702763199805, F_fool_loss: 0.02657023513689637, cycled_y_loss: 0.1888526798784733, D_Y_loss: 0.2964914876222611\n",
      "[3:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:900] Took 12.82s\n",
      "[3:900] loss_idt_x: 0.1946726056933403, G_fool_loss: 0.023160818507894875, cycled_x_loss: 0.2030357675999403, D_X_loss: 0.2967558519542217\n",
      "[3:900] loss_idt_y: 0.17142566733062267, F_fool_loss: 0.027110421946272254, cycled_y_loss: 0.18385873503983022, D_Y_loss: 0.293954491019249\n",
      "[3:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:1000] Took 12.82s\n",
      "[3:1000] loss_idt_x: 0.1845662572607398, G_fool_loss: 0.024348062463104725, cycled_x_loss: 0.1893146713450551, D_X_loss: 0.29928293734788897\n",
      "[3:1000] loss_idt_y: 0.16084436163306237, F_fool_loss: 0.026447565611451864, cycled_y_loss: 0.17848417282104492, D_Y_loss: 0.2973728524148464\n",
      "[3:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:1100] Took 12.82s\n",
      "[3:1100] loss_idt_x: 0.19000294607132673, G_fool_loss: 0.028484135484322905, cycled_x_loss: 0.19856291085481645, D_X_loss: 0.2936428725719452\n",
      "[3:1100] loss_idt_y: 0.1638058737665415, F_fool_loss: 0.029841803163290024, cycled_y_loss: 0.17670320034027098, D_Y_loss: 0.2928335326910019\n",
      "[3:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[3:END] Completed epoch in 156.87545490264893s\n",
      "[3:1199] ep_loss_idt_x: 0.203 ep_G_fool_loss: 0.027 ep_cycled_x_loss: 0.212 ep_D_X_loss: 0.297\n",
      "[3:1199] ep_loss_idt_y: 0.174 ep_F_fool_loss: 0.028 ep_cycled_y_loss: 0.189 ep_D_Y_loss: 0.298\n",
      "[3:END] Completed eval in 1.060166358947754s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[3:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[4:100] Took 13.33s\n",
      "[4:100] loss_idt_x: 0.21335584558546544, G_fool_loss: 0.02594736956059933, cycled_x_loss: 0.22330342445522547, D_X_loss: 0.3027490064501762\n",
      "[4:100] loss_idt_y: 0.17721466701477767, F_fool_loss: 0.025613641543313862, cycled_y_loss: 0.19444712817668916, D_Y_loss: 0.3045361076295376\n",
      "[4:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:200] Took 12.82s\n",
      "[4:200] loss_idt_x: 0.18597802337259053, G_fool_loss: 0.02437459602020681, cycled_x_loss: 0.20321827672421933, D_X_loss: 0.2996686333417892\n",
      "[4:200] loss_idt_y: 0.20123056001961231, F_fool_loss: 0.026202539755031465, cycled_y_loss: 0.20756880059838295, D_Y_loss: 0.3019845826923847\n",
      "[4:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:300] Took 12.83s\n",
      "[4:300] loss_idt_x: 0.23962596639990807, G_fool_loss: 0.024091259045526385, cycled_x_loss: 0.25103899620473386, D_X_loss: 0.2939445549249649\n",
      "[4:300] loss_idt_y: 0.20289561130106448, F_fool_loss: 0.029032884165644646, cycled_y_loss: 0.2237949938327074, D_Y_loss: 0.2981817048788071\n",
      "[4:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:400] Took 12.83s\n",
      "[4:400] loss_idt_x: 0.2029118115454912, G_fool_loss: 0.02673302064649761, cycled_x_loss: 0.20528941489756108, D_X_loss: 0.30426085367798805\n",
      "[4:400] loss_idt_y: 0.15560291774570942, F_fool_loss: 0.02454051507636905, cycled_y_loss: 0.1725886657088995, D_Y_loss: 0.29766183406114577\n",
      "[4:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:500] Took 12.83s\n",
      "[4:500] loss_idt_x: 0.20054554559290408, G_fool_loss: 0.02730039128102362, cycled_x_loss: 0.20973063185811042, D_X_loss: 0.2986668561398983\n",
      "[4:500] loss_idt_y: 0.1624469219520688, F_fool_loss: 0.02794992341659963, cycled_y_loss: 0.17974730215966703, D_Y_loss: 0.29389291316270827\n",
      "[4:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:600] Took 12.83s\n",
      "[4:600] loss_idt_x: 0.18620222300291062, G_fool_loss: 0.02093327509239316, cycled_x_loss: 0.19541148476302625, D_X_loss: 0.2999364145100117\n",
      "[4:600] loss_idt_y: 0.15398742765188217, F_fool_loss: 0.02625595751218498, cycled_y_loss: 0.1708240332454443, D_Y_loss: 0.2883808262646198\n",
      "[4:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:700] Took 12.83s\n",
      "[4:700] loss_idt_x: 0.20703715972602368, G_fool_loss: 0.025558436745777725, cycled_x_loss: 0.2105884964764118, D_X_loss: 0.2996611969172955\n",
      "[4:700] loss_idt_y: 0.15976059168577195, F_fool_loss: 0.02761758870445192, cycled_y_loss: 0.1779815486818552, D_Y_loss: 0.29475049421191213\n",
      "[4:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:800] Took 12.84s\n",
      "[4:800] loss_idt_x: 0.2033291670680046, G_fool_loss: 0.022022599866613746, cycled_x_loss: 0.21349443085491657, D_X_loss: 0.29893080160021784\n",
      "[4:800] loss_idt_y: 0.1583307695761323, F_fool_loss: 0.02561382467858493, cycled_y_loss: 0.17745110262185335, D_Y_loss: 0.2936651910841465\n",
      "[4:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:900] Took 12.85s\n",
      "[4:900] loss_idt_x: 0.19009682081639767, G_fool_loss: 0.021150076519697903, cycled_x_loss: 0.20420644998550416, D_X_loss: 0.2925078299641609\n",
      "[4:900] loss_idt_y: 0.16745917320251466, F_fool_loss: 0.023506531305611134, cycled_y_loss: 0.17437365144491196, D_Y_loss: 0.29682774633169173\n",
      "[4:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:1000] Took 12.83s\n",
      "[4:1000] loss_idt_x: 0.18530738830566407, G_fool_loss: 0.02654825325123966, cycled_x_loss: 0.1931736497581005, D_X_loss: 0.29669893860816954\n",
      "[4:1000] loss_idt_y: 0.14617657650262117, F_fool_loss: 0.021520696273073556, cycled_y_loss: 0.15544707089662552, D_Y_loss: 0.2935913898050785\n",
      "[4:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:1100] Took 12.83s\n",
      "[4:1100] loss_idt_x: 0.20441190659999847, G_fool_loss: 0.025218563210219144, cycled_x_loss: 0.210557614043355, D_X_loss: 0.29392450109124185\n",
      "[4:1100] loss_idt_y: 0.16513601701706648, F_fool_loss: 0.02198271807283163, cycled_y_loss: 0.18428592771291732, D_Y_loss: 0.29721947968006135\n",
      "[4:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[4:END] Completed epoch in 155.6586902141571s\n",
      "[4:1199] ep_loss_idt_x: 0.201 ep_G_fool_loss: 0.024 ep_cycled_x_loss: 0.210 ep_D_X_loss: 0.298\n",
      "[4:1199] ep_loss_idt_y: 0.166 ep_F_fool_loss: 0.025 ep_cycled_y_loss: 0.181 ep_D_Y_loss: 0.296\n",
      "[4:END] Completed eval in 1.2037835121154785s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[4:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[5:100] Took 14.80s\n",
      "[5:100] loss_idt_x: 0.19396788753569127, G_fool_loss: 0.022397939832881093, cycled_x_loss: 0.2067127652838826, D_X_loss: 0.3009417352080345\n",
      "[5:100] loss_idt_y: 0.1559009836986661, F_fool_loss: 0.02450881328433752, cycled_y_loss: 0.16262298807501793, D_Y_loss: 0.2949656763672829\n",
      "[5:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:200] Took 12.87s\n",
      "[5:200] loss_idt_x: 0.18858748070895673, G_fool_loss: 0.02709924114868045, cycled_x_loss: 0.2031540296971798, D_X_loss: 0.3019357322156429\n",
      "[5:200] loss_idt_y: 0.1520628361403942, F_fool_loss: 0.02678377980366349, cycled_y_loss: 0.16400540560483934, D_Y_loss: 0.28958659023046496\n",
      "[5:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:300] Took 12.86s\n",
      "[5:300] loss_idt_x: 0.1819874044507742, G_fool_loss: 0.021879956405609847, cycled_x_loss: 0.18786945022642612, D_X_loss: 0.29810203224420545\n",
      "[5:300] loss_idt_y: 0.14631365045905112, F_fool_loss: 0.021828869692981243, cycled_y_loss: 0.15702126309275627, D_Y_loss: 0.293607567101717\n",
      "[5:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:400] Took 12.86s\n",
      "[5:400] loss_idt_x: 0.18843301769346, G_fool_loss: 0.02211526925675571, cycled_x_loss: 0.19780968502163887, D_X_loss: 0.29399893775582314\n",
      "[5:400] loss_idt_y: 0.15259248055517674, F_fool_loss: 0.020678042015060783, cycled_y_loss: 0.16323685251176356, D_Y_loss: 0.2942276118695736\n",
      "[5:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:500] Took 12.86s\n",
      "[5:500] loss_idt_x: 0.19012808062136174, G_fool_loss: 0.022022806098684667, cycled_x_loss: 0.19715219885110855, D_X_loss: 0.29817982748150823\n",
      "[5:500] loss_idt_y: 0.15584050714969636, F_fool_loss: 0.024333073217421772, cycled_y_loss: 0.1660792801529169, D_Y_loss: 0.2938487334549427\n",
      "[5:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:600] Took 12.89s\n",
      "[5:600] loss_idt_x: 0.18896247133612631, G_fool_loss: 0.02130543703213334, cycled_x_loss: 0.19408347144722937, D_X_loss: 0.2984734757244587\n",
      "[5:600] loss_idt_y: 0.13471446596086026, F_fool_loss: 0.022170468950644135, cycled_y_loss: 0.14119613576680423, D_Y_loss: 0.2934658306837082\n",
      "[5:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:700] Took 12.86s\n",
      "[5:700] loss_idt_x: 0.19833105944097043, G_fool_loss: 0.022143177650868894, cycled_x_loss: 0.20318036280572416, D_X_loss: 0.2971673871576786\n",
      "[5:700] loss_idt_y: 0.14624760773032905, F_fool_loss: 0.02379880767315626, cycled_y_loss: 0.1610718060284853, D_Y_loss: 0.2922407801449299\n",
      "[5:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:800] Took 12.87s\n",
      "[5:800] loss_idt_x: 0.17629077658057213, G_fool_loss: 0.021395318070426585, cycled_x_loss: 0.19138510569930076, D_X_loss: 0.29498345717787744\n",
      "[5:800] loss_idt_y: 0.14524213515222073, F_fool_loss: 0.02312864372506738, cycled_y_loss: 0.1563655424490571, D_Y_loss: 0.2905297328531742\n",
      "[5:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:900] Took 12.86s\n",
      "[5:900] loss_idt_x: 0.20624350387603044, G_fool_loss: 0.02261311313137412, cycled_x_loss: 0.2159442303329706, D_X_loss: 0.2930782261490822\n",
      "[5:900] loss_idt_y: 0.15600410528481007, F_fool_loss: 0.019753361819311976, cycled_y_loss: 0.17110567227005957, D_Y_loss: 0.2949045856297016\n",
      "[5:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:1000] Took 12.86s\n",
      "[5:1000] loss_idt_x: 0.17861275516450406, G_fool_loss: 0.020146216303110122, cycled_x_loss: 0.1761330222338438, D_X_loss: 0.297096973657608\n",
      "[5:1000] loss_idt_y: 0.154766311571002, F_fool_loss: 0.02454289752058685, cycled_y_loss: 0.16878284599632024, D_Y_loss: 0.29337089136242867\n",
      "[5:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:1100] Took 12.85s\n",
      "[5:1100] loss_idt_x: 0.20709270767867566, G_fool_loss: 0.022862860849127174, cycled_x_loss: 0.21370223991572856, D_X_loss: 0.29684541329741476\n",
      "[5:1100] loss_idt_y: 0.15761933173984288, F_fool_loss: 0.023026959458366036, cycled_y_loss: 0.16573008030653, D_Y_loss: 0.2932735653221607\n",
      "[5:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[5:END] Completed epoch in 157.7530915737152s\n",
      "[5:1199] ep_loss_idt_x: 0.191 ep_G_fool_loss: 0.022 ep_cycled_x_loss: 0.199 ep_D_X_loss: 0.297\n",
      "[5:1199] ep_loss_idt_y: 0.149 ep_F_fool_loss: 0.023 ep_cycled_y_loss: 0.160 ep_D_Y_loss: 0.293\n",
      "[5:END] Completed eval in 1.2346725463867188s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[5:END] Saving models and training information permanently\n",
      "[6:100] Took 14.83s\n",
      "[6:100] loss_idt_x: 0.20228518292307854, G_fool_loss: 0.020941938031464814, cycled_x_loss: 0.20633828528225423, D_X_loss: 0.29674823984503745\n",
      "[6:100] loss_idt_y: 0.14800253316760062, F_fool_loss: 0.02148282396607101, cycled_y_loss: 0.15803587514907122, D_Y_loss: 0.299237545132637\n",
      "[6:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:200] Took 12.86s\n",
      "[6:200] loss_idt_x: 0.16642343968153, G_fool_loss: 0.021464811069890857, cycled_x_loss: 0.1802330359071493, D_X_loss: 0.2918676267564297\n",
      "[6:200] loss_idt_y: 0.14715055298060178, F_fool_loss: 0.021058117067441345, cycled_y_loss: 0.1657148727402091, D_Y_loss: 0.2955083446204662\n",
      "[6:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:300] Took 12.89s\n",
      "[6:300] loss_idt_x: 0.1713805903494358, G_fool_loss: 0.0208331766910851, cycled_x_loss: 0.18679167293012142, D_X_loss: 0.2933413353562355\n",
      "[6:300] loss_idt_y: 0.14920356441289187, F_fool_loss: 0.020616799388080836, cycled_y_loss: 0.15192636519670485, D_Y_loss: 0.29341286212205886\n",
      "[6:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:400] Took 12.86s\n",
      "[6:400] loss_idt_x: 0.17352034557610752, G_fool_loss: 0.02076552960090339, cycled_x_loss: 0.1766188084706664, D_X_loss: 0.29243372067809104\n",
      "[6:400] loss_idt_y: 0.1427969039231539, F_fool_loss: 0.019646372301504015, cycled_y_loss: 0.15205118991434574, D_Y_loss: 0.29509336143732073\n",
      "[6:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:500] Took 12.87s\n",
      "[6:500] loss_idt_x: 0.191557180583477, G_fool_loss: 0.022520756237208842, cycled_x_loss: 0.1970886243134737, D_X_loss: 0.2999591179192066\n",
      "[6:500] loss_idt_y: 0.12927645936608315, F_fool_loss: 0.021832126388326288, cycled_y_loss: 0.14000795289874077, D_Y_loss: 0.29166569516062735\n",
      "[6:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:600] Took 12.86s\n",
      "[6:600] loss_idt_x: 0.19923013813793658, G_fool_loss: 0.020261274399235845, cycled_x_loss: 0.20184601821005344, D_X_loss: 0.30036527261137963\n",
      "[6:600] loss_idt_y: 0.12697865564376115, F_fool_loss: 0.02223715016618371, cycled_y_loss: 0.13246406592428683, D_Y_loss: 0.2969730067253113\n",
      "[6:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:700] Took 12.86s\n",
      "[6:700] loss_idt_x: 0.19112359926104547, G_fool_loss: 0.019329769825562833, cycled_x_loss: 0.19691332474350928, D_X_loss: 0.2985672868788242\n",
      "[6:700] loss_idt_y: 0.14799184940755367, F_fool_loss: 0.01971442433074117, cycled_y_loss: 0.16320094801485538, D_Y_loss: 0.29101742565631866\n",
      "[6:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:800] Took 12.87s\n",
      "[6:800] loss_idt_x: 0.19326425708830355, G_fool_loss: 0.01995698716491461, cycled_x_loss: 0.2051654078811407, D_X_loss: 0.3015806242823601\n",
      "[6:800] loss_idt_y: 0.1401604040712118, F_fool_loss: 0.019617644557729363, cycled_y_loss: 0.14930804423987865, D_Y_loss: 0.2949592337012291\n",
      "[6:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:900] Took 12.87s\n",
      "[6:900] loss_idt_x: 0.18135261740535497, G_fool_loss: 0.021613010661676525, cycled_x_loss: 0.18996071293950081, D_X_loss: 0.2976352342963219\n",
      "[6:900] loss_idt_y: 0.14443715535104273, F_fool_loss: 0.02226245164871216, cycled_y_loss: 0.1493938758969307, D_Y_loss: 0.2976722037792206\n",
      "[6:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:1000] Took 12.87s\n",
      "[6:1000] loss_idt_x: 0.17250944517552852, G_fool_loss: 0.020752765247598292, cycled_x_loss: 0.18073174327611924, D_X_loss: 0.29760907471179965\n",
      "[6:1000] loss_idt_y: 0.1270425023511052, F_fool_loss: 0.021089339032769203, cycled_y_loss: 0.13432180855423212, D_Y_loss: 0.29304010719060897\n",
      "[6:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:1100] Took 12.86s\n",
      "[6:1100] loss_idt_x: 0.17295406579971315, G_fool_loss: 0.01843223301693797, cycled_x_loss: 0.17958490274846553, D_X_loss: 0.2986785104870796\n",
      "[6:1100] loss_idt_y: 0.13332268998026847, F_fool_loss: 0.020582482442259787, cycled_y_loss: 0.14487467989325523, D_Y_loss: 0.2934405633807182\n",
      "[6:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[6:END] Completed epoch in 158.00932812690735s\n",
      "[6:1199] ep_loss_idt_x: 0.183 ep_G_fool_loss: 0.021 ep_cycled_x_loss: 0.191 ep_D_X_loss: 0.297\n",
      "[6:1199] ep_loss_idt_y: 0.140 ep_F_fool_loss: 0.021 ep_cycled_y_loss: 0.150 ep_D_Y_loss: 0.294\n",
      "[6:END] Completed eval in 1.1389553546905518s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[6:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[7:100] Took 14.79s\n",
      "[7:100] loss_idt_x: 0.18136651784181596, G_fool_loss: 0.01867112850770354, cycled_x_loss: 0.18723526418209077, D_X_loss: 0.29949611946940424\n",
      "[7:100] loss_idt_y: 0.16097507011145354, F_fool_loss: 0.020073747066780924, cycled_y_loss: 0.17572571255266667, D_Y_loss: 0.2943689922988415\n",
      "[7:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:200] Took 12.86s\n",
      "[7:200] loss_idt_x: 0.17330221697688103, G_fool_loss: 0.019200258618220688, cycled_x_loss: 0.18249950155615807, D_X_loss: 0.2942777094244957\n",
      "[7:200] loss_idt_y: 0.1675652302801609, F_fool_loss: 0.018892873907461763, cycled_y_loss: 0.17725004971027375, D_Y_loss: 0.2927522297203541\n",
      "[7:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:300] Took 12.88s\n",
      "[7:300] loss_idt_x: 0.1905645788088441, G_fool_loss: 0.017663527289405467, cycled_x_loss: 0.19421858303248882, D_X_loss: 0.298140739351511\n",
      "[7:300] loss_idt_y: 0.12834799762815238, F_fool_loss: 0.01867198989726603, cycled_y_loss: 0.14044829573482276, D_Y_loss: 0.2924279624223709\n",
      "[7:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:400] Took 12.86s\n",
      "[7:400] loss_idt_x: 0.17729813288897275, G_fool_loss: 0.018226549606770278, cycled_x_loss: 0.19030071258544923, D_X_loss: 0.2964789758622646\n",
      "[7:400] loss_idt_y: 0.1318998409435153, F_fool_loss: 0.019782443614676595, cycled_y_loss: 0.1408917235955596, D_Y_loss: 0.2943376438319683\n",
      "[7:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:500] Took 12.86s\n",
      "[7:500] loss_idt_x: 0.18060433082282543, G_fool_loss: 0.01780924913473427, cycled_x_loss: 0.18851180586963892, D_X_loss: 0.29729954317212104\n",
      "[7:500] loss_idt_y: 0.14020214285701513, F_fool_loss: 0.020592758860439063, cycled_y_loss: 0.1478968144953251, D_Y_loss: 0.29392124235630035\n",
      "[7:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:600] Took 12.87s\n",
      "[7:600] loss_idt_x: 0.18909902688115834, G_fool_loss: 0.02002087077125907, cycled_x_loss: 0.1944893576949835, D_X_loss: 0.2967740699648857\n",
      "[7:600] loss_idt_y: 0.13602639000862837, F_fool_loss: 0.021236635642126203, cycled_y_loss: 0.14016207296401262, D_Y_loss: 0.29304295033216476\n",
      "[7:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:700] Took 12.86s\n",
      "[7:700] loss_idt_x: 0.17748596251010895, G_fool_loss: 0.01745416283607483, cycled_x_loss: 0.18240220546722413, D_X_loss: 0.8005806985497474\n",
      "[7:700] loss_idt_y: 0.1498227573186159, F_fool_loss: 0.5742350802849978, cycled_y_loss: 0.16139322087168695, D_Y_loss: 0.29482892334461214\n",
      "[7:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:800] Took 12.86s\n",
      "[7:800] loss_idt_x: 0.18429651249200105, G_fool_loss: 0.018467106809839606, cycled_x_loss: 0.19000113543123007, D_X_loss: 0.2974107161164284\n",
      "[7:800] loss_idt_y: 0.13533319268375635, F_fool_loss: 0.01643878808245063, cycled_y_loss: 0.149156830906868, D_Y_loss: 0.2935733956098556\n",
      "[7:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:900] Took 12.88s\n",
      "[7:900] loss_idt_x: 0.17096436090767383, G_fool_loss: 0.01782221077941358, cycled_x_loss: 0.17557203192263843, D_X_loss: 0.2970801594853401\n",
      "[7:900] loss_idt_y: 0.14208019644021988, F_fool_loss: 0.015796356815844775, cycled_y_loss: 0.15073179487138988, D_Y_loss: 0.2933774894475937\n",
      "[7:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:1000] Took 12.87s\n",
      "[7:1000] loss_idt_x: 0.1770131816715002, G_fool_loss: 0.017344557121396063, cycled_x_loss: 0.18130758870393038, D_X_loss: 0.29432874828577044\n",
      "[7:1000] loss_idt_y: 0.11620200544595718, F_fool_loss: 0.01563059269450605, cycled_y_loss: 0.12449901912361383, D_Y_loss: 0.2922305566072464\n",
      "[7:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:1100] Took 12.87s\n",
      "[7:1100] loss_idt_x: 0.15815357372164726, G_fool_loss: 0.018147718757390977, cycled_x_loss: 0.1654526896774769, D_X_loss: 0.292793382704258\n",
      "[7:1100] loss_idt_y: 0.13324271734803916, F_fool_loss: 0.015534292450174689, cycled_y_loss: 0.13651424534618856, D_Y_loss: 0.2947755652666092\n",
      "[7:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[7:END] Completed epoch in 157.92685437202454s\n",
      "[7:1199] ep_loss_idt_x: 0.178 ep_G_fool_loss: 0.018 ep_cycled_x_loss: 0.184 ep_D_X_loss: 0.338\n",
      "[7:1199] ep_loss_idt_y: 0.139 ep_F_fool_loss: 0.064 ep_cycled_y_loss: 0.149 ep_D_Y_loss: 0.294\n",
      "[7:END] Completed eval in 1.2237296104431152s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[7:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[8:100] Took 14.78s\n",
      "[8:100] loss_idt_x: 0.16216644152998924, G_fool_loss: 0.018563120802864434, cycled_x_loss: 0.17097253635525703, D_X_loss: 0.2982833626866341\n",
      "[8:100] loss_idt_y: 0.131876367777586, F_fool_loss: 0.01809288359247148, cycled_y_loss: 0.13855343606323003, D_Y_loss: 0.2989600533246994\n",
      "[8:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:200] Took 12.86s\n",
      "[8:200] loss_idt_x: 0.16768501862883567, G_fool_loss: 0.017610115502029657, cycled_x_loss: 0.17220688913017512, D_X_loss: 0.29311990141868594\n",
      "[8:200] loss_idt_y: 0.13093744829297066, F_fool_loss: 0.019672937616705896, cycled_y_loss: 0.1382663107290864, D_Y_loss: 0.2930312220752239\n",
      "[8:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:300] Took 12.87s\n",
      "[8:300] loss_idt_x: 0.18549334891140462, G_fool_loss: 0.01877348524518311, cycled_x_loss: 0.20545345105230808, D_X_loss: 0.2936850625276566\n",
      "[8:300] loss_idt_y: 0.1516652125865221, F_fool_loss: 0.015656610783189535, cycled_y_loss: 0.15514019023627043, D_Y_loss: 0.2983443224430084\n",
      "[8:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:400] Took 12.87s\n",
      "[8:400] loss_idt_x: 0.18011625550687313, G_fool_loss: 0.016519039403647184, cycled_x_loss: 0.1929095859080553, D_X_loss: 0.2939048478007317\n",
      "[8:400] loss_idt_y: 0.15490374755114317, F_fool_loss: 0.015628624623641372, cycled_y_loss: 0.1517506219446659, D_Y_loss: 0.2931783762574196\n",
      "[8:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:500] Took 12.86s\n",
      "[8:500] loss_idt_x: 0.16931815519928933, G_fool_loss: 0.01600890182889998, cycled_x_loss: 0.17131460279226304, D_X_loss: 0.2940656012296677\n",
      "[8:500] loss_idt_y: 0.13380680918693544, F_fool_loss: 0.015535800708457828, cycled_y_loss: 0.14119694881141187, D_Y_loss: 0.29502788558602333\n",
      "[8:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:600] Took 12.88s\n",
      "[8:600] loss_idt_x: 0.16764027286320926, G_fool_loss: 0.01610584042966366, cycled_x_loss: 0.17580869756639003, D_X_loss: 0.2927016323804855\n",
      "[8:600] loss_idt_y: 0.1534216793254018, F_fool_loss: 0.01621107635088265, cycled_y_loss: 0.1557715328782797, D_Y_loss: 0.2941910246014595\n",
      "[8:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:700] Took 12.87s\n",
      "[8:700] loss_idt_x: 0.17572305541485547, G_fool_loss: 0.016297398591414092, cycled_x_loss: 0.18467259421944618, D_X_loss: 0.2937745225429535\n",
      "[8:700] loss_idt_y: 0.14263494927436113, F_fool_loss: 0.01630698746070266, cycled_y_loss: 0.14985475197434425, D_Y_loss: 0.2946466775238514\n",
      "[8:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:800] Took 12.87s\n",
      "[8:800] loss_idt_x: 0.17338908415287732, G_fool_loss: 0.015550328334793449, cycled_x_loss: 0.1769052104651928, D_X_loss: 0.294236516058445\n",
      "[8:800] loss_idt_y: 0.13033394653350114, F_fool_loss: 0.01774427404627204, cycled_y_loss: 0.14060901738703252, D_Y_loss: 0.2933179716765881\n",
      "[8:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:900] Took 12.86s\n",
      "[8:900] loss_idt_x: 0.1770579994469881, G_fool_loss: 0.015746028972789646, cycled_x_loss: 0.18581167183816433, D_X_loss: 0.29446561723947523\n",
      "[8:900] loss_idt_y: 0.1490214116498828, F_fool_loss: 0.01609556471928954, cycled_y_loss: 0.15993458077311515, D_Y_loss: 0.2934860973060131\n",
      "[8:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:1000] Took 12.87s\n",
      "[8:1000] loss_idt_x: 0.17269809052348137, G_fool_loss: 0.015579778961837291, cycled_x_loss: 0.18252495914697647, D_X_loss: 0.2952000612020493\n",
      "[8:1000] loss_idt_y: 0.1343441690132022, F_fool_loss: 0.01624467324465513, cycled_y_loss: 0.14296435415744782, D_Y_loss: 0.29273748308420183\n",
      "[8:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:1100] Took 12.87s\n",
      "[8:1100] loss_idt_x: 0.16080826662480832, G_fool_loss: 0.015641765287145972, cycled_x_loss: 0.17649621628224849, D_X_loss: 0.2935053464770317\n",
      "[8:1100] loss_idt_y: 0.13052271824330092, F_fool_loss: 0.01659042856656015, cycled_y_loss: 0.1395360103622079, D_Y_loss: 0.29508923217654226\n",
      "[8:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[8:END] Completed epoch in 157.55674815177917s\n",
      "[8:1199] ep_loss_idt_x: 0.171 ep_G_fool_loss: 0.017 ep_cycled_x_loss: 0.180 ep_D_X_loss: 0.294\n",
      "[8:1199] ep_loss_idt_y: 0.139 ep_F_fool_loss: 0.017 ep_cycled_y_loss: 0.145 ep_D_Y_loss: 0.294\n",
      "[8:END] Completed eval in 1.2346718311309814s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[8:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[9:100] Took 14.78s\n",
      "[9:100] loss_idt_x: 0.1724221557751298, G_fool_loss: 0.016968258218839766, cycled_x_loss: 0.17932109110057354, D_X_loss: 0.2986166420578957\n",
      "[9:100] loss_idt_y: 0.13308715894818307, F_fool_loss: 0.01705337891355157, cycled_y_loss: 0.14339307188987732, D_Y_loss: 0.29770067021250723\n",
      "[9:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:200] Took 12.87s\n",
      "[9:200] loss_idt_x: 0.1985173974186182, G_fool_loss: 0.016027707811444997, cycled_x_loss: 0.20010659351944923, D_X_loss: 0.2943224740028381\n",
      "[9:200] loss_idt_y: 0.12543804105371237, F_fool_loss: 0.016266402630135415, cycled_y_loss: 0.13298717830330134, D_Y_loss: 0.293154466599226\n",
      "[9:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:300] Took 12.88s\n",
      "[9:300] loss_idt_x: 0.15931877646595238, G_fool_loss: 0.0160972560942173, cycled_x_loss: 0.171491388194263, D_X_loss: 0.29352538973093034\n",
      "[9:300] loss_idt_y: 0.12749700985848902, F_fool_loss: 0.016192362112924456, cycled_y_loss: 0.1328326916322112, D_Y_loss: 0.2936703276634216\n",
      "[9:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:400] Took 12.86s\n",
      "[9:400] loss_idt_x: 0.1724018432945013, G_fool_loss: 0.015778192514553667, cycled_x_loss: 0.17302262753248215, D_X_loss: 0.2946381413936615\n",
      "[9:400] loss_idt_y: 0.11614089664071799, F_fool_loss: 0.01652553723193705, cycled_y_loss: 0.1254667465388775, D_Y_loss: 0.29317243307828905\n",
      "[9:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:500] Took 12.86s\n",
      "[9:500] loss_idt_x: 0.16730570912361145, G_fool_loss: 0.015594359086826444, cycled_x_loss: 0.177213760279119, D_X_loss: 0.295086427628994\n",
      "[9:500] loss_idt_y: 0.13668644316494466, F_fool_loss: 0.016056127082556486, cycled_y_loss: 0.1402809265255928, D_Y_loss: 0.29484164744615554\n",
      "[9:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:600] Took 12.85s\n",
      "[9:600] loss_idt_x: 0.16095314778387546, G_fool_loss: 0.016423500506207347, cycled_x_loss: 0.17134738601744176, D_X_loss: 0.2945699182152748\n",
      "[9:600] loss_idt_y: 0.1444311236217618, F_fool_loss: 0.01683126631192863, cycled_y_loss: 0.15501637186855077, D_Y_loss: 0.2947067466378212\n",
      "[9:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:700] Took 12.86s\n",
      "[9:700] loss_idt_x: 0.17542687248438596, G_fool_loss: 0.01547458242624998, cycled_x_loss: 0.17683029621839524, D_X_loss: 0.295245797932148\n",
      "[9:700] loss_idt_y: 0.14279330477118493, F_fool_loss: 0.017724087368696927, cycled_y_loss: 0.1503870703279972, D_Y_loss: 0.29367014050483703\n",
      "[9:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:800] Took 12.86s\n",
      "[9:800] loss_idt_x: 0.18101185519248247, G_fool_loss: 0.016418587984517216, cycled_x_loss: 0.19007966920733452, D_X_loss: 0.2927913627028465\n",
      "[9:800] loss_idt_y: 0.13700951989740134, F_fool_loss: 0.01564368617720902, cycled_y_loss: 0.140264132283628, D_Y_loss: 0.29631187677383425\n",
      "[9:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:900] Took 12.86s\n",
      "[9:900] loss_idt_x: 0.1582525422424078, G_fool_loss: 0.015594461290165782, cycled_x_loss: 0.162238598652184, D_X_loss: 0.2928441172838211\n",
      "[9:900] loss_idt_y: 0.12393844991922379, F_fool_loss: 0.015566378543153405, cycled_y_loss: 0.1272825925052166, D_Y_loss: 0.2928226059675217\n",
      "[9:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:1000] Took 12.86s\n",
      "[9:1000] loss_idt_x: 0.17190176770091056, G_fool_loss: 0.016183125609531997, cycled_x_loss: 0.17806620955467223, D_X_loss: 0.2948413509130478\n",
      "[9:1000] loss_idt_y: 0.13297288931906223, F_fool_loss: 0.01629459952004254, cycled_y_loss: 0.13506630040705203, D_Y_loss: 0.29549201458692553\n",
      "[9:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:1100] Took 12.85s\n",
      "[9:1100] loss_idt_x: 0.1610719221457839, G_fool_loss: 0.016118558505550027, cycled_x_loss: 0.1674891319870949, D_X_loss: 0.29400220572948454\n",
      "[9:1100] loss_idt_y: 0.12935014948248863, F_fool_loss: 0.015942008653655648, cycled_y_loss: 0.13333848595619202, D_Y_loss: 0.2942622722685337\n",
      "[9:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[9:END] Completed epoch in 157.77396440505981s\n",
      "[9:1199] ep_loss_idt_x: 0.170 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.176 ep_D_X_loss: 0.294\n",
      "[9:1199] ep_loss_idt_y: 0.130 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.137 ep_D_Y_loss: 0.294\n",
      "[9:END] Completed eval in 1.152918815612793s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[9:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[10:100] Took 14.73s\n",
      "[10:100] loss_idt_x: 0.16568683385848998, G_fool_loss: 0.01613771573640406, cycled_x_loss: 0.17116807922720909, D_X_loss: 0.29575550198554995\n",
      "[10:100] loss_idt_y: 0.11513764765113592, F_fool_loss: 0.016278693582862616, cycled_y_loss: 0.12158578384667634, D_Y_loss: 0.2968150381743908\n",
      "[10:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:200] Took 12.83s\n",
      "[10:200] loss_idt_x: 0.16266821146011354, G_fool_loss: 0.016523731900379063, cycled_x_loss: 0.16747279260307552, D_X_loss: 0.29450159281492233\n",
      "[10:200] loss_idt_y: 0.13430437754839658, F_fool_loss: 0.01570521173067391, cycled_y_loss: 0.14166927009820937, D_Y_loss: 0.2940169233083725\n",
      "[10:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:300] Took 12.83s\n",
      "[10:300] loss_idt_x: 0.17366011455655098, G_fool_loss: 0.01622513046488166, cycled_x_loss: 0.17949743367731572, D_X_loss: 0.2963218155503273\n",
      "[10:300] loss_idt_y: 0.1580797054618597, F_fool_loss: 0.0167961198836565, cycled_y_loss: 0.15967929553240537, D_Y_loss: 0.29418795645236967\n",
      "[10:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:400] Took 12.83s\n",
      "[10:400] loss_idt_x: 0.1651699171215296, G_fool_loss: 0.01619198172353208, cycled_x_loss: 0.16969954550266267, D_X_loss: 0.2946705362200737\n",
      "[10:400] loss_idt_y: 0.12738355088979006, F_fool_loss: 0.016362423235550524, cycled_y_loss: 0.13549061473459006, D_Y_loss: 0.2937189549207687\n",
      "[10:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:500] Took 12.83s\n",
      "[10:500] loss_idt_x: 0.17474175419658422, G_fool_loss: 0.01646339373663068, cycled_x_loss: 0.17923176042735578, D_X_loss: 0.29555893689393997\n",
      "[10:500] loss_idt_y: 0.13610699862241746, F_fool_loss: 0.016471379566937686, cycled_y_loss: 0.14218110080808402, D_Y_loss: 0.2960162997245789\n",
      "[10:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:600] Took 12.82s\n",
      "[10:600] loss_idt_x: 0.19090991791337728, G_fool_loss: 0.016174659617245197, cycled_x_loss: 0.1945779759436846, D_X_loss: 0.29411417841911314\n",
      "[10:600] loss_idt_y: 0.13402351252734662, F_fool_loss: 0.016434415485709907, cycled_y_loss: 0.1429546757787466, D_Y_loss: 0.29334214195609093\n",
      "[10:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:700] Took 12.82s\n",
      "[10:700] loss_idt_x: 0.16516015477478505, G_fool_loss: 0.015853636115789414, cycled_x_loss: 0.17339915074408055, D_X_loss: 0.2937335008382797\n",
      "[10:700] loss_idt_y: 0.1287635125592351, F_fool_loss: 0.015843680808320642, cycled_y_loss: 0.13004107877612114, D_Y_loss: 0.2935904850065708\n",
      "[10:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:800] Took 12.82s\n",
      "[10:800] loss_idt_x: 0.1771338412538171, G_fool_loss: 0.016771178701892497, cycled_x_loss: 0.1809036774933338, D_X_loss: 0.2963260208070278\n",
      "[10:800] loss_idt_y: 0.13274914495646953, F_fool_loss: 0.01681557547301054, cycled_y_loss: 0.13337333120405673, D_Y_loss: 0.29490903139114377\n",
      "[10:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:900] Took 12.85s\n",
      "[10:900] loss_idt_x: 0.15980149365961552, G_fool_loss: 0.0164171526953578, cycled_x_loss: 0.16496045239269733, D_X_loss: 0.2942052412033081\n",
      "[10:900] loss_idt_y: 0.12634484052658082, F_fool_loss: 0.016355496514588595, cycled_y_loss: 0.13118445690721273, D_Y_loss: 0.2941650807857513\n",
      "[10:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:1000] Took 12.83s\n",
      "[10:1000] loss_idt_x: 0.1639780106395483, G_fool_loss: 0.015542805064469575, cycled_x_loss: 0.16964174047112465, D_X_loss: 0.29466314911842345\n",
      "[10:1000] loss_idt_y: 0.12637211065739393, F_fool_loss: 0.016046035988256335, cycled_y_loss: 0.13233024131506682, D_Y_loss: 0.29460844695568084\n",
      "[10:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:1100] Took 12.82s\n",
      "[10:1100] loss_idt_x: 0.16241366662085055, G_fool_loss: 0.01664812442846596, cycled_x_loss: 0.1652500319480896, D_X_loss: 0.29315240457654\n",
      "[10:1100] loss_idt_y: 0.12672792702913285, F_fool_loss: 0.016393588576465844, cycled_y_loss: 0.13283966351300477, D_Y_loss: 0.2963879033923149\n",
      "[10:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[10:END] Completed epoch in 157.2072958946228s\n",
      "[10:1199] ep_loss_idt_x: 0.168 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.173 ep_D_X_loss: 0.295\n",
      "[10:1199] ep_loss_idt_y: 0.131 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.137 ep_D_Y_loss: 0.294\n",
      "[10:END] Completed eval in 1.2705862522125244s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[10:END] Saving models and training information permanently\n",
      "[11:100] Took 14.74s\n",
      "[11:100] loss_idt_x: 0.1647035501897335, G_fool_loss: 0.016169905867427586, cycled_x_loss: 0.16757135480642318, D_X_loss: 0.2974917748570442\n",
      "[11:100] loss_idt_y: 0.13187027301639317, F_fool_loss: 0.016535543259233235, cycled_y_loss: 0.13726583782583476, D_Y_loss: 0.29674210876226426\n",
      "[11:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:200] Took 12.83s\n",
      "[11:200] loss_idt_x: 0.17216304548084735, G_fool_loss: 0.015989579763263463, cycled_x_loss: 0.1899290704727173, D_X_loss: 0.29509074091911314\n",
      "[11:200] loss_idt_y: 0.14236443508416413, F_fool_loss: 0.016079534962773322, cycled_y_loss: 0.14579766497015953, D_Y_loss: 0.2952990199625492\n",
      "[11:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:300] Took 12.83s\n",
      "[11:300] loss_idt_x: 0.1745267593488097, G_fool_loss: 0.0170419040042907, cycled_x_loss: 0.188176084831357, D_X_loss: 0.2928656497597694\n",
      "[11:300] loss_idt_y: 0.13634048625826836, F_fool_loss: 0.01595579427666962, cycled_y_loss: 0.1387493025511503, D_Y_loss: 0.2947635106742382\n",
      "[11:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:400] Took 12.84s\n",
      "[11:400] loss_idt_x: 0.16347540587186812, G_fool_loss: 0.01624884274788201, cycled_x_loss: 0.16923340059816838, D_X_loss: 0.2948212718963623\n",
      "[11:400] loss_idt_y: 0.12051619302481413, F_fool_loss: 0.015998828643932938, cycled_y_loss: 0.12595645923167467, D_Y_loss: 0.29449443742632864\n",
      "[11:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:500] Took 12.82s\n",
      "[11:500] loss_idt_x: 0.1779396003484726, G_fool_loss: 0.0157060220092535, cycled_x_loss: 0.1892976900562644, D_X_loss: 0.29464118093252184\n",
      "[11:500] loss_idt_y: 0.13533169776201248, F_fool_loss: 0.016625088546425103, cycled_y_loss: 0.1360150247067213, D_Y_loss: 0.29425189197063445\n",
      "[11:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:600] Took 12.85s\n",
      "[11:600] loss_idt_x: 0.15715908128768205, G_fool_loss: 0.016509072817862035, cycled_x_loss: 0.16717590555548667, D_X_loss: 0.29496182665228843\n",
      "[11:600] loss_idt_y: 0.14194948114454747, F_fool_loss: 0.016392521355301143, cycled_y_loss: 0.13965034738183021, D_Y_loss: 0.2956509332358837\n",
      "[11:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:700] Took 12.83s\n",
      "[11:700] loss_idt_x: 0.1627904127910733, G_fool_loss: 0.016519172815605998, cycled_x_loss: 0.16970593824982644, D_X_loss: 0.29465649887919426\n",
      "[11:700] loss_idt_y: 0.13176473222672938, F_fool_loss: 0.0163011637609452, cycled_y_loss: 0.13569125723093747, D_Y_loss: 0.2949364337325096\n",
      "[11:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:800] Took 12.83s\n",
      "[11:800] loss_idt_x: 0.16520979810506106, G_fool_loss: 0.015925169298425315, cycled_x_loss: 0.17013145960867404, D_X_loss: 0.2938099882006645\n",
      "[11:800] loss_idt_y: 0.11870778739452362, F_fool_loss: 0.015869672307744623, cycled_y_loss: 0.12670042101293802, D_Y_loss: 0.2948844204843044\n",
      "[11:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:900] Took 12.85s\n",
      "[11:900] loss_idt_x: 0.15458706226199864, G_fool_loss: 0.016283719837665557, cycled_x_loss: 0.15622824095189572, D_X_loss: 0.29295592397451403\n",
      "[11:900] loss_idt_y: 0.12275388557463884, F_fool_loss: 0.015938150426372887, cycled_y_loss: 0.13571354459971188, D_Y_loss: 0.29418004885315896\n",
      "[11:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:1000] Took 12.83s\n",
      "[11:1000] loss_idt_x: 0.16973650619387626, G_fool_loss: 0.01691754290834069, cycled_x_loss: 0.17158905416727066, D_X_loss: 0.2949139814078808\n",
      "[11:1000] loss_idt_y: 0.11041748262941838, F_fool_loss: 0.01605060744099319, cycled_y_loss: 0.12084632139652968, D_Y_loss: 0.2948969456553459\n",
      "[11:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:1100] Took 12.83s\n",
      "[11:1100] loss_idt_x: 0.16601993005722762, G_fool_loss: 0.01606939347460866, cycled_x_loss: 0.17579579971730708, D_X_loss: 0.294477216899395\n",
      "[11:1100] loss_idt_y: 0.12953440353274345, F_fool_loss: 0.016322772577404977, cycled_y_loss: 0.13324007708579302, D_Y_loss: 0.2939025636017323\n",
      "[11:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[11:END] Completed epoch in 157.1922161579132s\n",
      "[11:1199] ep_loss_idt_x: 0.166 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.174 ep_D_X_loss: 0.294\n",
      "[11:1199] ep_loss_idt_y: 0.128 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.133 ep_D_Y_loss: 0.295\n",
      "[11:END] Completed eval in 1.1499264240264893s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[11:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[12:100] Took 14.78s\n",
      "[12:100] loss_idt_x: 0.16351692881435156, G_fool_loss: 0.016266913805156945, cycled_x_loss: 0.1647718470543623, D_X_loss: 0.29772908851504326\n",
      "[12:100] loss_idt_y: 0.11891375072300434, F_fool_loss: 0.016509866015985607, cycled_y_loss: 0.12131394661962985, D_Y_loss: 0.2974654397368431\n",
      "[12:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:200] Took 12.86s\n",
      "[12:200] loss_idt_x: 0.15636923976242542, G_fool_loss: 0.016661053327843546, cycled_x_loss: 0.16447921201586724, D_X_loss: 0.2940158227086067\n",
      "[12:200] loss_idt_y: 0.12989292457699775, F_fool_loss: 0.01639818346127868, cycled_y_loss: 0.1380294481664896, D_Y_loss: 0.2942065581679344\n",
      "[12:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:300] Took 12.89s\n",
      "[12:300] loss_idt_x: 0.15548692852258683, G_fool_loss: 0.016188538810238243, cycled_x_loss: 0.1571783770620823, D_X_loss: 0.2944889058172703\n",
      "[12:300] loss_idt_y: 0.12239389862865209, F_fool_loss: 0.01605773976072669, cycled_y_loss: 0.12572735477238894, D_Y_loss: 0.29545102655887606\n",
      "[12:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:400] Took 12.86s\n",
      "[12:400] loss_idt_x: 0.15956710726022721, G_fool_loss: 0.015793933337554335, cycled_x_loss: 0.16396541863679887, D_X_loss: 0.2939651323854923\n",
      "[12:400] loss_idt_y: 0.11034182988107205, F_fool_loss: 0.015597308594733477, cycled_y_loss: 0.11860702145844698, D_Y_loss: 0.2948206074535847\n",
      "[12:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:500] Took 12.86s\n",
      "[12:500] loss_idt_x: 0.14993199415504932, G_fool_loss: 0.016401330297812818, cycled_x_loss: 0.15052820555865765, D_X_loss: 0.2945937989652157\n",
      "[12:500] loss_idt_y: 0.11096950318664313, F_fool_loss: 0.01633043844252825, cycled_y_loss: 0.12088210679590702, D_Y_loss: 0.2946016220748425\n",
      "[12:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:600] Took 12.86s\n",
      "[12:600] loss_idt_x: 0.1700099927559495, G_fool_loss: 0.016142985010519625, cycled_x_loss: 0.16879092924296857, D_X_loss: 0.2940275180339813\n",
      "[12:600] loss_idt_y: 0.11166702710092068, F_fool_loss: 0.016357220970094205, cycled_y_loss: 0.11728879936039448, D_Y_loss: 0.2957226730883121\n",
      "[12:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:700] Took 12.86s\n",
      "[12:700] loss_idt_x: 0.16051117159426212, G_fool_loss: 0.016827535154297947, cycled_x_loss: 0.1675456726178527, D_X_loss: 0.2937725028395653\n",
      "[12:700] loss_idt_y: 0.12392596550285816, F_fool_loss: 0.016136585874482988, cycled_y_loss: 0.12910693492740394, D_Y_loss: 0.295534769743681\n",
      "[12:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:800] Took 12.87s\n",
      "[12:800] loss_idt_x: 0.17590766903012992, G_fool_loss: 0.015800848230719568, cycled_x_loss: 0.1749113253504038, D_X_loss: 0.29388488486409187\n",
      "[12:800] loss_idt_y: 0.12730727337300776, F_fool_loss: 0.01630958599038422, cycled_y_loss: 0.1286319949105382, D_Y_loss: 0.2941554853320122\n",
      "[12:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:900] Took 12.86s\n",
      "[12:900] loss_idt_x: 0.18051885414868593, G_fool_loss: 0.016179319843649863, cycled_x_loss: 0.18314625080674887, D_X_loss: 0.29409386664628984\n",
      "[12:900] loss_idt_y: 0.12016121365129948, F_fool_loss: 0.016148059535771607, cycled_y_loss: 0.1283068111166358, D_Y_loss: 0.2947846844792366\n",
      "[12:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:1000] Took 12.86s\n",
      "[12:1000] loss_idt_x: 0.17372349251061678, G_fool_loss: 0.01644860900938511, cycled_x_loss: 0.1664712881296873, D_X_loss: 0.29394898787140844\n",
      "[12:1000] loss_idt_y: 0.1291145321726799, F_fool_loss: 0.015886959414929153, cycled_y_loss: 0.13773187413811683, D_Y_loss: 0.29491638466715814\n",
      "[12:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:1100] Took 12.86s\n",
      "[12:1100] loss_idt_x: 0.15637346152216197, G_fool_loss: 0.016161038354039193, cycled_x_loss: 0.16765957057476044, D_X_loss: 0.2954149663448334\n",
      "[12:1100] loss_idt_y: 0.12432195220142603, F_fool_loss: 0.01629322612658143, cycled_y_loss: 0.1285752834752202, D_Y_loss: 0.2929213519394398\n",
      "[12:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[12:END] Completed epoch in 157.64183855056763s\n",
      "[12:1199] ep_loss_idt_x: 0.164 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.166 ep_D_X_loss: 0.294\n",
      "[12:1199] ep_loss_idt_y: 0.119 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.126 ep_D_Y_loss: 0.295\n",
      "[12:END] Completed eval in 1.1589019298553467s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[12:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[13:100] Took 14.76s\n",
      "[13:100] loss_idt_x: 0.1620520553737879, G_fool_loss: 0.015839771470054984, cycled_x_loss: 0.16571818083524703, D_X_loss: 0.29668873593211176\n",
      "[13:100] loss_idt_y: 0.12600478917360305, F_fool_loss: 0.01606567201204598, cycled_y_loss: 0.13193851601332426, D_Y_loss: 0.29652496352791785\n",
      "[13:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:200] Took 12.86s\n",
      "[13:200] loss_idt_x: 0.16480546973645688, G_fool_loss: 0.016523011811077595, cycled_x_loss: 0.1700685251504183, D_X_loss: 0.2931588323414326\n",
      "[13:200] loss_idt_y: 0.119974624812603, F_fool_loss: 0.016114664999768137, cycled_y_loss: 0.12139533720910549, D_Y_loss: 0.2959424141049385\n",
      "[13:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:300] Took 12.87s\n",
      "[13:300] loss_idt_x: 0.16022581115365028, G_fool_loss: 0.01650702014565468, cycled_x_loss: 0.1644650984555483, D_X_loss: 0.2943097072839737\n",
      "[13:300] loss_idt_y: 0.1292633006721735, F_fool_loss: 0.016057994309812786, cycled_y_loss: 0.13793103635311127, D_Y_loss: 0.2933207887411118\n",
      "[13:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:400] Took 12.86s\n",
      "[13:400] loss_idt_x: 0.17783162642270325, G_fool_loss: 0.016498418860137462, cycled_x_loss: 0.18078373987227678, D_X_loss: 0.2934541228413582\n",
      "[13:400] loss_idt_y: 0.11574107799679041, F_fool_loss: 0.015984156308695673, cycled_y_loss: 0.12492901399731636, D_Y_loss: 0.29479044780135155\n",
      "[13:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:500] Took 12.87s\n",
      "[13:500] loss_idt_x: 0.15676956452429294, G_fool_loss: 0.015956905242055654, cycled_x_loss: 0.1621003445982933, D_X_loss: 0.29257384344935417\n",
      "[13:500] loss_idt_y: 0.12218682758510113, F_fool_loss: 0.01628580410964787, cycled_y_loss: 0.12464144188910722, D_Y_loss: 0.29279801607131956\n",
      "[13:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:600] Took 12.86s\n",
      "[13:600] loss_idt_x: 0.1745250802114606, G_fool_loss: 0.016248761396855115, cycled_x_loss: 0.17639559116214515, D_X_loss: 0.2942317332327366\n",
      "[13:600] loss_idt_y: 0.11275607727468014, F_fool_loss: 0.016189274303615095, cycled_y_loss: 0.11827842183411122, D_Y_loss: 0.2949586023390293\n",
      "[13:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:700] Took 12.86s\n",
      "[13:700] loss_idt_x: 0.15903885111212732, G_fool_loss: 0.01620292918756604, cycled_x_loss: 0.16352345943450927, D_X_loss: 0.29483129575848577\n",
      "[13:700] loss_idt_y: 0.13108102574944497, F_fool_loss: 0.01572547633200884, cycled_y_loss: 0.13261360373347997, D_Y_loss: 0.293564567565918\n",
      "[13:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:800] Took 12.86s\n",
      "[13:800] loss_idt_x: 0.15436856791377068, G_fool_loss: 0.016433412190526724, cycled_x_loss: 0.1580372827500105, D_X_loss: 0.29463684767484666\n",
      "[13:800] loss_idt_y: 0.11644920267164707, F_fool_loss: 0.016297053443267942, cycled_y_loss: 0.12281667780131102, D_Y_loss: 0.2938258308172226\n",
      "[13:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:900] Took 12.87s\n",
      "[13:900] loss_idt_x: 0.15711280334740876, G_fool_loss: 0.01589240361005068, cycled_x_loss: 0.1583882138133049, D_X_loss: 0.294345083385706\n",
      "[13:900] loss_idt_y: 0.11547918632626533, F_fool_loss: 0.015907151596620678, cycled_y_loss: 0.12102010272443295, D_Y_loss: 0.29574006170034406\n",
      "[13:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:1000] Took 12.88s\n",
      "[13:1000] loss_idt_x: 0.15953448109328747, G_fool_loss: 0.015983051219955087, cycled_x_loss: 0.1645481039211154, D_X_loss: 0.29449362263083456\n",
      "[13:1000] loss_idt_y: 0.11792627315968275, F_fool_loss: 0.016119006965309383, cycled_y_loss: 0.12376803688704968, D_Y_loss: 0.29401019304990766\n",
      "[13:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:1100] Took 12.86s\n",
      "[13:1100] loss_idt_x: 0.14039757154881954, G_fool_loss: 0.015833212248981, cycled_x_loss: 0.14259773515164853, D_X_loss: 0.29384546369314196\n",
      "[13:1100] loss_idt_y: 0.11944705456495285, F_fool_loss: 0.015966766513884068, cycled_y_loss: 0.13394895907491444, D_Y_loss: 0.2936473800241947\n",
      "[13:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[13:END] Completed epoch in 157.78675746917725s\n",
      "[13:1199] ep_loss_idt_x: 0.160 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.164 ep_D_X_loss: 0.294\n",
      "[13:1199] ep_loss_idt_y: 0.121 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.127 ep_D_Y_loss: 0.294\n",
      "[13:END] Completed eval in 1.1908175945281982s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[13:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[14:100] Took 14.83s\n",
      "[14:100] loss_idt_x: 0.16377100732177496, G_fool_loss: 0.01631526683457196, cycled_x_loss: 0.16616933319717644, D_X_loss: 0.2974268874526024\n",
      "[14:100] loss_idt_y: 0.12391815107315779, F_fool_loss: 0.016450741421431304, cycled_y_loss: 0.13193383879959583, D_Y_loss: 0.29758847326040266\n",
      "[14:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:200] Took 12.83s\n",
      "[14:200] loss_idt_x: 0.1679142152145505, G_fool_loss: 0.016409394331276417, cycled_x_loss: 0.17038106508553028, D_X_loss: 0.2935768961906433\n",
      "[14:200] loss_idt_y: 0.11863450609147548, F_fool_loss: 0.015773293105885388, cycled_y_loss: 0.1167431016266346, D_Y_loss: 0.2952073234319687\n",
      "[14:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:300] Took 12.83s\n",
      "[14:300] loss_idt_x: 0.1605644752457738, G_fool_loss: 0.0159921214915812, cycled_x_loss: 0.16426958825439214, D_X_loss: 0.2932779452204704\n",
      "[14:300] loss_idt_y: 0.12965266328305006, F_fool_loss: 0.016409634770825507, cycled_y_loss: 0.1396055145934224, D_Y_loss: 0.2950702886283398\n",
      "[14:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:400] Took 12.82s\n",
      "[14:400] loss_idt_x: 0.15317080546170472, G_fool_loss: 0.01609139178879559, cycled_x_loss: 0.15272737234830858, D_X_loss: 0.29601382970809936\n",
      "[14:400] loss_idt_y: 0.1048733014985919, F_fool_loss: 0.01675984709523618, cycled_y_loss: 0.11856322694569826, D_Y_loss: 0.2946937792003155\n",
      "[14:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:500] Took 12.83s\n",
      "[14:500] loss_idt_x: 0.16671211894601584, G_fool_loss: 0.015823599640280007, cycled_x_loss: 0.17066832430660725, D_X_loss: 0.29455269008874896\n",
      "[14:500] loss_idt_y: 0.11401014637202024, F_fool_loss: 0.01629869488067925, cycled_y_loss: 0.11579429671168327, D_Y_loss: 0.2944924411177635\n",
      "[14:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:600] Took 12.83s\n",
      "[14:600] loss_idt_x: 0.16901000030338764, G_fool_loss: 0.01632523871958256, cycled_x_loss: 0.1695479940995574, D_X_loss: 0.29367982372641566\n",
      "[14:600] loss_idt_y: 0.1137125937640667, F_fool_loss: 0.01594475917518139, cycled_y_loss: 0.12163312256336212, D_Y_loss: 0.2964259162545204\n",
      "[14:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:700] Took 12.84s\n",
      "[14:700] loss_idt_x: 0.15963919196277856, G_fool_loss: 0.015890809642150998, cycled_x_loss: 0.15780654724687337, D_X_loss: 0.29557019114494326\n",
      "[14:700] loss_idt_y: 0.12281521487981081, F_fool_loss: 0.016452083773911, cycled_y_loss: 0.12949806123971938, D_Y_loss: 0.29342459335923193\n",
      "[14:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:800] Took 12.82s\n",
      "[14:800] loss_idt_x: 0.1614061864092946, G_fool_loss: 0.015907622082158922, cycled_x_loss: 0.15806082028895616, D_X_loss: 0.2951401376724243\n",
      "[14:800] loss_idt_y: 0.10606779295951128, F_fool_loss: 0.016622809767723082, cycled_y_loss: 0.1116297361627221, D_Y_loss: 0.29449640199542043\n",
      "[14:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:900] Took 12.83s\n",
      "[14:900] loss_idt_x: 0.17051152754575014, G_fool_loss: 0.016589824119582774, cycled_x_loss: 0.17303692042827606, D_X_loss: 0.29459408462047576\n",
      "[14:900] loss_idt_y: 0.11449589047580958, F_fool_loss: 0.01646614361554384, cycled_y_loss: 0.11953297611325979, D_Y_loss: 0.29386153593659403\n",
      "[14:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:1000] Took 12.83s\n",
      "[14:1000] loss_idt_x: 0.16341278057545425, G_fool_loss: 0.01569654131308198, cycled_x_loss: 0.1587817580997944, D_X_loss: 0.2949692042171955\n",
      "[14:1000] loss_idt_y: 0.10865108963102102, F_fool_loss: 0.015895395865663887, cycled_y_loss: 0.11604910615831614, D_Y_loss: 0.2924347357451916\n",
      "[14:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:1100] Took 12.82s\n",
      "[14:1100] loss_idt_x: 0.17089076455682517, G_fool_loss: 0.015785445235669614, cycled_x_loss: 0.1717825148254633, D_X_loss: 0.29377828001976014\n",
      "[14:1100] loss_idt_y: 0.11037031177431345, F_fool_loss: 0.015549169881269335, cycled_y_loss: 0.11586639925837516, D_Y_loss: 0.29407568261027334\n",
      "[14:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[14:END] Completed epoch in 157.27606916427612s\n",
      "[14:1199] ep_loss_idt_x: 0.163 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.164 ep_D_X_loss: 0.295\n",
      "[14:1199] ep_loss_idt_y: 0.116 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.122 ep_D_Y_loss: 0.295\n",
      "[14:END] Completed eval in 1.2147533893585205s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[14:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[15:100] Took 14.72s\n",
      "[15:100] loss_idt_x: 0.1675239623710513, G_fool_loss: 0.016083023082464933, cycled_x_loss: 0.16562692195177078, D_X_loss: 0.29677428722381594\n",
      "[15:100] loss_idt_y: 0.11879626754671335, F_fool_loss: 0.016124887224286795, cycled_y_loss: 0.12484617311507464, D_Y_loss: 0.2962562583386898\n",
      "[15:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:200] Took 12.82s\n",
      "[15:200] loss_idt_x: 0.16222882226109506, G_fool_loss: 0.01593092135153711, cycled_x_loss: 0.1622035302221775, D_X_loss: 0.2948398697376251\n",
      "[15:200] loss_idt_y: 0.1211984657496214, F_fool_loss: 0.016011110739782453, cycled_y_loss: 0.12275183185935021, D_Y_loss: 0.2940539820492268\n",
      "[15:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:300] Took 12.83s\n",
      "[15:300] loss_idt_x: 0.15814404383301736, G_fool_loss: 0.016416301717981696, cycled_x_loss: 0.16274684004485607, D_X_loss: 0.2943464933335781\n",
      "[15:300] loss_idt_y: 0.12083666250109673, F_fool_loss: 0.0161857074405998, cycled_y_loss: 0.12700233463197946, D_Y_loss: 0.29498837381601334\n",
      "[15:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:400] Took 12.84s\n",
      "[15:400] loss_idt_x: 0.15954571623355152, G_fool_loss: 0.017240297673270108, cycled_x_loss: 0.1653700267523527, D_X_loss: 0.29525997772812845\n",
      "[15:400] loss_idt_y: 0.1110871421545744, F_fool_loss: 0.01600788696669042, cycled_y_loss: 0.11597060106694698, D_Y_loss: 0.2959856982529163\n",
      "[15:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:500] Took 12.82s\n",
      "[15:500] loss_idt_x: 0.15809310149401426, G_fool_loss: 0.016196227436885237, cycled_x_loss: 0.16087473690509796, D_X_loss: 0.29456215038895606\n",
      "[15:500] loss_idt_y: 0.1114373367652297, F_fool_loss: 0.016235836213454605, cycled_y_loss: 0.11900064315646887, D_Y_loss: 0.2935404945909977\n",
      "[15:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:600] Took 12.83s\n",
      "[15:600] loss_idt_x: 0.1611616314947605, G_fool_loss: 0.015937667237594724, cycled_x_loss: 0.1583030716329813, D_X_loss: 0.29535435408353805\n",
      "[15:600] loss_idt_y: 0.10782261654734611, F_fool_loss: 0.016381241837516426, cycled_y_loss: 0.11364752687513828, D_Y_loss: 0.295098382383585\n",
      "[15:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:700] Took 12.83s\n",
      "[15:700] loss_idt_x: 0.1627692375332117, G_fool_loss: 0.01621069652028382, cycled_x_loss: 0.15555464129894972, D_X_loss: 0.295681689530611\n",
      "[15:700] loss_idt_y: 0.10228314992040395, F_fool_loss: 0.016360504915937782, cycled_y_loss: 0.10594410829246044, D_Y_loss: 0.2948397035896778\n",
      "[15:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:800] Took 12.83s\n",
      "[15:800] loss_idt_x: 0.1696035785973072, G_fool_loss: 0.016072617508471013, cycled_x_loss: 0.17362455792725087, D_X_loss: 0.293392583578825\n",
      "[15:800] loss_idt_y: 0.10843888621777296, F_fool_loss: 0.016291184658184646, cycled_y_loss: 0.11724053125828504, D_Y_loss: 0.2954153497517109\n",
      "[15:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:900] Took 12.82s\n",
      "[15:900] loss_idt_x: 0.15217685386538504, G_fool_loss: 0.016224704105407, cycled_x_loss: 0.15087179113179444, D_X_loss: 0.2933193351328373\n",
      "[15:900] loss_idt_y: 0.11759308945387602, F_fool_loss: 0.01603603838942945, cycled_y_loss: 0.1199812975898385, D_Y_loss: 0.2930390982329845\n",
      "[15:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:1000] Took 12.82s\n",
      "[15:1000] loss_idt_x: 0.15685874335467814, G_fool_loss: 0.01644745297729969, cycled_x_loss: 0.16361444119364024, D_X_loss: 0.2942126029729843\n",
      "[15:1000] loss_idt_y: 0.12478915710002184, F_fool_loss: 0.016082437718287112, cycled_y_loss: 0.12761628415435552, D_Y_loss: 0.295420690625906\n",
      "[15:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:1100] Took 12.82s\n",
      "[15:1100] loss_idt_x: 0.1577451591193676, G_fool_loss: 0.016307859439402817, cycled_x_loss: 0.16295590609312058, D_X_loss: 0.29308198735117913\n",
      "[15:1100] loss_idt_y: 0.10856703974306584, F_fool_loss: 0.015881743775680662, cycled_y_loss: 0.11909759514033795, D_Y_loss: 0.2932014286518097\n",
      "[15:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[15:END] Completed epoch in 157.09631395339966s\n",
      "[15:1199] ep_loss_idt_x: 0.161 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.162 ep_D_X_loss: 0.294\n",
      "[15:1199] ep_loss_idt_y: 0.114 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.119 ep_D_Y_loss: 0.294\n",
      "[15:END] Completed eval in 1.2695815563201904s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[15:END] Saving models and training information permanently\n",
      "[16:100] Took 14.77s\n",
      "[16:100] loss_idt_x: 0.15966012921184303, G_fool_loss: 0.015828879661858083, cycled_x_loss: 0.15853681191802024, D_X_loss: 0.29792863860726354\n",
      "[16:100] loss_idt_y: 0.11519913222640753, F_fool_loss: 0.01644575039856136, cycled_y_loss: 0.12280269607901573, D_Y_loss: 0.2962077800929546\n",
      "[16:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:200] Took 12.82s\n",
      "[16:200] loss_idt_x: 0.15128172766417264, G_fool_loss: 0.01575556695461273, cycled_x_loss: 0.15771655954420566, D_X_loss: 0.2952502532303333\n",
      "[16:200] loss_idt_y: 0.11480695273727179, F_fool_loss: 0.01602202077396214, cycled_y_loss: 0.1213199471309781, D_Y_loss: 0.29472955033183096\n",
      "[16:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:300] Took 12.84s\n",
      "[16:300] loss_idt_x: 0.15738866206258537, G_fool_loss: 0.016490251971408725, cycled_x_loss: 0.15563422173261643, D_X_loss: 0.29373259767889975\n",
      "[16:300] loss_idt_y: 0.10654962241649628, F_fool_loss: 0.015945748100057243, cycled_y_loss: 0.1099296050146222, D_Y_loss: 0.29396596491336824\n",
      "[16:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:400] Took 12.83s\n",
      "[16:400] loss_idt_x: 0.15453947640955448, G_fool_loss: 0.01585232156328857, cycled_x_loss: 0.15818076767027378, D_X_loss: 0.2956870323419571\n",
      "[16:400] loss_idt_y: 0.11619344141334295, F_fool_loss: 0.01592265481129289, cycled_y_loss: 0.12440600749105216, D_Y_loss: 0.29469838097691536\n",
      "[16:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:500] Took 12.83s\n",
      "[16:500] loss_idt_x: 0.14533653076738118, G_fool_loss: 0.016050345590338112, cycled_x_loss: 0.14786020234227182, D_X_loss: 0.2945394468307495\n",
      "[16:500] loss_idt_y: 0.11102367796003819, F_fool_loss: 0.01661239636130631, cycled_y_loss: 0.11449491009116172, D_Y_loss: 0.29445581763982775\n",
      "[16:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:600] Took 12.82s\n",
      "[16:600] loss_idt_x: 0.15918315336108207, G_fool_loss: 0.01604937075637281, cycled_x_loss: 0.16809301737695934, D_X_loss: 0.29441511929035186\n",
      "[16:600] loss_idt_y: 0.10797832239419222, F_fool_loss: 0.01576351448893547, cycled_y_loss: 0.11855749316513538, D_Y_loss: 0.29580700427293777\n",
      "[16:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:700] Took 12.83s\n",
      "[16:700] loss_idt_x: 0.16530819594860077, G_fool_loss: 0.01606528096832335, cycled_x_loss: 0.16356650330126285, D_X_loss: 0.2938474126160145\n",
      "[16:700] loss_idt_y: 0.10344248976558447, F_fool_loss: 0.01625473437830806, cycled_y_loss: 0.11135446932166815, D_Y_loss: 0.29397513568401334\n",
      "[16:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:800] Took 12.83s\n",
      "[16:800] loss_idt_x: 0.16823564797639848, G_fool_loss: 0.01567827637307346, cycled_x_loss: 0.17488430321216583, D_X_loss: 0.2943264138698578\n",
      "[16:800] loss_idt_y: 0.12706586938351394, F_fool_loss: 0.016072665872052312, cycled_y_loss: 0.13204625565558673, D_Y_loss: 0.29408824265003203\n",
      "[16:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:900] Took 12.83s\n",
      "[16:900] loss_idt_x: 0.1519792276993394, G_fool_loss: 0.016226907884702088, cycled_x_loss: 0.15692541740834712, D_X_loss: 0.294794639647007\n",
      "[16:900] loss_idt_y: 0.11272437896579504, F_fool_loss: 0.01590972751379013, cycled_y_loss: 0.11987592920660972, D_Y_loss: 0.29607530415058136\n",
      "[16:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:1000] Took 12.86s\n",
      "[16:1000] loss_idt_x: 0.17338944129645825, G_fool_loss: 0.0158518454246223, cycled_x_loss: 0.1712315632775426, D_X_loss: 0.29369727879762647\n",
      "[16:1000] loss_idt_y: 0.10816739480942487, F_fool_loss: 0.0163735859002918, cycled_y_loss: 0.11203181710094214, D_Y_loss: 0.29421389326453207\n",
      "[16:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:1100] Took 12.83s\n",
      "[16:1100] loss_idt_x: 0.15520320352166891, G_fool_loss: 0.016031044842675327, cycled_x_loss: 0.15593059055507183, D_X_loss: 0.2943011848628521\n",
      "[16:1100] loss_idt_y: 0.11350957650691271, F_fool_loss: 0.016112279184162616, cycled_y_loss: 0.121668784879148, D_Y_loss: 0.2954298897087574\n",
      "[16:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[16:END] Completed epoch in 157.1855571269989s\n",
      "[16:1199] ep_loss_idt_x: 0.157 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.160 ep_D_X_loss: 0.295\n",
      "[16:1199] ep_loss_idt_y: 0.113 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.119 ep_D_Y_loss: 0.295\n",
      "[16:END] Completed eval in 1.2107651233673096s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[16:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[17:100] Took 14.75s\n",
      "[17:100] loss_idt_x: 0.14717457998543979, G_fool_loss: 0.01641571134328842, cycled_x_loss: 0.15205366265028716, D_X_loss: 0.29752598389983176\n",
      "[17:100] loss_idt_y: 0.12116213068366051, F_fool_loss: 0.015796311208978297, cycled_y_loss: 0.12889503356069326, D_Y_loss: 0.2980293455719948\n",
      "[17:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:200] Took 12.82s\n",
      "[17:200] loss_idt_x: 0.1611072364076972, G_fool_loss: 0.01592943926341832, cycled_x_loss: 0.16467453841120006, D_X_loss: 0.29296800658106803\n",
      "[17:200] loss_idt_y: 0.10884744994342327, F_fool_loss: 0.016664492348209024, cycled_y_loss: 0.10887716691941023, D_Y_loss: 0.2943193529546261\n",
      "[17:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:300] Took 12.82s\n",
      "[17:300] loss_idt_x: 0.15227046027779578, G_fool_loss: 0.015901333866640926, cycled_x_loss: 0.15965558059513568, D_X_loss: 0.2948452091217041\n",
      "[17:300] loss_idt_y: 0.11413496904075146, F_fool_loss: 0.016302885403856635, cycled_y_loss: 0.11682408306747676, D_Y_loss: 0.29383466109633444\n",
      "[17:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:400] Took 12.86s\n",
      "[17:400] loss_idt_x: 0.15303786389529705, G_fool_loss: 0.01696358579210937, cycled_x_loss: 0.1511764807254076, D_X_loss: 0.2958210352063179\n",
      "[17:400] loss_idt_y: 0.11863999951630831, F_fool_loss: 0.016114479871466757, cycled_y_loss: 0.12068102799355984, D_Y_loss: 0.2958314782381058\n",
      "[17:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:500] Took 12.89s\n",
      "[17:500] loss_idt_x: 0.15813227221369744, G_fool_loss: 0.01612268484197557, cycled_x_loss: 0.1614712742716074, D_X_loss: 0.29410680040717124\n",
      "[17:500] loss_idt_y: 0.09846015557646752, F_fool_loss: 0.016150976615026593, cycled_y_loss: 0.10447256136685609, D_Y_loss: 0.2947223690152168\n",
      "[17:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:600] Took 12.87s\n",
      "[17:600] loss_idt_x: 0.1450249331817031, G_fool_loss: 0.015701073640957474, cycled_x_loss: 0.14554269917309284, D_X_loss: 0.29469922587275504\n",
      "[17:600] loss_idt_y: 0.11980730958282948, F_fool_loss: 0.015698782950639725, cycled_y_loss: 0.12545338369905948, D_Y_loss: 0.2940461780130863\n",
      "[17:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:700] Took 12.91s\n",
      "[17:700] loss_idt_x: 0.1517717008665204, G_fool_loss: 0.016193483900278808, cycled_x_loss: 0.1549582849815488, D_X_loss: 0.2943230412900448\n",
      "[17:700] loss_idt_y: 0.12060054890811443, F_fool_loss: 0.01655955967493355, cycled_y_loss: 0.129741401784122, D_Y_loss: 0.2940099912881851\n",
      "[17:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:800] Took 12.86s\n",
      "[17:800] loss_idt_x: 0.15259464494884015, G_fool_loss: 0.015724851936101913, cycled_x_loss: 0.15112551558762788, D_X_loss: 0.29532944738864897\n",
      "[17:800] loss_idt_y: 0.11178431741893291, F_fool_loss: 0.016172203412279488, cycled_y_loss: 0.12029738917946815, D_Y_loss: 0.29501097559928896\n",
      "[17:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:900] Took 12.86s\n",
      "[17:900] loss_idt_x: 0.16270505934953688, G_fool_loss: 0.015785662280395626, cycled_x_loss: 0.16445027705281973, D_X_loss: 0.294604751765728\n",
      "[17:900] loss_idt_y: 0.11445169903337955, F_fool_loss: 0.01619792077690363, cycled_y_loss: 0.1249740068987012, D_Y_loss: 0.294842404127121\n",
      "[17:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:1000] Took 12.86s\n",
      "[17:1000] loss_idt_x: 0.15674982972443105, G_fool_loss: 0.01638188465498388, cycled_x_loss: 0.15791293501853942, D_X_loss: 0.29464099898934365\n",
      "[17:1000] loss_idt_y: 0.12199804730713368, F_fool_loss: 0.015790893770754336, cycled_y_loss: 0.12483166303485632, D_Y_loss: 0.2954621610045433\n",
      "[17:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:1100] Took 12.86s\n",
      "[17:1100] loss_idt_x: 0.1715173116326332, G_fool_loss: 0.015760717205703257, cycled_x_loss: 0.16836726397275925, D_X_loss: 0.2942990119755268\n",
      "[17:1100] loss_idt_y: 0.11833609838038683, F_fool_loss: 0.0167195990588516, cycled_y_loss: 0.12611053299158811, D_Y_loss: 0.29282532662153243\n",
      "[17:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[17:END] Completed epoch in 158.10765838623047s\n",
      "[17:1199] ep_loss_idt_x: 0.157 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.158 ep_D_X_loss: 0.294\n",
      "[17:1199] ep_loss_idt_y: 0.114 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.119 ep_D_Y_loss: 0.295\n",
      "[17:END] Completed eval in 1.3653512001037598s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[17:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[18:100] Took 14.72s\n",
      "[18:100] loss_idt_x: 0.16221049100160598, G_fool_loss: 0.01627426199615002, cycled_x_loss: 0.16213730335235596, D_X_loss: 0.29589188426733015\n",
      "[18:100] loss_idt_y: 0.12608275040984154, F_fool_loss: 0.016082702297717334, cycled_y_loss: 0.12880935579538344, D_Y_loss: 0.2966391459107399\n",
      "[18:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:200] Took 12.83s\n",
      "[18:200] loss_idt_x: 0.14897752966731787, G_fool_loss: 0.01593735163100064, cycled_x_loss: 0.14651492945849895, D_X_loss: 0.29432410225272176\n",
      "[18:200] loss_idt_y: 0.11017259109765291, F_fool_loss: 0.016053982209414244, cycled_y_loss: 0.10899749469012023, D_Y_loss: 0.29461914658546445\n",
      "[18:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:300] Took 12.83s\n",
      "[18:300] loss_idt_x: 0.15385503821074964, G_fool_loss: 0.016079621752724052, cycled_x_loss: 0.15082693163305522, D_X_loss: 0.29528754130005835\n",
      "[18:300] loss_idt_y: 0.10466380655765534, F_fool_loss: 0.016334737101569772, cycled_y_loss: 0.10711064085364341, D_Y_loss: 0.2946844099462032\n",
      "[18:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:400] Took 12.85s\n",
      "[18:400] loss_idt_x: 0.16177610144019128, G_fool_loss: 0.016180685441941022, cycled_x_loss: 0.16747010968625545, D_X_loss: 0.2948056395351887\n",
      "[18:400] loss_idt_y: 0.09636999893933534, F_fool_loss: 0.01614483476616442, cycled_y_loss: 0.09900997746735811, D_Y_loss: 0.2938027745485306\n",
      "[18:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:500] Took 12.83s\n",
      "[18:500] loss_idt_x: 0.13504121843725442, G_fool_loss: 0.01620246415026486, cycled_x_loss: 0.13744125794619322, D_X_loss: 0.2945578846335411\n",
      "[18:500] loss_idt_y: 0.1076149209588766, F_fool_loss: 0.015909978719428182, cycled_y_loss: 0.1087105992808938, D_Y_loss: 0.29444243758916855\n",
      "[18:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:600] Took 12.83s\n",
      "[18:600] loss_idt_x: 0.15878098960965872, G_fool_loss: 0.01577450944110751, cycled_x_loss: 0.1631155613064766, D_X_loss: 0.29364542439579966\n",
      "[18:600] loss_idt_y: 0.1095579855889082, F_fool_loss: 0.016090439995750785, cycled_y_loss: 0.11078792788088322, D_Y_loss: 0.29367757856845855\n",
      "[18:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:700] Took 12.82s\n",
      "[18:700] loss_idt_x: 0.15145672474056482, G_fool_loss: 0.01602336026728153, cycled_x_loss: 0.15159476194530724, D_X_loss: 0.29392634898424147\n",
      "[18:700] loss_idt_y: 0.11231291949748994, F_fool_loss: 0.015915935393422842, cycled_y_loss: 0.11492479223757983, D_Y_loss: 0.29470022931694984\n",
      "[18:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:800] Took 12.83s\n",
      "[18:800] loss_idt_x: 0.15730814479291438, G_fool_loss: 0.016013348642736673, cycled_x_loss: 0.1584612936899066, D_X_loss: 0.29394433557987215\n",
      "[18:800] loss_idt_y: 0.10334867116063834, F_fool_loss: 0.01632260799407959, cycled_y_loss: 0.10357609666883945, D_Y_loss: 0.2933982150256634\n",
      "[18:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:900] Took 12.83s\n",
      "[18:900] loss_idt_x: 0.1638402236998081, G_fool_loss: 0.01585691349580884, cycled_x_loss: 0.1658825435116887, D_X_loss: 0.29474358648061755\n",
      "[18:900] loss_idt_y: 0.09195104032754899, F_fool_loss: 0.016158194141462447, cycled_y_loss: 0.098121020719409, D_Y_loss: 0.2928819684684277\n",
      "[18:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:1000] Took 12.83s\n",
      "[18:1000] loss_idt_x: 0.15307745352387428, G_fool_loss: 0.016448258832097055, cycled_x_loss: 0.1494686280936003, D_X_loss: 0.29412594199180603\n",
      "[18:1000] loss_idt_y: 0.11166121691465378, F_fool_loss: 0.015744754178449512, cycled_y_loss: 0.11779208093881607, D_Y_loss: 0.29339044719934465\n",
      "[18:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:1100] Took 12.83s\n",
      "[18:1100] loss_idt_x: 0.15496220588684081, G_fool_loss: 0.01592440076172352, cycled_x_loss: 0.15416775621473788, D_X_loss: 0.2947050577402115\n",
      "[18:1100] loss_idt_y: 0.10773827955126762, F_fool_loss: 0.015995118580758572, cycled_y_loss: 0.11264019150286914, D_Y_loss: 0.29408748492598535\n",
      "[18:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[18:END] Completed epoch in 157.29073452949524s\n",
      "[18:1199] ep_loss_idt_x: 0.155 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.155 ep_D_X_loss: 0.294\n",
      "[18:1199] ep_loss_idt_y: 0.107 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.110 ep_D_Y_loss: 0.294\n",
      "[18:END] Completed eval in 1.3843278884887695s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[18:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[19:100] Took 14.78s\n",
      "[19:100] loss_idt_x: 0.1548978404328227, G_fool_loss: 0.016029494097456336, cycled_x_loss: 0.1578634774312377, D_X_loss: 0.297902961820364\n",
      "[19:100] loss_idt_y: 0.11133342180401087, F_fool_loss: 0.016055212896317242, cycled_y_loss: 0.11766357786953449, D_Y_loss: 0.2973530162870884\n",
      "[19:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:200] Took 12.83s\n",
      "[19:200] loss_idt_x: 0.14639797259122134, G_fool_loss: 0.015844111992046238, cycled_x_loss: 0.14956993333995341, D_X_loss: 0.2951259492337704\n",
      "[19:200] loss_idt_y: 0.11194592420011759, F_fool_loss: 0.015541114099323749, cycled_y_loss: 0.11377832345664501, D_Y_loss: 0.2944325348734856\n",
      "[19:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:300] Took 12.83s\n",
      "[19:300] loss_idt_x: 0.14310327056795358, G_fool_loss: 0.016066999090835452, cycled_x_loss: 0.14117176219820976, D_X_loss: 0.2944214737415314\n",
      "[19:300] loss_idt_y: 0.10714287169277668, F_fool_loss: 0.016013981979340314, cycled_y_loss: 0.11676871828734875, D_Y_loss: 0.29465469256043436\n",
      "[19:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:400] Took 12.82s\n",
      "[19:400] loss_idt_x: 0.14485147826373576, G_fool_loss: 0.015675624730065466, cycled_x_loss: 0.14965007662773133, D_X_loss: 0.2947111654281616\n",
      "[19:400] loss_idt_y: 0.1077875441685319, F_fool_loss: 0.016080947937443853, cycled_y_loss: 0.1095305097848177, D_Y_loss: 0.2936648625135422\n",
      "[19:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:500] Took 12.83s\n",
      "[19:500] loss_idt_x: 0.15538389652967452, G_fool_loss: 0.016324426978826523, cycled_x_loss: 0.1592118752375245, D_X_loss: 0.29412388876080514\n",
      "[19:500] loss_idt_y: 0.1143984728679061, F_fool_loss: 0.015854015182703733, cycled_y_loss: 0.12421320680528879, D_Y_loss: 0.2942770843207836\n",
      "[19:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:600] Took 12.82s\n",
      "[19:600] loss_idt_x: 0.14577793832868338, G_fool_loss: 0.01575938024558127, cycled_x_loss: 0.1480766109749675, D_X_loss: 0.2944716492295265\n",
      "[19:600] loss_idt_y: 0.11999123513698579, F_fool_loss: 0.016158321127295493, cycled_y_loss: 0.11700892440974713, D_Y_loss: 0.29237715631723404\n",
      "[19:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:700] Took 12.82s\n",
      "[19:700] loss_idt_x: 0.1504626601934433, G_fool_loss: 0.016352112991735338, cycled_x_loss: 0.15195961777120828, D_X_loss: 0.2959628173708916\n",
      "[19:700] loss_idt_y: 0.10037146240472794, F_fool_loss: 0.015944840172305703, cycled_y_loss: 0.10634246814996004, D_Y_loss: 0.29374934166669847\n",
      "[19:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:800] Took 12.82s\n",
      "[19:800] loss_idt_x: 0.14445142611861228, G_fool_loss: 0.015720993066206574, cycled_x_loss: 0.1458593710139394, D_X_loss: 0.29409842267632486\n",
      "[19:800] loss_idt_y: 0.1084578749537468, F_fool_loss: 0.015753205670043825, cycled_y_loss: 0.10805679395794869, D_Y_loss: 0.29430933654308317\n",
      "[19:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:900] Took 12.83s\n",
      "[19:900] loss_idt_x: 0.15936891127377747, G_fool_loss: 0.01633058221079409, cycled_x_loss: 0.15946303956210614, D_X_loss: 0.29329016625881194\n",
      "[19:900] loss_idt_y: 0.12336069665849209, F_fool_loss: 0.0158655658736825, cycled_y_loss: 0.12942195642739535, D_Y_loss: 0.29410536110401153\n",
      "[19:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:1000] Took 12.85s\n",
      "[19:1000] loss_idt_x: 0.15576072596013546, G_fool_loss: 0.016363849872723223, cycled_x_loss: 0.15667839858680963, D_X_loss: 0.29378269717097283\n",
      "[19:1000] loss_idt_y: 0.10659620471298695, F_fool_loss: 0.01616813472472131, cycled_y_loss: 0.10836744997650385, D_Y_loss: 0.2947067016363144\n",
      "[19:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:1100] Took 12.82s\n",
      "[19:1100] loss_idt_x: 0.16258535981178285, G_fool_loss: 0.01575622770935297, cycled_x_loss: 0.1640918118879199, D_X_loss: 0.2951507821679115\n",
      "[19:1100] loss_idt_y: 0.1038372952863574, F_fool_loss: 0.015815791198983787, cycled_y_loss: 0.10570762954652309, D_Y_loss: 0.2939348416030407\n",
      "[19:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[19:END] Completed epoch in 158.06879997253418s\n",
      "[19:1199] ep_loss_idt_x: 0.151 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.153 ep_D_X_loss: 0.294\n",
      "[19:1199] ep_loss_idt_y: 0.111 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.115 ep_D_Y_loss: 0.294\n",
      "[19:END] Completed eval in 1.2287178039550781s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[19:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[20:100] Took 14.76s\n",
      "[20:100] loss_idt_x: 0.1439382614940405, G_fool_loss: 0.015810788394883275, cycled_x_loss: 0.14710971407592296, D_X_loss: 0.2967985373735428\n",
      "[20:100] loss_idt_y: 0.1173056537285447, F_fool_loss: 0.016377160185948016, cycled_y_loss: 0.12224060401320458, D_Y_loss: 0.2963801747560501\n",
      "[20:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:200] Took 12.81s\n",
      "[20:200] loss_idt_x: 0.15373869340866805, G_fool_loss: 0.015807663137093187, cycled_x_loss: 0.15437449231743813, D_X_loss: 0.2931678880751133\n",
      "[20:200] loss_idt_y: 0.10381980791687966, F_fool_loss: 0.0161031916923821, cycled_y_loss: 0.10888075165450573, D_Y_loss: 0.2936324696242809\n",
      "[20:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:300] Took 12.81s\n",
      "[20:300] loss_idt_x: 0.15847857646644115, G_fool_loss: 0.016364153791218996, cycled_x_loss: 0.15607574827969073, D_X_loss: 0.2942534673213959\n",
      "[20:300] loss_idt_y: 0.10510404009371996, F_fool_loss: 0.015733174830675125, cycled_y_loss: 0.10586089611053467, D_Y_loss: 0.2927420125901699\n",
      "[20:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:400] Took 12.82s\n",
      "[20:400] loss_idt_x: 0.14448613714426756, G_fool_loss: 0.015851688235998154, cycled_x_loss: 0.14628260850906372, D_X_loss: 0.29356773644685746\n",
      "[20:400] loss_idt_y: 0.09114227756857872, F_fool_loss: 0.015584461074322462, cycled_y_loss: 0.09333491414785385, D_Y_loss: 0.29413221836090087\n",
      "[20:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:500] Took 12.81s\n",
      "[20:500] loss_idt_x: 0.1598785538598895, G_fool_loss: 0.01591899556107819, cycled_x_loss: 0.1628623703867197, D_X_loss: 0.29438396453857424\n",
      "[20:500] loss_idt_y: 0.10363866686820984, F_fool_loss: 0.01616034023463726, cycled_y_loss: 0.10961364511400461, D_Y_loss: 0.29450991868972776\n",
      "[20:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:600] Took 12.84s\n",
      "[20:600] loss_idt_x: 0.14319466304033995, G_fool_loss: 0.01557719794102013, cycled_x_loss: 0.14328565694391726, D_X_loss: 0.29603947445750234\n",
      "[20:600] loss_idt_y: 0.10910154648125171, F_fool_loss: 0.017069499716162683, cycled_y_loss: 0.11025979794561863, D_Y_loss: 0.2939652617275715\n",
      "[20:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:700] Took 12.85s\n",
      "[20:700] loss_idt_x: 0.1446368729695678, G_fool_loss: 0.01644105897285044, cycled_x_loss: 0.14820003192871808, D_X_loss: 0.2943647962808609\n",
      "[20:700] loss_idt_y: 0.09549730755388737, F_fool_loss: 0.016260521234944463, cycled_y_loss: 0.09635179448872805, D_Y_loss: 0.29424861922860146\n",
      "[20:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:800] Took 12.83s\n",
      "[20:800] loss_idt_x: 0.14220865044742823, G_fool_loss: 0.01612082052975893, cycled_x_loss: 0.143153243586421, D_X_loss: 0.2927942006289959\n",
      "[20:800] loss_idt_y: 0.10526060469448567, F_fool_loss: 0.016155130825936795, cycled_y_loss: 0.10960490178316831, D_Y_loss: 0.2947767861187458\n",
      "[20:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:900] Took 12.82s\n",
      "[20:900] loss_idt_x: 0.1522926405444741, G_fool_loss: 0.016153630716726184, cycled_x_loss: 0.14878820657730102, D_X_loss: 0.29413739502429964\n",
      "[20:900] loss_idt_y: 0.11770256981253624, F_fool_loss: 0.016483383635059, cycled_y_loss: 0.12269244968891144, D_Y_loss: 0.2940452967584133\n",
      "[20:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:1000] Took 12.82s\n",
      "[20:1000] loss_idt_x: 0.1570231693983078, G_fool_loss: 0.016091170879080893, cycled_x_loss: 0.15872419349849223, D_X_loss: 0.29441673144698144\n",
      "[20:1000] loss_idt_y: 0.10482114542275667, F_fool_loss: 0.016002821978181602, cycled_y_loss: 0.11590472683310508, D_Y_loss: 0.2947749476134777\n",
      "[20:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:1100] Took 12.83s\n",
      "[20:1100] loss_idt_x: 0.1538647062331438, G_fool_loss: 0.015607661567628384, cycled_x_loss: 0.15355005864053964, D_X_loss: 0.2943156558275223\n",
      "[20:1100] loss_idt_y: 0.11581777669489383, F_fool_loss: 0.015980396587401628, cycled_y_loss: 0.1206408566609025, D_Y_loss: 0.2943014821410179\n",
      "[20:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[20:END] Completed epoch in 157.1105034351349s\n",
      "[20:1199] ep_loss_idt_x: 0.151 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.152 ep_D_X_loss: 0.294\n",
      "[20:1199] ep_loss_idt_y: 0.106 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.110 ep_D_Y_loss: 0.294\n",
      "[20:END] Completed eval in 1.2346992492675781s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[20:END] Saving models and training information permanently\n",
      "[21:100] Took 25.62s\n",
      "[21:100] loss_idt_x: 0.16123426467180252, G_fool_loss: 0.01615841081365943, cycled_x_loss: 0.1575710415840149, D_X_loss: 0.2976749174296856\n",
      "[21:100] loss_idt_y: 0.10348675981163978, F_fool_loss: 0.0162806661054492, cycled_y_loss: 0.10863756585866213, D_Y_loss: 0.2969126591086388\n",
      "[21:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:200] Took 12.76s\n",
      "[21:200] loss_idt_x: 0.15317192941904068, G_fool_loss: 0.0158850309997797, cycled_x_loss: 0.14978960935026409, D_X_loss: 0.29402854919433596\n",
      "[21:200] loss_idt_y: 0.10415292166173458, F_fool_loss: 0.015563025660812855, cycled_y_loss: 0.10797110091894865, D_Y_loss: 0.2940044450759888\n",
      "[21:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:300] Took 12.84s\n",
      "[21:300] loss_idt_x: 0.1531750963255763, G_fool_loss: 0.015397919937968255, cycled_x_loss: 0.15593212619423866, D_X_loss: 0.2940760025382042\n",
      "[21:300] loss_idt_y: 0.11237547934055328, F_fool_loss: 0.015926413470879197, cycled_y_loss: 0.11793079879134893, D_Y_loss: 0.29434307515621183\n",
      "[21:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:400] Took 12.87s\n",
      "[21:400] loss_idt_x: 0.16129963401705028, G_fool_loss: 0.01639077783562243, cycled_x_loss: 0.16003520801663398, D_X_loss: 0.29399952992796896\n",
      "[21:400] loss_idt_y: 0.10374875131994486, F_fool_loss: 0.01589665855281055, cycled_y_loss: 0.10970755580812692, D_Y_loss: 0.2955180263519287\n",
      "[21:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:500] Took 12.87s\n",
      "[21:500] loss_idt_x: 0.15330578986555338, G_fool_loss: 0.015223729806020856, cycled_x_loss: 0.15120246548205615, D_X_loss: 0.29318646669387816\n",
      "[21:500] loss_idt_y: 0.10399167496711016, F_fool_loss: 0.01587286385707557, cycled_y_loss: 0.10841230452060699, D_Y_loss: 0.29374240070581437\n",
      "[21:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:600] Took 12.86s\n",
      "[21:600] loss_idt_x: 0.16076253440231084, G_fool_loss: 0.01603774255141616, cycled_x_loss: 0.1594404561072588, D_X_loss: 0.293605502396822\n",
      "[21:600] loss_idt_y: 0.10878177873790264, F_fool_loss: 0.015686247097328306, cycled_y_loss: 0.11408560067415237, D_Y_loss: 0.29544402241706846\n",
      "[21:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:700] Took 12.87s\n",
      "[21:700] loss_idt_x: 0.1580317623540759, G_fool_loss: 0.0161765740532428, cycled_x_loss: 0.15748530000448227, D_X_loss: 0.2932589663565159\n",
      "[21:700] loss_idt_y: 0.09558463882654905, F_fool_loss: 0.016035793526098133, cycled_y_loss: 0.10137754540890455, D_Y_loss: 0.2941828601062298\n",
      "[21:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:800] Took 12.87s\n",
      "[21:800] loss_idt_x: 0.16100107595324517, G_fool_loss: 0.016420126836746932, cycled_x_loss: 0.1627763044834137, D_X_loss: 0.29344693303108216\n",
      "[21:800] loss_idt_y: 0.11369323935359717, F_fool_loss: 0.01587929146364331, cycled_y_loss: 0.11261590328067542, D_Y_loss: 0.2944344864785671\n",
      "[21:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:900] Took 12.86s\n",
      "[21:900] loss_idt_x: 0.144032152146101, G_fool_loss: 0.01577553855255246, cycled_x_loss: 0.14393035229295492, D_X_loss: 0.29630496591329575\n",
      "[21:900] loss_idt_y: 0.0975261340662837, F_fool_loss: 0.016553790299221872, cycled_y_loss: 0.10762985117733478, D_Y_loss: 0.29359926387667656\n",
      "[21:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:1000] Took 12.86s\n",
      "[21:1000] loss_idt_x: 0.15063018813729287, G_fool_loss: 0.01645573473535478, cycled_x_loss: 0.15097905337810516, D_X_loss: 0.2939110904932022\n",
      "[21:1000] loss_idt_y: 0.10826328758150339, F_fool_loss: 0.015959303313866257, cycled_y_loss: 0.11136872358620167, D_Y_loss: 0.293887327760458\n",
      "[21:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:1100] Took 12.86s\n",
      "[21:1100] loss_idt_x: 0.15455375414341688, G_fool_loss: 0.015836565122008324, cycled_x_loss: 0.15913477670401335, D_X_loss: 0.29436263859272005\n",
      "[21:1100] loss_idt_y: 0.10694390758872033, F_fool_loss: 0.016055703358724714, cycled_y_loss: 0.10312622733414173, D_Y_loss: 0.2955504168570042\n",
      "[21:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[21:END] Completed epoch in 169.7984004020691s\n",
      "[21:1199] ep_loss_idt_x: 0.155 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.155 ep_D_X_loss: 0.294\n",
      "[21:1199] ep_loss_idt_y: 0.105 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.110 ep_D_Y_loss: 0.294\n",
      "[21:END] Completed eval in 1.265594482421875s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[21:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[22:100] Took 14.85s\n",
      "[22:100] loss_idt_x: 0.1556632326170802, G_fool_loss: 0.016158918552100658, cycled_x_loss: 0.15508819676935673, D_X_loss: 0.29740803450345993\n",
      "[22:100] loss_idt_y: 0.09829150177538395, F_fool_loss: 0.01602791739627719, cycled_y_loss: 0.10446498360484839, D_Y_loss: 0.296872231811285\n",
      "[22:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:200] Took 12.88s\n",
      "[22:200] loss_idt_x: 0.15495217632502317, G_fool_loss: 0.01587505765259266, cycled_x_loss: 0.1546636339277029, D_X_loss: 0.29506520822644233\n",
      "[22:200] loss_idt_y: 0.10257646415382624, F_fool_loss: 0.01590234459377825, cycled_y_loss: 0.10558696281164885, D_Y_loss: 0.29287855118513106\n",
      "[22:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:300] Took 12.87s\n",
      "[22:300] loss_idt_x: 0.1445825080946088, G_fool_loss: 0.015848544221371413, cycled_x_loss: 0.14236248776316643, D_X_loss: 0.29430802270770073\n",
      "[22:300] loss_idt_y: 0.10424818526953458, F_fool_loss: 0.01600619458593428, cycled_y_loss: 0.10868522275239229, D_Y_loss: 0.2932369011640549\n",
      "[22:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:400] Took 12.87s\n",
      "[22:400] loss_idt_x: 0.1440650572627783, G_fool_loss: 0.01608500210568309, cycled_x_loss: 0.13903491463512183, D_X_loss: 0.2933085696399212\n",
      "[22:400] loss_idt_y: 0.09540147468447685, F_fool_loss: 0.015830895695835352, cycled_y_loss: 0.0959484738111496, D_Y_loss: 0.2934583975374699\n",
      "[22:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:500] Took 12.86s\n",
      "[22:500] loss_idt_x: 0.14770826954394578, G_fool_loss: 0.01602830226533115, cycled_x_loss: 0.14260789763182402, D_X_loss: 0.2929823116958141\n",
      "[22:500] loss_idt_y: 0.09668891351670027, F_fool_loss: 0.016252196645364165, cycled_y_loss: 0.09723754286766052, D_Y_loss: 0.29504891380667686\n",
      "[22:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:600] Took 12.87s\n",
      "[22:600] loss_idt_x: 0.1462703574821353, G_fool_loss: 0.01569622435607016, cycled_x_loss: 0.14997495859861373, D_X_loss: 0.29528863474726674\n",
      "[22:600] loss_idt_y: 0.11613612048327923, F_fool_loss: 0.016355676278471946, cycled_y_loss: 0.11901618920266628, D_Y_loss: 0.29268154680728914\n",
      "[22:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:700] Took 12.85s\n",
      "[22:700] loss_idt_x: 0.14880411349236966, G_fool_loss: 0.01629692449234426, cycled_x_loss: 0.14670818574726582, D_X_loss: 0.29419600442051885\n",
      "[22:700] loss_idt_y: 0.10468145199120045, F_fool_loss: 0.015561230778694153, cycled_y_loss: 0.10416018560528756, D_Y_loss: 0.2944106093049049\n",
      "[22:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:800] Took 12.86s\n",
      "[22:800] loss_idt_x: 0.15317172229290008, G_fool_loss: 0.015880149565637113, cycled_x_loss: 0.15326976608484982, D_X_loss: 0.2958741240203381\n",
      "[22:800] loss_idt_y: 0.10025607917457818, F_fool_loss: 0.0165433347877115, cycled_y_loss: 0.11014390464872122, D_Y_loss: 0.29370061188936236\n",
      "[22:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:900] Took 12.89s\n",
      "[22:900] loss_idt_x: 0.15560122292488812, G_fool_loss: 0.016191949732601643, cycled_x_loss: 0.15487401347607374, D_X_loss: 0.29532586097717284\n",
      "[22:900] loss_idt_y: 0.10426992811262607, F_fool_loss: 0.015775268068537115, cycled_y_loss: 0.1103151509538293, D_Y_loss: 0.2947298902273178\n",
      "[22:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:1000] Took 12.87s\n",
      "[22:1000] loss_idt_x: 0.15017569489777088, G_fool_loss: 0.015706165879964828, cycled_x_loss: 0.14468124508857727, D_X_loss: 0.2939485405385494\n",
      "[22:1000] loss_idt_y: 0.1111873134970665, F_fool_loss: 0.015772639699280264, cycled_y_loss: 0.12291662700474262, D_Y_loss: 0.29463726431131365\n",
      "[22:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:1100] Took 12.87s\n",
      "[22:1100] loss_idt_x: 0.1527015046030283, G_fool_loss: 0.015844254828989504, cycled_x_loss: 0.1525957591086626, D_X_loss: 0.2939044912159443\n",
      "[22:1100] loss_idt_y: 0.11009392399340868, F_fool_loss: 0.015817582523450256, cycled_y_loss: 0.12200367376208306, D_Y_loss: 0.29574967503547667\n",
      "[22:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[22:END] Completed epoch in 157.92764139175415s\n",
      "[22:1199] ep_loss_idt_x: 0.150 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.149 ep_D_X_loss: 0.294\n",
      "[22:1199] ep_loss_idt_y: 0.104 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.109 ep_D_Y_loss: 0.294\n",
      "[22:END] Completed eval in 1.2601056098937988s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[22:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[23:100] Took 14.77s\n",
      "[23:100] loss_idt_x: 0.14067085593938827, G_fool_loss: 0.01606919340789318, cycled_x_loss: 0.1405032517388463, D_X_loss: 0.2974847772717476\n",
      "[23:100] loss_idt_y: 0.11396901305764913, F_fool_loss: 0.016146364100277425, cycled_y_loss: 0.11937034767121077, D_Y_loss: 0.29609093979001044\n",
      "[23:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:200] Took 12.87s\n",
      "[23:200] loss_idt_x: 0.16748234178870916, G_fool_loss: 0.01563726500608027, cycled_x_loss: 0.16864606201648713, D_X_loss: 0.2942405851185322\n",
      "[23:200] loss_idt_y: 0.10835892923176288, F_fool_loss: 0.016080013103783132, cycled_y_loss: 0.1130862620845437, D_Y_loss: 0.29492667138576506\n",
      "[23:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:300] Took 12.86s\n",
      "[23:300] loss_idt_x: 0.14853886812925338, G_fool_loss: 0.01633717612363398, cycled_x_loss: 0.15220692984759807, D_X_loss: 0.2947672514617443\n",
      "[23:300] loss_idt_y: 0.1010096226260066, F_fool_loss: 0.01579743922688067, cycled_y_loss: 0.10389414265751838, D_Y_loss: 0.29564850315451624\n",
      "[23:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:400] Took 12.86s\n",
      "[23:400] loss_idt_x: 0.1525694802775979, G_fool_loss: 0.01554224031046033, cycled_x_loss: 0.14612393416464328, D_X_loss: 0.2949473376572132\n",
      "[23:400] loss_idt_y: 0.10774353083223104, F_fool_loss: 0.016193226194009185, cycled_y_loss: 0.10767410643398762, D_Y_loss: 0.2934935061633587\n",
      "[23:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:500] Took 12.85s\n",
      "[23:500] loss_idt_x: 0.1591444343701005, G_fool_loss: 0.015860339868813755, cycled_x_loss: 0.15700214207172394, D_X_loss: 0.2956359948217869\n",
      "[23:500] loss_idt_y: 0.11516064342111348, F_fool_loss: 0.016380471074953676, cycled_y_loss: 0.12030124049633742, D_Y_loss: 0.2953149737417698\n",
      "[23:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:600] Took 12.88s\n",
      "[23:600] loss_idt_x: 0.15756826505064964, G_fool_loss: 0.016564685478806497, cycled_x_loss: 0.1617457488179207, D_X_loss: 0.2947621591389179\n",
      "[23:600] loss_idt_y: 0.09477922908961772, F_fool_loss: 0.015722477911040186, cycled_y_loss: 0.10212225008755922, D_Y_loss: 0.29480048432946204\n",
      "[23:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:700] Took 12.87s\n",
      "[23:700] loss_idt_x: 0.1430978512391448, G_fool_loss: 0.016079690381884573, cycled_x_loss: 0.14352359920740126, D_X_loss: 0.29392585590481757\n",
      "[23:700] loss_idt_y: 0.09239373132586479, F_fool_loss: 0.015522248484194279, cycled_y_loss: 0.10062939241528511, D_Y_loss: 0.29637372732162476\n",
      "[23:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:800] Took 12.86s\n",
      "[23:800] loss_idt_x: 0.14280090194195508, G_fool_loss: 0.015589243918657302, cycled_x_loss: 0.13814843140542507, D_X_loss: 0.29388460129499433\n",
      "[23:800] loss_idt_y: 0.09736002188175917, F_fool_loss: 0.016422550026327372, cycled_y_loss: 0.10776977743953467, D_Y_loss: 0.29356677174568174\n",
      "[23:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:900] Took 12.86s\n",
      "[23:900] loss_idt_x: 0.146155964396894, G_fool_loss: 0.0156452776119113, cycled_x_loss: 0.1489611067250371, D_X_loss: 0.29370469704270363\n",
      "[23:900] loss_idt_y: 0.0943928475677967, F_fool_loss: 0.01586403777822852, cycled_y_loss: 0.1001433790102601, D_Y_loss: 0.29324580639600756\n",
      "[23:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:1000] Took 12.87s\n",
      "[23:1000] loss_idt_x: 0.14851397782564163, G_fool_loss: 0.01590229225344956, cycled_x_loss: 0.1441006524860859, D_X_loss: 0.2936925974488258\n",
      "[23:1000] loss_idt_y: 0.09656728990375996, F_fool_loss: 0.015861496813595295, cycled_y_loss: 0.10605330351740122, D_Y_loss: 0.2941718238592148\n",
      "[23:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:1100] Took 12.86s\n",
      "[23:1100] loss_idt_x: 0.14295482859015465, G_fool_loss: 0.016307607162743806, cycled_x_loss: 0.1445881561562419, D_X_loss: 0.2949037989974022\n",
      "[23:1100] loss_idt_y: 0.10142910964787007, F_fool_loss: 0.01561722437851131, cycled_y_loss: 0.10894847750663757, D_Y_loss: 0.2959222435951233\n",
      "[23:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[23:END] Completed epoch in 157.72865223884583s\n",
      "[23:1199] ep_loss_idt_x: 0.150 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.150 ep_D_X_loss: 0.294\n",
      "[23:1199] ep_loss_idt_y: 0.101 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.107 ep_D_Y_loss: 0.294\n",
      "[23:END] Completed eval in 1.3743276596069336s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[23:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[24:100] Took 14.74s\n",
      "[24:100] loss_idt_x: 0.15541753362864255, G_fool_loss: 0.01599681726656854, cycled_x_loss: 0.15161653134971856, D_X_loss: 0.29775361135601996\n",
      "[24:100] loss_idt_y: 0.09436688706278801, F_fool_loss: 0.015990974884480237, cycled_y_loss: 0.10148970384150743, D_Y_loss: 0.2965712642669678\n",
      "[24:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:200] Took 12.85s\n",
      "[24:200] loss_idt_x: 0.1472044487670064, G_fool_loss: 0.01543432766571641, cycled_x_loss: 0.15146215349435807, D_X_loss: 0.29428627371788024\n",
      "[24:200] loss_idt_y: 0.1206692298874259, F_fool_loss: 0.015942833097651602, cycled_y_loss: 0.1254830778762698, D_Y_loss: 0.29411725983023645\n",
      "[24:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:300] Took 12.89s\n",
      "[24:300] loss_idt_x: 0.13837166592478753, G_fool_loss: 0.015549411177635192, cycled_x_loss: 0.1412249072268605, D_X_loss: 0.29274828016757964\n",
      "[24:300] loss_idt_y: 0.11222783375531435, F_fool_loss: 0.016072461111471058, cycled_y_loss: 0.11210049659013749, D_Y_loss: 0.29426273122429847\n",
      "[24:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:400] Took 12.86s\n",
      "[24:400] loss_idt_x: 0.15522955678403377, G_fool_loss: 0.01580599183216691, cycled_x_loss: 0.1557727912068367, D_X_loss: 0.2951065519452095\n",
      "[24:400] loss_idt_y: 0.10209822613745928, F_fool_loss: 0.016089818142354488, cycled_y_loss: 0.10510820001363755, D_Y_loss: 0.292907586991787\n",
      "[24:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:500] Took 12.86s\n",
      "[24:500] loss_idt_x: 0.15127132281661035, G_fool_loss: 0.016662823101505637, cycled_x_loss: 0.14893661439418793, D_X_loss: 0.2936898697912693\n",
      "[24:500] loss_idt_y: 0.1086612694337964, F_fool_loss: 0.015941461408510806, cycled_y_loss: 0.11416037403047084, D_Y_loss: 0.2945206858217716\n",
      "[24:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:600] Took 12.86s\n",
      "[24:600] loss_idt_x: 0.14854628406465054, G_fool_loss: 0.015447357278317213, cycled_x_loss: 0.1504166106879711, D_X_loss: 0.2951026077568531\n",
      "[24:600] loss_idt_y: 0.1081990783661604, F_fool_loss: 0.015735604194924237, cycled_y_loss: 0.10958870455622673, D_Y_loss: 0.29346829786896705\n",
      "[24:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:700] Took 12.87s\n",
      "[24:700] loss_idt_x: 0.15217300493270158, G_fool_loss: 0.015615817150101066, cycled_x_loss: 0.15004190031439066, D_X_loss: 0.2930408178269863\n",
      "[24:700] loss_idt_y: 0.10463337793946266, F_fool_loss: 0.016198743414133788, cycled_y_loss: 0.1073481497913599, D_Y_loss: 0.2934919676184654\n",
      "[24:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:800] Took 12.87s\n",
      "[24:800] loss_idt_x: 0.16538441885262728, G_fool_loss: 0.01608609258197248, cycled_x_loss: 0.16607407800853252, D_X_loss: 0.29398697897791864\n",
      "[24:800] loss_idt_y: 0.10317292336374521, F_fool_loss: 0.016223307996988297, cycled_y_loss: 0.10473040062934161, D_Y_loss: 0.2942484067380428\n",
      "[24:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:900] Took 12.86s\n",
      "[24:900] loss_idt_x: 0.150579574406147, G_fool_loss: 0.01623636556789279, cycled_x_loss: 0.15575305469334125, D_X_loss: 0.29470776349306105\n",
      "[24:900] loss_idt_y: 0.10401478175073862, F_fool_loss: 0.01614643733948469, cycled_y_loss: 0.10068932339549065, D_Y_loss: 0.2963752284646034\n",
      "[24:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:1000] Took 12.87s\n",
      "[24:1000] loss_idt_x: 0.14720748007297516, G_fool_loss: 0.01620301657356322, cycled_x_loss: 0.14726239405572414, D_X_loss: 0.29359878212213514\n",
      "[24:1000] loss_idt_y: 0.10627929788082838, F_fool_loss: 0.01609462233260274, cycled_y_loss: 0.10448272563517094, D_Y_loss: 0.29434103563427927\n",
      "[24:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:1100] Took 12.87s\n",
      "[24:1100] loss_idt_x: 0.14113249484449625, G_fool_loss: 0.015644157091155648, cycled_x_loss: 0.13454102896153927, D_X_loss: 0.2944560120999813\n",
      "[24:1100] loss_idt_y: 0.09085882034152747, F_fool_loss: 0.016296311113983393, cycled_y_loss: 0.09006552748382092, D_Y_loss: 0.29331503972411155\n",
      "[24:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[24:END] Completed epoch in 159.7676544189453s\n",
      "[24:1199] ep_loss_idt_x: 0.150 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.150 ep_D_X_loss: 0.294\n",
      "[24:1199] ep_loss_idt_y: 0.105 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.107 ep_D_Y_loss: 0.294\n",
      "[24:END] Completed eval in 1.275590181350708s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[24:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[25:100] Took 14.83s\n",
      "[25:100] loss_idt_x: 0.14108567889779805, G_fool_loss: 0.015791250858455896, cycled_x_loss: 0.14087697628885507, D_X_loss: 0.29805310755968095\n",
      "[25:100] loss_idt_y: 0.1025580857694149, F_fool_loss: 0.016152095943689347, cycled_y_loss: 0.10588548600673675, D_Y_loss: 0.2976390172541141\n",
      "[25:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:200] Took 12.85s\n",
      "[25:200] loss_idt_x: 0.1495410443469882, G_fool_loss: 0.015725102666765453, cycled_x_loss: 0.15226445600390434, D_X_loss: 0.2939411459863186\n",
      "[25:200] loss_idt_y: 0.10484666176140309, F_fool_loss: 0.01546987408772111, cycled_y_loss: 0.10925823602825403, D_Y_loss: 0.2935481196641922\n",
      "[25:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:300] Took 12.86s\n",
      "[25:300] loss_idt_x: 0.14315691240131856, G_fool_loss: 0.01567300150170922, cycled_x_loss: 0.14743359681218862, D_X_loss: 0.29424223855137827\n",
      "[25:300] loss_idt_y: 0.09744593042880297, F_fool_loss: 0.01614603600464761, cycled_y_loss: 0.10052970096468926, D_Y_loss: 0.29348156347870824\n",
      "[25:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:400] Took 12.86s\n",
      "[25:400] loss_idt_x: 0.14875735227018594, G_fool_loss: 0.015719337156042457, cycled_x_loss: 0.14817829832434654, D_X_loss: 0.2937950412929058\n",
      "[25:400] loss_idt_y: 0.09964979689568282, F_fool_loss: 0.0158466727565974, cycled_y_loss: 0.10502770893275738, D_Y_loss: 0.29504196003079414\n",
      "[25:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:500] Took 12.86s\n",
      "[25:500] loss_idt_x: 0.14098470117896794, G_fool_loss: 0.015793014438822865, cycled_x_loss: 0.14684418939054011, D_X_loss: 0.2944689558446407\n",
      "[25:500] loss_idt_y: 0.10513139575719833, F_fool_loss: 0.015748705957084896, cycled_y_loss: 0.1043714503198862, D_Y_loss: 0.2944567410647869\n",
      "[25:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:600] Took 12.86s\n",
      "[25:600] loss_idt_x: 0.14406900104135276, G_fool_loss: 0.016114384662359954, cycled_x_loss: 0.15032803356647492, D_X_loss: 0.2957740265130997\n",
      "[25:600] loss_idt_y: 0.11457048665732145, F_fool_loss: 0.015707925083115696, cycled_y_loss: 0.11567833822220563, D_Y_loss: 0.2936609536409378\n",
      "[25:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:700] Took 12.86s\n",
      "[25:700] loss_idt_x: 0.14466553926467896, G_fool_loss: 0.015369292637333274, cycled_x_loss: 0.13992205113172532, D_X_loss: 0.29372573509812355\n",
      "[25:700] loss_idt_y: 0.10443705026060343, F_fool_loss: 0.01605576922185719, cycled_y_loss: 0.10365436624735594, D_Y_loss: 0.29307147055864335\n",
      "[25:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:800] Took 12.87s\n",
      "[25:800] loss_idt_x: 0.15391999062150716, G_fool_loss: 0.01647989995777607, cycled_x_loss: 0.15395906463265419, D_X_loss: 0.29450427144765856\n",
      "[25:800] loss_idt_y: 0.10258871413767338, F_fool_loss: 0.01579148691147566, cycled_y_loss: 0.10708300851285457, D_Y_loss: 0.29506043672561644\n",
      "[25:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:900] Took 12.88s\n",
      "[25:900] loss_idt_x: 0.14225486379116772, G_fool_loss: 0.01578348031267524, cycled_x_loss: 0.13809376303106546, D_X_loss: 0.2941262672841549\n",
      "[25:900] loss_idt_y: 0.10401737473905087, F_fool_loss: 0.016381825683638454, cycled_y_loss: 0.111426669806242, D_Y_loss: 0.2923487918078899\n",
      "[25:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:1000] Took 12.85s\n",
      "[25:1000] loss_idt_x: 0.14208889089524745, G_fool_loss: 0.01592627553269267, cycled_x_loss: 0.1426687115058303, D_X_loss: 0.2935290721058845\n",
      "[25:1000] loss_idt_y: 0.09481204763054847, F_fool_loss: 0.01594917700625956, cycled_y_loss: 0.09525181084871293, D_Y_loss: 0.2950313277542591\n",
      "[25:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:1100] Took 12.86s\n",
      "[25:1100] loss_idt_x: 0.1462533037364483, G_fool_loss: 0.01557952856644988, cycled_x_loss: 0.14022938709706068, D_X_loss: 0.29434627532958985\n",
      "[25:1100] loss_idt_y: 0.10199322503060103, F_fool_loss: 0.015675547095015646, cycled_y_loss: 0.10835821315646171, D_Y_loss: 0.29372981294989586\n",
      "[25:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[25:END] Completed epoch in 157.56306409835815s\n",
      "[25:1199] ep_loss_idt_x: 0.145 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.145 ep_D_X_loss: 0.294\n",
      "[25:1199] ep_loss_idt_y: 0.102 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.105 ep_D_Y_loss: 0.294\n",
      "[25:END] Completed eval in 1.3155112266540527s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[25:END] Saving models and training information permanently\n",
      "[26:100] Took 14.79s\n",
      "[26:100] loss_idt_x: 0.13909844037145377, G_fool_loss: 0.016127036409452556, cycled_x_loss: 0.13796304024755954, D_X_loss: 0.2964476078748703\n",
      "[26:100] loss_idt_y: 0.09931771688163281, F_fool_loss: 0.01599603078328073, cycled_y_loss: 0.10618211138993501, D_Y_loss: 0.29519737347960473\n",
      "[26:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:200] Took 12.88s\n",
      "[26:200] loss_idt_x: 0.15422519829124212, G_fool_loss: 0.015787600120529533, cycled_x_loss: 0.14853453099727632, D_X_loss: 0.29450195252895356\n",
      "[26:200] loss_idt_y: 0.09474756296724081, F_fool_loss: 0.01585669431835413, cycled_y_loss: 0.1043670042604208, D_Y_loss: 0.2945209527015686\n",
      "[26:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:300] Took 12.86s\n",
      "[26:300] loss_idt_x: 0.1341648658365011, G_fool_loss: 0.015928176771849392, cycled_x_loss: 0.13220982134342193, D_X_loss: 0.2942662934958935\n",
      "[26:300] loss_idt_y: 0.1080471283942461, F_fool_loss: 0.01614736806601286, cycled_y_loss: 0.11916668348014355, D_Y_loss: 0.294577025026083\n",
      "[26:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:400] Took 12.87s\n",
      "[26:400] loss_idt_x: 0.13899014066904783, G_fool_loss: 0.015512416344136, cycled_x_loss: 0.1391789523139596, D_X_loss: 0.2946649892628193\n",
      "[26:400] loss_idt_y: 0.10698024269193411, F_fool_loss: 0.015837467992678284, cycled_y_loss: 0.110530108474195, D_Y_loss: 0.29201787784695626\n",
      "[26:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:500] Took 12.87s\n",
      "[26:500] loss_idt_x: 0.1519725328683853, G_fool_loss: 0.0157126625534147, cycled_x_loss: 0.1516435493901372, D_X_loss: 0.29368442714214327\n",
      "[26:500] loss_idt_y: 0.10710438095033169, F_fool_loss: 0.015675672935321926, cycled_y_loss: 0.11049584500491619, D_Y_loss: 0.2939827935397625\n",
      "[26:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:600] Took 12.89s\n",
      "[26:600] loss_idt_x: 0.15947867482900618, G_fool_loss: 0.015875563705340028, cycled_x_loss: 0.1550433563068509, D_X_loss: 0.2930343161523342\n",
      "[26:600] loss_idt_y: 0.10634350199252367, F_fool_loss: 0.016192416790872813, cycled_y_loss: 0.10997153788805009, D_Y_loss: 0.2934625741839409\n",
      "[26:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:700] Took 12.86s\n",
      "[26:700] loss_idt_x: 0.15311460088938475, G_fool_loss: 0.015805441662669183, cycled_x_loss: 0.1482294313982129, D_X_loss: 0.2945124018192291\n",
      "[26:700] loss_idt_y: 0.09520917423069478, F_fool_loss: 0.01618617701344192, cycled_y_loss: 0.09921971306204797, D_Y_loss: 0.29402540415525436\n",
      "[26:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:800] Took 12.86s\n",
      "[26:800] loss_idt_x: 0.14754926819354297, G_fool_loss: 0.015688560334965587, cycled_x_loss: 0.14641648765653373, D_X_loss: 0.29355867207050323\n",
      "[26:800] loss_idt_y: 0.10781272809952497, F_fool_loss: 0.016153202140703798, cycled_y_loss: 0.10776159808039665, D_Y_loss: 0.29303522512316704\n",
      "[26:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:900] Took 12.88s\n",
      "[26:900] loss_idt_x: 0.16152063570916653, G_fool_loss: 0.016218903735280038, cycled_x_loss: 0.1616774945706129, D_X_loss: 0.29493345648050306\n",
      "[26:900] loss_idt_y: 0.10409921914339065, F_fool_loss: 0.016053506368771196, cycled_y_loss: 0.10308480460196734, D_Y_loss: 0.2933219341933727\n",
      "[26:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:1000] Took 12.86s\n",
      "[26:1000] loss_idt_x: 0.15083891190588475, G_fool_loss: 0.015528466263785958, cycled_x_loss: 0.1490259402617812, D_X_loss: 0.29499401167035105\n",
      "[26:1000] loss_idt_y: 0.09953553557395935, F_fool_loss: 0.015944589367136358, cycled_y_loss: 0.10968643836677075, D_Y_loss: 0.2941216479241848\n",
      "[26:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:1100] Took 12.86s\n",
      "[26:1100] loss_idt_x: 0.1539359885454178, G_fool_loss: 0.01550862188450992, cycled_x_loss: 0.1502744572237134, D_X_loss: 0.29384382501244544\n",
      "[26:1100] loss_idt_y: 0.10423264987766742, F_fool_loss: 0.015710001569241284, cycled_y_loss: 0.10942253563553095, D_Y_loss: 0.2943327172100544\n",
      "[26:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[26:END] Completed epoch in 157.78488731384277s\n",
      "[26:1199] ep_loss_idt_x: 0.149 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.147 ep_D_X_loss: 0.294\n",
      "[26:1199] ep_loss_idt_y: 0.103 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.108 ep_D_Y_loss: 0.294\n",
      "[26:END] Completed eval in 1.375352144241333s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[26:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[27:100] Took 14.76s\n",
      "[27:100] loss_idt_x: 0.1396252567693591, G_fool_loss: 0.015569490697234869, cycled_x_loss: 0.1399544370546937, D_X_loss: 0.2977069367468357\n",
      "[27:100] loss_idt_y: 0.10342154938727617, F_fool_loss: 0.016204387471079825, cycled_y_loss: 0.1083988206088543, D_Y_loss: 0.2967351868748665\n",
      "[27:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:200] Took 12.86s\n",
      "[27:200] loss_idt_x: 0.13441809680312872, G_fool_loss: 0.01614482970908284, cycled_x_loss: 0.13507940873503685, D_X_loss: 0.2945048871636391\n",
      "[27:200] loss_idt_y: 0.09156268402934074, F_fool_loss: 0.01597311000339687, cycled_y_loss: 0.09553946651518345, D_Y_loss: 0.29429359585046766\n",
      "[27:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:300] Took 12.88s\n",
      "[27:300] loss_idt_x: 0.15545538689941168, G_fool_loss: 0.015466503566130996, cycled_x_loss: 0.15778705362230538, D_X_loss: 0.2951470224559307\n",
      "[27:300] loss_idt_y: 0.09825949039310217, F_fool_loss: 0.0161681323684752, cycled_y_loss: 0.09978496596217155, D_Y_loss: 0.2928671851754189\n",
      "[27:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:400] Took 12.85s\n",
      "[27:400] loss_idt_x: 0.15011745043098926, G_fool_loss: 0.01596906523220241, cycled_x_loss: 0.15345633383840324, D_X_loss: 0.29522775843739507\n",
      "[27:400] loss_idt_y: 0.10280689552426338, F_fool_loss: 0.016031914493069052, cycled_y_loss: 0.10328014321625233, D_Y_loss: 0.29391591176390647\n",
      "[27:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:500] Took 12.86s\n",
      "[27:500] loss_idt_x: 0.13562933810055255, G_fool_loss: 0.01593590173870325, cycled_x_loss: 0.13605119962245227, D_X_loss: 0.2943176785111427\n",
      "[27:500] loss_idt_y: 0.10953254219144583, F_fool_loss: 0.016034471970051527, cycled_y_loss: 0.11607015870511532, D_Y_loss: 0.2937705725431442\n",
      "[27:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:600] Took 12.86s\n",
      "[27:600] loss_idt_x: 0.1541769329085946, G_fool_loss: 0.015380808040499688, cycled_x_loss: 0.1483353839442134, D_X_loss: 0.29466624557971954\n",
      "[27:600] loss_idt_y: 0.10565950702875852, F_fool_loss: 0.015807232139632105, cycled_y_loss: 0.10594823252409696, D_Y_loss: 0.29407298922538755\n",
      "[27:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:700] Took 12.86s\n",
      "[27:700] loss_idt_x: 0.1469377601519227, G_fool_loss: 0.01574903872795403, cycled_x_loss: 0.13823959834873675, D_X_loss: 0.29501600325107574\n",
      "[27:700] loss_idt_y: 0.11074846789240837, F_fool_loss: 0.01584474364295602, cycled_y_loss: 0.12030298940837383, D_Y_loss: 0.2941025903820991\n",
      "[27:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:800] Took 12.86s\n",
      "[27:800] loss_idt_x: 0.1306736357137561, G_fool_loss: 0.014968014769256115, cycled_x_loss: 0.13454673141241075, D_X_loss: 0.294168054163456\n",
      "[27:800] loss_idt_y: 0.09968812603503466, F_fool_loss: 0.01571797242388129, cycled_y_loss: 0.10702951926738023, D_Y_loss: 0.2922936837375164\n",
      "[27:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:900] Took 12.86s\n",
      "[27:900] loss_idt_x: 0.13774531487375496, G_fool_loss: 0.015842809965834023, cycled_x_loss: 0.13642579820007086, D_X_loss: 0.29293388679623605\n",
      "[27:900] loss_idt_y: 0.09891844466328621, F_fool_loss: 0.015464051896706223, cycled_y_loss: 0.10001676477491855, D_Y_loss: 0.293772042542696\n",
      "[27:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:1000] Took 12.87s\n",
      "[27:1000] loss_idt_x: 0.14014688987284898, G_fool_loss: 0.015364252496510744, cycled_x_loss: 0.13877501156181096, D_X_loss: 0.2950176587700844\n",
      "[27:1000] loss_idt_y: 0.10682061843574048, F_fool_loss: 0.01582563235424459, cycled_y_loss: 0.11019138593226671, D_Y_loss: 0.29276101529598236\n",
      "[27:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:1100] Took 12.87s\n",
      "[27:1100] loss_idt_x: 0.14216546177864076, G_fool_loss: 0.0161710162833333, cycled_x_loss: 0.13899396862834693, D_X_loss: 0.2956482073664665\n",
      "[27:1100] loss_idt_y: 0.10313465535640716, F_fool_loss: 0.016224772837013006, cycled_y_loss: 0.10759332120418548, D_Y_loss: 0.29490895494818686\n",
      "[27:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[27:END] Completed epoch in 157.6381869316101s\n",
      "[27:1199] ep_loss_idt_x: 0.142 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.141 ep_D_X_loss: 0.295\n",
      "[27:1199] ep_loss_idt_y: 0.101 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.105 ep_D_Y_loss: 0.294\n",
      "[27:END] Completed eval in 1.331430196762085s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[27:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[28:100] Took 14.76s\n",
      "[28:100] loss_idt_x: 0.14377717543393373, G_fool_loss: 0.01582975698634982, cycled_x_loss: 0.14387098763138056, D_X_loss: 0.2967364628612995\n",
      "[28:100] loss_idt_y: 0.08797195069491863, F_fool_loss: 0.016202227501198648, cycled_y_loss: 0.09307809855788945, D_Y_loss: 0.2968390886485577\n",
      "[28:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:200] Took 12.82s\n",
      "[28:200] loss_idt_x: 0.14245889764279127, G_fool_loss: 0.015538579039275646, cycled_x_loss: 0.14311210695654153, D_X_loss: 0.2951923501491547\n",
      "[28:200] loss_idt_y: 0.10059867724776268, F_fool_loss: 0.01565250757150352, cycled_y_loss: 0.10297636672854424, D_Y_loss: 0.293200696259737\n",
      "[28:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:300] Took 12.82s\n",
      "[28:300] loss_idt_x: 0.1472823340073228, G_fool_loss: 0.015555717097595335, cycled_x_loss: 0.1506557222828269, D_X_loss: 0.29475113421678545\n",
      "[28:300] loss_idt_y: 0.10578223396092654, F_fool_loss: 0.016070703342556954, cycled_y_loss: 0.11328226804733277, D_Y_loss: 0.29397899806499483\n",
      "[28:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:400] Took 12.83s\n",
      "[28:400] loss_idt_x: 0.13096989035606385, G_fool_loss: 0.015361808324232697, cycled_x_loss: 0.1321996733173728, D_X_loss: 0.29466253861784936\n",
      "[28:400] loss_idt_y: 0.08757705647498369, F_fool_loss: 0.016569301718845963, cycled_y_loss: 0.09713146526366473, D_Y_loss: 0.2934370996057987\n",
      "[28:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:500] Took 12.82s\n",
      "[28:500] loss_idt_x: 0.14243056692183018, G_fool_loss: 0.016007287465035915, cycled_x_loss: 0.14173153072595596, D_X_loss: 0.2948026455938816\n",
      "[28:500] loss_idt_y: 0.09632822118699551, F_fool_loss: 0.01573340851813555, cycled_y_loss: 0.09891287997364998, D_Y_loss: 0.293599796295166\n",
      "[28:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:600] Took 12.83s\n",
      "[28:600] loss_idt_x: 0.14396658018231392, G_fool_loss: 0.015927045363932846, cycled_x_loss: 0.14664908714592456, D_X_loss: 0.29245848789811135\n",
      "[28:600] loss_idt_y: 0.10018803283572197, F_fool_loss: 0.015854865964502095, cycled_y_loss: 0.10214902501553297, D_Y_loss: 0.29604857966303827\n",
      "[28:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:700] Took 12.82s\n",
      "[28:700] loss_idt_x: 0.13868960186839105, G_fool_loss: 0.015601485632359982, cycled_x_loss: 0.13487869657576085, D_X_loss: 0.2952337540686131\n",
      "[28:700] loss_idt_y: 0.09956028699874878, F_fool_loss: 0.01573008330538869, cycled_y_loss: 0.09961802277714014, D_Y_loss: 0.2943239523470402\n",
      "[28:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:800] Took 12.85s\n",
      "[28:800] loss_idt_x: 0.13991424094885588, G_fool_loss: 0.015967573914676906, cycled_x_loss: 0.13651503957808017, D_X_loss: 0.29409256801009176\n",
      "[28:800] loss_idt_y: 0.10646948717534542, F_fool_loss: 0.015618253974243998, cycled_y_loss: 0.10737325875088573, D_Y_loss: 0.29508560404181483\n",
      "[28:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:900] Took 12.85s\n",
      "[28:900] loss_idt_x: 0.13846654310822487, G_fool_loss: 0.015818632822483778, cycled_x_loss: 0.13261347096413373, D_X_loss: 0.2934477074444294\n",
      "[28:900] loss_idt_y: 0.10559027619659901, F_fool_loss: 0.015285468529909849, cycled_y_loss: 0.1163044461235404, D_Y_loss: 0.29402492076158526\n",
      "[28:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:1000] Took 12.82s\n",
      "[28:1000] loss_idt_x: 0.13251516908407213, G_fool_loss: 0.015450142780318856, cycled_x_loss: 0.14040318854153155, D_X_loss: 0.2942919982969761\n",
      "[28:1000] loss_idt_y: 0.09680146791040897, F_fool_loss: 0.016436920138075947, cycled_y_loss: 0.10130876444280147, D_Y_loss: 0.29235581189394\n",
      "[28:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:1100] Took 12.83s\n",
      "[28:1100] loss_idt_x: 0.14645438469946384, G_fool_loss: 0.016456741997972132, cycled_x_loss: 0.14431509498506784, D_X_loss: 0.29431132689118383\n",
      "[28:1100] loss_idt_y: 0.0980231723934412, F_fool_loss: 0.016235310109332202, cycled_y_loss: 0.10416566424071788, D_Y_loss: 0.2950472941994667\n",
      "[28:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[28:END] Completed epoch in 157.57979106903076s\n",
      "[28:1199] ep_loss_idt_x: 0.141 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.142 ep_D_X_loss: 0.294\n",
      "[28:1199] ep_loss_idt_y: 0.098 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.103 ep_D_Y_loss: 0.294\n",
      "[28:END] Completed eval in 1.4192373752593994s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[28:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[29:100] Took 14.76s\n",
      "[29:100] loss_idt_x: 0.1401450043916702, G_fool_loss: 0.015356897553429007, cycled_x_loss: 0.13164348371326923, D_X_loss: 0.29667192935943604\n",
      "[29:100] loss_idt_y: 0.10018363930284976, F_fool_loss: 0.016032084273174405, cycled_y_loss: 0.10309051930904388, D_Y_loss: 0.2957769404351711\n",
      "[29:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:200] Took 12.82s\n",
      "[29:200] loss_idt_x: 0.12929343592375517, G_fool_loss: 0.015621482664719223, cycled_x_loss: 0.12411581624299288, D_X_loss: 0.2951567806303501\n",
      "[29:200] loss_idt_y: 0.09175847239792347, F_fool_loss: 0.015718762883916496, cycled_y_loss: 0.10015757951885462, D_Y_loss: 0.2933290648460388\n",
      "[29:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:300] Took 12.83s\n",
      "[29:300] loss_idt_x: 0.15153192512691022, G_fool_loss: 0.015318249017000199, cycled_x_loss: 0.14762510176748037, D_X_loss: 0.2938335743546486\n",
      "[29:300] loss_idt_y: 0.08919075783342123, F_fool_loss: 0.015829828698188067, cycled_y_loss: 0.09436246573925018, D_Y_loss: 0.2936012065410614\n",
      "[29:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:400] Took 12.83s\n",
      "[29:400] loss_idt_x: 0.13298660770058632, G_fool_loss: 0.015733495894819496, cycled_x_loss: 0.135366171002388, D_X_loss: 0.2931344969570637\n",
      "[29:400] loss_idt_y: 0.11362284064292907, F_fool_loss: 0.01577670811675489, cycled_y_loss: 0.11792434386909008, D_Y_loss: 0.2957454942166805\n",
      "[29:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:500] Took 12.83s\n",
      "[29:500] loss_idt_x: 0.15396280396729708, G_fool_loss: 0.01571883637458086, cycled_x_loss: 0.150909659601748, D_X_loss: 0.2943056194484234\n",
      "[29:500] loss_idt_y: 0.100168976187706, F_fool_loss: 0.015843236753717065, cycled_y_loss: 0.10446104116737842, D_Y_loss: 0.2956399694085121\n",
      "[29:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:600] Took 12.85s\n",
      "[29:600] loss_idt_x: 0.1365291066840291, G_fool_loss: 0.015398916406556964, cycled_x_loss: 0.14212388642132281, D_X_loss: 0.2928595247864723\n",
      "[29:600] loss_idt_y: 0.09622540164738894, F_fool_loss: 0.016024134308099746, cycled_y_loss: 0.10268979445099831, D_Y_loss: 0.29397796005010607\n",
      "[29:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:700] Took 12.82s\n",
      "[29:700] loss_idt_x: 0.15434850584715604, G_fool_loss: 0.015651163924485446, cycled_x_loss: 0.14750038649886846, D_X_loss: 0.2943969610333443\n",
      "[29:700] loss_idt_y: 0.09621946725994349, F_fool_loss: 0.01574801804497838, cycled_y_loss: 0.10150342632085085, D_Y_loss: 0.29517531022429466\n",
      "[29:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:800] Took 12.83s\n",
      "[29:800] loss_idt_x: 0.14953070782124997, G_fool_loss: 0.01594339417293668, cycled_x_loss: 0.14473430674523116, D_X_loss: 0.29538536369800567\n",
      "[29:800] loss_idt_y: 0.09414849441498518, F_fool_loss: 0.015995975052937865, cycled_y_loss: 0.10176985312253237, D_Y_loss: 0.29449794977903365\n",
      "[29:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:900] Took 12.83s\n",
      "[29:900] loss_idt_x: 0.13769765507429838, G_fool_loss: 0.015792466662824155, cycled_x_loss: 0.13527133649215103, D_X_loss: 0.29485094770789144\n",
      "[29:900] loss_idt_y: 0.09605991143733263, F_fool_loss: 0.015841865530237555, cycled_y_loss: 0.10527949690818787, D_Y_loss: 0.29246044501662255\n",
      "[29:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:1000] Took 12.82s\n",
      "[29:1000] loss_idt_x: 0.15145803343504669, G_fool_loss: 0.01555392174050212, cycled_x_loss: 0.13985864650458096, D_X_loss: 0.2943980164825916\n",
      "[29:1000] loss_idt_y: 0.10127157993614673, F_fool_loss: 0.01572257881052792, cycled_y_loss: 0.10703191202133894, D_Y_loss: 0.2935756489634514\n",
      "[29:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:1100] Took 12.90s\n",
      "[29:1100] loss_idt_x: 0.1328905153274536, G_fool_loss: 0.01551392856054008, cycled_x_loss: 0.13573118150234223, D_X_loss: 0.2935356466472149\n",
      "[29:1100] loss_idt_y: 0.09736152309924365, F_fool_loss: 0.016135184429585933, cycled_y_loss: 0.09930594488978386, D_Y_loss: 0.29412398308515547\n",
      "[29:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[29:END] Completed epoch in 158.0584099292755s\n",
      "[29:1199] ep_loss_idt_x: 0.143 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.139 ep_D_X_loss: 0.294\n",
      "[29:1199] ep_loss_idt_y: 0.097 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.103 ep_D_Y_loss: 0.294\n",
      "[29:END] Completed eval in 1.3374555110931396s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[29:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[30:100] Took 14.84s\n",
      "[30:100] loss_idt_x: 0.14836680833250285, G_fool_loss: 0.0160077684558928, cycled_x_loss: 0.15008518900722265, D_X_loss: 0.29781773149967194\n",
      "[30:100] loss_idt_y: 0.09376252129673958, F_fool_loss: 0.015670089796185494, cycled_y_loss: 0.09667527846992016, D_Y_loss: 0.29635037019848826\n",
      "[30:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:200] Took 12.83s\n",
      "[30:200] loss_idt_x: 0.13505264885723592, G_fool_loss: 0.015345826344564557, cycled_x_loss: 0.13527067702263593, D_X_loss: 0.293325884193182\n",
      "[30:200] loss_idt_y: 0.10878432359546424, F_fool_loss: 0.015712110782042144, cycled_y_loss: 0.10992080096155404, D_Y_loss: 0.2939307264983654\n",
      "[30:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:300] Took 12.85s\n",
      "[30:300] loss_idt_x: 0.14766056768596172, G_fool_loss: 0.01554075963795185, cycled_x_loss: 0.1424966137856245, D_X_loss: 0.29425691306591034\n",
      "[30:300] loss_idt_y: 0.10629671115428209, F_fool_loss: 0.015998523971065878, cycled_y_loss: 0.10968966003507376, D_Y_loss: 0.2926885715126991\n",
      "[30:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:400] Took 12.83s\n",
      "[30:400] loss_idt_x: 0.12586951244622469, G_fool_loss: 0.015586801860481501, cycled_x_loss: 0.12737147305160762, D_X_loss: 0.2939919824898243\n",
      "[30:400] loss_idt_y: 0.09645406655967236, F_fool_loss: 0.015521146720275283, cycled_y_loss: 0.09394698861986399, D_Y_loss: 0.29480094224214554\n",
      "[30:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:500] Took 12.83s\n",
      "[30:500] loss_idt_x: 0.1443002251908183, G_fool_loss: 0.015598890678957105, cycled_x_loss: 0.14330031167715787, D_X_loss: 0.2940009571611881\n",
      "[30:500] loss_idt_y: 0.10053329162299633, F_fool_loss: 0.015803566398099066, cycled_y_loss: 0.09731060404330492, D_Y_loss: 0.29335660979151723\n",
      "[30:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:600] Took 12.83s\n",
      "[30:600] loss_idt_x: 0.13334583181887866, G_fool_loss: 0.015539843617007136, cycled_x_loss: 0.13066733721643686, D_X_loss: 0.29388407453894616\n",
      "[30:600] loss_idt_y: 0.09978744190186262, F_fool_loss: 0.015759437531232833, cycled_y_loss: 0.10953858070075512, D_Y_loss: 0.2944015361368656\n",
      "[30:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:700] Took 12.82s\n",
      "[30:700] loss_idt_x: 0.13024847142398358, G_fool_loss: 0.015459657041355967, cycled_x_loss: 0.13008458238095044, D_X_loss: 0.29377284124493597\n",
      "[30:700] loss_idt_y: 0.09243404250591994, F_fool_loss: 0.016017163908109068, cycled_y_loss: 0.09428669605404139, D_Y_loss: 0.29458371847867965\n",
      "[30:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:800] Took 12.85s\n",
      "[30:800] loss_idt_x: 0.13913156289607287, G_fool_loss: 0.015184314092621207, cycled_x_loss: 0.14167887303978205, D_X_loss: 0.2945083485543728\n",
      "[30:800] loss_idt_y: 0.08934734113514424, F_fool_loss: 0.015937273716554047, cycled_y_loss: 0.09556897427886725, D_Y_loss: 0.29414997935295106\n",
      "[30:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:900] Took 12.83s\n",
      "[30:900] loss_idt_x: 0.14310357879847288, G_fool_loss: 0.01598714823834598, cycled_x_loss: 0.13596788369119167, D_X_loss: 0.2936702272295952\n",
      "[30:900] loss_idt_y: 0.1048110943287611, F_fool_loss: 0.0154402909707278, cycled_y_loss: 0.10755997434258462, D_Y_loss: 0.2920241129398346\n",
      "[30:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:1000] Took 12.83s\n",
      "[30:1000] loss_idt_x: 0.15387132041156293, G_fool_loss: 0.015048842830583452, cycled_x_loss: 0.15419304221868516, D_X_loss: 0.2935349442064762\n",
      "[30:1000] loss_idt_y: 0.09524768993258476, F_fool_loss: 0.0157906495872885, cycled_y_loss: 0.10504479967057705, D_Y_loss: 0.2925496307015419\n",
      "[30:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:1100] Took 12.83s\n",
      "[30:1100] loss_idt_x: 0.13235866904258728, G_fool_loss: 0.015725718084722756, cycled_x_loss: 0.13255782194435597, D_X_loss: 0.2943463724851608\n",
      "[30:1100] loss_idt_y: 0.09983700718730688, F_fool_loss: 0.01587177804671228, cycled_y_loss: 0.10473674733191729, D_Y_loss: 0.29463498905301094\n",
      "[30:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[30:END] Completed epoch in 158.10950756072998s\n",
      "[30:1199] ep_loss_idt_x: 0.139 ep_G_fool_loss: 0.016 ep_cycled_x_loss: 0.139 ep_D_X_loss: 0.294\n",
      "[30:1199] ep_loss_idt_y: 0.100 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.104 ep_D_Y_loss: 0.294\n",
      "[30:END] Completed eval in 1.3693406581878662s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[30:END] Saving models and training information permanently\n",
      "[31:100] Took 14.77s\n",
      "[31:100] loss_idt_x: 0.13336210411041974, G_fool_loss: 0.015812690733000637, cycled_x_loss: 0.1264298991113901, D_X_loss: 0.29716270297765734\n",
      "[31:100] loss_idt_y: 0.11715579725801945, F_fool_loss: 0.015913476683199406, cycled_y_loss: 0.12705259721726178, D_Y_loss: 0.2974194839596748\n",
      "[31:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:200] Took 12.84s\n",
      "[31:200] loss_idt_x: 0.14257520712912083, G_fool_loss: 0.015561954937875272, cycled_x_loss: 0.14233540140092374, D_X_loss: 0.29368831411004065\n",
      "[31:200] loss_idt_y: 0.10903119970113039, F_fool_loss: 0.015717021143063902, cycled_y_loss: 0.11661498073488474, D_Y_loss: 0.29333708584308626\n",
      "[31:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:300] Took 12.83s\n",
      "[31:300] loss_idt_x: 0.13651675317436457, G_fool_loss: 0.01548143221065402, cycled_x_loss: 0.1377927201613784, D_X_loss: 0.29321970000863073\n",
      "[31:300] loss_idt_y: 0.11275963108986616, F_fool_loss: 0.015465737786144018, cycled_y_loss: 0.11538449261337519, D_Y_loss: 0.29442105785012246\n",
      "[31:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:400] Took 12.83s\n",
      "[31:400] loss_idt_x: 0.13560716036707163, G_fool_loss: 0.015633148476481437, cycled_x_loss: 0.1362863229960203, D_X_loss: 0.2953029568493366\n",
      "[31:400] loss_idt_y: 0.0915524549409747, F_fool_loss: 0.016269276030361653, cycled_y_loss: 0.09408351752907038, D_Y_loss: 0.29263402745127676\n",
      "[31:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:500] Took 12.82s\n",
      "[31:500] loss_idt_x: 0.14227774687111377, G_fool_loss: 0.015265547167509795, cycled_x_loss: 0.13797806028276682, D_X_loss: 0.2938047060370445\n",
      "[31:500] loss_idt_y: 0.09506099205464125, F_fool_loss: 0.015386801911517978, cycled_y_loss: 0.09808812495321036, D_Y_loss: 0.2943826684355736\n",
      "[31:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:600] Took 12.82s\n",
      "[31:600] loss_idt_x: 0.1315849284082651, G_fool_loss: 0.015526931062340736, cycled_x_loss: 0.13004000395536422, D_X_loss: 0.2932444606721401\n",
      "[31:600] loss_idt_y: 0.09360973071306944, F_fool_loss: 0.015568503933027387, cycled_y_loss: 0.10397186476737261, D_Y_loss: 0.2935488957166672\n",
      "[31:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:700] Took 12.84s\n",
      "[31:700] loss_idt_x: 0.14722805865108968, G_fool_loss: 0.015604579327628017, cycled_x_loss: 0.147120067961514, D_X_loss: 0.2939093329012394\n",
      "[31:700] loss_idt_y: 0.09871538151055574, F_fool_loss: 0.01606276521459222, cycled_y_loss: 0.09738427262753248, D_Y_loss: 0.29401327535510063\n",
      "[31:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:800] Took 12.83s\n",
      "[31:800] loss_idt_x: 0.14002093311399222, G_fool_loss: 0.015417288215830922, cycled_x_loss: 0.14504140581935643, D_X_loss: 0.29395978286862373\n",
      "[31:800] loss_idt_y: 0.09422249518334866, F_fool_loss: 0.01572094907052815, cycled_y_loss: 0.09923259012401103, D_Y_loss: 0.29409933269023897\n",
      "[31:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:900] Took 12.84s\n",
      "[31:900] loss_idt_x: 0.14577886041253804, G_fool_loss: 0.015666245678439737, cycled_x_loss: 0.14742082931101322, D_X_loss: 0.29468346014618874\n",
      "[31:900] loss_idt_y: 0.10132016319781542, F_fool_loss: 0.015836041932925583, cycled_y_loss: 0.10831164456903934, D_Y_loss: 0.2932200358808041\n",
      "[31:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:1000] Took 12.83s\n",
      "[31:1000] loss_idt_x: 0.15160015761852264, G_fool_loss: 0.015025043757632375, cycled_x_loss: 0.15127499938011169, D_X_loss: 0.2936455599963665\n",
      "[31:1000] loss_idt_y: 0.10142399940639735, F_fool_loss: 0.015796252302825452, cycled_y_loss: 0.1075334133207798, D_Y_loss: 0.29377846568822863\n",
      "[31:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:1100] Took 12.83s\n",
      "[31:1100] loss_idt_x: 0.15948524463921784, G_fool_loss: 0.015074485801160336, cycled_x_loss: 0.15572585977613926, D_X_loss: 0.2952512499690056\n",
      "[31:1100] loss_idt_y: 0.09974905563518405, F_fool_loss: 0.015888449838384985, cycled_y_loss: 0.1116458186507225, D_Y_loss: 0.29344194769859316\n",
      "[31:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[31:END] Completed epoch in 157.7876787185669s\n",
      "[31:1199] ep_loss_idt_x: 0.142 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.141 ep_D_X_loss: 0.294\n",
      "[31:1199] ep_loss_idt_y: 0.100 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.106 ep_D_Y_loss: 0.294\n",
      "[31:END] Completed eval in 1.3723344802856445s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[31:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[32:100] Took 14.78s\n",
      "[32:100] loss_idt_x: 0.13970387738198042, G_fool_loss: 0.015750041333958506, cycled_x_loss: 0.1386982338130474, D_X_loss: 0.29635943815112115\n",
      "[32:100] loss_idt_y: 0.10494571972638368, F_fool_loss: 0.015840180013328792, cycled_y_loss: 0.10953267250210047, D_Y_loss: 0.2971571497619152\n",
      "[32:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:200] Took 12.82s\n",
      "[32:200] loss_idt_x: 0.13813892386853696, G_fool_loss: 0.015714738946408034, cycled_x_loss: 0.13398432977497576, D_X_loss: 0.29420781761407855\n",
      "[32:200] loss_idt_y: 0.08533041529357434, F_fool_loss: 0.01583506108261645, cycled_y_loss: 0.09391346890479327, D_Y_loss: 0.2944645573198795\n",
      "[32:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:300] Took 12.82s\n",
      "[32:300] loss_idt_x: 0.13770764034241437, G_fool_loss: 0.01524117740802467, cycled_x_loss: 0.13536419935524463, D_X_loss: 0.293188718855381\n",
      "[32:300] loss_idt_y: 0.08756238237023353, F_fool_loss: 0.015702403420582413, cycled_y_loss: 0.09230288702994585, D_Y_loss: 0.2936421513557434\n",
      "[32:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:400] Took 12.83s\n",
      "[32:400] loss_idt_x: 0.14583571534603834, G_fool_loss: 0.015317922197282315, cycled_x_loss: 0.1430622524395585, D_X_loss: 0.2935500027239323\n",
      "[32:400] loss_idt_y: 0.10997959192842245, F_fool_loss: 0.016212849300354718, cycled_y_loss: 0.10885310303419829, D_Y_loss: 0.2940188197791576\n",
      "[32:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:500] Took 12.82s\n",
      "[32:500] loss_idt_x: 0.1488316461071372, G_fool_loss: 0.015448979074135423, cycled_x_loss: 0.1537588269263506, D_X_loss: 0.29420129597187045\n",
      "[32:500] loss_idt_y: 0.10355013657361269, F_fool_loss: 0.015572555093094707, cycled_y_loss: 0.10324893917888403, D_Y_loss: 0.29504346191883085\n",
      "[32:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:600] Took 12.85s\n",
      "[32:600] loss_idt_x: 0.12651557803153993, G_fool_loss: 0.01533689571544528, cycled_x_loss: 0.1247237941250205, D_X_loss: 0.29293744832277296\n",
      "[32:600] loss_idt_y: 0.09910713959485293, F_fool_loss: 0.01567499116063118, cycled_y_loss: 0.10200000077486038, D_Y_loss: 0.29303155913949014\n",
      "[32:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:700] Took 12.83s\n",
      "[32:700] loss_idt_x: 0.13981050867587327, G_fool_loss: 0.015597650734707712, cycled_x_loss: 0.13179328694939613, D_X_loss: 0.2936181053519249\n",
      "[32:700] loss_idt_y: 0.09242508057504892, F_fool_loss: 0.01563324762508273, cycled_y_loss: 0.09856017917394638, D_Y_loss: 0.294195840805769\n",
      "[32:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:800] Took 12.83s\n",
      "[32:800] loss_idt_x: 0.14868582122027874, G_fool_loss: 0.015690725995227695, cycled_x_loss: 0.14421021033078432, D_X_loss: 0.2935398025810719\n",
      "[32:800] loss_idt_y: 0.10502965535968542, F_fool_loss: 0.015787097001448272, cycled_y_loss: 0.10661737710237502, D_Y_loss: 0.29430638015270233\n",
      "[32:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:900] Took 12.84s\n",
      "[32:900] loss_idt_x: 0.15759088307619096, G_fool_loss: 0.015188451986759902, cycled_x_loss: 0.15258197132498025, D_X_loss: 0.2947969700396061\n",
      "[32:900] loss_idt_y: 0.10663920380175114, F_fool_loss: 0.01584208062849939, cycled_y_loss: 0.11140531416982412, D_Y_loss: 0.2946290323138237\n",
      "[32:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:1000] Took 12.84s\n",
      "[32:1000] loss_idt_x: 0.13737080331891774, G_fool_loss: 0.015168904094025493, cycled_x_loss: 0.1364327284321189, D_X_loss: 0.29444531470537183\n",
      "[32:1000] loss_idt_y: 0.08976998422294855, F_fool_loss: 0.015619739145040511, cycled_y_loss: 0.0948930925130844, D_Y_loss: 0.29307962834835055\n",
      "[32:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:1100] Took 12.83s\n",
      "[32:1100] loss_idt_x: 0.1389102215692401, G_fool_loss: 0.015130622368305922, cycled_x_loss: 0.13619176138192415, D_X_loss: 0.29248817428946494\n",
      "[32:1100] loss_idt_y: 0.10401573047041893, F_fool_loss: 0.015216810842975974, cycled_y_loss: 0.09966666586697101, D_Y_loss: 0.29324483960866926\n",
      "[32:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[32:END] Completed epoch in 157.61264514923096s\n",
      "[32:1199] ep_loss_idt_x: 0.141 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.139 ep_D_X_loss: 0.294\n",
      "[32:1199] ep_loss_idt_y: 0.100 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.103 ep_D_Y_loss: 0.294\n",
      "[32:END] Completed eval in 1.4551105499267578s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[32:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[33:100] Took 14.83s\n",
      "[33:100] loss_idt_x: 0.13612924084067346, G_fool_loss: 0.015414800085127354, cycled_x_loss: 0.13781946074217558, D_X_loss: 0.29765912011265755\n",
      "[33:100] loss_idt_y: 0.11742295544594526, F_fool_loss: 0.015587669936940074, cycled_y_loss: 0.11522773686796427, D_Y_loss: 0.2970054702460766\n",
      "[33:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:200] Took 12.83s\n",
      "[33:200] loss_idt_x: 0.13220589090138674, G_fool_loss: 0.015018651969730854, cycled_x_loss: 0.13904818881303072, D_X_loss: 0.29307433068752287\n",
      "[33:200] loss_idt_y: 0.10774901311844587, F_fool_loss: 0.015427439510822295, cycled_y_loss: 0.1098515771701932, D_Y_loss: 0.2939226832985878\n",
      "[33:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:300] Took 12.86s\n",
      "[33:300] loss_idt_x: 0.1382197169959545, G_fool_loss: 0.015415838258340954, cycled_x_loss: 0.13463070575147867, D_X_loss: 0.29518125846982\n",
      "[33:300] loss_idt_y: 0.09160965539515019, F_fool_loss: 0.01570954253897071, cycled_y_loss: 0.0956860962882638, D_Y_loss: 0.2938851860165596\n",
      "[33:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:400] Took 12.82s\n",
      "[33:400] loss_idt_x: 0.13822240550071002, G_fool_loss: 0.01526520224288106, cycled_x_loss: 0.13454729083925485, D_X_loss: 0.29412751629948614\n",
      "[33:400] loss_idt_y: 0.09388383131474257, F_fool_loss: 0.01581586157903075, cycled_y_loss: 0.09445193599909545, D_Y_loss: 0.29451302081346514\n",
      "[33:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:500] Took 12.83s\n",
      "[33:500] loss_idt_x: 0.14047582626342772, G_fool_loss: 0.01529758787713945, cycled_x_loss: 0.14110436234623194, D_X_loss: 0.2953391228616238\n",
      "[33:500] loss_idt_y: 0.09349233742803335, F_fool_loss: 0.015751431174576284, cycled_y_loss: 0.09601335242390632, D_Y_loss: 0.29505167961120604\n",
      "[33:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:600] Took 12.83s\n",
      "[33:600] loss_idt_x: 0.12460660845041276, G_fool_loss: 0.015247005969285965, cycled_x_loss: 0.12091531448066234, D_X_loss: 0.29425346553325654\n",
      "[33:600] loss_idt_y: 0.09417562518268824, F_fool_loss: 0.015377093963325024, cycled_y_loss: 0.09782882038503886, D_Y_loss: 0.29267326831817625\n",
      "[33:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:700] Took 12.83s\n",
      "[33:700] loss_idt_x: 0.13999669648706914, G_fool_loss: 0.015328722894191743, cycled_x_loss: 0.14276733476668596, D_X_loss: 0.2941369390487671\n",
      "[33:700] loss_idt_y: 0.09708791725337505, F_fool_loss: 0.015705500775948168, cycled_y_loss: 0.09508766524493695, D_Y_loss: 0.29490484595298766\n",
      "[33:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:800] Took 12.83s\n",
      "[33:800] loss_idt_x: 0.1482468366995454, G_fool_loss: 0.015152477603405714, cycled_x_loss: 0.14789347272366285, D_X_loss: 0.2935579580068588\n",
      "[33:800] loss_idt_y: 0.09561185579746961, F_fool_loss: 0.01571833258494735, cycled_y_loss: 0.09987760961055756, D_Y_loss: 0.2940685021877289\n",
      "[33:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:900] Took 12.83s\n",
      "[33:900] loss_idt_x: 0.14488224938511848, G_fool_loss: 0.015152223035693168, cycled_x_loss: 0.14010230492800474, D_X_loss: 0.2947424581646919\n",
      "[33:900] loss_idt_y: 0.09884002909064293, F_fool_loss: 0.015787820275872947, cycled_y_loss: 0.1077486326918006, D_Y_loss: 0.29462540209293364\n",
      "[33:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:1000] Took 12.82s\n",
      "[33:1000] loss_idt_x: 0.14176302798092366, G_fool_loss: 0.015406572669744491, cycled_x_loss: 0.13616914626210927, D_X_loss: 0.2930855816602707\n",
      "[33:1000] loss_idt_y: 0.11062794163823128, F_fool_loss: 0.01551878085359931, cycled_y_loss: 0.11283090308308602, D_Y_loss: 0.29415314853191377\n",
      "[33:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:1100] Took 12.83s\n",
      "[33:1100] loss_idt_x: 0.1404482851922512, G_fool_loss: 0.015177458748221398, cycled_x_loss: 0.13808120213449002, D_X_loss: 0.2945540031790733\n",
      "[33:1100] loss_idt_y: 0.09787889543920755, F_fool_loss: 0.01561912516131997, cycled_y_loss: 0.09737944766879082, D_Y_loss: 0.2943000790476799\n",
      "[33:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[33:END] Completed epoch in 158.02011275291443s\n",
      "[33:1199] ep_loss_idt_x: 0.138 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.137 ep_D_X_loss: 0.294\n",
      "[33:1199] ep_loss_idt_y: 0.099 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.102 ep_D_Y_loss: 0.294\n",
      "[33:END] Completed eval in 1.5329034328460693s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[33:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[34:100] Took 14.85s\n",
      "[34:100] loss_idt_x: 0.12765742041170597, G_fool_loss: 0.0150324634462595, cycled_x_loss: 0.1297843249514699, D_X_loss: 0.2977011626958847\n",
      "[34:100] loss_idt_y: 0.09342376165091991, F_fool_loss: 0.015729741686955095, cycled_y_loss: 0.09841702491044999, D_Y_loss: 0.295966739654541\n",
      "[34:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:200] Took 12.83s\n",
      "[34:200] loss_idt_x: 0.14225471563637257, G_fool_loss: 0.015308390632271766, cycled_x_loss: 0.14167165111750366, D_X_loss: 0.2930920821428299\n",
      "[34:200] loss_idt_y: 0.10055130049586296, F_fool_loss: 0.01573246665298939, cycled_y_loss: 0.10329020872712136, D_Y_loss: 0.2937482926249504\n",
      "[34:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:300] Took 12.83s\n",
      "[34:300] loss_idt_x: 0.15073651619255543, G_fool_loss: 0.01487289272248745, cycled_x_loss: 0.15031735587865114, D_X_loss: 0.294924231171608\n",
      "[34:300] loss_idt_y: 0.10128325410187244, F_fool_loss: 0.01586013810709119, cycled_y_loss: 0.10315125569701195, D_Y_loss: 0.2933302429318428\n",
      "[34:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:400] Took 12.85s\n",
      "[34:400] loss_idt_x: 0.13987576022744178, G_fool_loss: 0.015047721806913614, cycled_x_loss: 0.14664343044161796, D_X_loss: 0.2935284724831581\n",
      "[34:400] loss_idt_y: 0.09588383346796035, F_fool_loss: 0.015682141399011015, cycled_y_loss: 0.10331587143242359, D_Y_loss: 0.2928252303600311\n",
      "[34:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:500] Took 12.84s\n",
      "[34:500] loss_idt_x: 0.12902576435357332, G_fool_loss: 0.015141088273376227, cycled_x_loss: 0.13188249498605728, D_X_loss: 0.29412006825208664\n",
      "[34:500] loss_idt_y: 0.1077506173402071, F_fool_loss: 0.015293589998036624, cycled_y_loss: 0.11125182211399079, D_Y_loss: 0.29159076064825057\n",
      "[34:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:600] Took 12.83s\n",
      "[34:600] loss_idt_x: 0.1459626641869545, G_fool_loss: 0.015020565250888468, cycled_x_loss: 0.14401023540645838, D_X_loss: 0.29299785688519475\n",
      "[34:600] loss_idt_y: 0.09572838552296162, F_fool_loss: 0.015766763174906374, cycled_y_loss: 0.10103140238672495, D_Y_loss: 0.29366581499576566\n",
      "[34:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:700] Took 12.82s\n",
      "[34:700] loss_idt_x: 0.15496801387518644, G_fool_loss: 0.015300122695043683, cycled_x_loss: 0.14268757224082948, D_X_loss: 0.29371545791625975\n",
      "[34:700] loss_idt_y: 0.10336425697430968, F_fool_loss: 0.015650186678394674, cycled_y_loss: 0.10419820345938206, D_Y_loss: 0.29353844463825224\n",
      "[34:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:800] Took 12.82s\n",
      "[34:800] loss_idt_x: 0.12930227231234312, G_fool_loss: 0.015187094239518046, cycled_x_loss: 0.1303369314968586, D_X_loss: 0.2941478672623634\n",
      "[34:800] loss_idt_y: 0.0915497912839055, F_fool_loss: 0.015607606442645193, cycled_y_loss: 0.0946309669315815, D_Y_loss: 0.29185034841299057\n",
      "[34:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:900] Took 12.83s\n",
      "[34:900] loss_idt_x: 0.1431054112315178, G_fool_loss: 0.015017612054944039, cycled_x_loss: 0.14087094131857156, D_X_loss: 0.2946804016828537\n",
      "[34:900] loss_idt_y: 0.09237579204142093, F_fool_loss: 0.015850139791145922, cycled_y_loss: 0.09795680601149798, D_Y_loss: 0.29379148468375205\n",
      "[34:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:1000] Took 12.85s\n",
      "[34:1000] loss_idt_x: 0.13254502084106207, G_fool_loss: 0.015207795603200793, cycled_x_loss: 0.1296372091770172, D_X_loss: 0.2936596137285232\n",
      "[34:1000] loss_idt_y: 0.08595282040536403, F_fool_loss: 0.016155327297747137, cycled_y_loss: 0.09131265312433243, D_Y_loss: 0.29297995910048485\n",
      "[34:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:1100] Took 12.83s\n",
      "[34:1100] loss_idt_x: 0.13908759351819755, G_fool_loss: 0.014554546605795622, cycled_x_loss: 0.1389240510389209, D_X_loss: 0.29355187445878983\n",
      "[34:1100] loss_idt_y: 0.08211945222690702, F_fool_loss: 0.015195558723062276, cycled_y_loss: 0.08469505324959754, D_Y_loss: 0.2934349727630615\n",
      "[34:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[34:END] Completed epoch in 158.4669361114502s\n",
      "[34:1199] ep_loss_idt_x: 0.140 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.139 ep_D_X_loss: 0.294\n",
      "[34:1199] ep_loss_idt_y: 0.096 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.100 ep_D_Y_loss: 0.293\n",
      "[34:END] Completed eval in 1.4102602005004883s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[34:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[35:100] Took 14.85s\n",
      "[35:100] loss_idt_x: 0.15169734109193087, G_fool_loss: 0.015323447985574603, cycled_x_loss: 0.14334906946867704, D_X_loss: 0.297426573485136\n",
      "[35:100] loss_idt_y: 0.0913534489646554, F_fool_loss: 0.016014474099501966, cycled_y_loss: 0.09769771616905927, D_Y_loss: 0.29546875834465025\n",
      "[35:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:200] Took 12.82s\n",
      "[35:200] loss_idt_x: 0.1362027708813548, G_fool_loss: 0.014891911093145608, cycled_x_loss: 0.1308476322516799, D_X_loss: 0.2940838465094566\n",
      "[35:200] loss_idt_y: 0.08697341132909059, F_fool_loss: 0.015468868156895042, cycled_y_loss: 0.09470927070826292, D_Y_loss: 0.29320677906274795\n",
      "[35:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:300] Took 12.83s\n",
      "[35:300] loss_idt_x: 0.13764943454414605, G_fool_loss: 0.01481327274814248, cycled_x_loss: 0.13638595655560493, D_X_loss: 0.2944654782116413\n",
      "[35:300] loss_idt_y: 0.0955984615907073, F_fool_loss: 0.015946966232731938, cycled_y_loss: 0.09925230011343956, D_Y_loss: 0.2938856230676174\n",
      "[35:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:400] Took 12.82s\n",
      "[35:400] loss_idt_x: 0.13288897935301067, G_fool_loss: 0.014887340050190687, cycled_x_loss: 0.13302257061004638, D_X_loss: 0.2932196551561356\n",
      "[35:400] loss_idt_y: 0.09294350069016218, F_fool_loss: 0.015633567087352276, cycled_y_loss: 0.09850465707480907, D_Y_loss: 0.2938280126452446\n",
      "[35:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:500] Took 12.82s\n",
      "[35:500] loss_idt_x: 0.14318070273846387, G_fool_loss: 0.014963926039636135, cycled_x_loss: 0.14179298616945743, D_X_loss: 0.2947110420465469\n",
      "[35:500] loss_idt_y: 0.09319474663585424, F_fool_loss: 0.01563445367850363, cycled_y_loss: 0.09568523645401, D_Y_loss: 0.29358940228819846\n",
      "[35:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:600] Took 12.83s\n",
      "[35:600] loss_idt_x: 0.14039706733077764, G_fool_loss: 0.014794570235535503, cycled_x_loss: 0.13315097987651825, D_X_loss: 0.2936863259971142\n",
      "[35:600] loss_idt_y: 0.08826329115778207, F_fool_loss: 0.015417725648730993, cycled_y_loss: 0.09733984418213368, D_Y_loss: 0.2939122352004051\n",
      "[35:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:700] Took 12.83s\n",
      "[35:700] loss_idt_x: 0.13679874047636986, G_fool_loss: 0.014878696966916323, cycled_x_loss: 0.1284445836022496, D_X_loss: 0.29430767089128496\n",
      "[35:700] loss_idt_y: 0.103166973143816, F_fool_loss: 0.015871075689792635, cycled_y_loss: 0.10589937012642622, D_Y_loss: 0.29309849739074706\n",
      "[35:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:800] Took 12.82s\n",
      "[35:800] loss_idt_x: 0.13083879623562097, G_fool_loss: 0.015084834545850754, cycled_x_loss: 0.1351875640824437, D_X_loss: 0.2944873693585396\n",
      "[35:800] loss_idt_y: 0.0943904485926032, F_fool_loss: 0.01585023049265146, cycled_y_loss: 0.10295612748712302, D_Y_loss: 0.2918994876742363\n",
      "[35:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:900] Took 12.82s\n",
      "[35:900] loss_idt_x: 0.14713674742728472, G_fool_loss: 0.01477517387829721, cycled_x_loss: 0.14306579630821945, D_X_loss: 0.29512887954711914\n",
      "[35:900] loss_idt_y: 0.10119058158248663, F_fool_loss: 0.015765675948932766, cycled_y_loss: 0.1044629143923521, D_Y_loss: 0.2935141822695732\n",
      "[35:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:1000] Took 12.82s\n",
      "[35:1000] loss_idt_x: 0.13464056700468063, G_fool_loss: 0.014910947624593973, cycled_x_loss: 0.13397198367863894, D_X_loss: 0.2937806896865368\n",
      "[35:1000] loss_idt_y: 0.09288640800863504, F_fool_loss: 0.015555694457143545, cycled_y_loss: 0.09679867997765541, D_Y_loss: 0.2916985182464123\n",
      "[35:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:1100] Took 12.83s\n",
      "[35:1100] loss_idt_x: 0.14411331977695227, G_fool_loss: 0.01492909981869161, cycled_x_loss: 0.13646330211311578, D_X_loss: 0.29400416910648347\n",
      "[35:1100] loss_idt_y: 0.0956687531620264, F_fool_loss: 0.015340415146201849, cycled_y_loss: 0.09814639519900084, D_Y_loss: 0.2929499983787537\n",
      "[35:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[35:END] Completed epoch in 158.0660891532898s\n",
      "[35:1199] ep_loss_idt_x: 0.139 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.135 ep_D_X_loss: 0.294\n",
      "[35:1199] ep_loss_idt_y: 0.094 ep_F_fool_loss: 0.016 ep_cycled_y_loss: 0.099 ep_D_Y_loss: 0.293\n",
      "[35:END] Completed eval in 1.5279161930084229s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[35:END] Saving models and training information permanently\n",
      "[36:100] Took 14.80s\n",
      "[36:100] loss_idt_x: 0.13219251487404107, G_fool_loss: 0.014983040802180768, cycled_x_loss: 0.12539256073534488, D_X_loss: 0.2972737695276737\n",
      "[36:100] loss_idt_y: 0.09019888039678335, F_fool_loss: 0.015643733479082586, cycled_y_loss: 0.09926404096186162, D_Y_loss: 0.2961550235748291\n",
      "[36:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:200] Took 12.82s\n",
      "[36:200] loss_idt_x: 0.13418872594833375, G_fool_loss: 0.014760953895747662, cycled_x_loss: 0.13589476265013217, D_X_loss: 0.293769788146019\n",
      "[36:200] loss_idt_y: 0.08658870220184327, F_fool_loss: 0.015401115817949175, cycled_y_loss: 0.08966807089745998, D_Y_loss: 0.2932110697031021\n",
      "[36:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:300] Took 12.82s\n",
      "[36:300] loss_idt_x: 0.14082943990826607, G_fool_loss: 0.014803770994767547, cycled_x_loss: 0.13690600920468568, D_X_loss: 0.29281145706772804\n",
      "[36:300] loss_idt_y: 0.09201028171926737, F_fool_loss: 0.015367395970970392, cycled_y_loss: 0.11264831598848105, D_Y_loss: 0.2941683119535446\n",
      "[36:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:400] Took 12.86s\n",
      "[36:400] loss_idt_x: 0.13587414473295212, G_fool_loss: 0.014921087548136711, cycled_x_loss: 0.13483948573470117, D_X_loss: 0.29270892336964605\n",
      "[36:400] loss_idt_y: 0.08570799153298139, F_fool_loss: 0.015496304975822568, cycled_y_loss: 0.08517756655812264, D_Y_loss: 0.2918243020772934\n",
      "[36:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:500] Took 12.83s\n",
      "[36:500] loss_idt_x: 0.14486849874258043, G_fool_loss: 0.014533065091818571, cycled_x_loss: 0.13973172191530467, D_X_loss: 0.29321075320243833\n",
      "[36:500] loss_idt_y: 0.08748072780668735, F_fool_loss: 0.015363762443885208, cycled_y_loss: 0.09053796205669641, D_Y_loss: 0.29196082532405854\n",
      "[36:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:600] Took 12.83s\n",
      "[36:600] loss_idt_x: 0.13553913839161397, G_fool_loss: 0.014870065227150918, cycled_x_loss: 0.13454971201717852, D_X_loss: 0.29265028521418573\n",
      "[36:600] loss_idt_y: 0.08908527288585902, F_fool_loss: 0.01537616684101522, cycled_y_loss: 0.09869640123099088, D_Y_loss: 0.29508867248892784\n",
      "[36:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:700] Took 12.84s\n",
      "[36:700] loss_idt_x: 0.13252590585500001, G_fool_loss: 0.014758887561038136, cycled_x_loss: 0.12298874013125896, D_X_loss: 0.29410105019807814\n",
      "[36:700] loss_idt_y: 0.0993146713078022, F_fool_loss: 0.01566920184530318, cycled_y_loss: 0.10080947667360306, D_Y_loss: 0.2929084077477455\n",
      "[36:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:800] Took 12.83s\n",
      "[36:800] loss_idt_x: 0.12145806916058063, G_fool_loss: 0.014729383578523993, cycled_x_loss: 0.12295410718768834, D_X_loss: 0.29563904508948324\n",
      "[36:800] loss_idt_y: 0.08744998402893543, F_fool_loss: 0.015260553788393735, cycled_y_loss: 0.09155152417719364, D_Y_loss: 0.29313299745321275\n",
      "[36:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:900] Took 12.82s\n",
      "[36:900] loss_idt_x: 0.14247526306658984, G_fool_loss: 0.014745475752279162, cycled_x_loss: 0.1480553163588047, D_X_loss: 0.29517156690359114\n",
      "[36:900] loss_idt_y: 0.09137121424078941, F_fool_loss: 0.015648093931376936, cycled_y_loss: 0.0933420167118311, D_Y_loss: 0.2929297459125519\n",
      "[36:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:1000] Took 12.83s\n",
      "[36:1000] loss_idt_x: 0.13181401051580907, G_fool_loss: 0.015018943343311547, cycled_x_loss: 0.1320114144310355, D_X_loss: 0.29478489369153976\n",
      "[36:1000] loss_idt_y: 0.10290148239582778, F_fool_loss: 0.015519901756197213, cycled_y_loss: 0.10358035203069449, D_Y_loss: 0.29275729656219485\n",
      "[36:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:1100] Took 12.83s\n",
      "[36:1100] loss_idt_x: 0.138772885017097, G_fool_loss: 0.014700309336185456, cycled_x_loss: 0.13891812652349472, D_X_loss: 0.29432189896702765\n",
      "[36:1100] loss_idt_y: 0.08956012476235628, F_fool_loss: 0.015479346103966236, cycled_y_loss: 0.09353521063923836, D_Y_loss: 0.2948211920261383\n",
      "[36:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[36:END] Completed epoch in 159.59441232681274s\n",
      "[36:1199] ep_loss_idt_x: 0.135 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.134 ep_D_X_loss: 0.294\n",
      "[36:1199] ep_loss_idt_y: 0.092 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.097 ep_D_Y_loss: 0.293\n",
      "[36:END] Completed eval in 1.416215181350708s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[36:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[37:100] Took 14.85s\n",
      "[37:100] loss_idt_x: 0.12380031932145358, G_fool_loss: 0.014892002120614051, cycled_x_loss: 0.12243355747312307, D_X_loss: 0.2956661981344223\n",
      "[37:100] loss_idt_y: 0.10993642933666706, F_fool_loss: 0.015423615919426084, cycled_y_loss: 0.11206994842737913, D_Y_loss: 0.2961897951364517\n",
      "[37:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:200] Took 12.82s\n",
      "[37:200] loss_idt_x: 0.1423707704618573, G_fool_loss: 0.01504549222998321, cycled_x_loss: 0.1394034470245242, D_X_loss: 0.2934912601113319\n",
      "[37:200] loss_idt_y: 0.09827096644788981, F_fool_loss: 0.015627264184877275, cycled_y_loss: 0.10360014986246824, D_Y_loss: 0.2938510127365589\n",
      "[37:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:300] Took 12.83s\n",
      "[37:300] loss_idt_x: 0.13667769361287355, G_fool_loss: 0.014745798325166107, cycled_x_loss: 0.14110191956162452, D_X_loss: 0.2945038658380508\n",
      "[37:300] loss_idt_y: 0.09139769062399865, F_fool_loss: 0.015227656699717046, cycled_y_loss: 0.09754825979471207, D_Y_loss: 0.292623333632946\n",
      "[37:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:400] Took 12.83s\n",
      "[37:400] loss_idt_x: 0.13941142126917838, G_fool_loss: 0.01455953661352396, cycled_x_loss: 0.13253835201263428, D_X_loss: 0.29350088447332384\n",
      "[37:400] loss_idt_y: 0.08019738107919692, F_fool_loss: 0.015197130842134357, cycled_y_loss: 0.0838379990682006, D_Y_loss: 0.2929933938384056\n",
      "[37:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:500] Took 12.83s\n",
      "[37:500] loss_idt_x: 0.14452985215932132, G_fool_loss: 0.014542880794033408, cycled_x_loss: 0.13727072436362506, D_X_loss: 0.29310515746474264\n",
      "[37:500] loss_idt_y: 0.09920059841126204, F_fool_loss: 0.015487107988446951, cycled_y_loss: 0.10169801812618971, D_Y_loss: 0.29258968353271486\n",
      "[37:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:600] Took 12.83s\n",
      "[37:600] loss_idt_x: 0.1414596525579691, G_fool_loss: 0.014759542513638734, cycled_x_loss: 0.1380858688801527, D_X_loss: 0.292858746945858\n",
      "[37:600] loss_idt_y: 0.09019179947674275, F_fool_loss: 0.015367875937372447, cycled_y_loss: 0.09366132244467736, D_Y_loss: 0.29390862554311753\n",
      "[37:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:700] Took 12.83s\n",
      "[37:700] loss_idt_x: 0.14042112845927476, G_fool_loss: 0.014748476184904576, cycled_x_loss: 0.13391956869512797, D_X_loss: 0.2928247866034508\n",
      "[37:700] loss_idt_y: 0.0904675368219614, F_fool_loss: 0.015170529633760452, cycled_y_loss: 0.09590541895478964, D_Y_loss: 0.2926622813940048\n",
      "[37:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:800] Took 12.83s\n",
      "[37:800] loss_idt_x: 0.13498003512620926, G_fool_loss: 0.014738442692905664, cycled_x_loss: 0.13127416860312224, D_X_loss: 0.29405280977487563\n",
      "[37:800] loss_idt_y: 0.09872547648847103, F_fool_loss: 0.01517357025295496, cycled_y_loss: 0.09924942322075367, D_Y_loss: 0.2938728931546211\n",
      "[37:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:900] Took 12.83s\n",
      "[37:900] loss_idt_x: 0.14490344580262898, G_fool_loss: 0.014698690325021744, cycled_x_loss: 0.14423263795673846, D_X_loss: 0.29568239897489546\n",
      "[37:900] loss_idt_y: 0.09714980412274599, F_fool_loss: 0.015385854467749595, cycled_y_loss: 0.10026867542415857, D_Y_loss: 0.2924953979253769\n",
      "[37:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:1000] Took 12.84s\n",
      "[37:1000] loss_idt_x: 0.14177964478731156, G_fool_loss: 0.014693006295710803, cycled_x_loss: 0.13743190821260215, D_X_loss: 0.29399234771728516\n",
      "[37:1000] loss_idt_y: 0.08775314629077911, F_fool_loss: 0.015245231296867133, cycled_y_loss: 0.09482913546264171, D_Y_loss: 0.29231993943452833\n",
      "[37:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:1100] Took 12.83s\n",
      "[37:1100] loss_idt_x: 0.12952038649469613, G_fool_loss: 0.014685020381584764, cycled_x_loss: 0.12652018524706363, D_X_loss: 0.29437620401382447\n",
      "[37:1100] loss_idt_y: 0.09597991611808539, F_fool_loss: 0.01511383954435587, cycled_y_loss: 0.10158176489174366, D_Y_loss: 0.2934630608558655\n",
      "[37:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[37:END] Completed epoch in 160.0581250190735s\n",
      "[37:1199] ep_loss_idt_x: 0.138 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.135 ep_D_X_loss: 0.294\n",
      "[37:1199] ep_loss_idt_y: 0.095 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.099 ep_D_Y_loss: 0.293\n",
      "[37:END] Completed eval in 1.3833022117614746s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[37:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[38:100] Took 14.79s\n",
      "[38:100] loss_idt_x: 0.1343166346102953, G_fool_loss: 0.014987849658355116, cycled_x_loss: 0.13142483867704868, D_X_loss: 0.29568949848413467\n",
      "[38:100] loss_idt_y: 0.10849842742085457, F_fool_loss: 0.01536956014111638, cycled_y_loss: 0.11054239384829997, D_Y_loss: 0.2951243072748184\n",
      "[38:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:200] Took 12.83s\n",
      "[38:200] loss_idt_x: 0.13944341033697127, G_fool_loss: 0.014826443362981081, cycled_x_loss: 0.13960250712931155, D_X_loss: 0.29408320397138593\n",
      "[38:200] loss_idt_y: 0.08891586054116488, F_fool_loss: 0.015222530951723457, cycled_y_loss: 0.09303705267608166, D_Y_loss: 0.2932007110118866\n",
      "[38:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:300] Took 12.82s\n",
      "[38:300] loss_idt_x: 0.13523605395108462, G_fool_loss: 0.014563212087377906, cycled_x_loss: 0.1353914849087596, D_X_loss: 0.29396990209817886\n",
      "[38:300] loss_idt_y: 0.09372303660959005, F_fool_loss: 0.015622647712007165, cycled_y_loss: 0.09840059716254473, D_Y_loss: 0.2941632667183876\n",
      "[38:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:400] Took 12.83s\n",
      "[38:400] loss_idt_x: 0.1332993594929576, G_fool_loss: 0.014784610336646438, cycled_x_loss: 0.12776850927621125, D_X_loss: 0.293015733063221\n",
      "[38:400] loss_idt_y: 0.09873182479292154, F_fool_loss: 0.015013920543715358, cycled_y_loss: 0.10118839405477047, D_Y_loss: 0.2938548266887665\n",
      "[38:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:500] Took 12.83s\n",
      "[38:500] loss_idt_x: 0.13281508505344392, G_fool_loss: 0.014398498758673668, cycled_x_loss: 0.13091393489390613, D_X_loss: 0.29219849571585654\n",
      "[38:500] loss_idt_y: 0.091736304089427, F_fool_loss: 0.015013765385374427, cycled_y_loss: 0.09024962220340967, D_Y_loss: 0.29283592879772186\n",
      "[38:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:600] Took 12.83s\n",
      "[38:600] loss_idt_x: 0.14736458033323288, G_fool_loss: 0.014896949622780084, cycled_x_loss: 0.14046956218779086, D_X_loss: 0.2929088555276394\n",
      "[38:600] loss_idt_y: 0.0857032946497202, F_fool_loss: 0.01523721383884549, cycled_y_loss: 0.08497310761362314, D_Y_loss: 0.29297366857528684\n",
      "[38:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:700] Took 12.83s\n",
      "[38:700] loss_idt_x: 0.1438380630686879, G_fool_loss: 0.014742286605760456, cycled_x_loss: 0.1395999677479267, D_X_loss: 0.29387751817703245\n",
      "[38:700] loss_idt_y: 0.09623234484344721, F_fool_loss: 0.015158133879303932, cycled_y_loss: 0.09620296824723482, D_Y_loss: 0.2932435312867165\n",
      "[38:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:800] Took 12.82s\n",
      "[38:800] loss_idt_x: 0.13596714682877065, G_fool_loss: 0.014402624126523733, cycled_x_loss: 0.1343106685206294, D_X_loss: 0.2922910577058792\n",
      "[38:800] loss_idt_y: 0.0808642914146185, F_fool_loss: 0.015065643694251776, cycled_y_loss: 0.08202837871387601, D_Y_loss: 0.2925461208820343\n",
      "[38:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:900] Took 12.82s\n",
      "[38:900] loss_idt_x: 0.1416794342547655, G_fool_loss: 0.014546037018299103, cycled_x_loss: 0.13567721519619227, D_X_loss: 0.293363955616951\n",
      "[38:900] loss_idt_y: 0.08628546640276909, F_fool_loss: 0.015090192509815097, cycled_y_loss: 0.0882368779182434, D_Y_loss: 0.2904103550314903\n",
      "[38:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:1000] Took 12.83s\n",
      "[38:1000] loss_idt_x: 0.1405203428864479, G_fool_loss: 0.014516431586816907, cycled_x_loss: 0.14097381718456745, D_X_loss: 0.2926208484172821\n",
      "[38:1000] loss_idt_y: 0.10795522958040238, F_fool_loss: 0.015044280216097832, cycled_y_loss: 0.11425085816532374, D_Y_loss: 0.29232576459646226\n",
      "[38:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:1100] Took 12.90s\n",
      "[38:1100] loss_idt_x: 0.1284102588891983, G_fool_loss: 0.01439496161416173, cycled_x_loss: 0.1270689555630088, D_X_loss: 0.2929398000240326\n",
      "[38:1100] loss_idt_y: 0.10037690382450819, F_fool_loss: 0.015310922851786018, cycled_y_loss: 0.10510390218347311, D_Y_loss: 0.29218624472618104\n",
      "[38:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[38:END] Completed epoch in 160.18922781944275s\n",
      "[38:1199] ep_loss_idt_x: 0.138 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.135 ep_D_X_loss: 0.293\n",
      "[38:1199] ep_loss_idt_y: 0.093 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.096 ep_D_Y_loss: 0.293\n",
      "[38:END] Completed eval in 1.5937044620513916s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[38:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[39:100] Took 14.92s\n",
      "[39:100] loss_idt_x: 0.1281609234958887, G_fool_loss: 0.014918823204934597, cycled_x_loss: 0.12812132239341736, D_X_loss: 0.29514174044132235\n",
      "[39:100] loss_idt_y: 0.08346343141049146, F_fool_loss: 0.015213961526751519, cycled_y_loss: 0.0902752928994596, D_Y_loss: 0.2948522427678108\n",
      "[39:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:200] Took 12.88s\n",
      "[39:200] loss_idt_x: 0.14307384550571442, G_fool_loss: 0.01491396125406027, cycled_x_loss: 0.1401383502036333, D_X_loss: 0.29116131067276\n",
      "[39:200] loss_idt_y: 0.09442902095615864, F_fool_loss: 0.014573754677549004, cycled_y_loss: 0.09575626719743013, D_Y_loss: 0.2915534043312073\n",
      "[39:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:300] Took 12.82s\n",
      "[39:300] loss_idt_x: 0.14001333203166724, G_fool_loss: 0.014542824709787966, cycled_x_loss: 0.1334597110003233, D_X_loss: 0.29378739565610884\n",
      "[39:300] loss_idt_y: 0.09066430795937777, F_fool_loss: 0.014909624950960279, cycled_y_loss: 0.09538818709552288, D_Y_loss: 0.2928022348880768\n",
      "[39:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:400] Took 12.84s\n",
      "[39:400] loss_idt_x: 0.14188123241066933, G_fool_loss: 0.01451822567731142, cycled_x_loss: 0.139134203158319, D_X_loss: 0.29226968944072723\n",
      "[39:400] loss_idt_y: 0.1140350154414773, F_fool_loss: 0.014816291024908423, cycled_y_loss: 0.12185386069118977, D_Y_loss: 0.2938085377216339\n",
      "[39:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:500] Took 12.82s\n",
      "[39:500] loss_idt_x: 0.13752134915441275, G_fool_loss: 0.014602926699444652, cycled_x_loss: 0.131598392277956, D_X_loss: 0.2938771817088127\n",
      "[39:500] loss_idt_y: 0.09914743047207594, F_fool_loss: 0.015026076771318913, cycled_y_loss: 0.09923120092600585, D_Y_loss: 0.29259477883577345\n",
      "[39:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:600] Took 12.83s\n",
      "[39:600] loss_idt_x: 0.12297350279986859, G_fool_loss: 0.014626785507425666, cycled_x_loss: 0.12185975890606641, D_X_loss: 0.2934584644436836\n",
      "[39:600] loss_idt_y: 0.09868372058495879, F_fool_loss: 0.015106036709621549, cycled_y_loss: 0.10258215624839068, D_Y_loss: 0.2932475745677948\n",
      "[39:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:700] Took 12.82s\n",
      "[39:700] loss_idt_x: 0.12752748046070336, G_fool_loss: 0.014424840258434414, cycled_x_loss: 0.12729099791496992, D_X_loss: 0.29385230094194414\n",
      "[39:700] loss_idt_y: 0.08999376386404037, F_fool_loss: 0.01498374137096107, cycled_y_loss: 0.0921510748565197, D_Y_loss: 0.2920986354351044\n",
      "[39:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:800] Took 12.83s\n",
      "[39:800] loss_idt_x: 0.13027779676020146, G_fool_loss: 0.01450783952139318, cycled_x_loss: 0.13198995299637317, D_X_loss: 0.2923159608244896\n",
      "[39:800] loss_idt_y: 0.0999059540219605, F_fool_loss: 0.01508560786023736, cycled_y_loss: 0.09942498400807381, D_Y_loss: 0.2937007541954517\n",
      "[39:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:900] Took 12.83s\n",
      "[39:900] loss_idt_x: 0.13018898785114288, G_fool_loss: 0.014377097599208355, cycled_x_loss: 0.13494722526520492, D_X_loss: 0.292308846116066\n",
      "[39:900] loss_idt_y: 0.09963732853531837, F_fool_loss: 0.014584681959822774, cycled_y_loss: 0.10483538839966058, D_Y_loss: 0.29316044121980667\n",
      "[39:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:1000] Took 12.83s\n",
      "[39:1000] loss_idt_x: 0.13192137602716683, G_fool_loss: 0.014297102121636271, cycled_x_loss: 0.13002314381301402, D_X_loss: 0.2947755026817322\n",
      "[39:1000] loss_idt_y: 0.0928660622984171, F_fool_loss: 0.01458875698968768, cycled_y_loss: 0.0987234702333808, D_Y_loss: 0.2926520723104477\n",
      "[39:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:1100] Took 12.86s\n",
      "[39:1100] loss_idt_x: 0.1427477490156889, G_fool_loss: 0.014765171725302935, cycled_x_loss: 0.1361034331843257, D_X_loss: 0.2920109894871712\n",
      "[39:1100] loss_idt_y: 0.09835066575556993, F_fool_loss: 0.014819468520581722, cycled_y_loss: 0.10381314430385828, D_Y_loss: 0.2932728084921837\n",
      "[39:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[39:END] Completed epoch in 159.92748260498047s\n",
      "[39:1199] ep_loss_idt_x: 0.134 ep_G_fool_loss: 0.015 ep_cycled_x_loss: 0.132 ep_D_X_loss: 0.293\n",
      "[39:1199] ep_loss_idt_y: 0.096 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.100 ep_D_Y_loss: 0.293\n",
      "[39:END] Completed eval in 1.4521193504333496s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[39:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[40:100] Took 14.99s\n",
      "[40:100] loss_idt_x: 0.1329244413599372, G_fool_loss: 0.01437135842628777, cycled_x_loss: 0.13000907007604837, D_X_loss: 0.2965210449695587\n",
      "[40:100] loss_idt_y: 0.09767321787774563, F_fool_loss: 0.014890783289447427, cycled_y_loss: 0.10614178378134966, D_Y_loss: 0.2959331476688385\n",
      "[40:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:200] Took 12.81s\n",
      "[40:200] loss_idt_x: 0.13242379639297724, G_fool_loss: 0.014552531382068992, cycled_x_loss: 0.12234485011547803, D_X_loss: 0.2925076040625572\n",
      "[40:200] loss_idt_y: 0.08878189506009221, F_fool_loss: 0.014844472305849194, cycled_y_loss: 0.09197508003562689, D_Y_loss: 0.29207473635673525\n",
      "[40:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:300] Took 12.83s\n",
      "[40:300] loss_idt_x: 0.1354076675325632, G_fool_loss: 0.014516263920813798, cycled_x_loss: 0.13159351464360952, D_X_loss: 0.29352094024419784\n",
      "[40:300] loss_idt_y: 0.08611157801002264, F_fool_loss: 0.014684089384973049, cycled_y_loss: 0.0858958575874567, D_Y_loss: 0.29249104499816897\n",
      "[40:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:400] Took 12.83s\n",
      "[40:400] loss_idt_x: 0.13096365574747323, G_fool_loss: 0.014419212061911822, cycled_x_loss: 0.1362795051187277, D_X_loss: 0.29341122657060625\n",
      "[40:400] loss_idt_y: 0.09895635090768337, F_fool_loss: 0.014577377522364258, cycled_y_loss: 0.10020747151225805, D_Y_loss: 0.2933973988890648\n",
      "[40:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:500] Took 12.83s\n",
      "[40:500] loss_idt_x: 0.1291992600634694, G_fool_loss: 0.014451513215899468, cycled_x_loss: 0.12348175089806318, D_X_loss: 0.29430788815021514\n",
      "[40:500] loss_idt_y: 0.10442583359777928, F_fool_loss: 0.014750191867351532, cycled_y_loss: 0.10617342840880156, D_Y_loss: 0.29285954058170316\n",
      "[40:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:600] Took 12.82s\n",
      "[40:600] loss_idt_x: 0.14828491244465114, G_fool_loss: 0.014533403171226382, cycled_x_loss: 0.14725400060415267, D_X_loss: 0.2930756440758705\n",
      "[40:600] loss_idt_y: 0.08723969653248786, F_fool_loss: 0.014574871379882098, cycled_y_loss: 0.09024418488144875, D_Y_loss: 0.29258932173252106\n",
      "[40:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:700] Took 12.83s\n",
      "[40:700] loss_idt_x: 0.1353085096552968, G_fool_loss: 0.014653479326516389, cycled_x_loss: 0.13135207403451205, D_X_loss: 0.29435927033424375\n",
      "[40:700] loss_idt_y: 0.08774368626996874, F_fool_loss: 0.014653463307768106, cycled_y_loss: 0.09375820256769657, D_Y_loss: 0.29322208762168883\n",
      "[40:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:800] Took 12.83s\n",
      "[40:800] loss_idt_x: 0.12959248434752227, G_fool_loss: 0.014646206125617027, cycled_x_loss: 0.12376097802072764, D_X_loss: 0.2918200480937958\n",
      "[40:800] loss_idt_y: 0.086950121819973, F_fool_loss: 0.01452246163971722, cycled_y_loss: 0.09206291478127242, D_Y_loss: 0.2924445739388466\n",
      "[40:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:900] Took 12.83s\n",
      "[40:900] loss_idt_x: 0.13416105184704066, G_fool_loss: 0.014550938494503498, cycled_x_loss: 0.13663821563124656, D_X_loss: 0.29220710158348084\n",
      "[40:900] loss_idt_y: 0.09622393444180488, F_fool_loss: 0.014775528647005558, cycled_y_loss: 0.09935465913265944, D_Y_loss: 0.2909880742430687\n",
      "[40:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:1000] Took 12.84s\n",
      "[40:1000] loss_idt_x: 0.12482494965195656, G_fool_loss: 0.014452490750700235, cycled_x_loss: 0.11876258958131075, D_X_loss: 0.2918668934702873\n",
      "[40:1000] loss_idt_y: 0.09222431562840938, F_fool_loss: 0.014522492280229926, cycled_y_loss: 0.09797381997108459, D_Y_loss: 0.29203077882528305\n",
      "[40:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:1100] Took 12.83s\n",
      "[40:1100] loss_idt_x: 0.1477355644479394, G_fool_loss: 0.01447598533704877, cycled_x_loss: 0.14431086257100106, D_X_loss: 0.29172533959150315\n",
      "[40:1100] loss_idt_y: 0.08529960632324218, F_fool_loss: 0.014496969105675817, cycled_y_loss: 0.09241087600588799, D_Y_loss: 0.2934393897652626\n",
      "[40:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[40:END] Completed epoch in 161.0630578994751s\n",
      "[40:1199] ep_loss_idt_x: 0.133 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.131 ep_D_X_loss: 0.293\n",
      "[40:1199] ep_loss_idt_y: 0.091 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.096 ep_D_Y_loss: 0.293\n",
      "[40:END] Completed eval in 1.4411234855651855s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[40:END] Saving models and training information permanently\n",
      "[41:100] Took 14.82s\n",
      "[41:100] loss_idt_x: 0.1509229002520442, G_fool_loss: 0.014552198089659215, cycled_x_loss: 0.15573482356965543, D_X_loss: 0.2965387201309204\n",
      "[41:100] loss_idt_y: 0.10504054848104716, F_fool_loss: 0.014725676234811545, cycled_y_loss: 0.110253977291286, D_Y_loss: 0.29507885485887525\n",
      "[41:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:200] Took 12.82s\n",
      "[41:200] loss_idt_x: 0.12293810851871967, G_fool_loss: 0.014435499496757985, cycled_x_loss: 0.12403840105980635, D_X_loss: 0.2926984575390816\n",
      "[41:200] loss_idt_y: 0.10068344812840223, F_fool_loss: 0.014599986914545298, cycled_y_loss: 0.10198312286287546, D_Y_loss: 0.2920845636725426\n",
      "[41:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:300] Took 12.82s\n",
      "[41:300] loss_idt_x: 0.1323367738723755, G_fool_loss: 0.014484766265377402, cycled_x_loss: 0.12811660271137953, D_X_loss: 0.2928367254137993\n",
      "[41:300] loss_idt_y: 0.09728552788496017, F_fool_loss: 0.01469097739085555, cycled_y_loss: 0.09979939499869943, D_Y_loss: 0.29261654525995257\n",
      "[41:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:400] Took 12.82s\n",
      "[41:400] loss_idt_x: 0.14039034098386766, G_fool_loss: 0.014331161994487047, cycled_x_loss: 0.13925517085939645, D_X_loss: 0.2933375057578087\n",
      "[41:400] loss_idt_y: 0.0925098849274218, F_fool_loss: 0.01456054113805294, cycled_y_loss: 0.09500017054378987, D_Y_loss: 0.29319046884775163\n",
      "[41:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:500] Took 12.83s\n",
      "[41:500] loss_idt_x: 0.1328829226270318, G_fool_loss: 0.014415599843487144, cycled_x_loss: 0.12846828784793615, D_X_loss: 0.2931676658987999\n",
      "[41:500] loss_idt_y: 0.08704316575080157, F_fool_loss: 0.014747540606185794, cycled_y_loss: 0.09487611584365369, D_Y_loss: 0.29327385663986205\n",
      "[41:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:600] Took 12.85s\n",
      "[41:600] loss_idt_x: 0.13327021781355142, G_fool_loss: 0.014615781884640456, cycled_x_loss: 0.12919313624501227, D_X_loss: 0.2928265434503555\n",
      "[41:600] loss_idt_y: 0.09784186139702797, F_fool_loss: 0.01469005928374827, cycled_y_loss: 0.10315915878862142, D_Y_loss: 0.2938442361354828\n",
      "[41:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:700] Took 12.82s\n",
      "[41:700] loss_idt_x: 0.11994487117975951, G_fool_loss: 0.014462735233828426, cycled_x_loss: 0.12366750836372375, D_X_loss: 0.29277521252632144\n",
      "[41:700] loss_idt_y: 0.0893928549438715, F_fool_loss: 0.014746504323557019, cycled_y_loss: 0.09587938301265239, D_Y_loss: 0.29389569491147993\n",
      "[41:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:800] Took 12.82s\n",
      "[41:800] loss_idt_x: 0.13368241012096405, G_fool_loss: 0.014597437372431158, cycled_x_loss: 0.13215309225022792, D_X_loss: 0.29199681103229524\n",
      "[41:800] loss_idt_y: 0.09363412050530315, F_fool_loss: 0.014524713205173612, cycled_y_loss: 0.09872595299035311, D_Y_loss: 0.2916875544190407\n",
      "[41:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:900] Took 12.83s\n",
      "[41:900] loss_idt_x: 0.1279059022665024, G_fool_loss: 0.014477468561381102, cycled_x_loss: 0.1245883971452713, D_X_loss: 0.2940793368220329\n",
      "[41:900] loss_idt_y: 0.0892207669466734, F_fool_loss: 0.014471936672925949, cycled_y_loss: 0.0917518663406372, D_Y_loss: 0.293640176653862\n",
      "[41:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:1000] Took 12.81s\n",
      "[41:1000] loss_idt_x: 0.14348192006349564, G_fool_loss: 0.014313882887363434, cycled_x_loss: 0.1357390146702528, D_X_loss: 0.29213186651468276\n",
      "[41:1000] loss_idt_y: 0.08976761393249034, F_fool_loss: 0.014594599697738886, cycled_y_loss: 0.09433009430766105, D_Y_loss: 0.29300799399614336\n",
      "[41:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:1100] Took 12.82s\n",
      "[41:1100] loss_idt_x: 0.1375069622695446, G_fool_loss: 0.014257705453783274, cycled_x_loss: 0.13240334261208772, D_X_loss: 0.2932972693443298\n",
      "[41:1100] loss_idt_y: 0.10338567957282066, F_fool_loss: 0.01447411322966218, cycled_y_loss: 0.10751261718571187, D_Y_loss: 0.2921779927611351\n",
      "[41:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[41:END] Completed epoch in 159.77923035621643s\n",
      "[41:1199] ep_loss_idt_x: 0.134 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.132 ep_D_X_loss: 0.293\n",
      "[41:1199] ep_loss_idt_y: 0.095 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.099 ep_D_Y_loss: 0.293\n",
      "[41:END] Completed eval in 1.4032518863677979s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[41:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[42:100] Took 14.81s\n",
      "[42:100] loss_idt_x: 0.12649372644722462, G_fool_loss: 0.014716404220089317, cycled_x_loss: 0.12271837390959263, D_X_loss: 0.29616214156150816\n",
      "[42:100] loss_idt_y: 0.08354834191501141, F_fool_loss: 0.014655733769759536, cycled_y_loss: 0.0846888816729188, D_Y_loss: 0.2966872042417526\n",
      "[42:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:200] Took 12.83s\n",
      "[42:200] loss_idt_x: 0.12234216511249542, G_fool_loss: 0.014462970849126577, cycled_x_loss: 0.12113376982510089, D_X_loss: 0.293883344233036\n",
      "[42:200] loss_idt_y: 0.09684734083712102, F_fool_loss: 0.014487416250631213, cycled_y_loss: 0.10358738012611866, D_Y_loss: 0.2934644514322281\n",
      "[42:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:300] Took 12.85s\n",
      "[42:300] loss_idt_x: 0.12923141941428185, G_fool_loss: 0.014314771275967359, cycled_x_loss: 0.13228857960551976, D_X_loss: 0.2924302417039871\n",
      "[42:300] loss_idt_y: 0.09777776956558228, F_fool_loss: 0.01439711419865489, cycled_y_loss: 0.09774692565202713, D_Y_loss: 0.29260390520095825\n",
      "[42:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:400] Took 12.84s\n",
      "[42:400] loss_idt_x: 0.13359532982110978, G_fool_loss: 0.01457036537118256, cycled_x_loss: 0.13049347531050443, D_X_loss: 0.2927993300557137\n",
      "[42:400] loss_idt_y: 0.10460795234888792, F_fool_loss: 0.014396298583596945, cycled_y_loss: 0.10538055397570133, D_Y_loss: 0.2918993216753006\n",
      "[42:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:500] Took 12.84s\n",
      "[42:500] loss_idt_x: 0.14367229156196118, G_fool_loss: 0.01457674590870738, cycled_x_loss: 0.14466471500694753, D_X_loss: 0.2935546413064003\n",
      "[42:500] loss_idt_y: 0.08679888911545276, F_fool_loss: 0.014456499814987183, cycled_y_loss: 0.08571294169872999, D_Y_loss: 0.2941098949313164\n",
      "[42:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:600] Took 12.83s\n",
      "[42:600] loss_idt_x: 0.12649030033499004, G_fool_loss: 0.01451509797014296, cycled_x_loss: 0.1296710114553571, D_X_loss: 0.29213968753814695\n",
      "[42:600] loss_idt_y: 0.09356200993061066, F_fool_loss: 0.014638721160590649, cycled_y_loss: 0.09848850674927234, D_Y_loss: 0.2923639968037605\n",
      "[42:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:700] Took 12.82s\n",
      "[42:700] loss_idt_x: 0.12520751647651196, G_fool_loss: 0.014397791791707278, cycled_x_loss: 0.12651436291635038, D_X_loss: 0.2936386936903\n",
      "[42:700] loss_idt_y: 0.1003259750828147, F_fool_loss: 0.014756144043058157, cycled_y_loss: 0.1008236800134182, D_Y_loss: 0.29219016671180725\n",
      "[42:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:800] Took 12.82s\n",
      "[42:800] loss_idt_x: 0.13494034070521593, G_fool_loss: 0.014485170459374785, cycled_x_loss: 0.13186269003897905, D_X_loss: 0.2941551971435547\n",
      "[42:800] loss_idt_y: 0.09410058554261923, F_fool_loss: 0.014503678977489472, cycled_y_loss: 0.09886068411171436, D_Y_loss: 0.29261055231094363\n",
      "[42:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:900] Took 12.83s\n",
      "[42:900] loss_idt_x: 0.13065887801349163, G_fool_loss: 0.014554154826328158, cycled_x_loss: 0.12631053637713194, D_X_loss: 0.2928937783837318\n",
      "[42:900] loss_idt_y: 0.08947321958839893, F_fool_loss: 0.01468955029733479, cycled_y_loss: 0.08963653106242418, D_Y_loss: 0.2909154358506203\n",
      "[42:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:1000] Took 12.83s\n",
      "[42:1000] loss_idt_x: 0.14279301699250938, G_fool_loss: 0.01440360900014639, cycled_x_loss: 0.13849109683185815, D_X_loss: 0.2926208236813545\n",
      "[42:1000] loss_idt_y: 0.09353263169527054, F_fool_loss: 0.01468487348407507, cycled_y_loss: 0.10338114678859711, D_Y_loss: 0.29185504734516143\n",
      "[42:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:1100] Took 12.83s\n",
      "[42:1100] loss_idt_x: 0.1348892603069544, G_fool_loss: 0.014313055705279111, cycled_x_loss: 0.13422357555478812, D_X_loss: 0.29166395604610446\n",
      "[42:1100] loss_idt_y: 0.10000912137329579, F_fool_loss: 0.014612152343615889, cycled_y_loss: 0.10442411568015814, D_Y_loss: 0.29245057225227356\n",
      "[42:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[42:END] Completed epoch in 160.0797598361969s\n",
      "[42:1199] ep_loss_idt_x: 0.133 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.131 ep_D_X_loss: 0.293\n",
      "[42:1199] ep_loss_idt_y: 0.095 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.098 ep_D_Y_loss: 0.293\n",
      "[42:END] Completed eval in 1.4282100200653076s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[42:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[43:100] Took 14.82s\n",
      "[43:100] loss_idt_x: 0.12383806996047497, G_fool_loss: 0.014754985459148884, cycled_x_loss: 0.12845922410488128, D_X_loss: 0.29577119946479796\n",
      "[43:100] loss_idt_y: 0.0926988934352994, F_fool_loss: 0.014622858949005604, cycled_y_loss: 0.09723976019769907, D_Y_loss: 0.2963603463768959\n",
      "[43:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:200] Took 12.83s\n",
      "[43:200] loss_idt_x: 0.13666257336735727, G_fool_loss: 0.014495250768959522, cycled_x_loss: 0.13807823561131954, D_X_loss: 0.2946738797426224\n",
      "[43:200] loss_idt_y: 0.09624581150710583, F_fool_loss: 0.014591768775135279, cycled_y_loss: 0.09832575481384992, D_Y_loss: 0.2923436638712883\n",
      "[43:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:300] Took 12.83s\n",
      "[43:300] loss_idt_x: 0.12205187756568193, G_fool_loss: 0.014493693364784122, cycled_x_loss: 0.12053564507514239, D_X_loss: 0.2922018560767174\n",
      "[43:300] loss_idt_y: 0.09688888143748045, F_fool_loss: 0.014583622962236404, cycled_y_loss: 0.09534274000674486, D_Y_loss: 0.2923657855391502\n",
      "[43:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:400] Took 12.82s\n",
      "[43:400] loss_idt_x: 0.13686428941786288, G_fool_loss: 0.014794004894793034, cycled_x_loss: 0.13913669757544994, D_X_loss: 0.2929946455359459\n",
      "[43:400] loss_idt_y: 0.10471223648637533, F_fool_loss: 0.014532241486012936, cycled_y_loss: 0.10625816479325295, D_Y_loss: 0.2925040706992149\n",
      "[43:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:500] Took 12.82s\n",
      "[43:500] loss_idt_x: 0.13043887067586182, G_fool_loss: 0.014325660392642022, cycled_x_loss: 0.1319069619476795, D_X_loss: 0.29484817922115325\n",
      "[43:500] loss_idt_y: 0.08832635965198278, F_fool_loss: 0.014572773715481163, cycled_y_loss: 0.09522942781448364, D_Y_loss: 0.29244995534420015\n",
      "[43:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:600] Took 12.83s\n",
      "[43:600] loss_idt_x: 0.13387916706502437, G_fool_loss: 0.014570233700796962, cycled_x_loss: 0.13323422200977802, D_X_loss: 0.2932136258482933\n",
      "[43:600] loss_idt_y: 0.0908373748883605, F_fool_loss: 0.014376544337719678, cycled_y_loss: 0.09260224230587483, D_Y_loss: 0.29324824720621107\n",
      "[43:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:700] Took 12.83s\n",
      "[43:700] loss_idt_x: 0.13775725044310094, G_fool_loss: 0.014306719293817877, cycled_x_loss: 0.14469539225101472, D_X_loss: 0.2932912063598633\n",
      "[43:700] loss_idt_y: 0.11271639801561832, F_fool_loss: 0.014449669104069472, cycled_y_loss: 0.10775707885622979, D_Y_loss: 0.29265936493873596\n",
      "[43:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:800] Took 12.84s\n",
      "[43:800] loss_idt_x: 0.13553391333669423, G_fool_loss: 0.014364843824878334, cycled_x_loss: 0.12906988054513932, D_X_loss: 0.2914673563838005\n",
      "[43:800] loss_idt_y: 0.08697571389377118, F_fool_loss: 0.014561943877488374, cycled_y_loss: 0.09068435717374086, D_Y_loss: 0.2919714152812958\n",
      "[43:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:900] Took 12.84s\n",
      "[43:900] loss_idt_x: 0.15146026149392128, G_fool_loss: 0.014488164382055402, cycled_x_loss: 0.14700930420309305, D_X_loss: 0.2923454427719116\n",
      "[43:900] loss_idt_y: 0.0847080759704113, F_fool_loss: 0.014453293299302459, cycled_y_loss: 0.08652168795466424, D_Y_loss: 0.29204465240240096\n",
      "[43:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:1000] Took 12.83s\n",
      "[43:1000] loss_idt_x: 0.1247408402338624, G_fool_loss: 0.014352793460711838, cycled_x_loss: 0.12223737262189388, D_X_loss: 0.2924708685278892\n",
      "[43:1000] loss_idt_y: 0.09192132081836463, F_fool_loss: 0.014761275937780738, cycled_y_loss: 0.09487871188670396, D_Y_loss: 0.2935842180252075\n",
      "[43:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:1100] Took 12.83s\n",
      "[43:1100] loss_idt_x: 0.1261329509317875, G_fool_loss: 0.01441038173623383, cycled_x_loss: 0.11884547058492899, D_X_loss: 0.29261083245277403\n",
      "[43:1100] loss_idt_y: 0.08763087447732687, F_fool_loss: 0.014483175482600927, cycled_y_loss: 0.09048609606921673, D_Y_loss: 0.2926429930329323\n",
      "[43:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[43:END] Completed epoch in 160.97806668281555s\n",
      "[43:1199] ep_loss_idt_x: 0.132 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.131 ep_D_X_loss: 0.293\n",
      "[43:1199] ep_loss_idt_y: 0.094 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.095 ep_D_Y_loss: 0.293\n",
      "[43:END] Completed eval in 1.4780399799346924s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[43:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[44:100] Took 14.80s\n",
      "[44:100] loss_idt_x: 0.13269732870161532, G_fool_loss: 0.014783539064228534, cycled_x_loss: 0.1277958795800805, D_X_loss: 0.29573444873094556\n",
      "[44:100] loss_idt_y: 0.09999016877263785, F_fool_loss: 0.014607002101838589, cycled_y_loss: 0.09909811332821845, D_Y_loss: 0.29633337080478667\n",
      "[44:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:200] Took 12.82s\n",
      "[44:200] loss_idt_x: 0.13107865706086158, G_fool_loss: 0.014438683986663819, cycled_x_loss: 0.12696165081113578, D_X_loss: 0.29133700162172316\n",
      "[44:200] loss_idt_y: 0.0898698092252016, F_fool_loss: 0.01446583801880479, cycled_y_loss: 0.09046455912292004, D_Y_loss: 0.29311969965696333\n",
      "[44:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:300] Took 12.82s\n",
      "[44:300] loss_idt_x: 0.12443724725395441, G_fool_loss: 0.014348611319437623, cycled_x_loss: 0.12486807502806187, D_X_loss: 0.2913999155163765\n",
      "[44:300] loss_idt_y: 0.0884359273687005, F_fool_loss: 0.01424120631068945, cycled_y_loss: 0.09346973203122616, D_Y_loss: 0.2931581112742424\n",
      "[44:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:400] Took 12.82s\n",
      "[44:400] loss_idt_x: 0.134334603138268, G_fool_loss: 0.014500326020643115, cycled_x_loss: 0.13404850121587514, D_X_loss: 0.29155912876129153\n",
      "[44:400] loss_idt_y: 0.09230391759425402, F_fool_loss: 0.014169344026595355, cycled_y_loss: 0.09863917805254459, D_Y_loss: 0.2925987035036087\n",
      "[44:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:500] Took 12.84s\n",
      "[44:500] loss_idt_x: 0.14564617339521646, G_fool_loss: 0.01447044407017529, cycled_x_loss: 0.139914953969419, D_X_loss: 0.2926407352089882\n",
      "[44:500] loss_idt_y: 0.08817422360181809, F_fool_loss: 0.014453620556741953, cycled_y_loss: 0.09262063175439834, D_Y_loss: 0.29228525608778\n",
      "[44:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:600] Took 12.84s\n",
      "[44:600] loss_idt_x: 0.12253605585545302, G_fool_loss: 0.014483896093443036, cycled_x_loss: 0.12215156685560942, D_X_loss: 0.2920778515934944\n",
      "[44:600] loss_idt_y: 0.09149082958698272, F_fool_loss: 0.014446861129254102, cycled_y_loss: 0.09612540040165186, D_Y_loss: 0.294550347328186\n",
      "[44:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:700] Took 12.82s\n",
      "[44:700] loss_idt_x: 0.1348374092951417, G_fool_loss: 0.014285464761778712, cycled_x_loss: 0.1328788560256362, D_X_loss: 0.2927152979373932\n",
      "[44:700] loss_idt_y: 0.09360485479235649, F_fool_loss: 0.014541777977719904, cycled_y_loss: 0.0993507532030344, D_Y_loss: 0.29375267565250396\n",
      "[44:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:800] Took 12.83s\n",
      "[44:800] loss_idt_x: 0.12206100601702928, G_fool_loss: 0.0144053528085351, cycled_x_loss: 0.11833065170794725, D_X_loss: 0.29295619904994963\n",
      "[44:800] loss_idt_y: 0.09887606225907802, F_fool_loss: 0.014369883313775063, cycled_y_loss: 0.10185785803943873, D_Y_loss: 0.294085421860218\n",
      "[44:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:900] Took 12.82s\n",
      "[44:900] loss_idt_x: 0.1287988594919443, G_fool_loss: 0.014349329676479101, cycled_x_loss: 0.12686410527676345, D_X_loss: 0.2930150029063225\n",
      "[44:900] loss_idt_y: 0.08991448432207108, F_fool_loss: 0.014379494283348322, cycled_y_loss: 0.09631756767630577, D_Y_loss: 0.2927826458215714\n",
      "[44:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:1000] Took 12.83s\n",
      "[44:1000] loss_idt_x: 0.13761425156146287, G_fool_loss: 0.014419579626992345, cycled_x_loss: 0.13625384096056223, D_X_loss: 0.29374953240156176\n",
      "[44:1000] loss_idt_y: 0.08020806893706321, F_fool_loss: 0.014476447105407715, cycled_y_loss: 0.08459185007959605, D_Y_loss: 0.2922072979807854\n",
      "[44:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:1100] Took 12.82s\n",
      "[44:1100] loss_idt_x: 0.13142532393336295, G_fool_loss: 0.014496805761009455, cycled_x_loss: 0.13161220017820596, D_X_loss: 0.29244147688150407\n",
      "[44:1100] loss_idt_y: 0.09349112316966057, F_fool_loss: 0.014374914383515715, cycled_y_loss: 0.09806876007467508, D_Y_loss: 0.29318766698241233\n",
      "[44:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[44:END] Completed epoch in 159.88184523582458s\n",
      "[44:1199] ep_loss_idt_x: 0.131 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.129 ep_D_X_loss: 0.292\n",
      "[44:1199] ep_loss_idt_y: 0.091 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.096 ep_D_Y_loss: 0.293\n",
      "[44:END] Completed eval in 1.446164608001709s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[44:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[45:100] Took 14.82s\n",
      "[45:100] loss_idt_x: 0.1267745192721486, G_fool_loss: 0.014724786961451172, cycled_x_loss: 0.1247077402845025, D_X_loss: 0.2956299003958702\n",
      "[45:100] loss_idt_y: 0.08373052962124347, F_fool_loss: 0.014768051132559776, cycled_y_loss: 0.08937156960368156, D_Y_loss: 0.2954929307103157\n",
      "[45:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:200] Took 12.82s\n",
      "[45:200] loss_idt_x: 0.11639754123985767, G_fool_loss: 0.014654590813443065, cycled_x_loss: 0.10361309643834829, D_X_loss: 0.29231717586517336\n",
      "[45:200] loss_idt_y: 0.09936758406460285, F_fool_loss: 0.014712147954851389, cycled_y_loss: 0.1065738184005022, D_Y_loss: 0.29374976515769957\n",
      "[45:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:300] Took 12.84s\n",
      "[45:300] loss_idt_x: 0.1332338162884116, G_fool_loss: 0.014246917553246021, cycled_x_loss: 0.12819401614367962, D_X_loss: 0.2911876454949379\n",
      "[45:300] loss_idt_y: 0.07921988483518362, F_fool_loss: 0.014738102396950125, cycled_y_loss: 0.08387845043092966, D_Y_loss: 0.2926766836643219\n",
      "[45:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:400] Took 12.83s\n",
      "[45:400] loss_idt_x: 0.131126067340374, G_fool_loss: 0.01433795359916985, cycled_x_loss: 0.12687750395387412, D_X_loss: 0.29290436625480654\n",
      "[45:400] loss_idt_y: 0.09572262238711118, F_fool_loss: 0.014272968955338002, cycled_y_loss: 0.09758607551455498, D_Y_loss: 0.29203218668699266\n",
      "[45:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:500] Took 12.85s\n",
      "[45:500] loss_idt_x: 0.13824242286384106, G_fool_loss: 0.014598480053246021, cycled_x_loss: 0.13595556918531657, D_X_loss: 0.2925376072525978\n",
      "[45:500] loss_idt_y: 0.08770712917670608, F_fool_loss: 0.01458373979665339, cycled_y_loss: 0.09116704426705838, D_Y_loss: 0.2940633657574654\n",
      "[45:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:600] Took 12.83s\n",
      "[45:600] loss_idt_x: 0.13038697063922883, G_fool_loss: 0.014593610577285289, cycled_x_loss: 0.12421011205762625, D_X_loss: 0.2915771695971489\n",
      "[45:600] loss_idt_y: 0.0804613359645009, F_fool_loss: 0.01445858766324818, cycled_y_loss: 0.08588469687849283, D_Y_loss: 0.2937945285439491\n",
      "[45:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:700] Took 12.83s\n",
      "[45:700] loss_idt_x: 0.12805174808949232, G_fool_loss: 0.01446953259408474, cycled_x_loss: 0.1289601130411029, D_X_loss: 0.29254253685474396\n",
      "[45:700] loss_idt_y: 0.09355423301458358, F_fool_loss: 0.01450608802959323, cycled_y_loss: 0.09495082840323449, D_Y_loss: 0.2923721757531166\n",
      "[45:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:800] Took 12.83s\n",
      "[45:800] loss_idt_x: 0.12283333282917738, G_fool_loss: 0.014389209635555743, cycled_x_loss: 0.12339720591902732, D_X_loss: 0.2930696699023247\n",
      "[45:800] loss_idt_y: 0.08976316519081592, F_fool_loss: 0.014459400977939367, cycled_y_loss: 0.09435983866453171, D_Y_loss: 0.2926716661453247\n",
      "[45:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:900] Took 12.83s\n",
      "[45:900] loss_idt_x: 0.11668985579162836, G_fool_loss: 0.014388027358800173, cycled_x_loss: 0.11331516262143851, D_X_loss: 0.2933603945374489\n",
      "[45:900] loss_idt_y: 0.08022033013403415, F_fool_loss: 0.014453325811773539, cycled_y_loss: 0.08227629028260708, D_Y_loss: 0.2929443174600601\n",
      "[45:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:1000] Took 12.83s\n",
      "[45:1000] loss_idt_x: 0.1482853999361396, G_fool_loss: 0.014220053870230913, cycled_x_loss: 0.14126765698194504, D_X_loss: 0.2927954486012459\n",
      "[45:1000] loss_idt_y: 0.08327667832374573, F_fool_loss: 0.014719762876629829, cycled_y_loss: 0.08378241803497076, D_Y_loss: 0.2921279689669609\n",
      "[45:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:1100] Took 12.82s\n",
      "[45:1100] loss_idt_x: 0.13745738603174687, G_fool_loss: 0.01448983528651297, cycled_x_loss: 0.13170870050787925, D_X_loss: 0.29265657514333726\n",
      "[45:1100] loss_idt_y: 0.1092750883847475, F_fool_loss: 0.014399339901283384, cycled_y_loss: 0.1121446019038558, D_Y_loss: 0.29302927166223525\n",
      "[45:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[45:END] Completed epoch in 161.04081892967224s\n",
      "[45:1199] ep_loss_idt_x: 0.130 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.126 ep_D_X_loss: 0.293\n",
      "[45:1199] ep_loss_idt_y: 0.091 ep_F_fool_loss: 0.015 ep_cycled_y_loss: 0.094 ep_D_Y_loss: 0.293\n",
      "[45:END] Completed eval in 1.4770538806915283s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[45:END] Saving models and training information permanently\n",
      "[46:100] Took 14.82s\n",
      "[46:100] loss_idt_x: 0.12398216903209686, G_fool_loss: 0.01460922553204, cycled_x_loss: 0.12320012971758842, D_X_loss: 0.2963126888871193\n",
      "[46:100] loss_idt_y: 0.09024608351290225, F_fool_loss: 0.014758876943960785, cycled_y_loss: 0.09613273162394761, D_Y_loss: 0.2943888866901398\n",
      "[46:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:200] Took 12.97s\n",
      "[46:200] loss_idt_x: 0.1273087116703391, G_fool_loss: 0.014487974131479859, cycled_x_loss: 0.12209518484771252, D_X_loss: 0.29351320773363115\n",
      "[46:200] loss_idt_y: 0.08231214594095945, F_fool_loss: 0.014327809326350688, cycled_y_loss: 0.08299260158091784, D_Y_loss: 0.2919954293966293\n",
      "[46:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:300] Took 12.82s\n",
      "[46:300] loss_idt_x: 0.1371111049503088, G_fool_loss: 0.014587928457185626, cycled_x_loss: 0.1306290901824832, D_X_loss: 0.29205359488725663\n",
      "[46:300] loss_idt_y: 0.09379385698586702, F_fool_loss: 0.014461703458800912, cycled_y_loss: 0.0937766906246543, D_Y_loss: 0.29425700664520266\n",
      "[46:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:400] Took 12.86s\n",
      "[46:400] loss_idt_x: 0.13742347557097673, G_fool_loss: 0.01433367433026433, cycled_x_loss: 0.1436745785176754, D_X_loss: 0.2932348382472992\n",
      "[46:400] loss_idt_y: 0.09019089788198471, F_fool_loss: 0.014408821193501353, cycled_y_loss: 0.09097075380384922, D_Y_loss: 0.29281402081251146\n",
      "[46:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:500] Took 12.86s\n",
      "[46:500] loss_idt_x: 0.1225241819024086, G_fool_loss: 0.01435879566706717, cycled_x_loss: 0.1214335960149765, D_X_loss: 0.2936244869232178\n",
      "[46:500] loss_idt_y: 0.08637661766260862, F_fool_loss: 0.014406661717221141, cycled_y_loss: 0.0844311823323369, D_Y_loss: 0.29303923130035403\n",
      "[46:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:600] Took 12.87s\n",
      "[46:600] loss_idt_x: 0.13900397036224604, G_fool_loss: 0.01425042200833559, cycled_x_loss: 0.14129351418465375, D_X_loss: 0.2932897612452507\n",
      "[46:600] loss_idt_y: 0.08524479944258928, F_fool_loss: 0.014458604007959366, cycled_y_loss: 0.08563357040286064, D_Y_loss: 0.29201122641563415\n",
      "[46:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:700] Took 12.86s\n",
      "[46:700] loss_idt_x: 0.1256722591817379, G_fool_loss: 0.014378853533416986, cycled_x_loss: 0.12329216446727514, D_X_loss: 0.29491259962320326\n",
      "[46:700] loss_idt_y: 0.08256545666605235, F_fool_loss: 0.01442290998995304, cycled_y_loss: 0.08401675824075937, D_Y_loss: 0.2924231424927711\n",
      "[46:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:800] Took 12.85s\n",
      "[46:800] loss_idt_x: 0.13812666185200215, G_fool_loss: 0.014316501356661319, cycled_x_loss: 0.1395083851367235, D_X_loss: 0.29397092819213866\n",
      "[46:800] loss_idt_y: 0.10299783002585172, F_fool_loss: 0.014869998339563609, cycled_y_loss: 0.10207948479801417, D_Y_loss: 0.2926252108812332\n",
      "[46:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:900] Took 12.88s\n",
      "[46:900] loss_idt_x: 0.12381369393318892, G_fool_loss: 0.014252304062247277, cycled_x_loss: 0.11687934923917055, D_X_loss: 0.29289924681186674\n",
      "[46:900] loss_idt_y: 0.08575269814580679, F_fool_loss: 0.014377669990062713, cycled_y_loss: 0.08949748039245606, D_Y_loss: 0.2927122986316681\n",
      "[46:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:1000] Took 12.87s\n",
      "[46:1000] loss_idt_x: 0.1389986989274621, G_fool_loss: 0.014426504382863642, cycled_x_loss: 0.13450184594839812, D_X_loss: 0.29303974270820615\n",
      "[46:1000] loss_idt_y: 0.09122513759881258, F_fool_loss: 0.014604193186387419, cycled_y_loss: 0.09418815992772579, D_Y_loss: 0.29269849926233293\n",
      "[46:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:1100] Took 12.86s\n",
      "[46:1100] loss_idt_x: 0.13438598494976758, G_fool_loss: 0.014601863026618957, cycled_x_loss: 0.13229814883321522, D_X_loss: 0.2932390943169594\n",
      "[46:1100] loss_idt_y: 0.08282195810228586, F_fool_loss: 0.01423335942439735, cycled_y_loss: 0.08558654144406319, D_Y_loss: 0.29317098796367647\n",
      "[46:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[46:END] Completed epoch in 160.92409801483154s\n",
      "[46:1199] ep_loss_idt_x: 0.131 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.129 ep_D_X_loss: 0.293\n",
      "[46:1199] ep_loss_idt_y: 0.089 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.090 ep_D_Y_loss: 0.293\n",
      "[46:END] Completed eval in 1.4592316150665283s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[46:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[47:100] Took 14.86s\n",
      "[47:100] loss_idt_x: 0.14024421099573373, G_fool_loss: 0.014407487846910953, cycled_x_loss: 0.1413486045971513, D_X_loss: 0.2962091085314751\n",
      "[47:100] loss_idt_y: 0.08438906565308571, F_fool_loss: 0.014582278747111559, cycled_y_loss: 0.08892241772264242, D_Y_loss: 0.2956260854005814\n",
      "[47:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:200] Took 12.87s\n",
      "[47:200] loss_idt_x: 0.11350883640348912, G_fool_loss: 0.014532586857676506, cycled_x_loss: 0.10876222126185894, D_X_loss: 0.29239146918058395\n",
      "[47:200] loss_idt_y: 0.08475282218307256, F_fool_loss: 0.014479113994166255, cycled_y_loss: 0.09191056367009878, D_Y_loss: 0.29215906679630277\n",
      "[47:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:300] Took 12.87s\n",
      "[47:300] loss_idt_x: 0.13248660411685706, G_fool_loss: 0.014243543203920126, cycled_x_loss: 0.12458318639546632, D_X_loss: 0.2944613230228424\n",
      "[47:300] loss_idt_y: 0.08396111954003573, F_fool_loss: 0.014521396113559603, cycled_y_loss: 0.08649474542587995, D_Y_loss: 0.2921124288439751\n",
      "[47:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:400] Took 12.86s\n",
      "[47:400] loss_idt_x: 0.13032060787081717, G_fool_loss: 0.014498328687623144, cycled_x_loss: 0.12080261740833521, D_X_loss: 0.29342304944992065\n",
      "[47:400] loss_idt_y: 0.09371413711458444, F_fool_loss: 0.014347254894673825, cycled_y_loss: 0.09770118180662393, D_Y_loss: 0.29416528433561323\n",
      "[47:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:500] Took 12.82s\n",
      "[47:500] loss_idt_x: 0.1171888729929924, G_fool_loss: 0.014245617147535085, cycled_x_loss: 0.1141932563483715, D_X_loss: 0.29307982087135315\n",
      "[47:500] loss_idt_y: 0.09158900842070579, F_fool_loss: 0.01458365498110652, cycled_y_loss: 0.09496440779417753, D_Y_loss: 0.29303630739450454\n",
      "[47:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:600] Took 12.86s\n",
      "[47:600] loss_idt_x: 0.1165076383203268, G_fool_loss: 0.01415733235888183, cycled_x_loss: 0.12009363614022732, D_X_loss: 0.2928279921412468\n",
      "[47:600] loss_idt_y: 0.08687744919210673, F_fool_loss: 0.014411705294623971, cycled_y_loss: 0.09533301208168268, D_Y_loss: 0.2925744101405144\n",
      "[47:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:700] Took 12.86s\n",
      "[47:700] loss_idt_x: 0.12903470434248449, G_fool_loss: 0.01433996639214456, cycled_x_loss: 0.12446304906159639, D_X_loss: 0.2953020390868187\n",
      "[47:700] loss_idt_y: 0.07986032329499722, F_fool_loss: 0.014404916185885668, cycled_y_loss: 0.08195286490023136, D_Y_loss: 0.2930373057723045\n",
      "[47:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:800] Took 12.86s\n",
      "[47:800] loss_idt_x: 0.1264244568347931, G_fool_loss: 0.01452786585316062, cycled_x_loss: 0.12506973817944528, D_X_loss: 0.2928052332997322\n",
      "[47:800] loss_idt_y: 0.07762888856232167, F_fool_loss: 0.014408239414915442, cycled_y_loss: 0.08163507863879203, D_Y_loss: 0.29256632685661316\n",
      "[47:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:900] Took 12.83s\n",
      "[47:900] loss_idt_x: 0.1262589130550623, G_fool_loss: 0.014492852576076985, cycled_x_loss: 0.12578863106667995, D_X_loss: 0.29353637546300887\n",
      "[47:900] loss_idt_y: 0.09686814945191145, F_fool_loss: 0.014352879645302892, cycled_y_loss: 0.10342604110017418, D_Y_loss: 0.2934392899274826\n",
      "[47:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:1000] Took 12.83s\n",
      "[47:1000] loss_idt_x: 0.130962714292109, G_fool_loss: 0.014524567713961005, cycled_x_loss: 0.12793744411319494, D_X_loss: 0.2921724796295166\n",
      "[47:1000] loss_idt_y: 0.0900205523520708, F_fool_loss: 0.01448648339137435, cycled_y_loss: 0.09757803212851286, D_Y_loss: 0.2917481926083565\n",
      "[47:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:1100] Took 12.83s\n",
      "[47:1100] loss_idt_x: 0.13713286727666854, G_fool_loss: 0.014602124923840165, cycled_x_loss: 0.13767481505870818, D_X_loss: 0.29324926137924195\n",
      "[47:1100] loss_idt_y: 0.07101218143478036, F_fool_loss: 0.014626149963587522, cycled_y_loss: 0.07891816690564156, D_Y_loss: 0.2924852728843689\n",
      "[47:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[47:END] Completed epoch in 162.57111072540283s\n",
      "[47:1199] ep_loss_idt_x: 0.127 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.125 ep_D_X_loss: 0.293\n",
      "[47:1199] ep_loss_idt_y: 0.086 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.091 ep_D_Y_loss: 0.293\n",
      "[47:END] Completed eval in 2.004021406173706s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[47:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[48:100] Took 14.81s\n",
      "[48:100] loss_idt_x: 0.11959204502403736, G_fool_loss: 0.014743152568116783, cycled_x_loss: 0.11352778699249029, D_X_loss: 0.2951237943768501\n",
      "[48:100] loss_idt_y: 0.09134134139865636, F_fool_loss: 0.014707091692835093, cycled_y_loss: 0.09412998527288437, D_Y_loss: 0.29540121376514433\n",
      "[48:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:200] Took 12.82s\n",
      "[48:200] loss_idt_x: 0.1294750329479575, G_fool_loss: 0.01438769383355975, cycled_x_loss: 0.12747560795396568, D_X_loss: 0.2930861496925354\n",
      "[48:200] loss_idt_y: 0.08640898909419775, F_fool_loss: 0.014599516559392213, cycled_y_loss: 0.09262726813554764, D_Y_loss: 0.29263598084449766\n",
      "[48:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:300] Took 12.84s\n",
      "[48:300] loss_idt_x: 0.11739008601754904, G_fool_loss: 0.014200143711641432, cycled_x_loss: 0.11338077388703822, D_X_loss: 0.2925693845748901\n",
      "[48:300] loss_idt_y: 0.08812752347439527, F_fool_loss: 0.014284565402194858, cycled_y_loss: 0.0912519432976842, D_Y_loss: 0.2923749226331711\n",
      "[48:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:400] Took 12.86s\n",
      "[48:400] loss_idt_x: 0.12900834422558546, G_fool_loss: 0.01445224231109023, cycled_x_loss: 0.13134186901152134, D_X_loss: 0.29123926877975465\n",
      "[48:400] loss_idt_y: 0.08017306800931692, F_fool_loss: 0.014392835041508078, cycled_y_loss: 0.08492618277668953, D_Y_loss: 0.2938001564145088\n",
      "[48:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:500] Took 12.85s\n",
      "[48:500] loss_idt_x: 0.12134157463908196, G_fool_loss: 0.014550092527642847, cycled_x_loss: 0.11898342855274677, D_X_loss: 0.29418278455734254\n",
      "[48:500] loss_idt_y: 0.08772088158875704, F_fool_loss: 0.014453576225787402, cycled_y_loss: 0.09481896597892046, D_Y_loss: 0.2931174385547638\n",
      "[48:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:600] Took 12.86s\n",
      "[48:600] loss_idt_x: 0.12139133658260107, G_fool_loss: 0.014611396295949817, cycled_x_loss: 0.12074842400848866, D_X_loss: 0.2920593774318695\n",
      "[48:600] loss_idt_y: 0.0887157964706421, F_fool_loss: 0.014189606420695782, cycled_y_loss: 0.09319709978997708, D_Y_loss: 0.29297559440135956\n",
      "[48:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:700] Took 12.86s\n",
      "[48:700] loss_idt_x: 0.1266437066346407, G_fool_loss: 0.014328804593533277, cycled_x_loss: 0.1296818996220827, D_X_loss: 0.2930948546528816\n",
      "[48:700] loss_idt_y: 0.09639772158116103, F_fool_loss: 0.014450392313301563, cycled_y_loss: 0.09733968298882247, D_Y_loss: 0.2930610656738281\n",
      "[48:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:800] Took 12.82s\n",
      "[48:800] loss_idt_x: 0.1286027406156063, G_fool_loss: 0.01441052489914, cycled_x_loss: 0.12407308947294951, D_X_loss: 0.2914034882187843\n",
      "[48:800] loss_idt_y: 0.09213093165308237, F_fool_loss: 0.014328263206407428, cycled_y_loss: 0.09124119915068149, D_Y_loss: 0.2933020669221878\n",
      "[48:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:900] Took 12.83s\n",
      "[48:900] loss_idt_x: 0.12424809571355581, G_fool_loss: 0.014330796850845217, cycled_x_loss: 0.12228057380765676, D_X_loss: 0.2931083020567894\n",
      "[48:900] loss_idt_y: 0.10088091429322958, F_fool_loss: 0.014351951135322451, cycled_y_loss: 0.1048884255066514, D_Y_loss: 0.29151038885116576\n",
      "[48:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:1000] Took 12.83s\n",
      "[48:1000] loss_idt_x: 0.13370129510760306, G_fool_loss: 0.014547039391472935, cycled_x_loss: 0.13394873093813658, D_X_loss: 0.2916648095846176\n",
      "[48:1000] loss_idt_y: 0.09485438842326403, F_fool_loss: 0.014424266098067164, cycled_y_loss: 0.09705865897238254, D_Y_loss: 0.2921039715409279\n",
      "[48:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:1100] Took 12.83s\n",
      "[48:1100] loss_idt_x: 0.13138935763388873, G_fool_loss: 0.01445442914031446, cycled_x_loss: 0.12551433112472296, D_X_loss: 0.2928816992044449\n",
      "[48:1100] loss_idt_y: 0.09604454413056374, F_fool_loss: 0.014529731580987573, cycled_y_loss: 0.10077023845165968, D_Y_loss: 0.29327223360538485\n",
      "[48:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[48:END] Completed epoch in 162.76554036140442s\n",
      "[48:1199] ep_loss_idt_x: 0.126 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.124 ep_D_X_loss: 0.292\n",
      "[48:1199] ep_loss_idt_y: 0.091 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.094 ep_D_Y_loss: 0.293\n",
      "[48:END] Completed eval in 1.5219316482543945s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[48:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[49:100] Took 14.80s\n",
      "[49:100] loss_idt_x: 0.13547636538743973, G_fool_loss: 0.014462411748245358, cycled_x_loss: 0.13065680120140313, D_X_loss: 0.29583913296461106\n",
      "[49:100] loss_idt_y: 0.08640872329473495, F_fool_loss: 0.014609755631536245, cycled_y_loss: 0.08899015184491872, D_Y_loss: 0.29459352999925614\n",
      "[49:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:200] Took 12.82s\n",
      "[49:200] loss_idt_x: 0.13233453541994095, G_fool_loss: 0.014510304033756256, cycled_x_loss: 0.13190677773207427, D_X_loss: 0.2915856710076332\n",
      "[49:200] loss_idt_y: 0.09181294428184629, F_fool_loss: 0.01445567817427218, cycled_y_loss: 0.09236536212265492, D_Y_loss: 0.2923188242316246\n",
      "[49:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:300] Took 12.90s\n",
      "[49:300] loss_idt_x: 0.12114267084747553, G_fool_loss: 0.014632273772731423, cycled_x_loss: 0.11795151408761739, D_X_loss: 0.29205167174339297\n",
      "[49:300] loss_idt_y: 0.08739068184047938, F_fool_loss: 0.014464102108031512, cycled_y_loss: 0.08566623117774724, D_Y_loss: 0.29224201768636704\n",
      "[49:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:400] Took 12.92s\n",
      "[49:400] loss_idt_x: 0.1292529182881117, G_fool_loss: 0.014402602994814516, cycled_x_loss: 0.13103445880115033, D_X_loss: 0.29347989171743394\n",
      "[49:400] loss_idt_y: 0.08085122752934694, F_fool_loss: 0.014237783439457417, cycled_y_loss: 0.08449455507099629, D_Y_loss: 0.29152355760335924\n",
      "[49:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:500] Took 12.84s\n",
      "[49:500] loss_idt_x: 0.11949614349752664, G_fool_loss: 0.014574366174638271, cycled_x_loss: 0.12116509880870581, D_X_loss: 0.2925975131988525\n",
      "[49:500] loss_idt_y: 0.08785113960504531, F_fool_loss: 0.014365812307223677, cycled_y_loss: 0.09027570262551307, D_Y_loss: 0.29294442385435104\n",
      "[49:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:600] Took 12.83s\n",
      "[49:600] loss_idt_x: 0.12522113062441348, G_fool_loss: 0.014323537526652217, cycled_x_loss: 0.119790025241673, D_X_loss: 0.2936167025566101\n",
      "[49:600] loss_idt_y: 0.09439029190689326, F_fool_loss: 0.014509773226454853, cycled_y_loss: 0.09997826538980008, D_Y_loss: 0.29384049236774445\n",
      "[49:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:700] Took 12.83s\n",
      "[49:700] loss_idt_x: 0.14080943278968333, G_fool_loss: 0.01437450448051095, cycled_x_loss: 0.1405900088325143, D_X_loss: 0.2930447396636009\n",
      "[49:700] loss_idt_y: 0.08124273115769029, F_fool_loss: 0.014633823065087198, cycled_y_loss: 0.08403405655175447, D_Y_loss: 0.2931857228279114\n",
      "[49:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:800] Took 12.86s\n",
      "[49:800] loss_idt_x: 0.13467621620744466, G_fool_loss: 0.01452898963354528, cycled_x_loss: 0.1287837665900588, D_X_loss: 0.292523986697197\n",
      "[49:800] loss_idt_y: 0.0918485026434064, F_fool_loss: 0.01418117648921907, cycled_y_loss: 0.09546608947217465, D_Y_loss: 0.29114413261413574\n",
      "[49:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:900] Took 12.83s\n",
      "[49:900] loss_idt_x: 0.13104599360376595, G_fool_loss: 0.01455924019217491, cycled_x_loss: 0.13322074871510267, D_X_loss: 0.2938975340127945\n",
      "[49:900] loss_idt_y: 0.08321926664561033, F_fool_loss: 0.014717072835192085, cycled_y_loss: 0.0894386488944292, D_Y_loss: 0.2925878530740738\n",
      "[49:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:1000] Took 12.83s\n",
      "[49:1000] loss_idt_x: 0.11675982635468245, G_fool_loss: 0.014396680295467377, cycled_x_loss: 0.11488104574382305, D_X_loss: 0.2938426184654236\n",
      "[49:1000] loss_idt_y: 0.0877853911370039, F_fool_loss: 0.014652400333434344, cycled_y_loss: 0.08875792302191257, D_Y_loss: 0.2933045971393585\n",
      "[49:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:1100] Took 12.83s\n",
      "[49:1100] loss_idt_x: 0.10479661952704192, G_fool_loss: 0.014433775413781404, cycled_x_loss: 0.10621037751436234, D_X_loss: 0.293348463177681\n",
      "[49:1100] loss_idt_y: 0.09549458123743534, F_fool_loss: 0.014249648796394468, cycled_y_loss: 0.09691939052194357, D_Y_loss: 0.2924684226512909\n",
      "[49:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[49:END] Completed epoch in 162.72114372253418s\n",
      "[49:1199] ep_loss_idt_x: 0.126 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.125 ep_D_X_loss: 0.293\n",
      "[49:1199] ep_loss_idt_y: 0.088 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.091 ep_D_Y_loss: 0.293\n",
      "[49:END] Completed eval in 1.4880244731903076s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[49:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[50:100] Took 14.86s\n",
      "[50:100] loss_idt_x: 0.12921328350901604, G_fool_loss: 0.014506336627528071, cycled_x_loss: 0.13164494808763266, D_X_loss: 0.2957170680165291\n",
      "[50:100] loss_idt_y: 0.0942021657153964, F_fool_loss: 0.014622089872136711, cycled_y_loss: 0.0963901661708951, D_Y_loss: 0.2950918114185333\n",
      "[50:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:200] Took 12.84s\n",
      "[50:200] loss_idt_x: 0.12876674223691226, G_fool_loss: 0.014369180416688323, cycled_x_loss: 0.12287000063806772, D_X_loss: 0.29218816965818406\n",
      "[50:200] loss_idt_y: 0.08032036405056715, F_fool_loss: 0.014368817834183574, cycled_y_loss: 0.08535705242305994, D_Y_loss: 0.29266306638717654\n",
      "[50:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:300] Took 12.85s\n",
      "[50:300] loss_idt_x: 0.12809758178889752, G_fool_loss: 0.01463894421234727, cycled_x_loss: 0.12941953420639038, D_X_loss: 0.29275205940008164\n",
      "[50:300] loss_idt_y: 0.08564909076318145, F_fool_loss: 0.014376416290178894, cycled_y_loss: 0.08829512782394885, D_Y_loss: 0.2913746652007103\n",
      "[50:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:400] Took 12.84s\n",
      "[50:400] loss_idt_x: 0.12302177254110575, G_fool_loss: 0.014443962210789323, cycled_x_loss: 0.12018918436020613, D_X_loss: 0.29343565076589584\n",
      "[50:400] loss_idt_y: 0.07350003786385059, F_fool_loss: 0.01421933926641941, cycled_y_loss: 0.07401712842285633, D_Y_loss: 0.2931421646475792\n",
      "[50:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:500] Took 12.89s\n",
      "[50:500] loss_idt_x: 0.1199183725938201, G_fool_loss: 0.014317841390147806, cycled_x_loss: 0.12086739089339972, D_X_loss: 0.2918708118796349\n",
      "[50:500] loss_idt_y: 0.09568414676934481, F_fool_loss: 0.014329734044149518, cycled_y_loss: 0.0961799418926239, D_Y_loss: 0.29215428590774534\n",
      "[50:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:600] Took 12.88s\n",
      "[50:600] loss_idt_x: 0.12417515959590673, G_fool_loss: 0.014484094744548202, cycled_x_loss: 0.12509846776723862, D_X_loss: 0.2928868207335472\n",
      "[50:600] loss_idt_y: 0.09574807222932577, F_fool_loss: 0.014553751293569804, cycled_y_loss: 0.0936076893657446, D_Y_loss: 0.29358565270900727\n",
      "[50:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:700] Took 12.87s\n",
      "[50:700] loss_idt_x: 0.13778673812747003, G_fool_loss: 0.014522844860330224, cycled_x_loss: 0.13766181468963623, D_X_loss: 0.2919529601931572\n",
      "[50:700] loss_idt_y: 0.09957474220544099, F_fool_loss: 0.014385067718103528, cycled_y_loss: 0.1038256761059165, D_Y_loss: 0.2906999108195305\n",
      "[50:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:800] Took 12.87s\n",
      "[50:800] loss_idt_x: 0.12421867776662111, G_fool_loss: 0.014338253503665329, cycled_x_loss: 0.1213627190887928, D_X_loss: 0.2913874337077141\n",
      "[50:800] loss_idt_y: 0.09158180471509696, F_fool_loss: 0.01430189806036651, cycled_y_loss: 0.09442535530775785, D_Y_loss: 0.2941311463713646\n",
      "[50:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:900] Took 12.88s\n",
      "[50:900] loss_idt_x: 0.12711258079856635, G_fool_loss: 0.014291661027818918, cycled_x_loss: 0.12490396559238434, D_X_loss: 0.29343785643577575\n",
      "[50:900] loss_idt_y: 0.08756968036293983, F_fool_loss: 0.01432530882768333, cycled_y_loss: 0.09289518572390079, D_Y_loss: 0.29216189980506896\n",
      "[50:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:1000] Took 12.86s\n",
      "[50:1000] loss_idt_x: 0.12725826691836117, G_fool_loss: 0.014382947981357575, cycled_x_loss: 0.1261046615615487, D_X_loss: 0.2928544959425926\n",
      "[50:1000] loss_idt_y: 0.08687610153108835, F_fool_loss: 0.014636656315997244, cycled_y_loss: 0.08733989167958497, D_Y_loss: 0.29271976590156557\n",
      "[50:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:1100] Took 12.88s\n",
      "[50:1100] loss_idt_x: 0.1141450773179531, G_fool_loss: 0.014491105787456035, cycled_x_loss: 0.11424592789262533, D_X_loss: 0.2912313884496689\n",
      "[50:1100] loss_idt_y: 0.0854740496724844, F_fool_loss: 0.014510347815230489, cycled_y_loss: 0.08946994064375759, D_Y_loss: 0.2920895129442215\n",
      "[50:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[50:END] Completed epoch in 162.1662561893463s\n",
      "[50:1199] ep_loss_idt_x: 0.125 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.124 ep_D_X_loss: 0.293\n",
      "[50:1199] ep_loss_idt_y: 0.089 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.091 ep_D_Y_loss: 0.293\n",
      "[50:END] Completed eval in 1.5987050533294678s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[50:END] Saving models and training information permanently\n",
      "[51:100] Took 14.83s\n",
      "[51:100] loss_idt_x: 0.1250357673689723, G_fool_loss: 0.014743332602083683, cycled_x_loss: 0.11870045103132724, D_X_loss: 0.2965517684817314\n",
      "[51:100] loss_idt_y: 0.07797956645488739, F_fool_loss: 0.014595989799126984, cycled_y_loss: 0.08213451236486435, D_Y_loss: 0.29523171097040174\n",
      "[51:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:200] Took 12.88s\n",
      "[51:200] loss_idt_x: 0.12004136711359024, G_fool_loss: 0.014348673019558191, cycled_x_loss: 0.11887735847383737, D_X_loss: 0.2922819438576698\n",
      "[51:200] loss_idt_y: 0.09440691825002431, F_fool_loss: 0.014477975014597178, cycled_y_loss: 0.09543950662016869, D_Y_loss: 0.2930295771360397\n",
      "[51:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:300] Took 12.87s\n",
      "[51:300] loss_idt_x: 0.13268682681024074, G_fool_loss: 0.014425802882760764, cycled_x_loss: 0.1268880083784461, D_X_loss: 0.2922946584224701\n",
      "[51:300] loss_idt_y: 0.08466804742813111, F_fool_loss: 0.014491903660818935, cycled_y_loss: 0.08978672184050084, D_Y_loss: 0.29315810739994047\n",
      "[51:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:400] Took 12.87s\n",
      "[51:400] loss_idt_x: 0.1257673490792513, G_fool_loss: 0.014248367287218571, cycled_x_loss: 0.12291277591139078, D_X_loss: 0.29252687871456146\n",
      "[51:400] loss_idt_y: 0.08923232231289148, F_fool_loss: 0.014415692137554288, cycled_y_loss: 0.09454127039760352, D_Y_loss: 0.2923236501216888\n",
      "[51:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:500] Took 12.87s\n",
      "[51:500] loss_idt_x: 0.12477106142789125, G_fool_loss: 0.014520234316587449, cycled_x_loss: 0.12727830801159143, D_X_loss: 0.29318904161453246\n",
      "[51:500] loss_idt_y: 0.08344182556495071, F_fool_loss: 0.0144698222912848, cycled_y_loss: 0.09032091908156872, D_Y_loss: 0.292743701338768\n",
      "[51:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:600] Took 12.87s\n",
      "[51:600] loss_idt_x: 0.1294457856193185, G_fool_loss: 0.014403564212843776, cycled_x_loss: 0.1271376447379589, D_X_loss: 0.2928681683540344\n",
      "[51:600] loss_idt_y: 0.08240884117782116, F_fool_loss: 0.014248447613790632, cycled_y_loss: 0.0886513102799654, D_Y_loss: 0.2927396973967552\n",
      "[51:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:700] Took 12.87s\n",
      "[51:700] loss_idt_x: 0.11906031671911478, G_fool_loss: 0.014490335835143925, cycled_x_loss: 0.10948990169912577, D_X_loss: 0.29226336389780044\n",
      "[51:700] loss_idt_y: 0.08330639585852623, F_fool_loss: 0.014434403218328952, cycled_y_loss: 0.08791323903948069, D_Y_loss: 0.2930377092957497\n",
      "[51:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:800] Took 12.86s\n",
      "[51:800] loss_idt_x: 0.12305919505655766, G_fool_loss: 0.014407739723101259, cycled_x_loss: 0.12472642239183188, D_X_loss: 0.293622662127018\n",
      "[51:800] loss_idt_y: 0.0879364787042141, F_fool_loss: 0.014409558838233352, cycled_y_loss: 0.09441253904253244, D_Y_loss: 0.2915960210561752\n",
      "[51:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:900] Took 12.88s\n",
      "[51:900] loss_idt_x: 0.11675713893026113, G_fool_loss: 0.014455947959795594, cycled_x_loss: 0.12317406680434942, D_X_loss: 0.2915089997649193\n",
      "[51:900] loss_idt_y: 0.08375454176217317, F_fool_loss: 0.014237315505743026, cycled_y_loss: 0.08995339196175337, D_Y_loss: 0.29163930416107176\n",
      "[51:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:1000] Took 12.89s\n",
      "[51:1000] loss_idt_x: 0.12786900993436576, G_fool_loss: 0.014206046797335148, cycled_x_loss: 0.12348243288695812, D_X_loss: 0.29179757565259934\n",
      "[51:1000] loss_idt_y: 0.08588855475187301, F_fool_loss: 0.01430126049555838, cycled_y_loss: 0.09236485930159688, D_Y_loss: 0.2923966071009636\n",
      "[51:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:1100] Took 12.90s\n",
      "[51:1100] loss_idt_x: 0.12859431229531765, G_fool_loss: 0.014330641822889447, cycled_x_loss: 0.12714593339711427, D_X_loss: 0.2927320012450218\n",
      "[51:1100] loss_idt_y: 0.08943402744829655, F_fool_loss: 0.014594117440283298, cycled_y_loss: 0.09386972185224295, D_Y_loss: 0.29206810891628265\n",
      "[51:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[51:END] Completed epoch in 162.0852906703949s\n",
      "[51:1199] ep_loss_idt_x: 0.125 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.123 ep_D_X_loss: 0.293\n",
      "[51:1199] ep_loss_idt_y: 0.086 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.090 ep_D_Y_loss: 0.292\n",
      "[51:END] Completed eval in 1.5209319591522217s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[51:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[52:100] Took 14.80s\n",
      "[52:100] loss_idt_x: 0.1335585630685091, G_fool_loss: 0.014335177019238471, cycled_x_loss: 0.14006137292832135, D_X_loss: 0.29731619566679\n",
      "[52:100] loss_idt_y: 0.0980878971889615, F_fool_loss: 0.014574829833582043, cycled_y_loss: 0.09845408212393522, D_Y_loss: 0.2937582817673683\n",
      "[52:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:200] Took 12.85s\n",
      "[52:200] loss_idt_x: 0.11469722725450993, G_fool_loss: 0.01446477085351944, cycled_x_loss: 0.11012311704456806, D_X_loss: 0.2931480872631073\n",
      "[52:200] loss_idt_y: 0.09780463751405477, F_fool_loss: 0.014440922373905778, cycled_y_loss: 0.10244387529790401, D_Y_loss: 0.29165489971637726\n",
      "[52:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:300] Took 12.88s\n",
      "[52:300] loss_idt_x: 0.1343610381707549, G_fool_loss: 0.01429965766146779, cycled_x_loss: 0.13066104978322982, D_X_loss: 0.2937585982680321\n",
      "[52:300] loss_idt_y: 0.0874971628934145, F_fool_loss: 0.014410669654607773, cycled_y_loss: 0.08377064753323793, D_Y_loss: 0.2921796187758446\n",
      "[52:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:400] Took 12.87s\n",
      "[52:400] loss_idt_x: 0.12900829125195742, G_fool_loss: 0.014318637223914266, cycled_x_loss: 0.12752942565828562, D_X_loss: 0.2933786889910698\n",
      "[52:400] loss_idt_y: 0.08910139035433531, F_fool_loss: 0.014566569272428751, cycled_y_loss: 0.09222547274082898, D_Y_loss: 0.2916402322053909\n",
      "[52:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:500] Took 12.88s\n",
      "[52:500] loss_idt_x: 0.12640676368027925, G_fool_loss: 0.014642784083262085, cycled_x_loss: 0.12420149471610785, D_X_loss: 0.2945040014386177\n",
      "[52:500] loss_idt_y: 0.07751523349434138, F_fool_loss: 0.014306587567552924, cycled_y_loss: 0.08135471876710654, D_Y_loss: 0.2916169500350952\n",
      "[52:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:600] Took 12.87s\n",
      "[52:600] loss_idt_x: 0.12434978161007165, G_fool_loss: 0.01437289796769619, cycled_x_loss: 0.12329424824565649, D_X_loss: 0.2908884561061859\n",
      "[52:600] loss_idt_y: 0.08372405756264925, F_fool_loss: 0.014332795413210989, cycled_y_loss: 0.08944445177912712, D_Y_loss: 0.29366050004959104\n",
      "[52:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:700] Took 12.88s\n",
      "[52:700] loss_idt_x: 0.11860204249620437, G_fool_loss: 0.014505292009562253, cycled_x_loss: 0.11447795748710632, D_X_loss: 0.29266638815402984\n",
      "[52:700] loss_idt_y: 0.09064290810376406, F_fool_loss: 0.014545170404016972, cycled_y_loss: 0.09585135085508227, D_Y_loss: 0.2922188350558281\n",
      "[52:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:800] Took 12.87s\n",
      "[52:800] loss_idt_x: 0.12460341263562441, G_fool_loss: 0.014434695960953831, cycled_x_loss: 0.123963927552104, D_X_loss: 0.2932922333478928\n",
      "[52:800] loss_idt_y: 0.09088158253580332, F_fool_loss: 0.014224802302196622, cycled_y_loss: 0.09660971399396658, D_Y_loss: 0.29251805812120435\n",
      "[52:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:900] Took 12.88s\n",
      "[52:900] loss_idt_x: 0.12441872134804725, G_fool_loss: 0.014462195709347725, cycled_x_loss: 0.12094539623707533, D_X_loss: 0.2939043885469437\n",
      "[52:900] loss_idt_y: 0.0828434020280838, F_fool_loss: 0.014543382283300162, cycled_y_loss: 0.0858261614665389, D_Y_loss: 0.29294482707977293\n",
      "[52:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:1000] Took 12.87s\n",
      "[52:1000] loss_idt_x: 0.12335076309740543, G_fool_loss: 0.014356206115335226, cycled_x_loss: 0.12463341653347015, D_X_loss: 0.29283502787351606\n",
      "[52:1000] loss_idt_y: 0.08202318144962191, F_fool_loss: 0.014391131354495884, cycled_y_loss: 0.08441867422312498, D_Y_loss: 0.29168760001659394\n",
      "[52:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:1100] Took 12.88s\n",
      "[52:1100] loss_idt_x: 0.12411705359816551, G_fool_loss: 0.01443841541185975, cycled_x_loss: 0.11767846319824457, D_X_loss: 0.2935611242055893\n",
      "[52:1100] loss_idt_y: 0.07950403589755296, F_fool_loss: 0.01435178929939866, cycled_y_loss: 0.0836381970718503, D_Y_loss: 0.29130408346652986\n",
      "[52:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[52:END] Completed epoch in 162.85462999343872s\n",
      "[52:1199] ep_loss_idt_x: 0.125 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.123 ep_D_X_loss: 0.293\n",
      "[52:1199] ep_loss_idt_y: 0.087 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.090 ep_D_Y_loss: 0.292\n",
      "[52:END] Completed eval in 1.5179431438446045s\n",
      "Updated G_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated F_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "[52:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[53:100] Took 14.88s\n",
      "[53:100] loss_idt_x: 0.11908978141844273, G_fool_loss: 0.014417001567780972, cycled_x_loss: 0.11589007340371608, D_X_loss: 0.2939744299650192\n",
      "[53:100] loss_idt_y: 0.08416583508253098, F_fool_loss: 0.014540186682716012, cycled_y_loss: 0.08585089448839427, D_Y_loss: 0.29704193949699403\n",
      "[53:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:200] Took 12.87s\n",
      "[53:200] loss_idt_x: 0.1243704154714942, G_fool_loss: 0.014437606614083052, cycled_x_loss: 0.12284677632153035, D_X_loss: 0.2935816204547882\n",
      "[53:200] loss_idt_y: 0.08826155498623849, F_fool_loss: 0.014386602435261011, cycled_y_loss: 0.09437416233122349, D_Y_loss: 0.29165888756513597\n",
      "[53:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:300] Took 12.86s\n",
      "[53:300] loss_idt_x: 0.11111487492918969, G_fool_loss: 0.014145642034709454, cycled_x_loss: 0.11032169051468373, D_X_loss: 0.2921809664368629\n",
      "[53:300] loss_idt_y: 0.08337187331169843, F_fool_loss: 0.014449050864204765, cycled_y_loss: 0.08691444039344788, D_Y_loss: 0.2921489208936691\n",
      "[53:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:400] Took 12.90s\n",
      "[53:400] loss_idt_x: 0.12330384928733111, G_fool_loss: 0.014237426044419408, cycled_x_loss: 0.12498314164578915, D_X_loss: 0.2928085017204285\n",
      "[53:400] loss_idt_y: 0.08402322486042976, F_fool_loss: 0.014497188860550523, cycled_y_loss: 0.08375963497906923, D_Y_loss: 0.2927401065826416\n",
      "[53:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:500] Took 12.88s\n",
      "[53:500] loss_idt_x: 0.11352188143879176, G_fool_loss: 0.014387520598247647, cycled_x_loss: 0.10726102642714977, D_X_loss: 0.29251508593559267\n",
      "[53:500] loss_idt_y: 0.07713845178484917, F_fool_loss: 0.01436446949839592, cycled_y_loss: 0.08469781041145324, D_Y_loss: 0.2920608115196228\n",
      "[53:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:600] Took 12.87s\n",
      "[53:600] loss_idt_x: 0.12883914649486541, G_fool_loss: 0.014329749131575227, cycled_x_loss: 0.1270265743881464, D_X_loss: 0.292985882461071\n",
      "[53:600] loss_idt_y: 0.07460838966071606, F_fool_loss: 0.014116741186007857, cycled_y_loss: 0.07654566656798124, D_Y_loss: 0.2931571972370148\n",
      "[53:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:700] Took 12.87s\n",
      "[53:700] loss_idt_x: 0.12234055202454329, G_fool_loss: 0.014401737023144961, cycled_x_loss: 0.12104273788630962, D_X_loss: 0.29292605876922606\n",
      "[53:700] loss_idt_y: 0.09028071500360965, F_fool_loss: 0.01472962435334921, cycled_y_loss: 0.09486592229455709, D_Y_loss: 0.2916737076640129\n",
      "[53:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:800] Took 12.88s\n",
      "[53:800] loss_idt_x: 0.1297610180079937, G_fool_loss: 0.014363598665222526, cycled_x_loss: 0.13087094403803348, D_X_loss: 0.2914183098077774\n",
      "[53:800] loss_idt_y: 0.07854945451021195, F_fool_loss: 0.014545025788247585, cycled_y_loss: 0.08339273437857628, D_Y_loss: 0.2934544569253921\n",
      "[53:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:900] Took 12.88s\n",
      "[53:900] loss_idt_x: 0.11864031150937081, G_fool_loss: 0.014293011631816626, cycled_x_loss: 0.11833441101014613, D_X_loss: 0.2932048194110394\n",
      "[53:900] loss_idt_y: 0.0830955171957612, F_fool_loss: 0.014311545379459858, cycled_y_loss: 0.08535632940009236, D_Y_loss: 0.2928838616609573\n",
      "[53:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:1000] Took 12.87s\n",
      "[53:1000] loss_idt_x: 0.11538121864199638, G_fool_loss: 0.0144950682669878, cycled_x_loss: 0.1194518369436264, D_X_loss: 0.29254749298095706\n",
      "[53:1000] loss_idt_y: 0.08413944955915213, F_fool_loss: 0.01438250619918108, cycled_y_loss: 0.08806115116924047, D_Y_loss: 0.2934291887283325\n",
      "[53:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:1100] Took 12.87s\n",
      "[53:1100] loss_idt_x: 0.12618108592927457, G_fool_loss: 0.01442506936378777, cycled_x_loss: 0.12140976779162883, D_X_loss: 0.29235753148794175\n",
      "[53:1100] loss_idt_y: 0.08965495809912681, F_fool_loss: 0.014318579258397222, cycled_y_loss: 0.09497358959168195, D_Y_loss: 0.29196352541446685\n",
      "[53:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[53:END] Completed epoch in 162.29085779190063s\n",
      "[53:1199] ep_loss_idt_x: 0.121 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.120 ep_D_X_loss: 0.293\n",
      "[53:1199] ep_loss_idt_y: 0.083 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.087 ep_D_Y_loss: 0.293\n",
      "[53:END] Completed eval in 1.5987274646759033s\n",
      "Updated G_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated F_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated D_X_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated D_Y_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "[53:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[54:100] Took 14.81s\n",
      "[54:100] loss_idt_x: 0.12142688520252705, G_fool_loss: 0.0142957036010921, cycled_x_loss: 0.12316138610243797, D_X_loss: 0.29686695605516433\n",
      "[54:100] loss_idt_y: 0.07748848021030426, F_fool_loss: 0.01445868618786335, cycled_y_loss: 0.07829878207296133, D_Y_loss: 0.29568244725465775\n",
      "[54:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:200] Took 12.87s\n",
      "[54:200] loss_idt_x: 0.13093325566500424, G_fool_loss: 0.014316609259694815, cycled_x_loss: 0.12384744327515364, D_X_loss: 0.2937327980995178\n",
      "[54:200] loss_idt_y: 0.0836515799164772, F_fool_loss: 0.014072962179780006, cycled_y_loss: 0.08499932345002889, D_Y_loss: 0.29221402198076246\n",
      "[54:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:300] Took 12.87s\n",
      "[54:300] loss_idt_x: 0.13378549266606568, G_fool_loss: 0.014447869136929511, cycled_x_loss: 0.1307096955180168, D_X_loss: 0.29264928579330446\n",
      "[54:300] loss_idt_y: 0.08662659196183085, F_fool_loss: 0.01439866884611547, cycled_y_loss: 0.08862480614334345, D_Y_loss: 0.2927041468024254\n",
      "[54:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:400] Took 12.87s\n",
      "[54:400] loss_idt_x: 0.13345487993210553, G_fool_loss: 0.014601951828226448, cycled_x_loss: 0.12986551389098167, D_X_loss: 0.29229953944683074\n",
      "[54:400] loss_idt_y: 0.0881877288594842, F_fool_loss: 0.01445650759153068, cycled_y_loss: 0.09302844628691673, D_Y_loss: 0.2934481805562973\n",
      "[54:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:500] Took 12.89s\n",
      "[54:500] loss_idt_x: 0.12647876307368278, G_fool_loss: 0.014401914235204458, cycled_x_loss: 0.12293048035353422, D_X_loss: 0.29328067004680636\n",
      "[54:500] loss_idt_y: 0.09300071772187948, F_fool_loss: 0.01438424332998693, cycled_y_loss: 0.09879021398723126, D_Y_loss: 0.29229356348514557\n",
      "[54:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:600] Took 12.87s\n",
      "[54:600] loss_idt_x: 0.12169886205345393, G_fool_loss: 0.014285850506275892, cycled_x_loss: 0.1171558828279376, D_X_loss: 0.29241945683956144\n",
      "[54:600] loss_idt_y: 0.0812451901100576, F_fool_loss: 0.014337716940790415, cycled_y_loss: 0.08927429258823395, D_Y_loss: 0.29363223135471345\n",
      "[54:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:700] Took 12.86s\n",
      "[54:700] loss_idt_x: 0.12323167074471712, G_fool_loss: 0.014547402560710907, cycled_x_loss: 0.12051363199949265, D_X_loss: 0.2915834867954254\n",
      "[54:700] loss_idt_y: 0.08270968150347471, F_fool_loss: 0.014475364461541176, cycled_y_loss: 0.08668086789548397, D_Y_loss: 0.2925343295931816\n",
      "[54:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:800] Took 12.87s\n",
      "[54:800] loss_idt_x: 0.12347554057836532, G_fool_loss: 0.01426482705399394, cycled_x_loss: 0.12283635556697846, D_X_loss: 0.2918938499689102\n",
      "[54:800] loss_idt_y: 0.08377444606274366, F_fool_loss: 0.014464552383869886, cycled_y_loss: 0.0863920896500349, D_Y_loss: 0.29251433819532396\n",
      "[54:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:900] Took 12.87s\n",
      "[54:900] loss_idt_x: 0.12521801978349686, G_fool_loss: 0.014524777662009, cycled_x_loss: 0.11983427718281746, D_X_loss: 0.29193458616733553\n",
      "[54:900] loss_idt_y: 0.07404846645891666, F_fool_loss: 0.014524985225871206, cycled_y_loss: 0.08035535179078579, D_Y_loss: 0.2922281950712204\n",
      "[54:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:1000] Took 12.89s\n",
      "[54:1000] loss_idt_x: 0.12306567434221506, G_fool_loss: 0.014238138739019633, cycled_x_loss: 0.1206739329919219, D_X_loss: 0.2920037153363228\n",
      "[54:1000] loss_idt_y: 0.08899700056761503, F_fool_loss: 0.014181302627548575, cycled_y_loss: 0.09364229146391154, D_Y_loss: 0.2915919527411461\n",
      "[54:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:1100] Took 12.88s\n",
      "[54:1100] loss_idt_x: 0.11868648797273636, G_fool_loss: 0.014443694576621056, cycled_x_loss: 0.11843552194535732, D_X_loss: 0.29194299012422564\n",
      "[54:1100] loss_idt_y: 0.08207155164331198, F_fool_loss: 0.014616776499897241, cycled_y_loss: 0.0889738205447793, D_Y_loss: 0.2927952748537064\n",
      "[54:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[54:END] Completed epoch in 163.6271688938141s\n",
      "[54:1199] ep_loss_idt_x: 0.125 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.121 ep_D_X_loss: 0.293\n",
      "[54:1199] ep_loss_idt_y: 0.083 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.088 ep_D_Y_loss: 0.293\n",
      "[54:END] Completed eval in 1.5219459533691406s\n",
      "Updated G_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated F_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated D_X_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated D_Y_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "[54:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[55:100] Took 14.83s\n",
      "[55:100] loss_idt_x: 0.13012844905257226, G_fool_loss: 0.014478562967851757, cycled_x_loss: 0.1246491863578558, D_X_loss: 0.2950818857550621\n",
      "[55:100] loss_idt_y: 0.07917901117354631, F_fool_loss: 0.014551101280376314, cycled_y_loss: 0.08658394139260053, D_Y_loss: 0.2952816718816757\n",
      "[55:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:200] Took 12.88s\n",
      "[55:200] loss_idt_x: 0.12082413490861654, G_fool_loss: 0.014355861293151974, cycled_x_loss: 0.12035617556422949, D_X_loss: 0.2927264434099197\n",
      "[55:200] loss_idt_y: 0.09850623853504657, F_fool_loss: 0.014399402821436525, cycled_y_loss: 0.09782165430486202, D_Y_loss: 0.2924372097849846\n",
      "[55:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:300] Took 12.86s\n",
      "[55:300] loss_idt_x: 0.12009287692606449, G_fool_loss: 0.014349589506164193, cycled_x_loss: 0.12205131489783526, D_X_loss: 0.29153379023075104\n",
      "[55:300] loss_idt_y: 0.09672862701117993, F_fool_loss: 0.014499133173376321, cycled_y_loss: 0.09921197151765228, D_Y_loss: 0.2925588029623032\n",
      "[55:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:400] Took 12.87s\n",
      "[55:400] loss_idt_x: 0.1296274361759424, G_fool_loss: 0.014419110845774413, cycled_x_loss: 0.12736570313572884, D_X_loss: 0.2928925111889839\n",
      "[55:400] loss_idt_y: 0.07735776960849762, F_fool_loss: 0.01446190913207829, cycled_y_loss: 0.07835874479264021, D_Y_loss: 0.29186185866594316\n",
      "[55:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:500] Took 12.87s\n",
      "[55:500] loss_idt_x: 0.1189960166439414, G_fool_loss: 0.01428337289020419, cycled_x_loss: 0.12091201428323985, D_X_loss: 0.2925573146343231\n",
      "[55:500] loss_idt_y: 0.0848041770979762, F_fool_loss: 0.014260829659178853, cycled_y_loss: 0.09125085901468992, D_Y_loss: 0.29422999113798143\n",
      "[55:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:600] Took 12.88s\n",
      "[55:600] loss_idt_x: 0.13581649128347636, G_fool_loss: 0.01427196995355189, cycled_x_loss: 0.13281130038201808, D_X_loss: 0.29126797899603846\n",
      "[55:600] loss_idt_y: 0.0827739042416215, F_fool_loss: 0.014355783704668284, cycled_y_loss: 0.08633177218958736, D_Y_loss: 0.29195162445306777\n",
      "[55:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:700] Took 12.89s\n",
      "[55:700] loss_idt_x: 0.11569179512560368, G_fool_loss: 0.014258064553141594, cycled_x_loss: 0.11375897157937288, D_X_loss: 0.2931263154745102\n",
      "[55:700] loss_idt_y: 0.09432687900960446, F_fool_loss: 0.01422843343578279, cycled_y_loss: 0.09753287024796009, D_Y_loss: 0.2920515790581703\n",
      "[55:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:800] Took 12.88s\n",
      "[55:800] loss_idt_x: 0.12319116950035096, G_fool_loss: 0.01438238493166864, cycled_x_loss: 0.12809410963207482, D_X_loss: 0.292336590886116\n",
      "[55:800] loss_idt_y: 0.09320646297186613, F_fool_loss: 0.014398964047431946, cycled_y_loss: 0.0955013981834054, D_Y_loss: 0.29216925114393233\n",
      "[55:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:900] Took 12.87s\n",
      "[55:900] loss_idt_x: 0.12369498666375875, G_fool_loss: 0.014470917750149965, cycled_x_loss: 0.12183763243258, D_X_loss: 0.29207238167524335\n",
      "[55:900] loss_idt_y: 0.09517988629639149, F_fool_loss: 0.014319819444790483, cycled_y_loss: 0.09680006735026836, D_Y_loss: 0.29336144149303434\n",
      "[55:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:1000] Took 12.88s\n",
      "[55:1000] loss_idt_x: 0.11882578771561385, G_fool_loss: 0.01442851522937417, cycled_x_loss: 0.11336102310568094, D_X_loss: 0.2940017756819725\n",
      "[55:1000] loss_idt_y: 0.08955949883908033, F_fool_loss: 0.014434196520596743, cycled_y_loss: 0.09307305194437504, D_Y_loss: 0.29311666905879974\n",
      "[55:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:1100] Took 12.86s\n",
      "[55:1100] loss_idt_x: 0.11528065819293261, G_fool_loss: 0.014533001389354467, cycled_x_loss: 0.11581998594105243, D_X_loss: 0.29108374536037446\n",
      "[55:1100] loss_idt_y: 0.07276879880577326, F_fool_loss: 0.014429176868870854, cycled_y_loss: 0.07362349301576615, D_Y_loss: 0.2915458008646965\n",
      "[55:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[55:END] Completed epoch in 162.67100381851196s\n",
      "[55:1199] ep_loss_idt_x: 0.122 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.121 ep_D_X_loss: 0.292\n",
      "[55:1199] ep_loss_idt_y: 0.087 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.090 ep_D_Y_loss: 0.293\n",
      "[55:END] Completed eval in 1.5837671756744385s\n",
      "Updated G_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated F_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated D_X_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated D_Y_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "[55:END] Saving models and training information permanently\n",
      "[56:100] Took 14.82s\n",
      "[56:100] loss_idt_x: 0.11881162494421005, G_fool_loss: 0.014602193599566817, cycled_x_loss: 0.11779926646500825, D_X_loss: 0.2968949815630913\n",
      "[56:100] loss_idt_y: 0.08824564918875694, F_fool_loss: 0.01448592847213149, cycled_y_loss: 0.09363837536424398, D_Y_loss: 0.2962752723693848\n",
      "[56:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:200] Took 12.86s\n",
      "[56:200] loss_idt_x: 0.11174397625029087, G_fool_loss: 0.01413063901476562, cycled_x_loss: 0.11360458195209504, D_X_loss: 0.2921077898144722\n",
      "[56:200] loss_idt_y: 0.07895055670291186, F_fool_loss: 0.014138268008828163, cycled_y_loss: 0.08114826750010252, D_Y_loss: 0.29169014692306516\n",
      "[56:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:300] Took 12.87s\n",
      "[56:300] loss_idt_x: 0.12727980241179465, G_fool_loss: 0.014306586077436805, cycled_x_loss: 0.12126220796257257, D_X_loss: 0.2925940006971359\n",
      "[56:300] loss_idt_y: 0.09322678884491324, F_fool_loss: 0.014278130196034909, cycled_y_loss: 0.09651223089545966, D_Y_loss: 0.2929216620326042\n",
      "[56:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:400] Took 12.89s\n",
      "[56:400] loss_idt_x: 0.11627080515027047, G_fool_loss: 0.014374243915081025, cycled_x_loss: 0.11415209032595158, D_X_loss: 0.2924528139829636\n",
      "[56:400] loss_idt_y: 0.07657357884570956, F_fool_loss: 0.01437711227685213, cycled_y_loss: 0.07976857800036669, D_Y_loss: 0.29264794498682023\n",
      "[56:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:500] Took 12.90s\n",
      "[56:500] loss_idt_x: 0.12589649759233, G_fool_loss: 0.014286464136093855, cycled_x_loss: 0.12544818788766862, D_X_loss: 0.29190548092126845\n",
      "[56:500] loss_idt_y: 0.0718139198422432, F_fool_loss: 0.014325694078579546, cycled_y_loss: 0.0770265669003129, D_Y_loss: 0.2923010021448135\n",
      "[56:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:600] Took 12.87s\n",
      "[56:600] loss_idt_x: 0.11335694141685963, G_fool_loss: 0.014496121322736144, cycled_x_loss: 0.10892706412822008, D_X_loss: 0.29348895758390425\n",
      "[56:600] loss_idt_y: 0.08975159186869859, F_fool_loss: 0.014491205317899585, cycled_y_loss: 0.09276152014732361, D_Y_loss: 0.29246017694473264\n",
      "[56:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:700] Took 12.87s\n",
      "[56:700] loss_idt_x: 0.12839377880096436, G_fool_loss: 0.01432941914536059, cycled_x_loss: 0.1266100386530161, D_X_loss: 0.2923169431090355\n",
      "[56:700] loss_idt_y: 0.0825923021696508, F_fool_loss: 0.01432670708745718, cycled_y_loss: 0.08249241713434458, D_Y_loss: 0.2919795623421669\n",
      "[56:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:800] Took 12.88s\n",
      "[56:800] loss_idt_x: 0.11802000716328621, G_fool_loss: 0.014315667767077685, cycled_x_loss: 0.1184378657117486, D_X_loss: 0.29165503948926924\n",
      "[56:800] loss_idt_y: 0.09798414189368486, F_fool_loss: 0.01425627144984901, cycled_y_loss: 0.0975916432403028, D_Y_loss: 0.29164348393678663\n",
      "[56:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:900] Took 12.88s\n",
      "[56:900] loss_idt_x: 0.11835493572056294, G_fool_loss: 0.014330570548772813, cycled_x_loss: 0.11829568285495043, D_X_loss: 0.2920129731297493\n",
      "[56:900] loss_idt_y: 0.08220412511378526, F_fool_loss: 0.01441661617718637, cycled_y_loss: 0.0868620465323329, D_Y_loss: 0.29321915805339815\n",
      "[56:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:1000] Took 12.88s\n",
      "[56:1000] loss_idt_x: 0.12505098655819893, G_fool_loss: 0.01438966847024858, cycled_x_loss: 0.12413195833563805, D_X_loss: 0.2925557142496109\n",
      "[56:1000] loss_idt_y: 0.0810297298617661, F_fool_loss: 0.014266578340902924, cycled_y_loss: 0.08484883192926646, D_Y_loss: 0.29189683496952057\n",
      "[56:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:1100] Took 12.88s\n",
      "[56:1100] loss_idt_x: 0.1272926540672779, G_fool_loss: 0.014127999069169164, cycled_x_loss: 0.13421599328517914, D_X_loss: 0.29324507027864455\n",
      "[56:1100] loss_idt_y: 0.08822799474000931, F_fool_loss: 0.01442349017597735, cycled_y_loss: 0.09449417155236006, D_Y_loss: 0.2929855042695999\n",
      "[56:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[56:END] Completed epoch in 161.37230396270752s\n",
      "[56:1199] ep_loss_idt_x: 0.120 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.119 ep_D_X_loss: 0.293\n",
      "[56:1199] ep_loss_idt_y: 0.084 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.087 ep_D_Y_loss: 0.292\n",
      "[56:END] Completed eval in 1.5658080577850342s\n",
      "Updated G_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated F_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated D_X_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated D_Y_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "[56:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[57:100] Took 14.85s\n",
      "[57:100] loss_idt_x: 0.11887103728950024, G_fool_loss: 0.014515738850459457, cycled_x_loss: 0.1187532441318035, D_X_loss: 0.2964558556675911\n",
      "[57:100] loss_idt_y: 0.0736835777387023, F_fool_loss: 0.014323121244087815, cycled_y_loss: 0.07950575549155474, D_Y_loss: 0.2957910680770874\n",
      "[57:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:200] Took 12.87s\n",
      "[57:200] loss_idt_x: 0.12078243058174848, G_fool_loss: 0.014136324198916554, cycled_x_loss: 0.11691506586968899, D_X_loss: 0.29330155313014983\n",
      "[57:200] loss_idt_y: 0.07584320783615112, F_fool_loss: 0.014156941594555973, cycled_y_loss: 0.07874513637274504, D_Y_loss: 0.2925557065010071\n",
      "[57:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:300] Took 12.87s\n",
      "[57:300] loss_idt_x: 0.11316441684961319, G_fool_loss: 0.014199277656152844, cycled_x_loss: 0.11037530682981014, D_X_loss: 0.29105196803808214\n",
      "[57:300] loss_idt_y: 0.07829033616930246, F_fool_loss: 0.014291786793619395, cycled_y_loss: 0.07792406667023898, D_Y_loss: 0.293397870361805\n",
      "[57:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:400] Took 12.87s\n",
      "[57:400] loss_idt_x: 0.12621399082243442, G_fool_loss: 0.014310618201270699, cycled_x_loss: 0.12718738716095687, D_X_loss: 0.2924865919351578\n",
      "[57:400] loss_idt_y: 0.07984227769076824, F_fool_loss: 0.014236214933916927, cycled_y_loss: 0.08341216031461954, D_Y_loss: 0.293018784224987\n",
      "[57:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:500] Took 12.87s\n",
      "[57:500] loss_idt_x: 0.11808410190045833, G_fool_loss: 0.014375295480713248, cycled_x_loss: 0.1202430223673582, D_X_loss: 0.29309036791324616\n",
      "[57:500] loss_idt_y: 0.07698251776397229, F_fool_loss: 0.014474437171593309, cycled_y_loss: 0.08012582005932928, D_Y_loss: 0.2936303597688675\n",
      "[57:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:600] Took 12.87s\n",
      "[57:600] loss_idt_x: 0.11626845639199018, G_fool_loss: 0.014278844855725765, cycled_x_loss: 0.11323750618845224, D_X_loss: 0.2923237305879593\n",
      "[57:600] loss_idt_y: 0.0826835418306291, F_fool_loss: 0.014278808804228903, cycled_y_loss: 0.0867829960025847, D_Y_loss: 0.2937704148888588\n",
      "[57:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:700] Took 12.87s\n",
      "[57:700] loss_idt_x: 0.11095704935491085, G_fool_loss: 0.014324053972959518, cycled_x_loss: 0.11299558807164431, D_X_loss: 0.29262008249759675\n",
      "[57:700] loss_idt_y: 0.0817358784377575, F_fool_loss: 0.01425054588355124, cycled_y_loss: 0.08114918302744627, D_Y_loss: 0.2919296142458916\n",
      "[57:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:800] Took 12.87s\n",
      "[57:800] loss_idt_x: 0.11226385712623596, G_fool_loss: 0.014293956588953733, cycled_x_loss: 0.11294336888939142, D_X_loss: 0.291879697740078\n",
      "[57:800] loss_idt_y: 0.08237228155136109, F_fool_loss: 0.014347923006862402, cycled_y_loss: 0.08784696478396654, D_Y_loss: 0.2922223317623138\n",
      "[57:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:900] Took 12.88s\n",
      "[57:900] loss_idt_x: 0.13077026952058077, G_fool_loss: 0.014189494783058762, cycled_x_loss: 0.13105491012334824, D_X_loss: 0.2925115606188774\n",
      "[57:900] loss_idt_y: 0.09073614979162813, F_fool_loss: 0.014253914840519428, cycled_y_loss: 0.09659641474485398, D_Y_loss: 0.29128547668457033\n",
      "[57:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:1000] Took 12.87s\n",
      "[57:1000] loss_idt_x: 0.12088121987879276, G_fool_loss: 0.014124428918585182, cycled_x_loss: 0.1234614333882928, D_X_loss: 0.29181877970695497\n",
      "[57:1000] loss_idt_y: 0.08725759714841842, F_fool_loss: 0.01433612304739654, cycled_y_loss: 0.09024054557085037, D_Y_loss: 0.2929920732975006\n",
      "[57:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:1100] Took 12.87s\n",
      "[57:1100] loss_idt_x: 0.12746954180300235, G_fool_loss: 0.014277286967262626, cycled_x_loss: 0.12309353191405535, D_X_loss: 0.29191311448812485\n",
      "[57:1100] loss_idt_y: 0.07623948622494936, F_fool_loss: 0.014183414625003934, cycled_y_loss: 0.07984183326363564, D_Y_loss: 0.2918302673101425\n",
      "[57:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[57:END] Completed epoch in 164.4675087928772s\n",
      "[57:1199] ep_loss_idt_x: 0.119 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.119 ep_D_X_loss: 0.292\n",
      "[57:1199] ep_loss_idt_y: 0.080 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.083 ep_D_Y_loss: 0.293\n",
      "[57:END] Completed eval in 1.6485941410064697s\n",
      "Updated G_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated F_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated D_X_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated D_Y_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "[57:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[58:100] Took 14.88s\n",
      "[58:100] loss_idt_x: 0.12409514177590608, G_fool_loss: 0.014273370336741208, cycled_x_loss: 0.12111708663403987, D_X_loss: 0.2950377222895622\n",
      "[58:100] loss_idt_y: 0.08514588411897421, F_fool_loss: 0.014579965276643634, cycled_y_loss: 0.09007812090218068, D_Y_loss: 0.29510590821504595\n",
      "[58:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:200] Took 12.89s\n",
      "[58:200] loss_idt_x: 0.12106259286403656, G_fool_loss: 0.014333180589601398, cycled_x_loss: 0.11767625093460082, D_X_loss: 0.2917345577478409\n",
      "[58:200] loss_idt_y: 0.08743842288851739, F_fool_loss: 0.014243188314139843, cycled_y_loss: 0.09326344337314367, D_Y_loss: 0.2921628886461258\n",
      "[58:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:300] Took 12.88s\n",
      "[58:300] loss_idt_x: 0.116547015234828, G_fool_loss: 0.014235568018630147, cycled_x_loss: 0.11495892867445946, D_X_loss: 0.29273348569869995\n",
      "[58:300] loss_idt_y: 0.07106225596740842, F_fool_loss: 0.014236322548240423, cycled_y_loss: 0.07366424519568682, D_Y_loss: 0.2927056610584259\n",
      "[58:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:400] Took 12.88s\n",
      "[58:400] loss_idt_x: 0.11924453116953374, G_fool_loss: 0.014333412246778608, cycled_x_loss: 0.11889144849032164, D_X_loss: 0.2928980702161789\n",
      "[58:400] loss_idt_y: 0.07737833838909865, F_fool_loss: 0.014171713525429367, cycled_y_loss: 0.07786150470376015, D_Y_loss: 0.291231270134449\n",
      "[58:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:500] Took 12.89s\n",
      "[58:500] loss_idt_x: 0.12630052153021099, G_fool_loss: 0.014252606825903059, cycled_x_loss: 0.12857942335307598, D_X_loss: 0.29308858662843706\n",
      "[58:500] loss_idt_y: 0.08376623764634132, F_fool_loss: 0.014365057926625013, cycled_y_loss: 0.08865247178822756, D_Y_loss: 0.2928602224588394\n",
      "[58:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:600] Took 12.89s\n",
      "[58:600] loss_idt_x: 0.1240385402366519, G_fool_loss: 0.014182769320905208, cycled_x_loss: 0.12401209495961667, D_X_loss: 0.2930000931024551\n",
      "[58:600] loss_idt_y: 0.07941944800317287, F_fool_loss: 0.014290245044976472, cycled_y_loss: 0.08165768899023533, D_Y_loss: 0.2924181231856346\n",
      "[58:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:700] Took 12.86s\n",
      "[58:700] loss_idt_x: 0.11663554355502129, G_fool_loss: 0.01428902555257082, cycled_x_loss: 0.1153918370231986, D_X_loss: 0.29259825736284256\n",
      "[58:700] loss_idt_y: 0.08131704803556204, F_fool_loss: 0.0144385539367795, cycled_y_loss: 0.08321400668472051, D_Y_loss: 0.2932874655723572\n",
      "[58:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:800] Took 12.88s\n",
      "[58:800] loss_idt_x: 0.11659335874021054, G_fool_loss: 0.014256170764565469, cycled_x_loss: 0.12171237196773291, D_X_loss: 0.2932481762766838\n",
      "[58:800] loss_idt_y: 0.07874138753861189, F_fool_loss: 0.01439474055543542, cycled_y_loss: 0.07949976190924644, D_Y_loss: 0.29241708844900133\n",
      "[58:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:900] Took 12.87s\n",
      "[58:900] loss_idt_x: 0.11324624851346016, G_fool_loss: 0.014255528571084142, cycled_x_loss: 0.11344205569475889, D_X_loss: 0.293191037774086\n",
      "[58:900] loss_idt_y: 0.0905688702687621, F_fool_loss: 0.014214089140295982, cycled_y_loss: 0.09331470301374793, D_Y_loss: 0.2914181879162788\n",
      "[58:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:1000] Took 12.87s\n",
      "[58:1000] loss_idt_x: 0.1119554803147912, G_fool_loss: 0.014265742022544145, cycled_x_loss: 0.10219530645757914, D_X_loss: 0.29257945269346236\n",
      "[58:1000] loss_idt_y: 0.08398247182369233, F_fool_loss: 0.014183167116716505, cycled_y_loss: 0.08494716584682464, D_Y_loss: 0.2924588346481323\n",
      "[58:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:1100] Took 12.86s\n",
      "[58:1100] loss_idt_x: 0.12596610508859157, G_fool_loss: 0.014231976848095655, cycled_x_loss: 0.12348139353096485, D_X_loss: 0.29321383029222486\n",
      "[58:1100] loss_idt_y: 0.08975291591137648, F_fool_loss: 0.014134764075279235, cycled_y_loss: 0.09451377928256989, D_Y_loss: 0.29272998601198197\n",
      "[58:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[58:END] Completed epoch in 162.79654574394226s\n",
      "[58:1199] ep_loss_idt_x: 0.120 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.119 ep_D_X_loss: 0.293\n",
      "[58:1199] ep_loss_idt_y: 0.083 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.086 ep_D_Y_loss: 0.292\n",
      "[58:END] Completed eval in 1.6266376972198486s\n",
      "Updated G_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated F_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated D_X_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated D_Y_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "[58:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[59:100] Took 14.84s\n",
      "[59:100] loss_idt_x: 0.11568574819713831, G_fool_loss: 0.01447095012292266, cycled_x_loss: 0.1170300754532218, D_X_loss: 0.2945677450299263\n",
      "[59:100] loss_idt_y: 0.0846441065147519, F_fool_loss: 0.014399654641747474, cycled_y_loss: 0.08814666114747524, D_Y_loss: 0.2959963309764862\n",
      "[59:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:200] Took 12.87s\n",
      "[59:200] loss_idt_x: 0.12674957893788816, G_fool_loss: 0.01393113545142114, cycled_x_loss: 0.12261432196944952, D_X_loss: 0.2912067750096321\n",
      "[59:200] loss_idt_y: 0.08139200437813997, F_fool_loss: 0.014171255258843303, cycled_y_loss: 0.0877159184217453, D_Y_loss: 0.29194734811782835\n",
      "[59:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:300] Took 12.89s\n",
      "[59:300] loss_idt_x: 0.12348971921950579, G_fool_loss: 0.014327657893300056, cycled_x_loss: 0.1241810055822134, D_X_loss: 0.2927913084626198\n",
      "[59:300] loss_idt_y: 0.07776722043752671, F_fool_loss: 0.014182156380265952, cycled_y_loss: 0.08209679450839757, D_Y_loss: 0.2933655443787575\n",
      "[59:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:400] Took 12.87s\n",
      "[59:400] loss_idt_x: 0.11843454387038946, G_fool_loss: 0.01425561236217618, cycled_x_loss: 0.12435101736336947, D_X_loss: 0.29254860371351243\n",
      "[59:400] loss_idt_y: 0.09585579505190253, F_fool_loss: 0.014277675393968821, cycled_y_loss: 0.09545207355171442, D_Y_loss: 0.2928363937139511\n",
      "[59:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:500] Took 12.87s\n",
      "[59:500] loss_idt_x: 0.11183195780962706, G_fool_loss: 0.01428056568838656, cycled_x_loss: 0.10387094222009181, D_X_loss: 0.29145288199186326\n",
      "[59:500] loss_idt_y: 0.0849770749732852, F_fool_loss: 0.014196120174601675, cycled_y_loss: 0.08916681412607431, D_Y_loss: 0.2940485143661499\n",
      "[59:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:600] Took 12.88s\n",
      "[59:600] loss_idt_x: 0.11095126122236251, G_fool_loss: 0.014166146805509925, cycled_x_loss: 0.11178049385547638, D_X_loss: 0.29360357820987704\n",
      "[59:600] loss_idt_y: 0.07822257714346051, F_fool_loss: 0.014149545282125474, cycled_y_loss: 0.0779288611188531, D_Y_loss: 0.29154367446899415\n",
      "[59:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:700] Took 12.89s\n",
      "[59:700] loss_idt_x: 0.11382948748767376, G_fool_loss: 0.014150208700448275, cycled_x_loss: 0.11078759830445051, D_X_loss: 0.29225140661001203\n",
      "[59:700] loss_idt_y: 0.08086329985409975, F_fool_loss: 0.014322205968201161, cycled_y_loss: 0.08275699779391289, D_Y_loss: 0.2920840895175934\n",
      "[59:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:800] Took 12.86s\n",
      "[59:800] loss_idt_x: 0.11358690580353141, G_fool_loss: 0.0143135900888592, cycled_x_loss: 0.11445070911198854, D_X_loss: 0.2921485617756844\n",
      "[59:800] loss_idt_y: 0.08093602333217859, F_fool_loss: 0.014020406808704138, cycled_y_loss: 0.08376249581575394, D_Y_loss: 0.29177048563957214\n",
      "[59:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:900] Took 12.88s\n",
      "[59:900] loss_idt_x: 0.1237763362005353, G_fool_loss: 0.014147528009489178, cycled_x_loss: 0.12143565077334642, D_X_loss: 0.2912331673502922\n",
      "[59:900] loss_idt_y: 0.08405032381415367, F_fool_loss: 0.01429544405080378, cycled_y_loss: 0.08245722755789757, D_Y_loss: 0.2932113578915596\n",
      "[59:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:1000] Took 12.88s\n",
      "[59:1000] loss_idt_x: 0.1283947452530265, G_fool_loss: 0.014226634157821536, cycled_x_loss: 0.12693615581840276, D_X_loss: 0.292838040292263\n",
      "[59:1000] loss_idt_y: 0.07333288431167602, F_fool_loss: 0.014323642579838633, cycled_y_loss: 0.07714271131902933, D_Y_loss: 0.2922067204117775\n",
      "[59:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:1100] Took 12.88s\n",
      "[59:1100] loss_idt_x: 0.1247313142940402, G_fool_loss: 0.014124606987461447, cycled_x_loss: 0.12630161210894586, D_X_loss: 0.2922539785504341\n",
      "[59:1100] loss_idt_y: 0.08044039651751518, F_fool_loss: 0.014358402723446488, cycled_y_loss: 0.07947571579366923, D_Y_loss: 0.29171036154031754\n",
      "[59:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[59:END] Completed epoch in 164.0873942375183s\n",
      "[59:1199] ep_loss_idt_x: 0.119 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.118 ep_D_X_loss: 0.292\n",
      "[59:1199] ep_loss_idt_y: 0.081 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.083 ep_D_Y_loss: 0.293\n",
      "[59:END] Completed eval in 1.5867295265197754s\n",
      "Updated G_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated F_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated D_X_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated D_Y_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "[59:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[60:100] Took 14.86s\n",
      "[60:100] loss_idt_x: 0.11554839361459017, G_fool_loss: 0.014355051666498184, cycled_x_loss: 0.11140408605337143, D_X_loss: 0.29449197262525556\n",
      "[60:100] loss_idt_y: 0.08279675394296646, F_fool_loss: 0.014480528542771936, cycled_y_loss: 0.08734073534607888, D_Y_loss: 0.2946271428465843\n",
      "[60:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:200] Took 12.87s\n",
      "[60:200] loss_idt_x: 0.11530484776943922, G_fool_loss: 0.01403306701220572, cycled_x_loss: 0.11455580096691848, D_X_loss: 0.2922696688771248\n",
      "[60:200] loss_idt_y: 0.07356052722781897, F_fool_loss: 0.014131053378805518, cycled_y_loss: 0.07795824345201254, D_Y_loss: 0.29179647237062456\n",
      "[60:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:300] Took 12.87s\n",
      "[60:300] loss_idt_x: 0.10616214487701654, G_fool_loss: 0.014293228732421994, cycled_x_loss: 0.10125540517270565, D_X_loss: 0.29203217566013334\n",
      "[60:300] loss_idt_y: 0.08571831174194813, F_fool_loss: 0.01419076149351895, cycled_y_loss: 0.08358830694109201, D_Y_loss: 0.29181418687105176\n",
      "[60:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:400] Took 12.88s\n",
      "[60:400] loss_idt_x: 0.1162861905619502, G_fool_loss: 0.014193734144791961, cycled_x_loss: 0.1144532387331128, D_X_loss: 0.29177132338285444\n",
      "[60:400] loss_idt_y: 0.07939860370010138, F_fool_loss: 0.014331101356074214, cycled_y_loss: 0.08031985774636269, D_Y_loss: 0.29275340676307676\n",
      "[60:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:500] Took 12.87s\n",
      "[60:500] loss_idt_x: 0.11391718950122595, G_fool_loss: 0.014177283244207502, cycled_x_loss: 0.11053496237844229, D_X_loss: 0.29358941584825515\n",
      "[60:500] loss_idt_y: 0.08321356983855367, F_fool_loss: 0.014032002817839385, cycled_y_loss: 0.0841450709477067, D_Y_loss: 0.2930461350083351\n",
      "[60:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:600] Took 12.87s\n",
      "[60:600] loss_idt_x: 0.11822809226810932, G_fool_loss: 0.014155099373310805, cycled_x_loss: 0.11649080488830804, D_X_loss: 0.2924952057003975\n",
      "[60:600] loss_idt_y: 0.0827106574550271, F_fool_loss: 0.0141580097284168, cycled_y_loss: 0.0879675349779427, D_Y_loss: 0.29227135628461837\n",
      "[60:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:700] Took 12.88s\n",
      "[60:700] loss_idt_x: 0.10729673691093922, G_fool_loss: 0.014423485603183508, cycled_x_loss: 0.10528032682836055, D_X_loss: 0.2934377709031105\n",
      "[60:700] loss_idt_y: 0.08536596529185772, F_fool_loss: 0.014183668410405517, cycled_y_loss: 0.08535762328654528, D_Y_loss: 0.2926864179968834\n",
      "[60:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:800] Took 12.89s\n",
      "[60:800] loss_idt_x: 0.11908153746277093, G_fool_loss: 0.014133363431319594, cycled_x_loss: 0.11736335139721632, D_X_loss: 0.29337975174188613\n",
      "[60:800] loss_idt_y: 0.08245750844478607, F_fool_loss: 0.014250561436638236, cycled_y_loss: 0.08487925231456757, D_Y_loss: 0.2926729413866997\n",
      "[60:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:900] Took 12.87s\n",
      "[60:900] loss_idt_x: 0.1292396079748869, G_fool_loss: 0.014133840696886182, cycled_x_loss: 0.12183173075318336, D_X_loss: 0.29255013704299926\n",
      "[60:900] loss_idt_y: 0.08716199554502964, F_fool_loss: 0.014266029940918088, cycled_y_loss: 0.09003526721149684, D_Y_loss: 0.2919788384437561\n",
      "[60:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:1000] Took 12.88s\n",
      "[60:1000] loss_idt_x: 0.12355194106698036, G_fool_loss: 0.014110179515555502, cycled_x_loss: 0.11718292787671089, D_X_loss: 0.2916078931093216\n",
      "[60:1000] loss_idt_y: 0.07409821236506105, F_fool_loss: 0.014315365105867386, cycled_y_loss: 0.07661328677088022, D_Y_loss: 0.2919600862264633\n",
      "[60:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:1100] Took 12.88s\n",
      "[60:1100] loss_idt_x: 0.12459756325930357, G_fool_loss: 0.014123012507334352, cycled_x_loss: 0.1220394403487444, D_X_loss: 0.29308626025915147\n",
      "[60:1100] loss_idt_y: 0.07624501444399356, F_fool_loss: 0.014043396171182394, cycled_y_loss: 0.08069380287081003, D_Y_loss: 0.2920676526427269\n",
      "[60:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[60:END] Completed epoch in 161.77162981033325s\n",
      "[60:1199] ep_loss_idt_x: 0.117 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.113 ep_D_X_loss: 0.292\n",
      "[60:1199] ep_loss_idt_y: 0.081 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.083 ep_D_Y_loss: 0.292\n",
      "[60:END] Completed eval in 1.6246592998504639s\n",
      "Updated G_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated F_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated D_X_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated D_Y_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "[60:END] Saving models and training information permanently\n",
      "[61:100] Took 14.86s\n",
      "[61:100] loss_idt_x: 0.12256382249295711, G_fool_loss: 0.014428516961634158, cycled_x_loss: 0.12262094385921955, D_X_loss: 0.2955609580874443\n",
      "[61:100] loss_idt_y: 0.07744237769395113, F_fool_loss: 0.014293524781242012, cycled_y_loss: 0.07957960393279791, D_Y_loss: 0.29532034039497373\n",
      "[61:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:200] Took 12.87s\n",
      "[61:200] loss_idt_x: 0.11811469294130802, G_fool_loss: 0.014145022118464112, cycled_x_loss: 0.1135675585642457, D_X_loss: 0.2928742986917496\n",
      "[61:200] loss_idt_y: 0.0848242606781423, F_fool_loss: 0.014174910075962544, cycled_y_loss: 0.08608507838100195, D_Y_loss: 0.29306433230638507\n",
      "[61:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:300] Took 12.89s\n",
      "[61:300] loss_idt_x: 0.1146902034804225, G_fool_loss: 0.014186922376975417, cycled_x_loss: 0.11339701745659113, D_X_loss: 0.293409381210804\n",
      "[61:300] loss_idt_y: 0.07575745098292827, F_fool_loss: 0.014162982366979122, cycled_y_loss: 0.07738960813730955, D_Y_loss: 0.2912972754240036\n",
      "[61:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:400] Took 12.89s\n",
      "[61:400] loss_idt_x: 0.113191874101758, G_fool_loss: 0.014231983302161098, cycled_x_loss: 0.11303548686206341, D_X_loss: 0.29321582794189455\n",
      "[61:400] loss_idt_y: 0.08356272179633378, F_fool_loss: 0.014140649624168873, cycled_y_loss: 0.08594558820128441, D_Y_loss: 0.2923277273774147\n",
      "[61:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:500] Took 12.88s\n",
      "[61:500] loss_idt_x: 0.10356555994600057, G_fool_loss: 0.014255926311016083, cycled_x_loss: 0.10088634680956603, D_X_loss: 0.29143351078033447\n",
      "[61:500] loss_idt_y: 0.07063741281628609, F_fool_loss: 0.01403426275588572, cycled_y_loss: 0.07222046978771686, D_Y_loss: 0.29142564207315447\n",
      "[61:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:600] Took 12.88s\n",
      "[61:600] loss_idt_x: 0.12440836805850268, G_fool_loss: 0.014195323819294572, cycled_x_loss: 0.11396732714027166, D_X_loss: 0.2922847118973732\n",
      "[61:600] loss_idt_y: 0.08686162915080786, F_fool_loss: 0.014122420297935605, cycled_y_loss: 0.08891229096800089, D_Y_loss: 0.2917859417200088\n",
      "[61:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:700] Took 12.87s\n",
      "[61:700] loss_idt_x: 0.1176601479202509, G_fool_loss: 0.014290816122666002, cycled_x_loss: 0.11802639897912741, D_X_loss: 0.2917222335934639\n",
      "[61:700] loss_idt_y: 0.08261732421815396, F_fool_loss: 0.01408212567679584, cycled_y_loss: 0.08251396670937539, D_Y_loss: 0.29296041578054427\n",
      "[61:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:800] Took 12.88s\n",
      "[61:800] loss_idt_x: 0.12140072621405125, G_fool_loss: 0.014111432489007711, cycled_x_loss: 0.11804609894752502, D_X_loss: 0.29302166402339935\n",
      "[61:800] loss_idt_y: 0.07667522471398115, F_fool_loss: 0.014471868481487037, cycled_y_loss: 0.08154405616223812, D_Y_loss: 0.29254709333181383\n",
      "[61:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:900] Took 12.88s\n",
      "[61:900] loss_idt_x: 0.11460356950759888, G_fool_loss: 0.014348631473258138, cycled_x_loss: 0.10621937483549118, D_X_loss: 0.2919990754127502\n",
      "[61:900] loss_idt_y: 0.07485615566372872, F_fool_loss: 0.014305884065106512, cycled_y_loss: 0.08126089315861464, D_Y_loss: 0.293062684237957\n",
      "[61:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:1000] Took 12.86s\n",
      "[61:1000] loss_idt_x: 0.1173701873421669, G_fool_loss: 0.01429905055090785, cycled_x_loss: 0.11833074565976859, D_X_loss: 0.29390924006700514\n",
      "[61:1000] loss_idt_y: 0.0868720008060336, F_fool_loss: 0.014477553302422166, cycled_y_loss: 0.08973758935928344, D_Y_loss: 0.29196695119142535\n",
      "[61:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:1100] Took 12.88s\n",
      "[61:1100] loss_idt_x: 0.10701090045273304, G_fool_loss: 0.014176962561905385, cycled_x_loss: 0.10665111813694239, D_X_loss: 0.29351844161748886\n",
      "[61:1100] loss_idt_y: 0.07890838811174035, F_fool_loss: 0.014334118207916618, cycled_y_loss: 0.08468437116593122, D_Y_loss: 0.2928701236844063\n",
      "[61:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[61:END] Completed epoch in 161.7191846370697s\n",
      "[61:1199] ep_loss_idt_x: 0.115 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.113 ep_D_X_loss: 0.293\n",
      "[61:1199] ep_loss_idt_y: 0.079 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.082 ep_D_Y_loss: 0.292\n",
      "[61:END] Completed eval in 1.6886038780212402s\n",
      "Updated G_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated F_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated D_X_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated D_Y_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "[61:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[62:100] Took 14.86s\n",
      "[62:100] loss_idt_x: 0.11763764496892691, G_fool_loss: 0.01430928399786353, cycled_x_loss: 0.11687058977782726, D_X_loss: 0.2966208842396736\n",
      "[62:100] loss_idt_y: 0.08106504136696457, F_fool_loss: 0.014306740676984191, cycled_y_loss: 0.08177952595055103, D_Y_loss: 0.29676915526390074\n",
      "[62:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:200] Took 12.89s\n",
      "[62:200] loss_idt_x: 0.12994363866746425, G_fool_loss: 0.0143909902125597, cycled_x_loss: 0.12791002508252858, D_X_loss: 0.29196249395608903\n",
      "[62:200] loss_idt_y: 0.08306943662464619, F_fool_loss: 0.014308882197365164, cycled_y_loss: 0.09022588353604079, D_Y_loss: 0.29240621834993363\n",
      "[62:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:300] Took 12.88s\n",
      "[62:300] loss_idt_x: 0.11819425962865353, G_fool_loss: 0.014211465548723936, cycled_x_loss: 0.11312668167054653, D_X_loss: 0.29212465822696687\n",
      "[62:300] loss_idt_y: 0.08479032102972268, F_fool_loss: 0.014319033436477184, cycled_y_loss: 0.08466774176806212, D_Y_loss: 0.2941939625144005\n",
      "[62:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:400] Took 12.87s\n",
      "[62:400] loss_idt_x: 0.11023754157125949, G_fool_loss: 0.014267042921856045, cycled_x_loss: 0.10367294084280729, D_X_loss: 0.2926302295923233\n",
      "[62:400] loss_idt_y: 0.08021323945373297, F_fool_loss: 0.01412115341052413, cycled_y_loss: 0.08685905802994967, D_Y_loss: 0.2930806651711464\n",
      "[62:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:500] Took 12.88s\n",
      "[62:500] loss_idt_x: 0.12349479161202907, G_fool_loss: 0.014195112781599163, cycled_x_loss: 0.11848832592368126, D_X_loss: 0.2919442677497864\n",
      "[62:500] loss_idt_y: 0.08449414484202862, F_fool_loss: 0.014262365093454719, cycled_y_loss: 0.0871179343573749, D_Y_loss: 0.2927870896458626\n",
      "[62:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:600] Took 12.87s\n",
      "[62:600] loss_idt_x: 0.11739427704364061, G_fool_loss: 0.014187319902703166, cycled_x_loss: 0.1123883219063282, D_X_loss: 0.29203532457351683\n",
      "[62:600] loss_idt_y: 0.07986844887956977, F_fool_loss: 0.014256942169740796, cycled_y_loss: 0.08281683504581451, D_Y_loss: 0.2926370996236801\n",
      "[62:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:700] Took 12.87s\n",
      "[62:700] loss_idt_x: 0.12232905510812998, G_fool_loss: 0.014229171443730593, cycled_x_loss: 0.11796202290803194, D_X_loss: 0.29341578006744384\n",
      "[62:700] loss_idt_y: 0.07729712277650833, F_fool_loss: 0.014169298075139523, cycled_y_loss: 0.07841122915968299, D_Y_loss: 0.29464175581932067\n",
      "[62:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:800] Took 12.88s\n",
      "[62:800] loss_idt_x: 0.10780532751232386, G_fool_loss: 0.01419742968864739, cycled_x_loss: 0.11104747906327248, D_X_loss: 0.29349933058023453\n",
      "[62:800] loss_idt_y: 0.08062873404473066, F_fool_loss: 0.014251199755817652, cycled_y_loss: 0.08371175818145275, D_Y_loss: 0.29314245223999025\n",
      "[62:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:900] Took 12.88s\n",
      "[62:900] loss_idt_x: 0.12972033351659776, G_fool_loss: 0.014109603818506003, cycled_x_loss: 0.12387626070529223, D_X_loss: 0.2922293543815613\n",
      "[62:900] loss_idt_y: 0.08369556128978729, F_fool_loss: 0.014138048999011516, cycled_y_loss: 0.08647570878267288, D_Y_loss: 0.2914789190888405\n",
      "[62:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:1000] Took 12.87s\n",
      "[62:1000] loss_idt_x: 0.11552679475396871, G_fool_loss: 0.014259217530488968, cycled_x_loss: 0.11198253385722637, D_X_loss: 0.29382434278726577\n",
      "[62:1000] loss_idt_y: 0.08447100505232812, F_fool_loss: 0.01399584485217929, cycled_y_loss: 0.0898233438655734, D_Y_loss: 0.2903513327240944\n",
      "[62:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:1100] Took 12.93s\n",
      "[62:1100] loss_idt_x: 0.10059523474425078, G_fool_loss: 0.014164116252213716, cycled_x_loss: 0.09683958273380995, D_X_loss: 0.29280062645673754\n",
      "[62:1100] loss_idt_y: 0.075760338306427, F_fool_loss: 0.014290819773450494, cycled_y_loss: 0.07668781906366348, D_Y_loss: 0.29112479150295256\n",
      "[62:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[62:END] Completed epoch in 161.91525197029114s\n",
      "[62:1199] ep_loss_idt_x: 0.118 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.114 ep_D_X_loss: 0.293\n",
      "[62:1199] ep_loss_idt_y: 0.081 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.084 ep_D_Y_loss: 0.293\n",
      "[62:END] Completed eval in 1.607703447341919s\n",
      "Updated G_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated F_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated D_X_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated D_Y_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "[62:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[63:100] Took 14.82s\n",
      "[63:100] loss_idt_x: 0.12124698869884014, G_fool_loss: 0.01405689211562276, cycled_x_loss: 0.11886229641735553, D_X_loss: 0.29618419766426085\n",
      "[63:100] loss_idt_y: 0.0860679804906249, F_fool_loss: 0.014204638572409748, cycled_y_loss: 0.0904596815072, D_Y_loss: 0.2950264397263527\n",
      "[63:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:200] Took 12.87s\n",
      "[63:200] loss_idt_x: 0.10579917531460524, G_fool_loss: 0.014238202283158898, cycled_x_loss: 0.10467968553304673, D_X_loss: 0.29164072185754775\n",
      "[63:200] loss_idt_y: 0.0756783283315599, F_fool_loss: 0.014194239005446434, cycled_y_loss: 0.07838616423308849, D_Y_loss: 0.2934745818376541\n",
      "[63:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:300] Took 12.88s\n",
      "[63:300] loss_idt_x: 0.12942687276750803, G_fool_loss: 0.014250991884618997, cycled_x_loss: 0.12443417690694332, D_X_loss: 0.2924541014432907\n",
      "[63:300] loss_idt_y: 0.07040039032697677, F_fool_loss: 0.014246810246258974, cycled_y_loss: 0.07461786990985274, D_Y_loss: 0.29056598275899886\n",
      "[63:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:400] Took 12.87s\n",
      "[63:400] loss_idt_x: 0.10822849057614803, G_fool_loss: 0.014084653882309794, cycled_x_loss: 0.10354785110801458, D_X_loss: 0.2919596141576767\n",
      "[63:400] loss_idt_y: 0.07757214481011034, F_fool_loss: 0.014046435784548521, cycled_y_loss: 0.07868460699915886, D_Y_loss: 0.2914564290642738\n",
      "[63:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:500] Took 12.88s\n",
      "[63:500] loss_idt_x: 0.1254162346571684, G_fool_loss: 0.013995867930352688, cycled_x_loss: 0.12097030699253082, D_X_loss: 0.2918081733584404\n",
      "[63:500] loss_idt_y: 0.07157467119395733, F_fool_loss: 0.014250434376299382, cycled_y_loss: 0.07295931451022625, D_Y_loss: 0.29156430929899213\n",
      "[63:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:600] Took 12.88s\n",
      "[63:600] loss_idt_x: 0.1134557992592454, G_fool_loss: 0.01421765203587711, cycled_x_loss: 0.11285947117954492, D_X_loss: 0.29353673607110975\n",
      "[63:600] loss_idt_y: 0.08252512969076634, F_fool_loss: 0.014184128139168023, cycled_y_loss: 0.08281010191887617, D_Y_loss: 0.29214010685682296\n",
      "[63:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:700] Took 12.87s\n",
      "[63:700] loss_idt_x: 0.11096978425979614, G_fool_loss: 0.01434922487474978, cycled_x_loss: 0.10529469605535269, D_X_loss: 0.29145140796899793\n",
      "[63:700] loss_idt_y: 0.08465509669855237, F_fool_loss: 0.014173947796225548, cycled_y_loss: 0.08776671661064028, D_Y_loss: 0.291807667016983\n",
      "[63:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:800] Took 12.87s\n",
      "[63:800] loss_idt_x: 0.13143485993146897, G_fool_loss: 0.013981702774763106, cycled_x_loss: 0.12666606646031142, D_X_loss: 0.2931640499830246\n",
      "[63:800] loss_idt_y: 0.07841161660850048, F_fool_loss: 0.014196944814175367, cycled_y_loss: 0.08078022494912147, D_Y_loss: 0.2931204545497894\n",
      "[63:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:900] Took 12.88s\n",
      "[63:900] loss_idt_x: 0.11640267852693796, G_fool_loss: 0.014063156796619297, cycled_x_loss: 0.1115270197018981, D_X_loss: 0.29270002245903015\n",
      "[63:900] loss_idt_y: 0.08473585678264499, F_fool_loss: 0.014128344589844346, cycled_y_loss: 0.08881921300664544, D_Y_loss: 0.2931888860464096\n",
      "[63:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:1000] Took 12.88s\n",
      "[63:1000] loss_idt_x: 0.10663028661161661, G_fool_loss: 0.014020444378256797, cycled_x_loss: 0.10704807963222265, D_X_loss: 0.2917517709732056\n",
      "[63:1000] loss_idt_y: 0.09203758902847767, F_fool_loss: 0.01400883317925036, cycled_y_loss: 0.09326646463945508, D_Y_loss: 0.29140440076589585\n",
      "[63:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:1100] Took 12.87s\n",
      "[63:1100] loss_idt_x: 0.11985726427286864, G_fool_loss: 0.014257624736055732, cycled_x_loss: 0.11451322376728058, D_X_loss: 0.29355569928884506\n",
      "[63:1100] loss_idt_y: 0.08170041307806969, F_fool_loss: 0.013984870370477439, cycled_y_loss: 0.08141774360090494, D_Y_loss: 0.29176124900579453\n",
      "[63:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[63:END] Completed epoch in 164.1489405632019s\n",
      "[63:1199] ep_loss_idt_x: 0.117 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.113 ep_D_X_loss: 0.293\n",
      "[63:1199] ep_loss_idt_y: 0.081 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.083 ep_D_Y_loss: 0.292\n",
      "[63:END] Completed eval in 1.6236603260040283s\n",
      "Updated G_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated F_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated D_X_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated D_Y_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "[63:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[64:100] Took 14.87s\n",
      "[64:100] loss_idt_x: 0.13505427971482276, G_fool_loss: 0.014353103237226605, cycled_x_loss: 0.12534567814320327, D_X_loss: 0.29562465876340865\n",
      "[64:100] loss_idt_y: 0.08890666477382184, F_fool_loss: 0.014265082478523254, cycled_y_loss: 0.09107487458735704, D_Y_loss: 0.29497902691364286\n",
      "[64:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:200] Took 12.87s\n",
      "[64:200] loss_idt_x: 0.11646229028701782, G_fool_loss: 0.013949050223454834, cycled_x_loss: 0.11634142719209194, D_X_loss: 0.29205635070800784\n",
      "[64:200] loss_idt_y: 0.08008427310734988, F_fool_loss: 0.014118510875850915, cycled_y_loss: 0.08331647828221321, D_Y_loss: 0.29090959995985033\n",
      "[64:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:300] Took 12.87s\n",
      "[64:300] loss_idt_x: 0.11912501499056816, G_fool_loss: 0.014174761278554797, cycled_x_loss: 0.1128246706724167, D_X_loss: 0.2921188777685165\n",
      "[64:300] loss_idt_y: 0.08190725600346922, F_fool_loss: 0.014011975200846792, cycled_y_loss: 0.08763042148202657, D_Y_loss: 0.29328256338834763\n",
      "[64:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:400] Took 12.90s\n",
      "[64:400] loss_idt_x: 0.12017842009663582, G_fool_loss: 0.013970051631331444, cycled_x_loss: 0.1172774375230074, D_X_loss: 0.29304173946380613\n",
      "[64:400] loss_idt_y: 0.06708700776100159, F_fool_loss: 0.01407744025811553, cycled_y_loss: 0.06940090045332908, D_Y_loss: 0.2918381264805794\n",
      "[64:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:500] Took 12.88s\n",
      "[64:500] loss_idt_x: 0.11111490778625012, G_fool_loss: 0.014196581589058042, cycled_x_loss: 0.10799021225422621, D_X_loss: 0.2922082969546318\n",
      "[64:500] loss_idt_y: 0.08614694140851498, F_fool_loss: 0.014190982487052679, cycled_y_loss: 0.08941667947918176, D_Y_loss: 0.29234676897525785\n",
      "[64:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:600] Took 12.88s\n",
      "[64:600] loss_idt_x: 0.12339852012693882, G_fool_loss: 0.014017028314992786, cycled_x_loss: 0.12101617857813834, D_X_loss: 0.2937392818927765\n",
      "[64:600] loss_idt_y: 0.08389806587249041, F_fool_loss: 0.014026800347492098, cycled_y_loss: 0.08539021380245686, D_Y_loss: 0.29375134617090226\n",
      "[64:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:700] Took 12.88s\n",
      "[64:700] loss_idt_x: 0.1221283058822155, G_fool_loss: 0.01419221691787243, cycled_x_loss: 0.118498012162745, D_X_loss: 0.29260967165231705\n",
      "[64:700] loss_idt_y: 0.08072394214570522, F_fool_loss: 0.014068172909319401, cycled_y_loss: 0.0821460035443306, D_Y_loss: 0.2927463039755821\n",
      "[64:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:800] Took 12.87s\n",
      "[64:800] loss_idt_x: 0.10876491811126471, G_fool_loss: 0.014120122445747256, cycled_x_loss: 0.10450399402529001, D_X_loss: 0.2914847505092621\n",
      "[64:800] loss_idt_y: 0.07768989335745573, F_fool_loss: 0.014188098078593612, cycled_y_loss: 0.0776731589064002, D_Y_loss: 0.2925146844983101\n",
      "[64:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:900] Took 12.88s\n",
      "[64:900] loss_idt_x: 0.1226812556758523, G_fool_loss: 0.0140719732362777, cycled_x_loss: 0.1185856480523944, D_X_loss: 0.2918635153770447\n",
      "[64:900] loss_idt_y: 0.0748543418943882, F_fool_loss: 0.013970477795228363, cycled_y_loss: 0.07597835760563612, D_Y_loss: 0.29275611639022825\n",
      "[64:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:1000] Took 12.88s\n",
      "[64:1000] loss_idt_x: 0.11004150971770287, G_fool_loss: 0.014119682144373655, cycled_x_loss: 0.10467161063104868, D_X_loss: 0.2919015157222748\n",
      "[64:1000] loss_idt_y: 0.06978916119784116, F_fool_loss: 0.014110989728942513, cycled_y_loss: 0.0719289556145668, D_Y_loss: 0.2914477825164795\n",
      "[64:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:1100] Took 12.88s\n",
      "[64:1100] loss_idt_x: 0.09380178432911634, G_fool_loss: 0.01402148918248713, cycled_x_loss: 0.09325112245976924, D_X_loss: 0.2919074243307114\n",
      "[64:1100] loss_idt_y: 0.08011709215119481, F_fool_loss: 0.014242261741310358, cycled_y_loss: 0.08420067522674798, D_Y_loss: 0.2923568958044052\n",
      "[64:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[64:END] Completed epoch in 166.97318720817566s\n",
      "[64:1199] ep_loss_idt_x: 0.117 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.113 ep_D_X_loss: 0.292\n",
      "[64:1199] ep_loss_idt_y: 0.079 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.081 ep_D_Y_loss: 0.292\n",
      "[64:END] Completed eval in 1.6954691410064697s\n",
      "Updated G_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated F_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated D_X_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated D_Y_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "[64:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[65:100] Took 14.85s\n",
      "[65:100] loss_idt_x: 0.11723035536706447, G_fool_loss: 0.0140836366917938, cycled_x_loss: 0.11316855795681477, D_X_loss: 0.29538641452789305\n",
      "[65:100] loss_idt_y: 0.07567575544118882, F_fool_loss: 0.014232988562434911, cycled_y_loss: 0.07772104930132627, D_Y_loss: 0.2949435624480248\n",
      "[65:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:200] Took 12.86s\n",
      "[65:200] loss_idt_x: 0.11431219074875117, G_fool_loss: 0.014170676339417695, cycled_x_loss: 0.11319574672728777, D_X_loss: 0.2922162285447121\n",
      "[65:200] loss_idt_y: 0.08975501671433449, F_fool_loss: 0.014351599738001824, cycled_y_loss: 0.09150451168417931, D_Y_loss: 0.2923870635032654\n",
      "[65:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:300] Took 12.87s\n",
      "[65:300] loss_idt_x: 0.10722632292658091, G_fool_loss: 0.014231382869184017, cycled_x_loss: 0.10413417849689723, D_X_loss: 0.29255121856927874\n",
      "[65:300] loss_idt_y: 0.08195782009512186, F_fool_loss: 0.014012642307206988, cycled_y_loss: 0.08101245447993279, D_Y_loss: 0.29281275510787963\n",
      "[65:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:400] Took 12.87s\n",
      "[65:400] loss_idt_x: 0.11385413240641355, G_fool_loss: 0.014188119173049928, cycled_x_loss: 0.11140223521739244, D_X_loss: 0.2928210398554802\n",
      "[65:400] loss_idt_y: 0.06932118639349938, F_fool_loss: 0.014104622174054384, cycled_y_loss: 0.07315335139632224, D_Y_loss: 0.2940939131379128\n",
      "[65:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:500] Took 12.87s\n",
      "[65:500] loss_idt_x: 0.10753151565790177, G_fool_loss: 0.014173842957243324, cycled_x_loss: 0.10336418896913528, D_X_loss: 0.2930201771855354\n",
      "[65:500] loss_idt_y: 0.07203253844752908, F_fool_loss: 0.014204651480540634, cycled_y_loss: 0.07923526516184211, D_Y_loss: 0.2921011418104172\n",
      "[65:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:600] Took 12.87s\n",
      "[65:600] loss_idt_x: 0.12766343511641026, G_fool_loss: 0.014092523772269487, cycled_x_loss: 0.11937239393591881, D_X_loss: 0.29339421808719635\n",
      "[65:600] loss_idt_y: 0.07848145056515932, F_fool_loss: 0.014148665368556976, cycled_y_loss: 0.08260527787730097, D_Y_loss: 0.29240811109542847\n",
      "[65:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:700] Took 12.87s\n",
      "[65:700] loss_idt_x: 0.11289102654904128, G_fool_loss: 0.014053602516651154, cycled_x_loss: 0.11107278905808926, D_X_loss: 0.2920367980003357\n",
      "[65:700] loss_idt_y: 0.07128924913704396, F_fool_loss: 0.014229866592213512, cycled_y_loss: 0.07478725843131542, D_Y_loss: 0.2925094857811928\n",
      "[65:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:800] Took 12.87s\n",
      "[65:800] loss_idt_x: 0.11936834558844567, G_fool_loss: 0.013929338892921805, cycled_x_loss: 0.11614299956709147, D_X_loss: 0.2910901549458504\n",
      "[65:800] loss_idt_y: 0.07616785246878863, F_fool_loss: 0.014148889426141977, cycled_y_loss: 0.08005804780870676, D_Y_loss: 0.2923259922862053\n",
      "[65:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:900] Took 12.86s\n",
      "[65:900] loss_idt_x: 0.1154533626884222, G_fool_loss: 0.014018904827535152, cycled_x_loss: 0.10914441827684641, D_X_loss: 0.29226647526025773\n",
      "[65:900] loss_idt_y: 0.07267589993774891, F_fool_loss: 0.014063299987465144, cycled_y_loss: 0.07757749412208796, D_Y_loss: 0.29415621995925906\n",
      "[65:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:1000] Took 12.88s\n",
      "[65:1000] loss_idt_x: 0.10373282264918089, G_fool_loss: 0.014163327887654304, cycled_x_loss: 0.10101353269070387, D_X_loss: 0.29360385179519655\n",
      "[65:1000] loss_idt_y: 0.07889705212786793, F_fool_loss: 0.014161641104146838, cycled_y_loss: 0.08274912547320128, D_Y_loss: 0.29147489070892335\n",
      "[65:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:1100] Took 12.87s\n",
      "[65:1100] loss_idt_x: 0.10895518161356449, G_fool_loss: 0.014047823147848248, cycled_x_loss: 0.10591942667961121, D_X_loss: 0.2922186824679375\n",
      "[65:1100] loss_idt_y: 0.07267190245911478, F_fool_loss: 0.014046348333358764, cycled_y_loss: 0.07652498289942741, D_Y_loss: 0.29164149016141894\n",
      "[65:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[65:END] Completed epoch in 167.35906767845154s\n",
      "[65:1199] ep_loss_idt_x: 0.113 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.110 ep_D_X_loss: 0.292\n",
      "[65:1199] ep_loss_idt_y: 0.076 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.080 ep_D_Y_loss: 0.292\n",
      "[65:END] Completed eval in 1.6462996006011963s\n",
      "Updated G_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated F_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated D_X_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated D_Y_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "[65:END] Saving models and training information permanently\n",
      "[66:100] Took 14.83s\n",
      "[66:100] loss_idt_x: 0.10667061291635037, G_fool_loss: 0.014435532689094543, cycled_x_loss: 0.09929490879178048, D_X_loss: 0.2961517369747162\n",
      "[66:100] loss_idt_y: 0.06755209242925048, F_fool_loss: 0.014199692020192743, cycled_y_loss: 0.07219874866306782, D_Y_loss: 0.2938710579276085\n",
      "[66:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:200] Took 12.87s\n",
      "[66:200] loss_idt_x: 0.11501686960458755, G_fool_loss: 0.014007029505446553, cycled_x_loss: 0.10992050636559725, D_X_loss: 0.2914858922362328\n",
      "[66:200] loss_idt_y: 0.0730211522243917, F_fool_loss: 0.01405911979265511, cycled_y_loss: 0.07924781352281571, D_Y_loss: 0.292515512406826\n",
      "[66:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:300] Took 12.87s\n",
      "[66:300] loss_idt_x: 0.11880301762372256, G_fool_loss: 0.014079762464389205, cycled_x_loss: 0.11493102222681045, D_X_loss: 0.29281845659017564\n",
      "[66:300] loss_idt_y: 0.06739105882123113, F_fool_loss: 0.01399132807739079, cycled_y_loss: 0.07056532407179475, D_Y_loss: 0.29279422760009766\n",
      "[66:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:400] Took 12.88s\n",
      "[66:400] loss_idt_x: 0.11885478254407644, G_fool_loss: 0.014177073929458857, cycled_x_loss: 0.11213760867714882, D_X_loss: 0.2920447799563408\n",
      "[66:400] loss_idt_y: 0.07721101406961679, F_fool_loss: 0.014009995991364122, cycled_y_loss: 0.0802783340960741, D_Y_loss: 0.29253544062376025\n",
      "[66:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:500] Took 12.87s\n",
      "[66:500] loss_idt_x: 0.11723854720592498, G_fool_loss: 0.013944938639178872, cycled_x_loss: 0.11574795559048652, D_X_loss: 0.2925815948843956\n",
      "[66:500] loss_idt_y: 0.08875851590186358, F_fool_loss: 0.014323911713436246, cycled_y_loss: 0.09061938740313052, D_Y_loss: 0.29104764938354494\n",
      "[66:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:600] Took 12.89s\n",
      "[66:600] loss_idt_x: 0.11361771710216999, G_fool_loss: 0.013990188697353006, cycled_x_loss: 0.10970915168523789, D_X_loss: 0.2930931493639946\n",
      "[66:600] loss_idt_y: 0.08673859223723411, F_fool_loss: 0.014076135186478496, cycled_y_loss: 0.0870676269195974, D_Y_loss: 0.29271302491426465\n",
      "[66:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:700] Took 12.87s\n",
      "[66:700] loss_idt_x: 0.11499738819897175, G_fool_loss: 0.014321536272764206, cycled_x_loss: 0.11674969848245383, D_X_loss: 0.29212870955467224\n",
      "[66:700] loss_idt_y: 0.08099024383351207, F_fool_loss: 0.013990444149821996, cycled_y_loss: 0.08236189041286707, D_Y_loss: 0.29196596443653106\n",
      "[66:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:800] Took 12.87s\n",
      "[66:800] loss_idt_x: 0.11024273946881294, G_fool_loss: 0.014154949486255645, cycled_x_loss: 0.10879504043608904, D_X_loss: 0.29163033366203306\n",
      "[66:800] loss_idt_y: 0.0826517147757113, F_fool_loss: 0.014131049020215869, cycled_y_loss: 0.08585185147821903, D_Y_loss: 0.2921240136027336\n",
      "[66:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:900] Took 12.87s\n",
      "[66:900] loss_idt_x: 0.11357708554714918, G_fool_loss: 0.014006519354879857, cycled_x_loss: 0.10930528543889523, D_X_loss: 0.2925060874223709\n",
      "[66:900] loss_idt_y: 0.0773210996761918, F_fool_loss: 0.014090660605579614, cycled_y_loss: 0.0829984673857689, D_Y_loss: 0.2935151708126068\n",
      "[66:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:1000] Took 12.87s\n",
      "[66:1000] loss_idt_x: 0.09980097360908985, G_fool_loss: 0.014085215730592609, cycled_x_loss: 0.09896055050194263, D_X_loss: 0.29156759679317473\n",
      "[66:1000] loss_idt_y: 0.06886477001011372, F_fool_loss: 0.01401500215753913, cycled_y_loss: 0.07289157141000033, D_Y_loss: 0.2922392988204956\n",
      "[66:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:1100] Took 12.87s\n",
      "[66:1100] loss_idt_x: 0.11933272399008274, G_fool_loss: 0.014162879418581725, cycled_x_loss: 0.11781112629920244, D_X_loss: 0.29128851622343066\n",
      "[66:1100] loss_idt_y: 0.06871520472690464, F_fool_loss: 0.014205836923792958, cycled_y_loss: 0.07162286065518857, D_Y_loss: 0.2916775357723236\n",
      "[66:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[66:END] Completed epoch in 167.10568118095398s\n",
      "[66:1199] ep_loss_idt_x: 0.114 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.111 ep_D_X_loss: 0.292\n",
      "[66:1199] ep_loss_idt_y: 0.076 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.080 ep_D_Y_loss: 0.292\n",
      "[66:END] Completed eval in 1.6755218505859375s\n",
      "Updated G_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated F_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated D_X_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated D_Y_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "[66:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[67:100] Took 14.85s\n",
      "[67:100] loss_idt_x: 0.11899723388254642, G_fool_loss: 0.014197355741634965, cycled_x_loss: 0.11132755644619464, D_X_loss: 0.2962712073326111\n",
      "[67:100] loss_idt_y: 0.07902123967185616, F_fool_loss: 0.014087231187149883, cycled_y_loss: 0.08233455963432788, D_Y_loss: 0.29631917148828507\n",
      "[67:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:200] Took 12.87s\n",
      "[67:200] loss_idt_x: 0.10507144555449485, G_fool_loss: 0.014085653768852353, cycled_x_loss: 0.10300396237522363, D_X_loss: 0.29105949729681013\n",
      "[67:200] loss_idt_y: 0.08456778448075056, F_fool_loss: 0.014007267793640494, cycled_y_loss: 0.08320787962526083, D_Y_loss: 0.29296648293733596\n",
      "[67:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:300] Took 12.87s\n",
      "[67:300] loss_idt_x: 0.11875132750719786, G_fool_loss: 0.014121653586626053, cycled_x_loss: 0.11679017417132855, D_X_loss: 0.29292849868536\n",
      "[67:300] loss_idt_y: 0.07621608462184667, F_fool_loss: 0.013960342919453979, cycled_y_loss: 0.07540190890431404, D_Y_loss: 0.2928663420677185\n",
      "[67:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:400] Took 12.86s\n",
      "[67:400] loss_idt_x: 0.100203016102314, G_fool_loss: 0.014164359429851175, cycled_x_loss: 0.09382478982210159, D_X_loss: 0.2923467776179314\n",
      "[67:400] loss_idt_y: 0.07373853510245681, F_fool_loss: 0.014249709015712143, cycled_y_loss: 0.07319211572408676, D_Y_loss: 0.29236208736896513\n",
      "[67:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:500] Took 12.87s\n",
      "[67:500] loss_idt_x: 0.10910016059875488, G_fool_loss: 0.014095203466713429, cycled_x_loss: 0.10278809104114771, D_X_loss: 0.29323878765106204\n",
      "[67:500] loss_idt_y: 0.06908366540446878, F_fool_loss: 0.014159190692007542, cycled_y_loss: 0.07192842811346054, D_Y_loss: 0.2917399725317955\n",
      "[67:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:600] Took 12.86s\n",
      "[67:600] loss_idt_x: 0.1255846467986703, G_fool_loss: 0.014091874929144979, cycled_x_loss: 0.11927822172641754, D_X_loss: 0.293800134062767\n",
      "[67:600] loss_idt_y: 0.08126712262630463, F_fool_loss: 0.014159318739548326, cycled_y_loss: 0.08011851834133267, D_Y_loss: 0.2908552885055542\n",
      "[67:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:700] Took 12.87s\n",
      "[67:700] loss_idt_x: 0.10606866646558047, G_fool_loss: 0.013814311316236854, cycled_x_loss: 0.10126489583402871, D_X_loss: 0.29251104265451433\n",
      "[67:700] loss_idt_y: 0.07462079647928477, F_fool_loss: 0.014226033026352525, cycled_y_loss: 0.08199705567210913, D_Y_loss: 0.29190578252077104\n",
      "[67:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:800] Took 12.87s\n",
      "[67:800] loss_idt_x: 0.10040979340672493, G_fool_loss: 0.014043616876006127, cycled_x_loss: 0.09741790879517793, D_X_loss: 0.2928850585222244\n",
      "[67:800] loss_idt_y: 0.07887764506042004, F_fool_loss: 0.013951268149539828, cycled_y_loss: 0.08344628509134054, D_Y_loss: 0.29198460310697555\n",
      "[67:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:900] Took 12.88s\n",
      "[67:900] loss_idt_x: 0.11712400127202273, G_fool_loss: 0.013998890677466989, cycled_x_loss: 0.11327358532696963, D_X_loss: 0.2931776088476181\n",
      "[67:900] loss_idt_y: 0.08722049420699478, F_fool_loss: 0.014081317875534296, cycled_y_loss: 0.09013042513281107, D_Y_loss: 0.29230695486068725\n",
      "[67:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:1000] Took 12.87s\n",
      "[67:1000] loss_idt_x: 0.11573373433202505, G_fool_loss: 0.014126536985859275, cycled_x_loss: 0.11404103942215443, D_X_loss: 0.29246523648500444\n",
      "[67:1000] loss_idt_y: 0.07471381716430187, F_fool_loss: 0.014150753989815712, cycled_y_loss: 0.07455794382840394, D_Y_loss: 0.29239809900522234\n",
      "[67:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:1100] Took 12.89s\n",
      "[67:1100] loss_idt_x: 0.12067940261214971, G_fool_loss: 0.01401266478933394, cycled_x_loss: 0.12080261491239071, D_X_loss: 0.29365135729312897\n",
      "[67:1100] loss_idt_y: 0.07847406236454844, F_fool_loss: 0.013980998629704118, cycled_y_loss: 0.0819792002812028, D_Y_loss: 0.2912401834130287\n",
      "[67:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[67:END] Completed epoch in 167.78881788253784s\n",
      "[67:1199] ep_loss_idt_x: 0.112 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.108 ep_D_X_loss: 0.293\n",
      "[67:1199] ep_loss_idt_y: 0.078 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.080 ep_D_Y_loss: 0.292\n",
      "[67:END] Completed eval in 1.6615147590637207s\n",
      "Updated G_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated F_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated D_X_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated D_Y_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "[67:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[68:100] Took 14.84s\n",
      "[68:100] loss_idt_x: 0.12378266770392657, G_fool_loss: 0.014166980581358075, cycled_x_loss: 0.11750023253262043, D_X_loss: 0.29638145595788956\n",
      "[68:100] loss_idt_y: 0.07638406842947006, F_fool_loss: 0.014423353224992752, cycled_y_loss: 0.07929838106036186, D_Y_loss: 0.29441807717084884\n",
      "[68:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:200] Took 12.84s\n",
      "[68:200] loss_idt_x: 0.10936954967677594, G_fool_loss: 0.013915887363255023, cycled_x_loss: 0.10685203358530998, D_X_loss: 0.292444087266922\n",
      "[68:200] loss_idt_y: 0.07213364217430353, F_fool_loss: 0.014091493654996156, cycled_y_loss: 0.07276756180450321, D_Y_loss: 0.2923093447089195\n",
      "[68:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:300] Took 12.87s\n",
      "[68:300] loss_idt_x: 0.12568855192512274, G_fool_loss: 0.014119678707793355, cycled_x_loss: 0.12085755437612533, D_X_loss: 0.2921358245611191\n",
      "[68:300] loss_idt_y: 0.08276326008141041, F_fool_loss: 0.013995807748287917, cycled_y_loss: 0.08111354198306799, D_Y_loss: 0.2922541481256485\n",
      "[68:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:400] Took 12.87s\n",
      "[68:400] loss_idt_x: 0.10319505646824836, G_fool_loss: 0.013972615310922264, cycled_x_loss: 0.09733502484858036, D_X_loss: 0.29124061614274976\n",
      "[68:400] loss_idt_y: 0.0763577638566494, F_fool_loss: 0.014027548786252737, cycled_y_loss: 0.07642609173431993, D_Y_loss: 0.29204636365175246\n",
      "[68:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:500] Took 12.87s\n",
      "[68:500] loss_idt_x: 0.11107784792780877, G_fool_loss: 0.01411820107139647, cycled_x_loss: 0.11435786131769418, D_X_loss: 0.2918708661198616\n",
      "[68:500] loss_idt_y: 0.08083396511152387, F_fool_loss: 0.014196101743727922, cycled_y_loss: 0.0768301298841834, D_Y_loss: 0.2919381535053253\n",
      "[68:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:600] Took 12.87s\n",
      "[68:600] loss_idt_x: 0.1070095880702138, G_fool_loss: 0.013993759108707308, cycled_x_loss: 0.10831215679645538, D_X_loss: 0.2924352252483368\n",
      "[68:600] loss_idt_y: 0.07593832736834884, F_fool_loss: 0.014104488985612989, cycled_y_loss: 0.07714327365159988, D_Y_loss: 0.29259101778268815\n",
      "[68:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:700] Took 12.88s\n",
      "[68:700] loss_idt_x: 0.11456010358408093, G_fool_loss: 0.013886946039274334, cycled_x_loss: 0.11039916649460793, D_X_loss: 0.29311835020780563\n",
      "[68:700] loss_idt_y: 0.07457104604691267, F_fool_loss: 0.01413792728446424, cycled_y_loss: 0.07869221769273281, D_Y_loss: 0.2914176604151726\n",
      "[68:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:800] Took 12.89s\n",
      "[68:800] loss_idt_x: 0.11060928486287594, G_fool_loss: 0.014115025084465741, cycled_x_loss: 0.10624379701912404, D_X_loss: 0.2925252211093903\n",
      "[68:800] loss_idt_y: 0.07926500555127859, F_fool_loss: 0.013833111766725779, cycled_y_loss: 0.07897408828139305, D_Y_loss: 0.29324998378753664\n",
      "[68:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:900] Took 12.87s\n",
      "[68:900] loss_idt_x: 0.11289550360292196, G_fool_loss: 0.013989283787086606, cycled_x_loss: 0.11269595600664616, D_X_loss: 0.29313967525959017\n",
      "[68:900] loss_idt_y: 0.07749816900119186, F_fool_loss: 0.013973459647968412, cycled_y_loss: 0.07885274972766637, D_Y_loss: 0.29243791073560715\n",
      "[68:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:1000] Took 12.88s\n",
      "[68:1000] loss_idt_x: 0.1125619887188077, G_fool_loss: 0.014036629367619752, cycled_x_loss: 0.10958271697163582, D_X_loss: 0.29240706622600554\n",
      "[68:1000] loss_idt_y: 0.07764538992196321, F_fool_loss: 0.014024560190737247, cycled_y_loss: 0.07686014823615551, D_Y_loss: 0.2937403517961502\n",
      "[68:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:1100] Took 12.88s\n",
      "[68:1100] loss_idt_x: 0.11098846670240164, G_fool_loss: 0.014001202825456858, cycled_x_loss: 0.10652445383369923, D_X_loss: 0.2942470785975456\n",
      "[68:1100] loss_idt_y: 0.07851038821041584, F_fool_loss: 0.01400164222344756, cycled_y_loss: 0.07973301652818918, D_Y_loss: 0.29257678508758544\n",
      "[68:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[68:END] Completed epoch in 168.51699209213257s\n",
      "[68:1199] ep_loss_idt_x: 0.114 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.111 ep_D_X_loss: 0.293\n",
      "[68:1199] ep_loss_idt_y: 0.077 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.078 ep_D_Y_loss: 0.292\n",
      "[68:END] Completed eval in 1.6665213108062744s\n",
      "Updated G_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated F_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated D_X_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated D_Y_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "[68:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[69:100] Took 14.86s\n",
      "[69:100] loss_idt_x: 0.11370843093842269, G_fool_loss: 0.013968799086287618, cycled_x_loss: 0.10648486908525229, D_X_loss: 0.2942753404378891\n",
      "[69:100] loss_idt_y: 0.08438547816127538, F_fool_loss: 0.014088320275768638, cycled_y_loss: 0.08953487657010556, D_Y_loss: 0.2966307565569878\n",
      "[69:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:200] Took 12.87s\n",
      "[69:200] loss_idt_x: 0.11915256269276142, G_fool_loss: 0.013880482725799084, cycled_x_loss: 0.11689462639391422, D_X_loss: 0.2931070014834404\n",
      "[69:200] loss_idt_y: 0.07228132117539644, F_fool_loss: 0.013956172997131944, cycled_y_loss: 0.07737854119390249, D_Y_loss: 0.2925494754314423\n",
      "[69:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:300] Took 12.86s\n",
      "[69:300] loss_idt_x: 0.11321573000401258, G_fool_loss: 0.014118523169308901, cycled_x_loss: 0.11013620711863041, D_X_loss: 0.292075335085392\n",
      "[69:300] loss_idt_y: 0.07229501975700259, F_fool_loss: 0.014013251233845949, cycled_y_loss: 0.07311353899538517, D_Y_loss: 0.2924030438065529\n",
      "[69:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:400] Took 12.88s\n",
      "[69:400] loss_idt_x: 0.10633107155561447, G_fool_loss: 0.013908322462812065, cycled_x_loss: 0.10271686255931854, D_X_loss: 0.2929977563023567\n",
      "[69:400] loss_idt_y: 0.07405585251748562, F_fool_loss: 0.01420847793109715, cycled_y_loss: 0.07721462443470956, D_Y_loss: 0.2928976535797119\n",
      "[69:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:500] Took 12.86s\n",
      "[69:500] loss_idt_x: 0.09432574041187763, G_fool_loss: 0.014085977710783482, cycled_x_loss: 0.0890318863093853, D_X_loss: 0.29283241003751753\n",
      "[69:500] loss_idt_y: 0.07351990222930908, F_fool_loss: 0.013976118350401521, cycled_y_loss: 0.07812587209045888, D_Y_loss: 0.2905594852566719\n",
      "[69:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:600] Took 12.88s\n",
      "[69:600] loss_idt_x: 0.10347957961261273, G_fool_loss: 0.014131719470024109, cycled_x_loss: 0.10659673970192671, D_X_loss: 0.29187420904636385\n",
      "[69:600] loss_idt_y: 0.08581894252449274, F_fool_loss: 0.013919968688860536, cycled_y_loss: 0.08024570610374213, D_Y_loss: 0.29195909172296525\n",
      "[69:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:700] Took 12.88s\n",
      "[69:700] loss_idt_x: 0.11465689230710269, G_fool_loss: 0.014051743149757386, cycled_x_loss: 0.11400084655731917, D_X_loss: 0.29356467992067337\n",
      "[69:700] loss_idt_y: 0.09059987816959619, F_fool_loss: 0.014181277034804225, cycled_y_loss: 0.08825332928448916, D_Y_loss: 0.2931376829743385\n",
      "[69:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:800] Took 12.88s\n",
      "[69:800] loss_idt_x: 0.11361456479877234, G_fool_loss: 0.014049158096313477, cycled_x_loss: 0.11191513881087303, D_X_loss: 0.29232646107673643\n",
      "[69:800] loss_idt_y: 0.06895550403743983, F_fool_loss: 0.014124120241031051, cycled_y_loss: 0.07024305114522576, D_Y_loss: 0.29205066978931427\n",
      "[69:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:900] Took 12.87s\n",
      "[69:900] loss_idt_x: 0.11389245484024287, G_fool_loss: 0.013996651582419872, cycled_x_loss: 0.1110015730932355, D_X_loss: 0.29200476467609404\n",
      "[69:900] loss_idt_y: 0.07594031736254692, F_fool_loss: 0.013949751276522876, cycled_y_loss: 0.07830188473686577, D_Y_loss: 0.29211188226938245\n",
      "[69:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:1000] Took 12.84s\n",
      "[69:1000] loss_idt_x: 0.10643990000709891, G_fool_loss: 0.013704765578731895, cycled_x_loss: 0.10293272782117129, D_X_loss: 0.2923767277598381\n",
      "[69:1000] loss_idt_y: 0.0810107759013772, F_fool_loss: 0.014010096108540893, cycled_y_loss: 0.08296500630676747, D_Y_loss: 0.2920691081881523\n",
      "[69:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:1100] Took 12.85s\n",
      "[69:1100] loss_idt_x: 0.11051486488431692, G_fool_loss: 0.014084067149087786, cycled_x_loss: 0.10887480359524489, D_X_loss: 0.29122046947479246\n",
      "[69:1100] loss_idt_y: 0.07980953894555569, F_fool_loss: 0.0141135623306036, cycled_y_loss: 0.08084186211228371, D_Y_loss: 0.29370941787958144\n",
      "[69:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[69:END] Completed epoch in 168.04846787452698s\n",
      "[69:1199] ep_loss_idt_x: 0.109 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.106 ep_D_X_loss: 0.292\n",
      "[69:1199] ep_loss_idt_y: 0.077 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.079 ep_D_Y_loss: 0.292\n",
      "[69:END] Completed eval in 1.6706416606903076s\n",
      "Updated G_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated F_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated D_X_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated D_Y_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "[69:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[70:100] Took 14.82s\n",
      "[70:100] loss_idt_x: 0.10528048723936081, G_fool_loss: 0.014062979901209473, cycled_x_loss: 0.10192305747419596, D_X_loss: 0.29461795300245286\n",
      "[70:100] loss_idt_y: 0.07582656431943179, F_fool_loss: 0.01422149763442576, cycled_y_loss: 0.07979400577023625, D_Y_loss: 0.2959290954470635\n",
      "[70:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:200] Took 12.87s\n",
      "[70:200] loss_idt_x: 0.11417802326381206, G_fool_loss: 0.01399791163392365, cycled_x_loss: 0.11058732580393553, D_X_loss: 0.2918650895357132\n",
      "[70:200] loss_idt_y: 0.0671374642662704, F_fool_loss: 0.013889128556475044, cycled_y_loss: 0.0655829818919301, D_Y_loss: 0.29148753225803375\n",
      "[70:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:300] Took 12.87s\n",
      "[70:300] loss_idt_x: 0.11965044677257537, G_fool_loss: 0.014067241949960589, cycled_x_loss: 0.11111846823245287, D_X_loss: 0.2910019987821579\n",
      "[70:300] loss_idt_y: 0.07036025911569595, F_fool_loss: 0.014090016214177013, cycled_y_loss: 0.07185962069779635, D_Y_loss: 0.2925548940896988\n",
      "[70:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:400] Took 12.90s\n",
      "[70:400] loss_idt_x: 0.09415369413793087, G_fool_loss: 0.013977564964443445, cycled_x_loss: 0.0933015287667513, D_X_loss: 0.2921733736991882\n",
      "[70:400] loss_idt_y: 0.07163747802376746, F_fool_loss: 0.01407309359870851, cycled_y_loss: 0.07366444911807775, D_Y_loss: 0.2932053855061531\n",
      "[70:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:500] Took 12.87s\n",
      "[70:500] loss_idt_x: 0.10977371037006378, G_fool_loss: 0.014040235811844468, cycled_x_loss: 0.10922221761196851, D_X_loss: 0.2935897260904312\n",
      "[70:500] loss_idt_y: 0.07349735703319311, F_fool_loss: 0.014030452556908131, cycled_y_loss: 0.07440516792237759, D_Y_loss: 0.2914161401987076\n",
      "[70:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:600] Took 12.87s\n",
      "[70:600] loss_idt_x: 0.10691535003483295, G_fool_loss: 0.014109071316197515, cycled_x_loss: 0.10488864604383707, D_X_loss: 0.2933983248472214\n",
      "[70:600] loss_idt_y: 0.07016815243288875, F_fool_loss: 0.014257395379245282, cycled_y_loss: 0.07158464208245277, D_Y_loss: 0.29158652156591414\n",
      "[70:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:700] Took 12.88s\n",
      "[70:700] loss_idt_x: 0.10987332116812468, G_fool_loss: 0.014050029292702675, cycled_x_loss: 0.10257783617824316, D_X_loss: 0.2938863816857338\n",
      "[70:700] loss_idt_y: 0.07907479943707585, F_fool_loss: 0.013985249446704984, cycled_y_loss: 0.08459275156259537, D_Y_loss: 0.290932303071022\n",
      "[70:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:800] Took 12.88s\n",
      "[70:800] loss_idt_x: 0.11956932161003352, G_fool_loss: 0.014101772792637348, cycled_x_loss: 0.1158830252289772, D_X_loss: 0.2918726170063019\n",
      "[70:800] loss_idt_y: 0.08123902598395943, F_fool_loss: 0.013824674785137176, cycled_y_loss: 0.08735340967774391, D_Y_loss: 0.2923569306731224\n",
      "[70:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:900] Took 12.90s\n",
      "[70:900] loss_idt_x: 0.10744827806949615, G_fool_loss: 0.013928019478917121, cycled_x_loss: 0.10149281635880471, D_X_loss: 0.2915820413827896\n",
      "[70:900] loss_idt_y: 0.06827725902199745, F_fool_loss: 0.014070751741528512, cycled_y_loss: 0.0675565430149436, D_Y_loss: 0.290277761220932\n",
      "[70:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:1000] Took 12.86s\n",
      "[70:1000] loss_idt_x: 0.10178639702498912, G_fool_loss: 0.013957043346017599, cycled_x_loss: 0.09922651689499616, D_X_loss: 0.2923541036248207\n",
      "[70:1000] loss_idt_y: 0.07361493844538927, F_fool_loss: 0.014111371664330363, cycled_y_loss: 0.07702769372612238, D_Y_loss: 0.2933359631896019\n",
      "[70:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:1100] Took 12.86s\n",
      "[70:1100] loss_idt_x: 0.09563085161149502, G_fool_loss: 0.014031315995380282, cycled_x_loss: 0.09596459973603487, D_X_loss: 0.29152814745903016\n",
      "[70:1100] loss_idt_y: 0.07784314770251513, F_fool_loss: 0.013990590460598468, cycled_y_loss: 0.07517699923366308, D_Y_loss: 0.29197154700756073\n",
      "[70:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[70:END] Completed epoch in 169.56170868873596s\n",
      "[70:1199] ep_loss_idt_x: 0.108 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.104 ep_D_X_loss: 0.292\n",
      "[70:1199] ep_loss_idt_y: 0.074 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.075 ep_D_Y_loss: 0.292\n",
      "[70:END] Completed eval in 1.7034473419189453s\n",
      "Updated G_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated F_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated D_X_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated D_Y_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "[70:END] Saving models and training information permanently\n",
      "[71:100] Took 14.86s\n",
      "[71:100] loss_idt_x: 0.1192734421417117, G_fool_loss: 0.014089278550818563, cycled_x_loss: 0.1173195257037878, D_X_loss: 0.2952648675441742\n",
      "[71:100] loss_idt_y: 0.06669230405241251, F_fool_loss: 0.014139673113822937, cycled_y_loss: 0.07130526553839445, D_Y_loss: 0.2952984008193016\n",
      "[71:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:200] Took 12.86s\n",
      "[71:200] loss_idt_x: 0.10076376151293516, G_fool_loss: 0.013846632298082114, cycled_x_loss: 0.10132215566933155, D_X_loss: 0.2925365787744522\n",
      "[71:200] loss_idt_y: 0.07724625583738089, F_fool_loss: 0.014105169698596001, cycled_y_loss: 0.07816584102809429, D_Y_loss: 0.2927176761627197\n",
      "[71:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:300] Took 12.86s\n",
      "[71:300] loss_idt_x: 0.11299423165619374, G_fool_loss: 0.013940572161227465, cycled_x_loss: 0.10709969889372588, D_X_loss: 0.2931303730607033\n",
      "[71:300] loss_idt_y: 0.07333040058612823, F_fool_loss: 0.014016959127038717, cycled_y_loss: 0.07645614571869373, D_Y_loss: 0.29201941430568695\n",
      "[71:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:400] Took 12.85s\n",
      "[71:400] loss_idt_x: 0.10426390253007412, G_fool_loss: 0.01397237580269575, cycled_x_loss: 0.09946487735956908, D_X_loss: 0.29281787782907487\n",
      "[71:400] loss_idt_y: 0.07464408738538623, F_fool_loss: 0.014012958807870745, cycled_y_loss: 0.07874236732721329, D_Y_loss: 0.29175123006105425\n",
      "[71:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:500] Took 12.86s\n",
      "[71:500] loss_idt_x: 0.10304928962141276, G_fool_loss: 0.013940616063773632, cycled_x_loss: 0.10563627306371927, D_X_loss: 0.291604517698288\n",
      "[71:500] loss_idt_y: 0.0731000155210495, F_fool_loss: 0.014049470005556942, cycled_y_loss: 0.07376670382916928, D_Y_loss: 0.292613987326622\n",
      "[71:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:600] Took 12.87s\n",
      "[71:600] loss_idt_x: 0.10991647079586983, G_fool_loss: 0.013855191403999925, cycled_x_loss: 0.10061027877032756, D_X_loss: 0.29280260562896726\n",
      "[71:600] loss_idt_y: 0.08521274024620652, F_fool_loss: 0.014047188609838486, cycled_y_loss: 0.08905011884868146, D_Y_loss: 0.29102957010269165\n",
      "[71:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:700] Took 12.86s\n",
      "[71:700] loss_idt_x: 0.10719251573085785, G_fool_loss: 0.014058664971962571, cycled_x_loss: 0.10079002302139997, D_X_loss: 0.2929093614220619\n",
      "[71:700] loss_idt_y: 0.07125092508271337, F_fool_loss: 0.014195701219141483, cycled_y_loss: 0.0709411858394742, D_Y_loss: 0.292586732506752\n",
      "[71:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:800] Took 12.86s\n",
      "[71:800] loss_idt_x: 0.11969302162528038, G_fool_loss: 0.013942923713475466, cycled_x_loss: 0.10885168593376875, D_X_loss: 0.2938528740406036\n",
      "[71:800] loss_idt_y: 0.07482600359246135, F_fool_loss: 0.01398043153807521, cycled_y_loss: 0.0786938413605094, D_Y_loss: 0.2914523404836655\n",
      "[71:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:900] Took 12.88s\n",
      "[71:900] loss_idt_x: 0.1255512459203601, G_fool_loss: 0.014039163757115603, cycled_x_loss: 0.1218637641146779, D_X_loss: 0.292872319817543\n",
      "[71:900] loss_idt_y: 0.07778242425993084, F_fool_loss: 0.01393415846861899, cycled_y_loss: 0.07688814628869295, D_Y_loss: 0.2926017987728119\n",
      "[71:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:1000] Took 12.87s\n",
      "[71:1000] loss_idt_x: 0.10334531217813492, G_fool_loss: 0.013972010277211667, cycled_x_loss: 0.10058139406144619, D_X_loss: 0.2919137281179428\n",
      "[71:1000] loss_idt_y: 0.07040687885135412, F_fool_loss: 0.014058886906132101, cycled_y_loss: 0.07542391205206514, D_Y_loss: 0.29061501652002336\n",
      "[71:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:1100] Took 12.86s\n",
      "[71:1100] loss_idt_x: 0.11094444826245307, G_fool_loss: 0.013943127663806081, cycled_x_loss: 0.10461184211075306, D_X_loss: 0.2910434150695801\n",
      "[71:1100] loss_idt_y: 0.08073603674769401, F_fool_loss: 0.013890833389014005, cycled_y_loss: 0.07760268058627844, D_Y_loss: 0.29264037281274796\n",
      "[71:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[71:END] Completed epoch in 171.0126509666443s\n",
      "[71:1199] ep_loss_idt_x: 0.111 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.106 ep_D_X_loss: 0.293\n",
      "[71:1199] ep_loss_idt_y: 0.075 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.077 ep_D_Y_loss: 0.292\n",
      "[71:END] Completed eval in 1.7094268798828125s\n",
      "Updated G_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated F_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated D_X_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated D_Y_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "[71:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[72:100] Took 14.92s\n",
      "[72:100] loss_idt_x: 0.1041486195474863, G_fool_loss: 0.013866686290130019, cycled_x_loss: 0.09933545704931021, D_X_loss: 0.29620451867580416\n",
      "[72:100] loss_idt_y: 0.07227456212043762, F_fool_loss: 0.014034215873107315, cycled_y_loss: 0.0701255601271987, D_Y_loss: 0.29463682502508165\n",
      "[72:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:200] Took 12.87s\n",
      "[72:200] loss_idt_x: 0.10655065536499024, G_fool_loss: 0.014004020346328616, cycled_x_loss: 0.10109366871416568, D_X_loss: 0.2907914000749588\n",
      "[72:200] loss_idt_y: 0.06482280796393752, F_fool_loss: 0.013948499169200658, cycled_y_loss: 0.06548709563910961, D_Y_loss: 0.29228253543376925\n",
      "[72:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:300] Took 12.87s\n",
      "[72:300] loss_idt_x: 0.1050476510077715, G_fool_loss: 0.014088467573747038, cycled_x_loss: 0.10205863781273365, D_X_loss: 0.2919982871413231\n",
      "[72:300] loss_idt_y: 0.08006029587239027, F_fool_loss: 0.013974288515746593, cycled_y_loss: 0.08110185449942947, D_Y_loss: 0.29126070350408556\n",
      "[72:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:400] Took 12.87s\n",
      "[72:400] loss_idt_x: 0.10579220850020647, G_fool_loss: 0.01395463002845645, cycled_x_loss: 0.10084869243204593, D_X_loss: 0.29276165962219236\n",
      "[72:400] loss_idt_y: 0.08614734828472137, F_fool_loss: 0.014066299041733146, cycled_y_loss: 0.0862135137245059, D_Y_loss: 0.2921785497665405\n",
      "[72:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:500] Took 12.86s\n",
      "[72:500] loss_idt_x: 0.10885029405355454, G_fool_loss: 0.014012621622532606, cycled_x_loss: 0.10447736639529466, D_X_loss: 0.29072375237941744\n",
      "[72:500] loss_idt_y: 0.07736173052340746, F_fool_loss: 0.013940809508785606, cycled_y_loss: 0.07982199724763632, D_Y_loss: 0.2923810076713562\n",
      "[72:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:600] Took 12.85s\n",
      "[72:600] loss_idt_x: 0.1073147713765502, G_fool_loss: 0.013927220664918423, cycled_x_loss: 0.10686965204775334, D_X_loss: 0.2925251358747482\n",
      "[72:600] loss_idt_y: 0.07309301434084774, F_fool_loss: 0.014072794960811734, cycled_y_loss: 0.07462289143353701, D_Y_loss: 0.2922203120589256\n",
      "[72:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:700] Took 12.85s\n",
      "[72:700] loss_idt_x: 0.10683581814169883, G_fool_loss: 0.013881521560251712, cycled_x_loss: 0.09993130575865507, D_X_loss: 0.29139743447303773\n",
      "[72:700] loss_idt_y: 0.07386476043611764, F_fool_loss: 0.01411368601024151, cycled_y_loss: 0.07756018651649356, D_Y_loss: 0.2925433197617531\n",
      "[72:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:800] Took 12.87s\n",
      "[72:800] loss_idt_x: 0.1157804835960269, G_fool_loss: 0.014033366777002811, cycled_x_loss: 0.10888754673302174, D_X_loss: 0.29293100714683534\n",
      "[72:800] loss_idt_y: 0.08070814687758684, F_fool_loss: 0.013955075265839697, cycled_y_loss: 0.081039231531322, D_Y_loss: 0.2922131085395813\n",
      "[72:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:900] Took 12.87s\n",
      "[72:900] loss_idt_x: 0.11476718999445439, G_fool_loss: 0.014131075404584408, cycled_x_loss: 0.1103893306106329, D_X_loss: 0.2925811806321144\n",
      "[72:900] loss_idt_y: 0.08545319994911552, F_fool_loss: 0.013927781330421567, cycled_y_loss: 0.08896541107445956, D_Y_loss: 0.29169150948524475\n",
      "[72:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:1000] Took 12.86s\n",
      "[72:1000] loss_idt_x: 0.10537657737731934, G_fool_loss: 0.013918156335130334, cycled_x_loss: 0.09745281960815191, D_X_loss: 0.2934761181473732\n",
      "[72:1000] loss_idt_y: 0.06982298964634538, F_fool_loss: 0.013865860840305687, cycled_y_loss: 0.07079263649880886, D_Y_loss: 0.292191082239151\n",
      "[72:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:1100] Took 12.87s\n",
      "[72:1100] loss_idt_x: 0.11781819391995668, G_fool_loss: 0.013899064427241682, cycled_x_loss: 0.10893481146544218, D_X_loss: 0.2921448740363121\n",
      "[72:1100] loss_idt_y: 0.07320388508960604, F_fool_loss: 0.01400906196795404, cycled_y_loss: 0.07747754354029894, D_Y_loss: 0.29195692151784897\n",
      "[72:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[72:END] Completed epoch in 170.73571848869324s\n",
      "[72:1199] ep_loss_idt_x: 0.110 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.105 ep_D_X_loss: 0.292\n",
      "[72:1199] ep_loss_idt_y: 0.076 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.077 ep_D_Y_loss: 0.292\n",
      "[72:END] Completed eval in 1.7543115615844727s\n",
      "Updated G_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated F_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated D_X_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated D_Y_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "[72:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[73:100] Took 14.78s\n",
      "[73:100] loss_idt_x: 0.11436746444553136, G_fool_loss: 0.01399260813370347, cycled_x_loss: 0.10266145773231983, D_X_loss: 0.29507739961147306\n",
      "[73:100] loss_idt_y: 0.07003626503050327, F_fool_loss: 0.01410191866569221, cycled_y_loss: 0.07261959657073021, D_Y_loss: 0.29448522567749025\n",
      "[73:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:200] Took 12.85s\n",
      "[73:200] loss_idt_x: 0.11621755607426167, G_fool_loss: 0.0138339086715132, cycled_x_loss: 0.1108181595057249, D_X_loss: 0.29315446346998214\n",
      "[73:200] loss_idt_y: 0.0747277825511992, F_fool_loss: 0.01381585055962205, cycled_y_loss: 0.0778643198683858, D_Y_loss: 0.2926256972551346\n",
      "[73:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:300] Took 12.85s\n",
      "[73:300] loss_idt_x: 0.10032956164330244, G_fool_loss: 0.013909051269292831, cycled_x_loss: 0.09594759024679661, D_X_loss: 0.291534965634346\n",
      "[73:300] loss_idt_y: 0.07069428721442819, F_fool_loss: 0.013992937058210373, cycled_y_loss: 0.0668431007862091, D_Y_loss: 0.2927380636334419\n",
      "[73:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:400] Took 12.86s\n",
      "[73:400] loss_idt_x: 0.11207874659448862, G_fool_loss: 0.013958261655643582, cycled_x_loss: 0.11267023902386426, D_X_loss: 0.29081586927175523\n",
      "[73:400] loss_idt_y: 0.06942947171628475, F_fool_loss: 0.013929650587961077, cycled_y_loss: 0.07389425799250603, D_Y_loss: 0.29221775323152543\n",
      "[73:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:500] Took 12.85s\n",
      "[73:500] loss_idt_x: 0.10972715485841036, G_fool_loss: 0.013852801797911525, cycled_x_loss: 0.10964649859815837, D_X_loss: 0.2924803757667542\n",
      "[73:500] loss_idt_y: 0.07270553911104799, F_fool_loss: 0.014054630137979984, cycled_y_loss: 0.07383926531299949, D_Y_loss: 0.29036870986223223\n",
      "[73:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:600] Took 12.87s\n",
      "[73:600] loss_idt_x: 0.10209282800555229, G_fool_loss: 0.014009130895137787, cycled_x_loss: 0.09888487856835126, D_X_loss: 0.29147240310907363\n",
      "[73:600] loss_idt_y: 0.06931770652532578, F_fool_loss: 0.013978144507855178, cycled_y_loss: 0.07467035226523876, D_Y_loss: 0.29268343061208724\n",
      "[73:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:700] Took 12.88s\n",
      "[73:700] loss_idt_x: 0.09847415443509817, G_fool_loss: 0.013979846248403191, cycled_x_loss: 0.09500652842223645, D_X_loss: 0.29335118144750594\n",
      "[73:700] loss_idt_y: 0.07578812338411808, F_fool_loss: 0.01397003066726029, cycled_y_loss: 0.0774795200675726, D_Y_loss: 0.2931348368525505\n",
      "[73:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:800] Took 12.86s\n",
      "[73:800] loss_idt_x: 0.10657505489885807, G_fool_loss: 0.013918403275310994, cycled_x_loss: 0.0995962768420577, D_X_loss: 0.291598916053772\n",
      "[73:800] loss_idt_y: 0.06892718477174639, F_fool_loss: 0.013820241698995232, cycled_y_loss: 0.07301699280738831, D_Y_loss: 0.2937667381763458\n",
      "[73:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:900] Took 12.87s\n",
      "[73:900] loss_idt_x: 0.11761277131736278, G_fool_loss: 0.014074233854189514, cycled_x_loss: 0.11493040923029184, D_X_loss: 0.2923473897576332\n",
      "[73:900] loss_idt_y: 0.07331090018153191, F_fool_loss: 0.014012540513649583, cycled_y_loss: 0.07654042232781649, D_Y_loss: 0.2922274672985077\n",
      "[73:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:1000] Took 12.85s\n",
      "[73:1000] loss_idt_x: 0.10342929441481828, G_fool_loss: 0.013995388252660633, cycled_x_loss: 0.10059234600514173, D_X_loss: 0.2926414433121681\n",
      "[73:1000] loss_idt_y: 0.06798913732171058, F_fool_loss: 0.013942675599828362, cycled_y_loss: 0.07129020089283586, D_Y_loss: 0.29139300048351285\n",
      "[73:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:1100] Took 12.86s\n",
      "[73:1100] loss_idt_x: 0.10472498182207346, G_fool_loss: 0.01411976140923798, cycled_x_loss: 0.10643343899399042, D_X_loss: 0.29267725586891175\n",
      "[73:1100] loss_idt_y: 0.07473281251266599, F_fool_loss: 0.013885561330243944, cycled_y_loss: 0.07256025463342666, D_Y_loss: 0.29169427961111066\n",
      "[73:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[73:END] Completed epoch in 170.82343554496765s\n",
      "[73:1199] ep_loss_idt_x: 0.107 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.104 ep_D_X_loss: 0.292\n",
      "[73:1199] ep_loss_idt_y: 0.071 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.074 ep_D_Y_loss: 0.292\n",
      "[73:END] Completed eval in 1.7194092273712158s\n",
      "Updated G_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated F_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated D_X_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated D_Y_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "[73:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[74:100] Took 14.91s\n",
      "[74:100] loss_idt_x: 0.11408728316426277, G_fool_loss: 0.014216692484915257, cycled_x_loss: 0.104701121263206, D_X_loss: 0.2955450543761253\n",
      "[74:100] loss_idt_y: 0.07163878712803125, F_fool_loss: 0.014103466337546706, cycled_y_loss: 0.07554048903286457, D_Y_loss: 0.29487488269805906\n",
      "[74:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:200] Took 12.87s\n",
      "[74:200] loss_idt_x: 0.10752103812992572, G_fool_loss: 0.013825723826885223, cycled_x_loss: 0.10464061003178358, D_X_loss: 0.29309542596340177\n",
      "[74:200] loss_idt_y: 0.07382871894165874, F_fool_loss: 0.013879382954910398, cycled_y_loss: 0.07272716291248799, D_Y_loss: 0.2933060064911842\n",
      "[74:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:300] Took 12.88s\n",
      "[74:300] loss_idt_x: 0.10596057780086994, G_fool_loss: 0.013947879895567894, cycled_x_loss: 0.10108316678553819, D_X_loss: 0.29114019304513933\n",
      "[74:300] loss_idt_y: 0.08025455418974162, F_fool_loss: 0.014096195111051202, cycled_y_loss: 0.07908518344163895, D_Y_loss: 0.29171873241662977\n",
      "[74:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:400] Took 12.86s\n",
      "[74:400] loss_idt_x: 0.10884961910545826, G_fool_loss: 0.013876493610441685, cycled_x_loss: 0.1015878303349018, D_X_loss: 0.2933929044008255\n",
      "[74:400] loss_idt_y: 0.06710820330306888, F_fool_loss: 0.013917706180363894, cycled_y_loss: 0.06819750165566801, D_Y_loss: 0.29213472962379455\n",
      "[74:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:500] Took 12.87s\n",
      "[74:500] loss_idt_x: 0.11580337420105934, G_fool_loss: 0.01375787035562098, cycled_x_loss: 0.1134763115644455, D_X_loss: 0.2917509624361992\n",
      "[74:500] loss_idt_y: 0.07568982154130936, F_fool_loss: 0.013960756305605173, cycled_y_loss: 0.07970297049731016, D_Y_loss: 0.29113591969013214\n",
      "[74:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:600] Took 12.85s\n",
      "[74:600] loss_idt_x: 0.10990297727286816, G_fool_loss: 0.01376824064180255, cycled_x_loss: 0.10923458334058524, D_X_loss: 0.29230842500925064\n",
      "[74:600] loss_idt_y: 0.0697419960051775, F_fool_loss: 0.013960946630686522, cycled_y_loss: 0.07441035412251949, D_Y_loss: 0.2919342786073685\n",
      "[74:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:700] Took 12.86s\n",
      "[74:700] loss_idt_x: 0.11457780472934247, G_fool_loss: 0.013815181348472833, cycled_x_loss: 0.10863446667790413, D_X_loss: 0.29319961458444593\n",
      "[74:700] loss_idt_y: 0.07072233982384205, F_fool_loss: 0.014079423369839788, cycled_y_loss: 0.0743654902279377, D_Y_loss: 0.2925689798593521\n",
      "[74:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:800] Took 12.86s\n",
      "[74:800] loss_idt_x: 0.10590442106127738, G_fool_loss: 0.013828451354056597, cycled_x_loss: 0.09725211657583714, D_X_loss: 0.2919322568178177\n",
      "[74:800] loss_idt_y: 0.07070623019710183, F_fool_loss: 0.014041875442489981, cycled_y_loss: 0.07431851491332055, D_Y_loss: 0.29268715500831605\n",
      "[74:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:900] Took 12.87s\n",
      "[74:900] loss_idt_x: 0.10618707951158285, G_fool_loss: 0.014017624007537961, cycled_x_loss: 0.10036001842468976, D_X_loss: 0.29254793912172317\n",
      "[74:900] loss_idt_y: 0.07412625214084984, F_fool_loss: 0.013958262503147125, cycled_y_loss: 0.07799893237650395, D_Y_loss: 0.2916101649403572\n",
      "[74:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:1000] Took 12.86s\n",
      "[74:1000] loss_idt_x: 0.11427043065428734, G_fool_loss: 0.013984541650861501, cycled_x_loss: 0.11083813559263944, D_X_loss: 0.29120842814445497\n",
      "[74:1000] loss_idt_y: 0.06849638575688005, F_fool_loss: 0.013981350818648935, cycled_y_loss: 0.07200709447264671, D_Y_loss: 0.2927140933275223\n",
      "[74:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:1100] Took 12.87s\n",
      "[74:1100] loss_idt_x: 0.1064672203361988, G_fool_loss: 0.014003686476498842, cycled_x_loss: 0.10760293789207935, D_X_loss: 0.2922558650374413\n",
      "[74:1100] loss_idt_y: 0.06682271886616946, F_fool_loss: 0.013930621473118663, cycled_y_loss: 0.06721152309328318, D_Y_loss: 0.2922607785463333\n",
      "[74:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[74:END] Completed epoch in 170.32613921165466s\n",
      "[74:1199] ep_loss_idt_x: 0.109 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.104 ep_D_X_loss: 0.292\n",
      "[74:1199] ep_loss_idt_y: 0.071 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.073 ep_D_Y_loss: 0.292\n",
      "[74:END] Completed eval in 1.7852580547332764s\n",
      "Updated G_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated F_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated D_X_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated D_Y_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "[74:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[75:100] Took 14.82s\n",
      "[75:100] loss_idt_x: 0.10656209133565425, G_fool_loss: 0.014168822625651955, cycled_x_loss: 0.10168418731540442, D_X_loss: 0.2950573441386223\n",
      "[75:100] loss_idt_y: 0.07128997430205346, F_fool_loss: 0.014122652374207973, cycled_y_loss: 0.07605695199221373, D_Y_loss: 0.2946181184053421\n",
      "[75:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:200] Took 12.86s\n",
      "[75:200] loss_idt_x: 0.10460503671318293, G_fool_loss: 0.013859822051599621, cycled_x_loss: 0.10555739551782609, D_X_loss: 0.2935021802783012\n",
      "[75:200] loss_idt_y: 0.0691725342348218, F_fool_loss: 0.013867707699537277, cycled_y_loss: 0.06913573164492845, D_Y_loss: 0.29294108927249907\n",
      "[75:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:300] Took 12.86s\n",
      "[75:300] loss_idt_x: 0.09719386573880912, G_fool_loss: 0.013929121345281601, cycled_x_loss: 0.09603129886090755, D_X_loss: 0.2924086421728134\n",
      "[75:300] loss_idt_y: 0.06841544888913631, F_fool_loss: 0.014006298454478382, cycled_y_loss: 0.06962946020066738, D_Y_loss: 0.29151875525712967\n",
      "[75:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:400] Took 12.85s\n",
      "[75:400] loss_idt_x: 0.10470884926617145, G_fool_loss: 0.013824483500793577, cycled_x_loss: 0.10257852640002967, D_X_loss: 0.2930181950330734\n",
      "[75:400] loss_idt_y: 0.075367152672261, F_fool_loss: 0.01395583339035511, cycled_y_loss: 0.07855157226324082, D_Y_loss: 0.29309006839990615\n",
      "[75:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:500] Took 12.86s\n",
      "[75:500] loss_idt_x: 0.11186939194798469, G_fool_loss: 0.013893502652645112, cycled_x_loss: 0.10857513204216956, D_X_loss: 0.2919268435239792\n",
      "[75:500] loss_idt_y: 0.07211612027138471, F_fool_loss: 0.013889782121405006, cycled_y_loss: 0.07232566986232997, D_Y_loss: 0.29292634457349775\n",
      "[75:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:600] Took 12.88s\n",
      "[75:600] loss_idt_x: 0.1019311511144042, G_fool_loss: 0.013849180992692708, cycled_x_loss: 0.1051396657899022, D_X_loss: 0.2901262167096138\n",
      "[75:600] loss_idt_y: 0.07964707726612687, F_fool_loss: 0.013810268035158516, cycled_y_loss: 0.08053092062473297, D_Y_loss: 0.29303932428359986\n",
      "[75:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:700] Took 12.88s\n",
      "[75:700] loss_idt_x: 0.11900229327380657, G_fool_loss: 0.013873618692159653, cycled_x_loss: 0.11344877529889345, D_X_loss: 0.2913946506381035\n",
      "[75:700] loss_idt_y: 0.06711377404630184, F_fool_loss: 0.014042833922430872, cycled_y_loss: 0.06960125667974353, D_Y_loss: 0.2926979237794876\n",
      "[75:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:800] Took 12.89s\n",
      "[75:800] loss_idt_x: 0.11145072408020497, G_fool_loss: 0.0139059385843575, cycled_x_loss: 0.10786848954856396, D_X_loss: 0.2924338775873184\n",
      "[75:800] loss_idt_y: 0.0687197683006525, F_fool_loss: 0.013933253604918719, cycled_y_loss: 0.07633208882063627, D_Y_loss: 0.2925877383351326\n",
      "[75:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:900] Took 12.87s\n",
      "[75:900] loss_idt_x: 0.1108712775632739, G_fool_loss: 0.014036940159276128, cycled_x_loss: 0.10685702793300152, D_X_loss: 0.2913566678762436\n",
      "[75:900] loss_idt_y: 0.07721694741398095, F_fool_loss: 0.013922678418457507, cycled_y_loss: 0.0801126216351986, D_Y_loss: 0.29347598493099214\n",
      "[75:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:1000] Took 12.87s\n",
      "[75:1000] loss_idt_x: 0.10416796632111072, G_fool_loss: 0.013903248738497496, cycled_x_loss: 0.10434326402842999, D_X_loss: 0.29264529079198837\n",
      "[75:1000] loss_idt_y: 0.08275016494095326, F_fool_loss: 0.01388998824171722, cycled_y_loss: 0.08289043501019477, D_Y_loss: 0.2929267457127571\n",
      "[75:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:1100] Took 12.88s\n",
      "[75:1100] loss_idt_x: 0.09366688594222068, G_fool_loss: 0.013828198695555328, cycled_x_loss: 0.0922880007699132, D_X_loss: 0.2914223575592041\n",
      "[75:1100] loss_idt_y: 0.06758568294346333, F_fool_loss: 0.013821991896256804, cycled_y_loss: 0.06884169835597277, D_Y_loss: 0.2911325988173485\n",
      "[75:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[75:END] Completed epoch in 168.6949064731598s\n",
      "[75:1199] ep_loss_idt_x: 0.106 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.104 ep_D_X_loss: 0.292\n",
      "[75:1199] ep_loss_idt_y: 0.072 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.074 ep_D_Y_loss: 0.293\n",
      "[75:END] Completed eval in 2.3347597122192383s\n",
      "Updated G_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated F_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated D_X_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated D_Y_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "[75:END] Saving models and training information permanently\n",
      "[76:100] Took 14.85s\n",
      "[76:100] loss_idt_x: 0.1027311011776328, G_fool_loss: 0.014142227172851563, cycled_x_loss: 0.09590329047292472, D_X_loss: 0.2951944273710251\n",
      "[76:100] loss_idt_y: 0.06924554010853172, F_fool_loss: 0.014153621718287468, cycled_y_loss: 0.0699757321178913, D_Y_loss: 0.2947304937243462\n",
      "[76:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:200] Took 12.86s\n",
      "[76:200] loss_idt_x: 0.1133919245004654, G_fool_loss: 0.013851195173338056, cycled_x_loss: 0.10533783622086049, D_X_loss: 0.29282952070236207\n",
      "[76:200] loss_idt_y: 0.07436394665390253, F_fool_loss: 0.013953487100079655, cycled_y_loss: 0.07381998013705016, D_Y_loss: 0.2922621691226959\n",
      "[76:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:300] Took 12.87s\n",
      "[76:300] loss_idt_x: 0.10621474586427211, G_fool_loss: 0.013698863470926881, cycled_x_loss: 0.100180002450943, D_X_loss: 0.2913159281015396\n",
      "[76:300] loss_idt_y: 0.07153310151770712, F_fool_loss: 0.013797311894595623, cycled_y_loss: 0.07430965170264243, D_Y_loss: 0.2907790720462799\n",
      "[76:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:400] Took 12.86s\n",
      "[76:400] loss_idt_x: 0.10379729907959699, G_fool_loss: 0.01379805114120245, cycled_x_loss: 0.0973934182152152, D_X_loss: 0.2925786811113358\n",
      "[76:400] loss_idt_y: 0.06006889322772622, F_fool_loss: 0.013636298347264528, cycled_y_loss: 0.062672586645931, D_Y_loss: 0.2923745933175087\n",
      "[76:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:500] Took 12.87s\n",
      "[76:500] loss_idt_x: 0.0983437366783619, G_fool_loss: 0.013796712411567569, cycled_x_loss: 0.09159349340945483, D_X_loss: 0.2922025352716446\n",
      "[76:500] loss_idt_y: 0.06614424346014858, F_fool_loss: 0.013869764674454927, cycled_y_loss: 0.0671563160046935, D_Y_loss: 0.2920443722605705\n",
      "[76:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:600] Took 12.88s\n",
      "[76:600] loss_idt_x: 0.10363380938768386, G_fool_loss: 0.013785554384812713, cycled_x_loss: 0.10544223107397556, D_X_loss: 0.2925981244444847\n",
      "[76:600] loss_idt_y: 0.0796568070165813, F_fool_loss: 0.013970205998048187, cycled_y_loss: 0.08010121194645763, D_Y_loss: 0.29270786106586455\n",
      "[76:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:700] Took 12.87s\n",
      "[76:700] loss_idt_x: 0.10020850196480752, G_fool_loss: 0.014059850769117475, cycled_x_loss: 0.10005398761481046, D_X_loss: 0.2911834540963173\n",
      "[76:700] loss_idt_y: 0.07796108920127154, F_fool_loss: 0.013929713238030671, cycled_y_loss: 0.0790979429334402, D_Y_loss: 0.291062451004982\n",
      "[76:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:800] Took 12.87s\n",
      "[76:800] loss_idt_x: 0.10837719786912203, G_fool_loss: 0.013706610277295113, cycled_x_loss: 0.10097558535635472, D_X_loss: 0.2929987570643425\n",
      "[76:800] loss_idt_y: 0.07065395692363381, F_fool_loss: 0.013861756548285484, cycled_y_loss: 0.0703776653110981, D_Y_loss: 0.2913918253779411\n",
      "[76:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:900] Took 12.87s\n",
      "[76:900] loss_idt_x: 0.1006239290162921, G_fool_loss: 0.013864413974806667, cycled_x_loss: 0.09960880778729915, D_X_loss: 0.29212226420640947\n",
      "[76:900] loss_idt_y: 0.06641468401998281, F_fool_loss: 0.013880092920735478, cycled_y_loss: 0.06788244558498263, D_Y_loss: 0.2921704179048538\n",
      "[76:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:1000] Took 12.87s\n",
      "[76:1000] loss_idt_x: 0.11765863325446844, G_fool_loss: 0.013771840995177627, cycled_x_loss: 0.1158181094005704, D_X_loss: 0.29126212269067764\n",
      "[76:1000] loss_idt_y: 0.06957526018843055, F_fool_loss: 0.013839604435488581, cycled_y_loss: 0.07090272836387157, D_Y_loss: 0.2917263919115067\n",
      "[76:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:1100] Took 12.87s\n",
      "[76:1100] loss_idt_x: 0.09620606731623411, G_fool_loss: 0.01373125160112977, cycled_x_loss: 0.09568156618624926, D_X_loss: 0.2928928300738335\n",
      "[76:1100] loss_idt_y: 0.06254732143133879, F_fool_loss: 0.013930970076471568, cycled_y_loss: 0.06704583598300815, D_Y_loss: 0.2933529648184776\n",
      "[76:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[76:END] Completed epoch in 168.90813398361206s\n",
      "[76:1199] ep_loss_idt_x: 0.105 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.101 ep_D_X_loss: 0.292\n",
      "[76:1199] ep_loss_idt_y: 0.070 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.071 ep_D_Y_loss: 0.292\n",
      "[76:END] Completed eval in 1.7922074794769287s\n",
      "Updated G_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated F_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated D_X_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated D_Y_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "[76:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[77:100] Took 14.89s\n",
      "[77:100] loss_idt_x: 0.09929381288588048, G_fool_loss: 0.014107637144625186, cycled_x_loss: 0.09270437061786652, D_X_loss: 0.29486593008041384\n",
      "[77:100] loss_idt_y: 0.0742046931758523, F_fool_loss: 0.013977360120043159, cycled_y_loss: 0.07601165287196636, D_Y_loss: 0.2959369391202927\n",
      "[77:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:200] Took 12.86s\n",
      "[77:200] loss_idt_x: 0.10760342005640268, G_fool_loss: 0.013740807613357902, cycled_x_loss: 0.09865775788202882, D_X_loss: 0.2921728202700615\n",
      "[77:200] loss_idt_y: 0.05970348719507456, F_fool_loss: 0.014010455645620822, cycled_y_loss: 0.061710704285651445, D_Y_loss: 0.2929954487085342\n",
      "[77:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:300] Took 12.86s\n",
      "[77:300] loss_idt_x: 0.09986937753856182, G_fool_loss: 0.013802833268418907, cycled_x_loss: 0.0929111098870635, D_X_loss: 0.2921838471293449\n",
      "[77:300] loss_idt_y: 0.0763766878657043, F_fool_loss: 0.013855597404763102, cycled_y_loss: 0.07303083505481482, D_Y_loss: 0.2929183062911034\n",
      "[77:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:400] Took 12.87s\n",
      "[77:400] loss_idt_x: 0.10054050326347351, G_fool_loss: 0.013751197550445795, cycled_x_loss: 0.09818132665008307, D_X_loss: 0.293124760389328\n",
      "[77:400] loss_idt_y: 0.06782034173607826, F_fool_loss: 0.013707892186939716, cycled_y_loss: 0.0684961823374033, D_Y_loss: 0.29344958037137986\n",
      "[77:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:500] Took 12.88s\n",
      "[77:500] loss_idt_x: 0.10684945859014988, G_fool_loss: 0.014047731403261423, cycled_x_loss: 0.10448083590716123, D_X_loss: 0.2931268057227135\n",
      "[77:500] loss_idt_y: 0.07024567643180489, F_fool_loss: 0.01390044391155243, cycled_y_loss: 0.07097424436360597, D_Y_loss: 0.29167253971099855\n",
      "[77:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:600] Took 12.88s\n",
      "[77:600] loss_idt_x: 0.10741155959665775, G_fool_loss: 0.014002207340672613, cycled_x_loss: 0.10551338512450456, D_X_loss: 0.2940011078119278\n",
      "[77:600] loss_idt_y: 0.07884291334077716, F_fool_loss: 0.013720560586079955, cycled_y_loss: 0.08084560301154851, D_Y_loss: 0.291966053545475\n",
      "[77:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:700] Took 12.88s\n",
      "[77:700] loss_idt_x: 0.10706692364066839, G_fool_loss: 0.013564802864566445, cycled_x_loss: 0.10485998537391424, D_X_loss: 0.2928729996085167\n",
      "[77:700] loss_idt_y: 0.07527760591357946, F_fool_loss: 0.013775994516909123, cycled_y_loss: 0.07857287032529711, D_Y_loss: 0.2908815675973892\n",
      "[77:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:800] Took 12.88s\n",
      "[77:800] loss_idt_x: 0.10332536846399307, G_fool_loss: 0.013851951817050576, cycled_x_loss: 0.09949426308274269, D_X_loss: 0.2911019864678383\n",
      "[77:800] loss_idt_y: 0.07327180121093989, F_fool_loss: 0.013730853721499443, cycled_y_loss: 0.07366312593221665, D_Y_loss: 0.29305120795965195\n",
      "[77:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:900] Took 12.87s\n",
      "[77:900] loss_idt_x: 0.11097087372094393, G_fool_loss: 0.013860895568504929, cycled_x_loss: 0.10620005425065755, D_X_loss: 0.29244929403066633\n",
      "[77:900] loss_idt_y: 0.06613958645612002, F_fool_loss: 0.013737798938527702, cycled_y_loss: 0.06969966465607286, D_Y_loss: 0.29198629468679427\n",
      "[77:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:1000] Took 12.87s\n",
      "[77:1000] loss_idt_x: 0.11156441148370505, G_fool_loss: 0.013969677481800318, cycled_x_loss: 0.10623355910181999, D_X_loss: 0.29253423035144804\n",
      "[77:1000] loss_idt_y: 0.07164541199803352, F_fool_loss: 0.013752277856692672, cycled_y_loss: 0.0738574918359518, D_Y_loss: 0.2917743244767189\n",
      "[77:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:1100] Took 12.88s\n",
      "[77:1100] loss_idt_x: 0.11412721503525973, G_fool_loss: 0.014087494416162371, cycled_x_loss: 0.11074249152094126, D_X_loss: 0.2925679063796997\n",
      "[77:1100] loss_idt_y: 0.06520652109757066, F_fool_loss: 0.013760613184422255, cycled_y_loss: 0.06631731491535903, D_Y_loss: 0.2933215031027794\n",
      "[77:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[77:END] Completed epoch in 168.70732355117798s\n",
      "[77:1199] ep_loss_idt_x: 0.107 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.102 ep_D_X_loss: 0.293\n",
      "[77:1199] ep_loss_idt_y: 0.070 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.072 ep_D_Y_loss: 0.293\n",
      "[77:END] Completed eval in 1.7553081512451172s\n",
      "Updated G_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated F_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated D_X_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated D_Y_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "[77:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[78:100] Took 14.88s\n",
      "[78:100] loss_idt_x: 0.09271830108016729, G_fool_loss: 0.013965143095701934, cycled_x_loss: 0.09217901606112719, D_X_loss: 0.2953536558151245\n",
      "[78:100] loss_idt_y: 0.0727529401704669, F_fool_loss: 0.014160949047654867, cycled_y_loss: 0.076406683139503, D_Y_loss: 0.29477824717760087\n",
      "[78:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:200] Took 12.88s\n",
      "[78:200] loss_idt_x: 0.11539781663566828, G_fool_loss: 0.01385352292098105, cycled_x_loss: 0.10586110353469849, D_X_loss: 0.2917597052454948\n",
      "[78:200] loss_idt_y: 0.07539679255336523, F_fool_loss: 0.01381280368193984, cycled_y_loss: 0.07656869597733021, D_Y_loss: 0.2918923419713974\n",
      "[78:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:300] Took 12.88s\n",
      "[78:300] loss_idt_x: 0.10640276674181223, G_fool_loss: 0.013785137794911861, cycled_x_loss: 0.0999298868700862, D_X_loss: 0.29287180870771407\n",
      "[78:300] loss_idt_y: 0.07341022165492177, F_fool_loss: 0.013875644719228149, cycled_y_loss: 0.0725739947333932, D_Y_loss: 0.2916833183169365\n",
      "[78:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:400] Took 12.87s\n",
      "[78:400] loss_idt_x: 0.10723883133381605, G_fool_loss: 0.013706159824505449, cycled_x_loss: 0.10535772915929556, D_X_loss: 0.29109532058238985\n",
      "[78:400] loss_idt_y: 0.07150613002479077, F_fool_loss: 0.013838390773162245, cycled_y_loss: 0.07410254308953881, D_Y_loss: 0.2920136034488678\n",
      "[78:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:500] Took 12.88s\n",
      "[78:500] loss_idt_x: 0.10422569610178471, G_fool_loss: 0.01379784021526575, cycled_x_loss: 0.10319249577820301, D_X_loss: 0.2914038172364235\n",
      "[78:500] loss_idt_y: 0.07088152104988694, F_fool_loss: 0.013870536424219608, cycled_y_loss: 0.07110215593129396, D_Y_loss: 0.2922068923711777\n",
      "[78:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:600] Took 12.89s\n",
      "[78:600] loss_idt_x: 0.097857661023736, G_fool_loss: 0.01390983622521162, cycled_x_loss: 0.09483262300491332, D_X_loss: 0.2920223543047905\n",
      "[78:600] loss_idt_y: 0.07517645332962275, F_fool_loss: 0.013786706365644932, cycled_y_loss: 0.07632182385772467, D_Y_loss: 0.2926618278026581\n",
      "[78:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:700] Took 12.87s\n",
      "[78:700] loss_idt_x: 0.11658872529864311, G_fool_loss: 0.01397451269440353, cycled_x_loss: 0.10700122203677892, D_X_loss: 0.29172908514738083\n",
      "[78:700] loss_idt_y: 0.06318671932443977, F_fool_loss: 0.013977294452488423, cycled_y_loss: 0.06359989078715443, D_Y_loss: 0.29239443957805633\n",
      "[78:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:800] Took 12.87s\n",
      "[78:800] loss_idt_x: 0.0978789409250021, G_fool_loss: 0.01385378765873611, cycled_x_loss: 0.09577583022415638, D_X_loss: 0.2917148044705391\n",
      "[78:800] loss_idt_y: 0.06524878490716218, F_fool_loss: 0.013862512921914458, cycled_y_loss: 0.06596699297428131, D_Y_loss: 0.2908789789676666\n",
      "[78:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:900] Took 12.88s\n",
      "[78:900] loss_idt_x: 0.0977562602609396, G_fool_loss: 0.013935262793675065, cycled_x_loss: 0.09632073011249304, D_X_loss: 0.29196913957595827\n",
      "[78:900] loss_idt_y: 0.07362529635429382, F_fool_loss: 0.013908758191391826, cycled_y_loss: 0.07332423899322749, D_Y_loss: 0.2914409518241882\n",
      "[78:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:1000] Took 12.87s\n",
      "[78:1000] loss_idt_x: 0.10263751070946454, G_fool_loss: 0.013807716984301806, cycled_x_loss: 0.10023894332349301, D_X_loss: 0.29210982531309126\n",
      "[78:1000] loss_idt_y: 0.0800008825957775, F_fool_loss: 0.0138123388774693, cycled_y_loss: 0.07902126612141729, D_Y_loss: 0.29179348319768905\n",
      "[78:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:1100] Took 12.88s\n",
      "[78:1100] loss_idt_x: 0.1032403177022934, G_fool_loss: 0.013791277054697276, cycled_x_loss: 0.09793900210410357, D_X_loss: 0.29132557958364486\n",
      "[78:1100] loss_idt_y: 0.06874245163053275, F_fool_loss: 0.013808273021131754, cycled_y_loss: 0.07187065362930298, D_Y_loss: 0.2914092370867729\n",
      "[78:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[78:END] Completed epoch in 168.704772233963s\n",
      "[78:1199] ep_loss_idt_x: 0.103 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.099 ep_D_X_loss: 0.292\n",
      "[78:1199] ep_loss_idt_y: 0.072 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.073 ep_D_Y_loss: 0.292\n",
      "[78:END] Completed eval in 1.861053228378296s\n",
      "Updated G_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated F_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated D_X_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated D_Y_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "[78:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[79:100] Took 14.79s\n",
      "[79:100] loss_idt_x: 0.09935884688049555, G_fool_loss: 0.014099083468317985, cycled_x_loss: 0.09782614946365356, D_X_loss: 0.29550800621509554\n",
      "[79:100] loss_idt_y: 0.06826121620833873, F_fool_loss: 0.014027927741408349, cycled_y_loss: 0.06973219772800804, D_Y_loss: 0.296327161192894\n",
      "[79:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:200] Took 12.88s\n",
      "[79:200] loss_idt_x: 0.1018467229604721, G_fool_loss: 0.013791380254551767, cycled_x_loss: 0.09780769731849431, D_X_loss: 0.2922778412699699\n",
      "[79:200] loss_idt_y: 0.07526657272130251, F_fool_loss: 0.013784778388217091, cycled_y_loss: 0.07355786755681037, D_Y_loss: 0.2920962691307068\n",
      "[79:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:300] Took 12.87s\n",
      "[79:300] loss_idt_x: 0.08522417768836021, G_fool_loss: 0.013896166970953345, cycled_x_loss: 0.08561688184738159, D_X_loss: 0.29144160360097887\n",
      "[79:300] loss_idt_y: 0.06194375768303871, F_fool_loss: 0.013913758592680096, cycled_y_loss: 0.06315206808969379, D_Y_loss: 0.2923643231391907\n",
      "[79:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:400] Took 12.87s\n",
      "[79:400] loss_idt_x: 0.10746669486165046, G_fool_loss: 0.013996551409363747, cycled_x_loss: 0.10714020557701588, D_X_loss: 0.29211601108312607\n",
      "[79:400] loss_idt_y: 0.07288307758048176, F_fool_loss: 0.013890867913141846, cycled_y_loss: 0.07703811027109624, D_Y_loss: 0.2910147970914841\n",
      "[79:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:500] Took 12.87s\n",
      "[79:500] loss_idt_x: 0.10506336081773043, G_fool_loss: 0.013813237277790904, cycled_x_loss: 0.10462224707007409, D_X_loss: 0.29096236288547517\n",
      "[79:500] loss_idt_y: 0.07610580574721099, F_fool_loss: 0.013862227145582438, cycled_y_loss: 0.07610876437276602, D_Y_loss: 0.2925145414471626\n",
      "[79:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:600] Took 12.90s\n",
      "[79:600] loss_idt_x: 0.10390375833958387, G_fool_loss: 0.013695542505010962, cycled_x_loss: 0.10326776701956987, D_X_loss: 0.2915280175209045\n",
      "[79:600] loss_idt_y: 0.061945190355181694, F_fool_loss: 0.013784001506865024, cycled_y_loss: 0.06516654144972563, D_Y_loss: 0.2927146649360657\n",
      "[79:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:700] Took 12.87s\n",
      "[79:700] loss_idt_x: 0.10203245773911476, G_fool_loss: 0.014008580828085542, cycled_x_loss: 0.09192587595432997, D_X_loss: 0.29122232884168625\n",
      "[79:700] loss_idt_y: 0.06450499966740608, F_fool_loss: 0.013665848029777408, cycled_y_loss: 0.06278035908937454, D_Y_loss: 0.291145501434803\n",
      "[79:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:800] Took 12.88s\n",
      "[79:800] loss_idt_x: 0.09566334746778012, G_fool_loss: 0.013774262266233564, cycled_x_loss: 0.09210445050150157, D_X_loss: 0.29318884819746016\n",
      "[79:800] loss_idt_y: 0.06868322480469942, F_fool_loss: 0.013757576681673527, cycled_y_loss: 0.07128817461431027, D_Y_loss: 0.2921611079573631\n",
      "[79:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:900] Took 12.88s\n",
      "[79:900] loss_idt_x: 0.09886824242770671, G_fool_loss: 0.013871703306213021, cycled_x_loss: 0.09400369450449944, D_X_loss: 0.29147006511688234\n",
      "[79:900] loss_idt_y: 0.0698133080638945, F_fool_loss: 0.013842141656205058, cycled_y_loss: 0.06874449225142598, D_Y_loss: 0.2924589270353317\n",
      "[79:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:1000] Took 12.88s\n",
      "[79:1000] loss_idt_x: 0.096879368647933, G_fool_loss: 0.013645137446001172, cycled_x_loss: 0.09354758024215698, D_X_loss: 0.2914566308259964\n",
      "[79:1000] loss_idt_y: 0.061723861005157234, F_fool_loss: 0.013667906261980533, cycled_y_loss: 0.060689701978117225, D_Y_loss: 0.29245121449232103\n",
      "[79:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:1100] Took 12.89s\n",
      "[79:1100] loss_idt_x: 0.10563602481037378, G_fool_loss: 0.013782814787700772, cycled_x_loss: 0.10338948547840118, D_X_loss: 0.29132653802633285\n",
      "[79:1100] loss_idt_y: 0.07098439341410995, F_fool_loss: 0.013885995959863067, cycled_y_loss: 0.06908948203548788, D_Y_loss: 0.29243414640426635\n",
      "[79:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[79:END] Completed epoch in 169.51652836799622s\n",
      "[79:1199] ep_loss_idt_x: 0.101 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.097 ep_D_X_loss: 0.292\n",
      "[79:1199] ep_loss_idt_y: 0.069 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.069 ep_D_Y_loss: 0.292\n",
      "[79:END] Completed eval in 1.8101904392242432s\n",
      "Updated G_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated F_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated D_X_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated D_Y_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "[79:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[80:100] Took 14.79s\n",
      "[80:100] loss_idt_x: 0.10365177623927593, G_fool_loss: 0.013811621069908141, cycled_x_loss: 0.09833349153399468, D_X_loss: 0.2952424782514572\n",
      "[80:100] loss_idt_y: 0.07419621173292398, F_fool_loss: 0.014047960722818971, cycled_y_loss: 0.07175083871930837, D_Y_loss: 0.293854296207428\n",
      "[80:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:200] Took 12.86s\n",
      "[80:200] loss_idt_x: 0.11747496709227562, G_fool_loss: 0.013895480204373598, cycled_x_loss: 0.1076560477539897, D_X_loss: 0.29190252870321276\n",
      "[80:200] loss_idt_y: 0.06913465891033412, F_fool_loss: 0.013894313713535666, cycled_y_loss: 0.06989019308239222, D_Y_loss: 0.2928368532657623\n",
      "[80:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:300] Took 12.87s\n",
      "[80:300] loss_idt_x: 0.09367502123117447, G_fool_loss: 0.01366095956414938, cycled_x_loss: 0.09137576028704643, D_X_loss: 0.29215885668992997\n",
      "[80:300] loss_idt_y: 0.07644180607050657, F_fool_loss: 0.013686771588400006, cycled_y_loss: 0.08271000284701585, D_Y_loss: 0.29253288805484773\n",
      "[80:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:400] Took 12.88s\n",
      "[80:400] loss_idt_x: 0.09800838191062212, G_fool_loss: 0.01382628950290382, cycled_x_loss: 0.09457237306982279, D_X_loss: 0.2934085729718208\n",
      "[80:400] loss_idt_y: 0.07800419067963958, F_fool_loss: 0.013682849397882819, cycled_y_loss: 0.07997754413634539, D_Y_loss: 0.29082257360219954\n",
      "[80:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:500] Took 12.87s\n",
      "[80:500] loss_idt_x: 0.10656110484153032, G_fool_loss: 0.013731132475659252, cycled_x_loss: 0.10624722126871347, D_X_loss: 0.29243165493011475\n",
      "[80:500] loss_idt_y: 0.07532447537407279, F_fool_loss: 0.013755370276048779, cycled_y_loss: 0.07455182185396553, D_Y_loss: 0.292002831697464\n",
      "[80:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:600] Took 12.87s\n",
      "[80:600] loss_idt_x: 0.10156748112291097, G_fool_loss: 0.013667359836399556, cycled_x_loss: 0.0960568879544735, D_X_loss: 0.29096367448568344\n",
      "[80:600] loss_idt_y: 0.07524087378755212, F_fool_loss: 0.013972979784011842, cycled_y_loss: 0.07861952954903245, D_Y_loss: 0.2909389171004295\n",
      "[80:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:700] Took 12.90s\n",
      "[80:700] loss_idt_x: 0.1047249348834157, G_fool_loss: 0.013795590279623866, cycled_x_loss: 0.09957877974957227, D_X_loss: 0.2916755536198616\n",
      "[80:700] loss_idt_y: 0.07756701711565256, F_fool_loss: 0.01392300850711763, cycled_y_loss: 0.07709998425096273, D_Y_loss: 0.29077405512332916\n",
      "[80:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:800] Took 12.88s\n",
      "[80:800] loss_idt_x: 0.08997288480401039, G_fool_loss: 0.013663878720253706, cycled_x_loss: 0.08637551251798868, D_X_loss: 0.2915798771381378\n",
      "[80:800] loss_idt_y: 0.0751252249442041, F_fool_loss: 0.013810010012239218, cycled_y_loss: 0.07775637421756983, D_Y_loss: 0.29190880954265597\n",
      "[80:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:900] Took 12.88s\n",
      "[80:900] loss_idt_x: 0.09656304739415646, G_fool_loss: 0.013959575798362494, cycled_x_loss: 0.09378447964787483, D_X_loss: 0.2920993521809578\n",
      "[80:900] loss_idt_y: 0.07037118734791875, F_fool_loss: 0.013876942973583937, cycled_y_loss: 0.06943920213729143, D_Y_loss: 0.29122015297412873\n",
      "[80:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:1000] Took 12.90s\n",
      "[80:1000] loss_idt_x: 0.0953238034620881, G_fool_loss: 0.013823757916688918, cycled_x_loss: 0.09313532169908285, D_X_loss: 0.29214991599321366\n",
      "[80:1000] loss_idt_y: 0.07619384195655585, F_fool_loss: 0.01364915176294744, cycled_y_loss: 0.0795384981483221, D_Y_loss: 0.2908072903752327\n",
      "[80:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:1100] Took 12.88s\n",
      "[80:1100] loss_idt_x: 0.10696501910686493, G_fool_loss: 0.013754208786413074, cycled_x_loss: 0.10640998840332032, D_X_loss: 0.2920563846826553\n",
      "[80:1100] loss_idt_y: 0.07367273418232799, F_fool_loss: 0.0139377420861274, cycled_y_loss: 0.07395777583122254, D_Y_loss: 0.29189595133066176\n",
      "[80:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[80:END] Completed epoch in 170.18326711654663s\n",
      "[80:1199] ep_loss_idt_x: 0.101 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.097 ep_D_X_loss: 0.292\n",
      "[80:1199] ep_loss_idt_y: 0.074 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.075 ep_D_Y_loss: 0.291\n",
      "[80:END] Completed eval in 1.8221232891082764s\n",
      "Updated G_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated F_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated D_X_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated D_Y_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "[80:END] Saving models and training information permanently\n",
      "[81:100] Took 14.82s\n",
      "[81:100] loss_idt_x: 0.09635842399671674, G_fool_loss: 0.01386425593867898, cycled_x_loss: 0.090643661133945, D_X_loss: 0.2955876210331917\n",
      "[81:100] loss_idt_y: 0.0707919131591916, F_fool_loss: 0.013819853952154517, cycled_y_loss: 0.06988791625946761, D_Y_loss: 0.2954373893141746\n",
      "[81:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:200] Took 12.94s\n",
      "[81:200] loss_idt_x: 0.09984964817762375, G_fool_loss: 0.013767901565879584, cycled_x_loss: 0.0970000908523798, D_X_loss: 0.29166881561279295\n",
      "[81:200] loss_idt_y: 0.07546250948682427, F_fool_loss: 0.01365155391395092, cycled_y_loss: 0.07933883875608444, D_Y_loss: 0.29198340624570845\n",
      "[81:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:300] Took 12.87s\n",
      "[81:300] loss_idt_x: 0.09287200963124632, G_fool_loss: 0.013759901067242026, cycled_x_loss: 0.08434264164417982, D_X_loss: 0.2924256443977356\n",
      "[81:300] loss_idt_y: 0.07330629400908947, F_fool_loss: 0.013816776601597667, cycled_y_loss: 0.07335341921076179, D_Y_loss: 0.2916658389568329\n",
      "[81:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:400] Took 12.90s\n",
      "[81:400] loss_idt_x: 0.1136823134124279, G_fool_loss: 0.01385367595590651, cycled_x_loss: 0.1096434560790658, D_X_loss: 0.29270098567008973\n",
      "[81:400] loss_idt_y: 0.07043540397658944, F_fool_loss: 0.013787542106583714, cycled_y_loss: 0.07185852164402604, D_Y_loss: 0.29040745466947554\n",
      "[81:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:500] Took 12.88s\n",
      "[81:500] loss_idt_x: 0.10011285841464997, G_fool_loss: 0.013474553488194943, cycled_x_loss: 0.0971517677605152, D_X_loss: 0.2924788126349449\n",
      "[81:500] loss_idt_y: 0.06653822217136622, F_fool_loss: 0.013782769963145257, cycled_y_loss: 0.07067385867238045, D_Y_loss: 0.29147240161895754\n",
      "[81:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:600] Took 12.87s\n",
      "[81:600] loss_idt_x: 0.10449243642389774, G_fool_loss: 0.013777433214709162, cycled_x_loss: 0.09726194601505994, D_X_loss: 0.29072227120399474\n",
      "[81:600] loss_idt_y: 0.07417849330231548, F_fool_loss: 0.013702981136739255, cycled_y_loss: 0.0754550439119339, D_Y_loss: 0.2908720651268959\n",
      "[81:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:700] Took 12.92s\n",
      "[81:700] loss_idt_x: 0.1221972370147705, G_fool_loss: 0.013722099317237734, cycled_x_loss: 0.11401932267472148, D_X_loss: 0.2927088335156441\n",
      "[81:700] loss_idt_y: 0.07732919231057167, F_fool_loss: 0.013778676502406597, cycled_y_loss: 0.07794487373903394, D_Y_loss: 0.2927149522304535\n",
      "[81:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:800] Took 12.89s\n",
      "[81:800] loss_idt_x: 0.10866137154400349, G_fool_loss: 0.013757743583992123, cycled_x_loss: 0.10710485979914665, D_X_loss: 0.29276135444641116\n",
      "[81:800] loss_idt_y: 0.06477288817986845, F_fool_loss: 0.013815456088632345, cycled_y_loss: 0.0673166722804308, D_Y_loss: 0.2915255433320999\n",
      "[81:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:900] Took 12.88s\n",
      "[81:900] loss_idt_x: 0.10897424336522818, G_fool_loss: 0.013748493287712335, cycled_x_loss: 0.10245643392205238, D_X_loss: 0.2919191563129425\n",
      "[81:900] loss_idt_y: 0.06407782811671496, F_fool_loss: 0.013878520242869855, cycled_y_loss: 0.06310374740511179, D_Y_loss: 0.2926968428492546\n",
      "[81:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:1000] Took 12.87s\n",
      "[81:1000] loss_idt_x: 0.09466423630714417, G_fool_loss: 0.01374573384411633, cycled_x_loss: 0.09299773793667555, D_X_loss: 0.2924876034259796\n",
      "[81:1000] loss_idt_y: 0.06140176268294453, F_fool_loss: 0.013828387772664428, cycled_y_loss: 0.061083733439445495, D_Y_loss: 0.2919427555799484\n",
      "[81:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:1100] Took 12.88s\n",
      "[81:1100] loss_idt_x: 0.10248224500566722, G_fool_loss: 0.013845018958672881, cycled_x_loss: 0.09941880293190479, D_X_loss: 0.292136515378952\n",
      "[81:1100] loss_idt_y: 0.07125070927664638, F_fool_loss: 0.013728584721684456, cycled_y_loss: 0.07180240603163839, D_Y_loss: 0.29219089150428773\n",
      "[81:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[81:END] Completed epoch in 171.03101420402527s\n",
      "[81:1199] ep_loss_idt_x: 0.103 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.099 ep_D_X_loss: 0.292\n",
      "[81:1199] ep_loss_idt_y: 0.070 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.071 ep_D_Y_loss: 0.292\n",
      "[81:END] Completed eval in 1.7842330932617188s\n",
      "Updated G_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated F_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated D_X_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated D_Y_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "[81:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[82:100] Took 14.83s\n",
      "[82:100] loss_idt_x: 0.10297201693058014, G_fool_loss: 0.013972386131063103, cycled_x_loss: 0.09737494871020318, D_X_loss: 0.29429386258125306\n",
      "[82:100] loss_idt_y: 0.07253678780049086, F_fool_loss: 0.013813041187822818, cycled_y_loss: 0.07509500272572041, D_Y_loss: 0.2937908884882927\n",
      "[82:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:200] Took 12.87s\n",
      "[82:200] loss_idt_x: 0.0967951876297593, G_fool_loss: 0.013725145617499948, cycled_x_loss: 0.08721687801182271, D_X_loss: 0.2935616010427475\n",
      "[82:200] loss_idt_y: 0.06899352889508009, F_fool_loss: 0.013727117590606212, cycled_y_loss: 0.06976083628833293, D_Y_loss: 0.29308350712060927\n",
      "[82:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:300] Took 12.87s\n",
      "[82:300] loss_idt_x: 0.10334398005157709, G_fool_loss: 0.01368888994678855, cycled_x_loss: 0.10008142039179801, D_X_loss: 0.2935618343949318\n",
      "[82:300] loss_idt_y: 0.0638924098201096, F_fool_loss: 0.013684437209740281, cycled_y_loss: 0.06909831967204809, D_Y_loss: 0.29162095457315446\n",
      "[82:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:400] Took 12.88s\n",
      "[82:400] loss_idt_x: 0.10710271790623666, G_fool_loss: 0.013820841573178769, cycled_x_loss: 0.10389956355094909, D_X_loss: 0.2923684653639793\n",
      "[82:400] loss_idt_y: 0.07132792752236128, F_fool_loss: 0.01389405912719667, cycled_y_loss: 0.07232458289712668, D_Y_loss: 0.2914941456913948\n",
      "[82:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:500] Took 12.87s\n",
      "[82:500] loss_idt_x: 0.11007169742137193, G_fool_loss: 0.013666882961988449, cycled_x_loss: 0.10218407936394215, D_X_loss: 0.29302814960479734\n",
      "[82:500] loss_idt_y: 0.06783742215484381, F_fool_loss: 0.013712041256949305, cycled_y_loss: 0.06942964376881719, D_Y_loss: 0.2908926913142204\n",
      "[82:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:600] Took 12.87s\n",
      "[82:600] loss_idt_x: 0.11281630929559469, G_fool_loss: 0.01374996591359377, cycled_x_loss: 0.11238592498004436, D_X_loss: 0.29361460149288177\n",
      "[82:600] loss_idt_y: 0.06672821201384067, F_fool_loss: 0.013779761865735055, cycled_y_loss: 0.06885939640924335, D_Y_loss: 0.29164273768663407\n",
      "[82:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:700] Took 12.88s\n",
      "[82:700] loss_idt_x: 0.11548674408346414, G_fool_loss: 0.013810364622622728, cycled_x_loss: 0.10729675110429525, D_X_loss: 0.29146105945110323\n",
      "[82:700] loss_idt_y: 0.06276871809735894, F_fool_loss: 0.013615498440340162, cycled_y_loss: 0.061092359125614164, D_Y_loss: 0.2924323838949203\n",
      "[82:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:800] Took 12.90s\n",
      "[82:800] loss_idt_x: 0.09548090245574713, G_fool_loss: 0.013771112030372023, cycled_x_loss: 0.0890884954109788, D_X_loss: 0.2927211970090866\n",
      "[82:800] loss_idt_y: 0.0653947689011693, F_fool_loss: 0.013692959463223815, cycled_y_loss: 0.06547447681427002, D_Y_loss: 0.2923507922887802\n",
      "[82:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:900] Took 12.88s\n",
      "[82:900] loss_idt_x: 0.10981329843401909, G_fool_loss: 0.013789832917973399, cycled_x_loss: 0.1054902844130993, D_X_loss: 0.29105591535568237\n",
      "[82:900] loss_idt_y: 0.08048431381583214, F_fool_loss: 0.013885770812630654, cycled_y_loss: 0.07977632207795977, D_Y_loss: 0.2917502173781395\n",
      "[82:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:1000] Took 12.87s\n",
      "[82:1000] loss_idt_x: 0.09985907085239887, G_fool_loss: 0.013747764779254793, cycled_x_loss: 0.09566270772367716, D_X_loss: 0.29247692435979844\n",
      "[82:1000] loss_idt_y: 0.06203308558091521, F_fool_loss: 0.013595995688810945, cycled_y_loss: 0.06545965358614922, D_Y_loss: 0.291395982503891\n",
      "[82:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:1100] Took 12.87s\n",
      "[82:1100] loss_idt_x: 0.09431342847645283, G_fool_loss: 0.013906017420813441, cycled_x_loss: 0.09165393438190222, D_X_loss: 0.2916644164919853\n",
      "[82:1100] loss_idt_y: 0.07238852016627789, F_fool_loss: 0.013719461346045136, cycled_y_loss: 0.07446514002978802, D_Y_loss: 0.2935331204533577\n",
      "[82:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[82:END] Completed epoch in 172.57420587539673s\n",
      "[82:1199] ep_loss_idt_x: 0.103 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.098 ep_D_X_loss: 0.293\n",
      "[82:1199] ep_loss_idt_y: 0.069 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.070 ep_D_Y_loss: 0.292\n",
      "[82:END] Completed eval in 1.8989264965057373s\n",
      "Updated G_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated F_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated D_X_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated D_Y_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "[82:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[83:100] Took 14.84s\n",
      "[83:100] loss_idt_x: 0.085085046030581, G_fool_loss: 0.013782488955184817, cycled_x_loss: 0.08304734028875828, D_X_loss: 0.2949442705512047\n",
      "[83:100] loss_idt_y: 0.07201422654092311, F_fool_loss: 0.014007360665127635, cycled_y_loss: 0.06745210129767656, D_Y_loss: 0.294955361187458\n",
      "[83:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:200] Took 12.87s\n",
      "[83:200] loss_idt_x: 0.11119321957230568, G_fool_loss: 0.013807029239833355, cycled_x_loss: 0.10593235962092877, D_X_loss: 0.2917727100849152\n",
      "[83:200] loss_idt_y: 0.07907206868752838, F_fool_loss: 0.013935228791087866, cycled_y_loss: 0.07929500414058566, D_Y_loss: 0.2907735627889633\n",
      "[83:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:300] Took 12.88s\n",
      "[83:300] loss_idt_x: 0.10241712827235461, G_fool_loss: 0.013408629931509495, cycled_x_loss: 0.09289892625063657, D_X_loss: 0.29144599676132205\n",
      "[83:300] loss_idt_y: 0.07263049457222223, F_fool_loss: 0.013728619255125522, cycled_y_loss: 0.07532995827496052, D_Y_loss: 0.29307165026664733\n",
      "[83:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:400] Took 12.86s\n",
      "[83:400] loss_idt_x: 0.10657785788178444, G_fool_loss: 0.013792586168274284, cycled_x_loss: 0.10082719366997481, D_X_loss: 0.2924585834145546\n",
      "[83:400] loss_idt_y: 0.06104009602218866, F_fool_loss: 0.013705385839566589, cycled_y_loss: 0.062122485488653185, D_Y_loss: 0.29278173387050627\n",
      "[83:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:500] Took 12.89s\n",
      "[83:500] loss_idt_x: 0.09721558142453432, G_fool_loss: 0.013560346923768521, cycled_x_loss: 0.09286547988653183, D_X_loss: 0.29237998425960543\n",
      "[83:500] loss_idt_y: 0.0707353268750012, F_fool_loss: 0.013874912625178695, cycled_y_loss: 0.06885001759976149, D_Y_loss: 0.2934951823949814\n",
      "[83:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:600] Took 12.88s\n",
      "[83:600] loss_idt_x: 0.1004352005943656, G_fool_loss: 0.013838254325091838, cycled_x_loss: 0.09670983131974936, D_X_loss: 0.2932430797815323\n",
      "[83:600] loss_idt_y: 0.06772549826651812, F_fool_loss: 0.0137582350615412, cycled_y_loss: 0.06755479071289301, D_Y_loss: 0.29285052090883257\n",
      "[83:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:700] Took 12.88s\n",
      "[83:700] loss_idt_x: 0.1022372767329216, G_fool_loss: 0.013751759743317962, cycled_x_loss: 0.09296563062816858, D_X_loss: 0.2938673251867294\n",
      "[83:700] loss_idt_y: 0.06678527437150478, F_fool_loss: 0.013686559516936541, cycled_y_loss: 0.06700958531349897, D_Y_loss: 0.2927682507038116\n",
      "[83:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:800] Took 12.87s\n",
      "[83:800] loss_idt_x: 0.09961986795067787, G_fool_loss: 0.013790490115061402, cycled_x_loss: 0.09050581146031618, D_X_loss: 0.2924562421441078\n",
      "[83:800] loss_idt_y: 0.07067668849602342, F_fool_loss: 0.013873964436352254, cycled_y_loss: 0.07145223252475262, D_Y_loss: 0.2925080859661102\n",
      "[83:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:900] Took 12.88s\n",
      "[83:900] loss_idt_x: 0.09175575774163008, G_fool_loss: 0.013635695278644562, cycled_x_loss: 0.08399430360645056, D_X_loss: 0.29217838138341906\n",
      "[83:900] loss_idt_y: 0.07300423789769411, F_fool_loss: 0.01377013662829995, cycled_y_loss: 0.07012437548488379, D_Y_loss: 0.2919751191139221\n",
      "[83:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:1000] Took 12.88s\n",
      "[83:1000] loss_idt_x: 0.10165791139006615, G_fool_loss: 0.013638777351006865, cycled_x_loss: 0.09784623011946678, D_X_loss: 0.29020177900791166\n",
      "[83:1000] loss_idt_y: 0.0638089682534337, F_fool_loss: 0.01385053708218038, cycled_y_loss: 0.06271392030641437, D_Y_loss: 0.2919345277547836\n",
      "[83:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:1100] Took 12.87s\n",
      "[83:1100] loss_idt_x: 0.09529246784746646, G_fool_loss: 0.0138132709171623, cycled_x_loss: 0.09742629937827588, D_X_loss: 0.2921957066655159\n",
      "[83:1100] loss_idt_y: 0.07017745247110724, F_fool_loss: 0.013754998669028282, cycled_y_loss: 0.07333473142236471, D_Y_loss: 0.29334776669740675\n",
      "[83:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[83:END] Completed epoch in 172.64384722709656s\n",
      "[83:1199] ep_loss_idt_x: 0.099 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.094 ep_D_X_loss: 0.292\n",
      "[83:1199] ep_loss_idt_y: 0.070 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.070 ep_D_Y_loss: 0.293\n",
      "[83:END] Completed eval in 1.8161461353302002s\n",
      "Updated G_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated F_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated D_X_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated D_Y_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "[83:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[84:100] Took 14.81s\n",
      "[84:100] loss_idt_x: 0.10226955838501453, G_fool_loss: 0.01404893457889557, cycled_x_loss: 0.09642154980450869, D_X_loss: 0.2957300314307213\n",
      "[84:100] loss_idt_y: 0.06651784896850586, F_fool_loss: 0.013807523027062417, cycled_y_loss: 0.06696266211569309, D_Y_loss: 0.2946559923887253\n",
      "[84:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:200] Took 12.86s\n",
      "[84:200] loss_idt_x: 0.09512083541601896, G_fool_loss: 0.013844440495595335, cycled_x_loss: 0.08881422095000743, D_X_loss: 0.29398573815822604\n",
      "[84:200] loss_idt_y: 0.07273156883195042, F_fool_loss: 0.013703096583485603, cycled_y_loss: 0.0707552532106638, D_Y_loss: 0.29262945026159287\n",
      "[84:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:300] Took 12.88s\n",
      "[84:300] loss_idt_x: 0.10544796500355005, G_fool_loss: 0.013828230863437057, cycled_x_loss: 0.10023811031132937, D_X_loss: 0.29061332941055296\n",
      "[84:300] loss_idt_y: 0.06633066210895777, F_fool_loss: 0.013729008007794618, cycled_y_loss: 0.06501599717885256, D_Y_loss: 0.2912843286991119\n",
      "[84:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:400] Took 12.88s\n",
      "[84:400] loss_idt_x: 0.09864441007375717, G_fool_loss: 0.013634100565686822, cycled_x_loss: 0.09525872569531202, D_X_loss: 0.2911586233973503\n",
      "[84:400] loss_idt_y: 0.06135164115577936, F_fool_loss: 0.013776367157697677, cycled_y_loss: 0.06040563203394413, D_Y_loss: 0.2919634214043617\n",
      "[84:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:500] Took 12.87s\n",
      "[84:500] loss_idt_x: 0.09187446314841509, G_fool_loss: 0.01367637344636023, cycled_x_loss: 0.08818451143801212, D_X_loss: 0.2919383516907692\n",
      "[84:500] loss_idt_y: 0.06167970843613148, F_fool_loss: 0.013792144767940044, cycled_y_loss: 0.0648875392600894, D_Y_loss: 0.2927896323800087\n",
      "[84:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:600] Took 12.88s\n",
      "[84:600] loss_idt_x: 0.10257078792899847, G_fool_loss: 0.013779920898377896, cycled_x_loss: 0.09433152101933956, D_X_loss: 0.29295589208602907\n",
      "[84:600] loss_idt_y: 0.069799486361444, F_fool_loss: 0.01368105418048799, cycled_y_loss: 0.06786307822912932, D_Y_loss: 0.29222788602113725\n",
      "[84:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:700] Took 12.88s\n",
      "[84:700] loss_idt_x: 0.08938930083066225, G_fool_loss: 0.013642458096146583, cycled_x_loss: 0.08232244405895471, D_X_loss: 0.2913283637166023\n",
      "[84:700] loss_idt_y: 0.062319729682058095, F_fool_loss: 0.013775705508887768, cycled_y_loss: 0.06190079929307103, D_Y_loss: 0.2917524981498718\n",
      "[84:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:800] Took 12.88s\n",
      "[84:800] loss_idt_x: 0.10355218701064586, G_fool_loss: 0.013717180294916033, cycled_x_loss: 0.09685861136764289, D_X_loss: 0.29187520474195483\n",
      "[84:800] loss_idt_y: 0.06756858069449663, F_fool_loss: 0.013783842520788313, cycled_y_loss: 0.06611857099458575, D_Y_loss: 0.29177943646907806\n",
      "[84:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:900] Took 12.90s\n",
      "[84:900] loss_idt_x: 0.10156286306679249, G_fool_loss: 0.013624572781845928, cycled_x_loss: 0.09701797287911176, D_X_loss: 0.2928620964288712\n",
      "[84:900] loss_idt_y: 0.0627909218147397, F_fool_loss: 0.013552532941102981, cycled_y_loss: 0.06766165195032954, D_Y_loss: 0.29193855047225953\n",
      "[84:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:1000] Took 12.88s\n",
      "[84:1000] loss_idt_x: 0.1056475504860282, G_fool_loss: 0.013602066356688737, cycled_x_loss: 0.09296523444354535, D_X_loss: 0.2915098011493683\n",
      "[84:1000] loss_idt_y: 0.0700217381119728, F_fool_loss: 0.013763573979958891, cycled_y_loss: 0.07060757415369152, D_Y_loss: 0.290376700758934\n",
      "[84:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:1100] Took 12.88s\n",
      "[84:1100] loss_idt_x: 0.1000200829282403, G_fool_loss: 0.013800149448215962, cycled_x_loss: 0.09454998645931482, D_X_loss: 0.29121273159980776\n",
      "[84:1100] loss_idt_y: 0.05991792246699333, F_fool_loss: 0.01369496688246727, cycled_y_loss: 0.06244049103930593, D_Y_loss: 0.29254485815763476\n",
      "[84:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[84:END] Completed epoch in 172.7422914505005s\n",
      "[84:1199] ep_loss_idt_x: 0.099 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.093 ep_D_X_loss: 0.292\n",
      "[84:1199] ep_loss_idt_y: 0.066 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.066 ep_D_Y_loss: 0.292\n",
      "[84:END] Completed eval in 1.8091692924499512s\n",
      "Updated G_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated F_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated D_X_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated D_Y_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "[84:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[85:100] Took 14.80s\n",
      "[85:100] loss_idt_x: 0.09869984421879054, G_fool_loss: 0.013940047221258283, cycled_x_loss: 0.09041047912091017, D_X_loss: 0.2953789609670639\n",
      "[85:100] loss_idt_y: 0.0750242479518056, F_fool_loss: 0.013904602555558086, cycled_y_loss: 0.07077265042811633, D_Y_loss: 0.29418161064386367\n",
      "[85:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:200] Took 12.87s\n",
      "[85:200] loss_idt_x: 0.08695313243195414, G_fool_loss: 0.013702974384650589, cycled_x_loss: 0.08592236619442702, D_X_loss: 0.29192140728235244\n",
      "[85:200] loss_idt_y: 0.06578542565926909, F_fool_loss: 0.013741141287609934, cycled_y_loss: 0.06301412757486105, D_Y_loss: 0.29151139736175535\n",
      "[85:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:300] Took 12.87s\n",
      "[85:300] loss_idt_x: 0.0909737160615623, G_fool_loss: 0.013744550375267863, cycled_x_loss: 0.0899350130930543, D_X_loss: 0.29241150557994844\n",
      "[85:300] loss_idt_y: 0.06511883731931448, F_fool_loss: 0.013811249630525707, cycled_y_loss: 0.06539564669132232, D_Y_loss: 0.29269913405179976\n",
      "[85:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:400] Took 12.88s\n",
      "[85:400] loss_idt_x: 0.09413046984001994, G_fool_loss: 0.013712976155802607, cycled_x_loss: 0.08583726374432445, D_X_loss: 0.2918553501367569\n",
      "[85:400] loss_idt_y: 0.06867609173059464, F_fool_loss: 0.013602643813937903, cycled_y_loss: 0.06792551651597023, D_Y_loss: 0.29272411614656446\n",
      "[85:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:500] Took 12.88s\n",
      "[85:500] loss_idt_x: 0.09633206952363253, G_fool_loss: 0.013673889730125666, cycled_x_loss: 0.09238522868603467, D_X_loss: 0.2933571752905846\n",
      "[85:500] loss_idt_y: 0.05781426263973117, F_fool_loss: 0.013726070914417505, cycled_y_loss: 0.05950998105108738, D_Y_loss: 0.29221491307020186\n",
      "[85:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:600] Took 12.88s\n",
      "[85:600] loss_idt_x: 0.08717343423515558, G_fool_loss: 0.013623076686635614, cycled_x_loss: 0.08187317188829184, D_X_loss: 0.2927039179205895\n",
      "[85:600] loss_idt_y: 0.06564099989831447, F_fool_loss: 0.01363898633979261, cycled_y_loss: 0.06568637564778328, D_Y_loss: 0.2927347764372826\n",
      "[85:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:700] Took 12.88s\n",
      "[85:700] loss_idt_x: 0.0852726524323225, G_fool_loss: 0.013750367350876331, cycled_x_loss: 0.08370894655585288, D_X_loss: 0.29282508343458175\n",
      "[85:700] loss_idt_y: 0.06797468284144997, F_fool_loss: 0.013800925891846418, cycled_y_loss: 0.0683710840716958, D_Y_loss: 0.29167495012283323\n",
      "[85:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:800] Took 12.87s\n",
      "[85:800] loss_idt_x: 0.10195020988583564, G_fool_loss: 0.013649313217028976, cycled_x_loss: 0.09593883629888296, D_X_loss: 0.29142564088106154\n",
      "[85:800] loss_idt_y: 0.06731881959363818, F_fool_loss: 0.013731993297114968, cycled_y_loss: 0.06603366099298, D_Y_loss: 0.2925575265288353\n",
      "[85:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:900] Took 12.87s\n",
      "[85:900] loss_idt_x: 0.10565528515726327, G_fool_loss: 0.013868473991751671, cycled_x_loss: 0.09857092387974262, D_X_loss: 0.29097712963819505\n",
      "[85:900] loss_idt_y: 0.06022415652871132, F_fool_loss: 0.013713858509436249, cycled_y_loss: 0.05965739557519555, D_Y_loss: 0.2919599315524101\n",
      "[85:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:1000] Took 12.86s\n",
      "[85:1000] loss_idt_x: 0.10484322417527438, G_fool_loss: 0.013807876855134965, cycled_x_loss: 0.09595490276813506, D_X_loss: 0.29276584446430204\n",
      "[85:1000] loss_idt_y: 0.06289867792278528, F_fool_loss: 0.01378842036239803, cycled_y_loss: 0.06636507861316204, D_Y_loss: 0.2924622413516045\n",
      "[85:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:1100] Took 12.86s\n",
      "[85:1100] loss_idt_x: 0.09640420213341713, G_fool_loss: 0.013579519307240844, cycled_x_loss: 0.08972748633474112, D_X_loss: 0.2917079594731331\n",
      "[85:1100] loss_idt_y: 0.06479483261704445, F_fool_loss: 0.013645796496421099, cycled_y_loss: 0.06581509059295058, D_Y_loss: 0.292835998237133\n",
      "[85:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[85:END] Completed epoch in 173.6028277873993s\n",
      "[85:1199] ep_loss_idt_x: 0.095 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.090 ep_D_X_loss: 0.292\n",
      "[85:1199] ep_loss_idt_y: 0.066 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.066 ep_D_Y_loss: 0.292\n",
      "[85:END] Completed eval in 1.8041787147521973s\n",
      "Updated G_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated F_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated D_X_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated D_Y_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "[85:END] Saving models and training information permanently\n",
      "[86:100] Took 14.81s\n",
      "[86:100] loss_idt_x: 0.09551755722612143, G_fool_loss: 0.013868439076468349, cycled_x_loss: 0.09243370320647955, D_X_loss: 0.29601938009262085\n",
      "[86:100] loss_idt_y: 0.06630220755934715, F_fool_loss: 0.01391200253739953, cycled_y_loss: 0.064735939912498, D_Y_loss: 0.2954298436641693\n",
      "[86:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:200] Took 12.89s\n",
      "[86:200] loss_idt_x: 0.09213746417313814, G_fool_loss: 0.013744657402858138, cycled_x_loss: 0.08956467751413584, D_X_loss: 0.29266438573598863\n",
      "[86:200] loss_idt_y: 0.06878297226503491, F_fool_loss: 0.013689141813665628, cycled_y_loss: 0.06911919156089424, D_Y_loss: 0.2931124025583267\n",
      "[86:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:300] Took 12.87s\n",
      "[86:300] loss_idt_x: 0.0987915725633502, G_fool_loss: 0.013623808966949582, cycled_x_loss: 0.09138375632464886, D_X_loss: 0.2912050649523735\n",
      "[86:300] loss_idt_y: 0.06795398516580463, F_fool_loss: 0.013681941973045468, cycled_y_loss: 0.06466950517147779, D_Y_loss: 0.29051390796899795\n",
      "[86:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:400] Took 12.87s\n",
      "[86:400] loss_idt_x: 0.10008466441184283, G_fool_loss: 0.013424225682392717, cycled_x_loss: 0.09313588757067918, D_X_loss: 0.29248629331588744\n",
      "[86:400] loss_idt_y: 0.0655201374180615, F_fool_loss: 0.013626437839120627, cycled_y_loss: 0.06717442872002721, D_Y_loss: 0.290475449860096\n",
      "[86:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:500] Took 12.88s\n",
      "[86:500] loss_idt_x: 0.09402089055627584, G_fool_loss: 0.013528728429228067, cycled_x_loss: 0.08603907383978367, D_X_loss: 0.29111410975456237\n",
      "[86:500] loss_idt_y: 0.06335976593196392, F_fool_loss: 0.013560105618089437, cycled_y_loss: 0.06151036297902465, D_Y_loss: 0.2915118330717087\n",
      "[86:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:600] Took 12.87s\n",
      "[86:600] loss_idt_x: 0.10675084929913282, G_fool_loss: 0.013548842407763004, cycled_x_loss: 0.09996402917429804, D_X_loss: 0.29230276972055436\n",
      "[86:600] loss_idt_y: 0.05334707824513316, F_fool_loss: 0.01373214258812368, cycled_y_loss: 0.05477145606651902, D_Y_loss: 0.2927656337618828\n",
      "[86:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:700] Took 12.86s\n",
      "[86:700] loss_idt_x: 0.09003191521391272, G_fool_loss: 0.013603923050686717, cycled_x_loss: 0.0847099695727229, D_X_loss: 0.29063380032777786\n",
      "[86:700] loss_idt_y: 0.06191096628084779, F_fool_loss: 0.01375595934689045, cycled_y_loss: 0.06270783923566342, D_Y_loss: 0.29190444260835646\n",
      "[86:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:800] Took 12.88s\n",
      "[86:800] loss_idt_x: 0.0995103362761438, G_fool_loss: 0.013794696694239973, cycled_x_loss: 0.09532457400113344, D_X_loss: 0.2920854860544205\n",
      "[86:800] loss_idt_y: 0.06515440344810486, F_fool_loss: 0.013649823945015668, cycled_y_loss: 0.0589858865737915, D_Y_loss: 0.2925438180565834\n",
      "[86:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:900] Took 12.88s\n",
      "[86:900] loss_idt_x: 0.09757534433156252, G_fool_loss: 0.01362150426954031, cycled_x_loss: 0.0925824324414134, D_X_loss: 0.2939580971002579\n",
      "[86:900] loss_idt_y: 0.06265338035300375, F_fool_loss: 0.013768077678978443, cycled_y_loss: 0.06075133498758078, D_Y_loss: 0.29158452033996585\n",
      "[86:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:1000] Took 12.89s\n",
      "[86:1000] loss_idt_x: 0.09620388992130756, G_fool_loss: 0.01376314613968134, cycled_x_loss: 0.09311068385839462, D_X_loss: 0.29302661269903185\n",
      "[86:1000] loss_idt_y: 0.06835401501506568, F_fool_loss: 0.01368346375413239, cycled_y_loss: 0.06504730917513371, D_Y_loss: 0.2921354651451111\n",
      "[86:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:1100] Took 12.87s\n",
      "[86:1100] loss_idt_x: 0.09632855247706175, G_fool_loss: 0.013850916428491473, cycled_x_loss: 0.0894409653544426, D_X_loss: 0.2918258637189865\n",
      "[86:1100] loss_idt_y: 0.06953760141506792, F_fool_loss: 0.013559898845851421, cycled_y_loss: 0.0696156900934875, D_Y_loss: 0.2920853114128113\n",
      "[86:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[86:END] Completed epoch in 173.91192865371704s\n",
      "[86:1199] ep_loss_idt_x: 0.097 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.091 ep_D_X_loss: 0.292\n",
      "[86:1199] ep_loss_idt_y: 0.065 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.064 ep_D_Y_loss: 0.292\n",
      "[86:END] Completed eval in 1.826111078262329s\n",
      "Updated G_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated F_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated D_X_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated D_Y_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "[86:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[87:100] Took 14.84s\n",
      "[87:100] loss_idt_x: 0.08995074808597564, G_fool_loss: 0.013780117183923721, cycled_x_loss: 0.08396739613264799, D_X_loss: 0.29502583026885987\n",
      "[87:100] loss_idt_y: 0.05991254732012749, F_fool_loss: 0.013918235013261438, cycled_y_loss: 0.060446970127522946, D_Y_loss: 0.29605888038873673\n",
      "[87:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:200] Took 12.88s\n",
      "[87:200] loss_idt_x: 0.11177252069115638, G_fool_loss: 0.013565585240721703, cycled_x_loss: 0.10017309553921222, D_X_loss: 0.291220860183239\n",
      "[87:200] loss_idt_y: 0.06380886470898986, F_fool_loss: 0.013486222010105848, cycled_y_loss: 0.06624397600069643, D_Y_loss: 0.29112589955329893\n",
      "[87:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:300] Took 12.88s\n",
      "[87:300] loss_idt_x: 0.0853630319237709, G_fool_loss: 0.013795678773894905, cycled_x_loss: 0.08563217494636774, D_X_loss: 0.2930746003985405\n",
      "[87:300] loss_idt_y: 0.05761130394414067, F_fool_loss: 0.013863811558112503, cycled_y_loss: 0.0602312371134758, D_Y_loss: 0.2925929254293442\n",
      "[87:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:400] Took 12.87s\n",
      "[87:400] loss_idt_x: 0.11034988876432181, G_fool_loss: 0.013744238121435047, cycled_x_loss: 0.10141822231933474, D_X_loss: 0.29365292817354205\n",
      "[87:400] loss_idt_y: 0.06868372984230518, F_fool_loss: 0.013651375025510788, cycled_y_loss: 0.06659054527059198, D_Y_loss: 0.2928213205933571\n",
      "[87:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:500] Took 12.87s\n",
      "[87:500] loss_idt_x: 0.09420178148895503, G_fool_loss: 0.013670449033379556, cycled_x_loss: 0.09407872751355172, D_X_loss: 0.2928043881058693\n",
      "[87:500] loss_idt_y: 0.06646078938618302, F_fool_loss: 0.013674886878579855, cycled_y_loss: 0.06658902637660503, D_Y_loss: 0.29153018981218337\n",
      "[87:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:600] Took 12.87s\n",
      "[87:600] loss_idt_x: 0.11327231768518686, G_fool_loss: 0.01362068091519177, cycled_x_loss: 0.10456017337739468, D_X_loss: 0.2914936575293541\n",
      "[87:600] loss_idt_y: 0.061678562350571155, F_fool_loss: 0.013785162847489119, cycled_y_loss: 0.06321620503440499, D_Y_loss: 0.2915663096308708\n",
      "[87:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:700] Took 12.88s\n",
      "[87:700] loss_idt_x: 0.0900561372935772, G_fool_loss: 0.013637147136032582, cycled_x_loss: 0.08532088078558445, D_X_loss: 0.2917865887284279\n",
      "[87:700] loss_idt_y: 0.07393781529739499, F_fool_loss: 0.013756236964836717, cycled_y_loss: 0.07122740112245082, D_Y_loss: 0.29301205098628996\n",
      "[87:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:800] Took 12.87s\n",
      "[87:800] loss_idt_x: 0.0961185746267438, G_fool_loss: 0.013535926006734372, cycled_x_loss: 0.0898914898186922, D_X_loss: 0.2918220841884613\n",
      "[87:800] loss_idt_y: 0.06642970832064748, F_fool_loss: 0.01361057322472334, cycled_y_loss: 0.06715879248455167, D_Y_loss: 0.2911196956038475\n",
      "[87:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:900] Took 12.87s\n",
      "[87:900] loss_idt_x: 0.0902580464631319, G_fool_loss: 0.01363178919069469, cycled_x_loss: 0.08238453336060048, D_X_loss: 0.2909663432836533\n",
      "[87:900] loss_idt_y: 0.067722420822829, F_fool_loss: 0.013738029720261693, cycled_y_loss: 0.06859509591013194, D_Y_loss: 0.2917299926280975\n",
      "[87:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:1000] Took 12.86s\n",
      "[87:1000] loss_idt_x: 0.0911464273929596, G_fool_loss: 0.013683545459061862, cycled_x_loss: 0.08517909578979016, D_X_loss: 0.29382560700178145\n",
      "[87:1000] loss_idt_y: 0.06097876058891415, F_fool_loss: 0.013631567088887096, cycled_y_loss: 0.0630272107757628, D_Y_loss: 0.2929177466034889\n",
      "[87:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:1100] Took 12.86s\n",
      "[87:1100] loss_idt_x: 0.09951245225965977, G_fool_loss: 0.013622950101271271, cycled_x_loss: 0.08883625898510218, D_X_loss: 0.2922213405370712\n",
      "[87:1100] loss_idt_y: 0.06718107648193836, F_fool_loss: 0.0135240576043725, cycled_y_loss: 0.07075974248349666, D_Y_loss: 0.2926833590865135\n",
      "[87:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[87:END] Completed epoch in 172.6083528995514s\n",
      "[87:1199] ep_loss_idt_x: 0.097 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.091 ep_D_X_loss: 0.292\n",
      "[87:1199] ep_loss_idt_y: 0.065 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.066 ep_D_Y_loss: 0.292\n",
      "[87:END] Completed eval in 2.0126492977142334s\n",
      "Updated G_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated F_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated D_X_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated D_Y_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "[87:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[88:100] Took 14.82s\n",
      "[88:100] loss_idt_x: 0.09142845433205365, G_fool_loss: 0.01367136336863041, cycled_x_loss: 0.08441222354769706, D_X_loss: 0.29257102370262145\n",
      "[88:100] loss_idt_y: 0.07397345954552292, F_fool_loss: 0.013729469906538725, cycled_y_loss: 0.0729436239413917, D_Y_loss: 0.2937513342499733\n",
      "[88:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:200] Took 12.85s\n",
      "[88:200] loss_idt_x: 0.10859860127791762, G_fool_loss: 0.013665080610662699, cycled_x_loss: 0.1002119406685233, D_X_loss: 0.290896677672863\n",
      "[88:200] loss_idt_y: 0.059582431111484764, F_fool_loss: 0.013691792031750083, cycled_y_loss: 0.059138740859925744, D_Y_loss: 0.29158291429281236\n",
      "[88:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:300] Took 12.86s\n",
      "[88:300] loss_idt_x: 0.09822799544781446, G_fool_loss: 0.013557599540799856, cycled_x_loss: 0.09547579940408468, D_X_loss: 0.29151899546384813\n",
      "[88:300] loss_idt_y: 0.06123002629727125, F_fool_loss: 0.013803427712991834, cycled_y_loss: 0.06114047950133681, D_Y_loss: 0.2917917588353157\n",
      "[88:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:400] Took 12.86s\n",
      "[88:400] loss_idt_x: 0.10001055128872395, G_fool_loss: 0.013694006437435745, cycled_x_loss: 0.0958745389431715, D_X_loss: 0.292663736641407\n",
      "[88:400] loss_idt_y: 0.06909924572333694, F_fool_loss: 0.013611477138474583, cycled_y_loss: 0.0711425288580358, D_Y_loss: 0.2914990711212158\n",
      "[88:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:500] Took 12.86s\n",
      "[88:500] loss_idt_x: 0.09009756769984961, G_fool_loss: 0.0137017070222646, cycled_x_loss: 0.08950291734188795, D_X_loss: 0.2917808750271797\n",
      "[88:500] loss_idt_y: 0.06486532995477319, F_fool_loss: 0.01361918351612985, cycled_y_loss: 0.06597430163994432, D_Y_loss: 0.2922351562976837\n",
      "[88:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:600] Took 12.87s\n",
      "[88:600] loss_idt_x: 0.09295618709176778, G_fool_loss: 0.013587313313037157, cycled_x_loss: 0.09057509083300828, D_X_loss: 0.29261341601610186\n",
      "[88:600] loss_idt_y: 0.06523385716602206, F_fool_loss: 0.013582828277722002, cycled_y_loss: 0.06336225088685751, D_Y_loss: 0.29183402508497236\n",
      "[88:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:700] Took 12.87s\n",
      "[88:700] loss_idt_x: 0.09761602763086558, G_fool_loss: 0.013607260631397366, cycled_x_loss: 0.09076965492218733, D_X_loss: 0.2916195124387741\n",
      "[88:700] loss_idt_y: 0.06032052045688033, F_fool_loss: 0.013604783862829208, cycled_y_loss: 0.06235288007184863, D_Y_loss: 0.290936144888401\n",
      "[88:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:800] Took 12.86s\n",
      "[88:800] loss_idt_x: 0.09319561932235956, G_fool_loss: 0.013726082006469369, cycled_x_loss: 0.08536123115569354, D_X_loss: 0.2915117877721787\n",
      "[88:800] loss_idt_y: 0.062173628471791746, F_fool_loss: 0.013641913328319788, cycled_y_loss: 0.06131527483463287, D_Y_loss: 0.29256617069244384\n",
      "[88:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:900] Took 12.86s\n",
      "[88:900] loss_idt_x: 0.10214588895440102, G_fool_loss: 0.013538492787629365, cycled_x_loss: 0.09706863339990378, D_X_loss: 0.29194454312324525\n",
      "[88:900] loss_idt_y: 0.06879416216164827, F_fool_loss: 0.013645886881276966, cycled_y_loss: 0.07074281916022301, D_Y_loss: 0.29257741063833237\n",
      "[88:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:1000] Took 12.87s\n",
      "[88:1000] loss_idt_x: 0.09753365628421307, G_fool_loss: 0.013746386161074042, cycled_x_loss: 0.09285277996212243, D_X_loss: 0.29296404629945755\n",
      "[88:1000] loss_idt_y: 0.06472263252362609, F_fool_loss: 0.013653289154171943, cycled_y_loss: 0.06349538322538137, D_Y_loss: 0.29153695166110993\n",
      "[88:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:1100] Took 12.87s\n",
      "[88:1100] loss_idt_x: 0.09724991681054235, G_fool_loss: 0.013635708121582865, cycled_x_loss: 0.09193190593272448, D_X_loss: 0.291409792304039\n",
      "[88:1100] loss_idt_y: 0.07238772237673402, F_fool_loss: 0.01355787287466228, cycled_y_loss: 0.07423384077847003, D_Y_loss: 0.2903447952866554\n",
      "[88:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[88:END] Completed epoch in 170.98868036270142s\n",
      "[88:1199] ep_loss_idt_x: 0.098 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.093 ep_D_X_loss: 0.292\n",
      "[88:1199] ep_loss_idt_y: 0.065 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.066 ep_D_Y_loss: 0.292\n",
      "[88:END] Completed eval in 1.8570661544799805s\n",
      "Updated G_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated F_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated D_X_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated D_Y_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "[88:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[89:100] Took 14.83s\n",
      "[89:100] loss_idt_x: 0.0942279439792037, G_fool_loss: 0.01380922731012106, cycled_x_loss: 0.09214120354503393, D_X_loss: 0.2963519430160522\n",
      "[89:100] loss_idt_y: 0.06339428188279271, F_fool_loss: 0.013698467928916215, cycled_y_loss: 0.06343294981867074, D_Y_loss: 0.29498942524194716\n",
      "[89:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:200] Took 12.85s\n",
      "[89:200] loss_idt_x: 0.09049844870343804, G_fool_loss: 0.013722872100770474, cycled_x_loss: 0.08594019092619419, D_X_loss: 0.2914241600036621\n",
      "[89:200] loss_idt_y: 0.06603520095348359, F_fool_loss: 0.01373623587191105, cycled_y_loss: 0.06391198489814996, D_Y_loss: 0.29142860770225526\n",
      "[89:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:300] Took 12.86s\n",
      "[89:300] loss_idt_x: 0.08902617525309324, G_fool_loss: 0.013616053033620118, cycled_x_loss: 0.08504703950136899, D_X_loss: 0.291722746193409\n",
      "[89:300] loss_idt_y: 0.06063452653586864, F_fool_loss: 0.013564737820997834, cycled_y_loss: 0.06111330954357982, D_Y_loss: 0.29291252881288526\n",
      "[89:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:400] Took 12.86s\n",
      "[89:400] loss_idt_x: 0.09375033868476748, G_fool_loss: 0.013746860353276134, cycled_x_loss: 0.088329644985497, D_X_loss: 0.29092887371778486\n",
      "[89:400] loss_idt_y: 0.0684994762763381, F_fool_loss: 0.013625598968937993, cycled_y_loss: 0.06959382295608521, D_Y_loss: 0.2937124940752983\n",
      "[89:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:500] Took 12.87s\n",
      "[89:500] loss_idt_x: 0.10023388026282191, G_fool_loss: 0.013539291666820646, cycled_x_loss: 0.09594605349004269, D_X_loss: 0.2918936213850975\n",
      "[89:500] loss_idt_y: 0.06347774218767882, F_fool_loss: 0.013490952923893929, cycled_y_loss: 0.06526774110272526, D_Y_loss: 0.2919719195365906\n",
      "[89:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:600] Took 12.85s\n",
      "[89:600] loss_idt_x: 0.0967554597556591, G_fool_loss: 0.013547024130821228, cycled_x_loss: 0.09041144493967294, D_X_loss: 0.2919436505436897\n",
      "[89:600] loss_idt_y: 0.059852258041501044, F_fool_loss: 0.013582305163145065, cycled_y_loss: 0.06286576041951776, D_Y_loss: 0.29244752883911135\n",
      "[89:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:700] Took 12.88s\n",
      "[89:700] loss_idt_x: 0.09200031263753772, G_fool_loss: 0.013635035175830125, cycled_x_loss: 0.09133894771337508, D_X_loss: 0.29301492393016815\n",
      "[89:700] loss_idt_y: 0.08166743146255612, F_fool_loss: 0.01371118625625968, cycled_y_loss: 0.07518551429733634, D_Y_loss: 0.29100721925497053\n",
      "[89:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:800] Took 12.85s\n",
      "[89:800] loss_idt_x: 0.10422928025946021, G_fool_loss: 0.013817468220368027, cycled_x_loss: 0.09802809476852417, D_X_loss: 0.2913612073659897\n",
      "[89:800] loss_idt_y: 0.05799800157546997, F_fool_loss: 0.01365523213520646, cycled_y_loss: 0.0581447815336287, D_Y_loss: 0.2919550177454948\n",
      "[89:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:900] Took 12.86s\n",
      "[89:900] loss_idt_x: 0.09025510860607028, G_fool_loss: 0.013698812201619148, cycled_x_loss: 0.08524706777185202, D_X_loss: 0.29094935148954393\n",
      "[89:900] loss_idt_y: 0.08144334867596627, F_fool_loss: 0.013641338823363184, cycled_y_loss: 0.07845257567241788, D_Y_loss: 0.29146278828382494\n",
      "[89:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:1000] Took 12.86s\n",
      "[89:1000] loss_idt_x: 0.10707810336723923, G_fool_loss: 0.013710181266069411, cycled_x_loss: 0.0975964354723692, D_X_loss: 0.29179019510746\n",
      "[89:1000] loss_idt_y: 0.0613721077889204, F_fool_loss: 0.013631777204573155, cycled_y_loss: 0.05852485196664929, D_Y_loss: 0.2913241696357727\n",
      "[89:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:1100] Took 12.85s\n",
      "[89:1100] loss_idt_x: 0.09708602204918862, G_fool_loss: 0.013580326158553362, cycled_x_loss: 0.09238425018265843, D_X_loss: 0.2912715059518814\n",
      "[89:1100] loss_idt_y: 0.06651987401768565, F_fool_loss: 0.013591773370280861, cycled_y_loss: 0.06429139189422131, D_Y_loss: 0.292364145219326\n",
      "[89:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[89:END] Completed epoch in 172.37808966636658s\n",
      "[89:1199] ep_loss_idt_x: 0.095 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.090 ep_D_X_loss: 0.292\n",
      "[89:1199] ep_loss_idt_y: 0.066 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.065 ep_D_Y_loss: 0.292\n",
      "[89:END] Completed eval in 2.047572612762451s\n",
      "Updated G_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated F_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated D_X_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated D_Y_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "[89:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[90:100] Took 14.83s\n",
      "[90:100] loss_idt_x: 0.09547400072216988, G_fool_loss: 0.013762533385306596, cycled_x_loss: 0.0926364405080676, D_X_loss: 0.29617299407720565\n",
      "[90:100] loss_idt_y: 0.06660988645628095, F_fool_loss: 0.013863659668713809, cycled_y_loss: 0.06848831797018647, D_Y_loss: 0.29498251080513\n",
      "[90:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:200] Took 12.85s\n",
      "[90:200] loss_idt_x: 0.10300320249050855, G_fool_loss: 0.013572221603244543, cycled_x_loss: 0.09464825924485921, D_X_loss: 0.29229574650526047\n",
      "[90:200] loss_idt_y: 0.0626009451970458, F_fool_loss: 0.01354192255064845, cycled_y_loss: 0.0654873955436051, D_Y_loss: 0.29314231425523757\n",
      "[90:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:300] Took 12.86s\n",
      "[90:300] loss_idt_x: 0.09178951568901539, G_fool_loss: 0.013416053149849177, cycled_x_loss: 0.07981030646711589, D_X_loss: 0.29239133387804034\n",
      "[90:300] loss_idt_y: 0.06696809047833086, F_fool_loss: 0.01358772998675704, cycled_y_loss: 0.06690759344026447, D_Y_loss: 0.29263878136873245\n",
      "[90:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:400] Took 12.89s\n",
      "[90:400] loss_idt_x: 0.09757326278835535, G_fool_loss: 0.013693671179935337, cycled_x_loss: 0.09119311869144439, D_X_loss: 0.29154723048210146\n",
      "[90:400] loss_idt_y: 0.057869783509522675, F_fool_loss: 0.013498055860400199, cycled_y_loss: 0.05856058247387409, D_Y_loss: 0.2940276589989662\n",
      "[90:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:500] Took 12.87s\n",
      "[90:500] loss_idt_x: 0.09803730614483357, G_fool_loss: 0.013457137979567052, cycled_x_loss: 0.09290412526577711, D_X_loss: 0.2914546346664429\n",
      "[90:500] loss_idt_y: 0.06407101839780807, F_fool_loss: 0.013667082898318767, cycled_y_loss: 0.06626141440123319, D_Y_loss: 0.29150016635656356\n",
      "[90:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:600] Took 12.86s\n",
      "[90:600] loss_idt_x: 0.10491008725017309, G_fool_loss: 0.013497948860749603, cycled_x_loss: 0.09628806535154581, D_X_loss: 0.2922555395960808\n",
      "[90:600] loss_idt_y: 0.06636518990620971, F_fool_loss: 0.01360021660104394, cycled_y_loss: 0.06694551574066282, D_Y_loss: 0.29248701423406603\n",
      "[90:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:700] Took 12.86s\n",
      "[90:700] loss_idt_x: 0.09571539718657732, G_fool_loss: 0.01349343135021627, cycled_x_loss: 0.09178148243576288, D_X_loss: 0.2920600426197052\n",
      "[90:700] loss_idt_y: 0.07122928848490119, F_fool_loss: 0.013676354503259063, cycled_y_loss: 0.07173160349950194, D_Y_loss: 0.2923120447993279\n",
      "[90:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:800] Took 12.85s\n",
      "[90:800] loss_idt_x: 0.09860493941232562, G_fool_loss: 0.01361093120649457, cycled_x_loss: 0.09509580066427588, D_X_loss: 0.29128045082092285\n",
      "[90:800] loss_idt_y: 0.0663572052679956, F_fool_loss: 0.01347939901985228, cycled_y_loss: 0.06536744991317392, D_Y_loss: 0.293027777671814\n",
      "[90:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:900] Took 12.85s\n",
      "[90:900] loss_idt_x: 0.1019832969084382, G_fool_loss: 0.013568200496956706, cycled_x_loss: 0.09559795781970024, D_X_loss: 0.29219024926424025\n",
      "[90:900] loss_idt_y: 0.06941944312304259, F_fool_loss: 0.013647787049412727, cycled_y_loss: 0.06942612119019032, D_Y_loss: 0.291564681828022\n",
      "[90:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:1000] Took 12.86s\n",
      "[90:1000] loss_idt_x: 0.10549564473330975, G_fool_loss: 0.013522748332470656, cycled_x_loss: 0.09455820795148612, D_X_loss: 0.29180746018886566\n",
      "[90:1000] loss_idt_y: 0.06903382826596499, F_fool_loss: 0.013665453754365444, cycled_y_loss: 0.0679991614446044, D_Y_loss: 0.2923614439368248\n",
      "[90:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:1100] Took 12.85s\n",
      "[90:1100] loss_idt_x: 0.0881697915121913, G_fool_loss: 0.01358924739062786, cycled_x_loss: 0.08278409436345101, D_X_loss: 0.29047620952129366\n",
      "[90:1100] loss_idt_y: 0.06602407338097692, F_fool_loss: 0.013601967804133893, cycled_y_loss: 0.06771869136020542, D_Y_loss: 0.29100695431232454\n",
      "[90:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[90:END] Completed epoch in 171.97883248329163s\n",
      "[90:1199] ep_loss_idt_x: 0.098 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.092 ep_D_X_loss: 0.292\n",
      "[90:1199] ep_loss_idt_y: 0.066 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.066 ep_D_Y_loss: 0.292\n",
      "[90:END] Completed eval in 1.8989253044128418s\n",
      "Updated G_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated F_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated D_X_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated D_Y_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "[90:END] Saving models and training information permanently\n",
      "[91:100] Took 14.86s\n",
      "[91:100] loss_idt_x: 0.08473653655499219, G_fool_loss: 0.013681889092549682, cycled_x_loss: 0.0788457103818655, D_X_loss: 0.2953602847456932\n",
      "[91:100] loss_idt_y: 0.06143277509137988, F_fool_loss: 0.013605005582794547, cycled_y_loss: 0.06306216776371003, D_Y_loss: 0.295378198325634\n",
      "[91:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:200] Took 12.86s\n",
      "[91:200] loss_idt_x: 0.1088911147415638, G_fool_loss: 0.013550469977781176, cycled_x_loss: 0.09902602508664131, D_X_loss: 0.29314859956502914\n",
      "[91:200] loss_idt_y: 0.0641305342502892, F_fool_loss: 0.013665434317663311, cycled_y_loss: 0.06295756565406918, D_Y_loss: 0.2934421291947365\n",
      "[91:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:300] Took 12.86s\n",
      "[91:300] loss_idt_x: 0.08392914030700922, G_fool_loss: 0.013439213624224067, cycled_x_loss: 0.07755065716803074, D_X_loss: 0.2926215916872025\n",
      "[91:300] loss_idt_y: 0.05816507449373603, F_fool_loss: 0.013650815421715378, cycled_y_loss: 0.058507844787091014, D_Y_loss: 0.2925965362787247\n",
      "[91:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:400] Took 12.87s\n",
      "[91:400] loss_idt_x: 0.10054022170603276, G_fool_loss: 0.013627083953469992, cycled_x_loss: 0.09312554866075516, D_X_loss: 0.2905677133798599\n",
      "[91:400] loss_idt_y: 0.06399773268029094, F_fool_loss: 0.013519520731642842, cycled_y_loss: 0.06841518623754382, D_Y_loss: 0.2904530042409897\n",
      "[91:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:500] Took 12.86s\n",
      "[91:500] loss_idt_x: 0.09987285142764449, G_fool_loss: 0.013601462002843618, cycled_x_loss: 0.09766948092728853, D_X_loss: 0.2927377605438232\n",
      "[91:500] loss_idt_y: 0.062050113417208196, F_fool_loss: 0.013522958569228648, cycled_y_loss: 0.061591274850070474, D_Y_loss: 0.29145524084568025\n",
      "[91:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:600] Took 12.86s\n",
      "[91:600] loss_idt_x: 0.09795116748660802, G_fool_loss: 0.013589700441807509, cycled_x_loss: 0.0865606403723359, D_X_loss: 0.2908474293351173\n",
      "[91:600] loss_idt_y: 0.06022943459451199, F_fool_loss: 0.013643335746601225, cycled_y_loss: 0.05987778194248676, D_Y_loss: 0.2916979798674583\n",
      "[91:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:700] Took 12.86s\n",
      "[91:700] loss_idt_x: 0.08995648115873336, G_fool_loss: 0.013560911603271962, cycled_x_loss: 0.08278648316860199, D_X_loss: 0.29033804416656495\n",
      "[91:700] loss_idt_y: 0.06803717985749244, F_fool_loss: 0.013485398599877954, cycled_y_loss: 0.0669443236105144, D_Y_loss: 0.29343903332948684\n",
      "[91:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:800] Took 12.88s\n",
      "[91:800] loss_idt_x: 0.0958246337249875, G_fool_loss: 0.01362151125445962, cycled_x_loss: 0.09199773613363504, D_X_loss: 0.29108284950256347\n",
      "[91:800] loss_idt_y: 0.06115384059026838, F_fool_loss: 0.013442333526909352, cycled_y_loss: 0.06064911166206002, D_Y_loss: 0.29201683670282363\n",
      "[91:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:900] Took 12.85s\n",
      "[91:900] loss_idt_x: 0.08968838654458523, G_fool_loss: 0.013583446480333805, cycled_x_loss: 0.08212523866444826, D_X_loss: 0.29216704815626143\n",
      "[91:900] loss_idt_y: 0.07305082160979509, F_fool_loss: 0.01355268368497491, cycled_y_loss: 0.07423758517950774, D_Y_loss: 0.2929181161522865\n",
      "[91:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:1000] Took 12.86s\n",
      "[91:1000] loss_idt_x: 0.0946407887712121, G_fool_loss: 0.01367217956110835, cycled_x_loss: 0.08741376090794802, D_X_loss: 0.2908694612979889\n",
      "[91:1000] loss_idt_y: 0.07485797448083759, F_fool_loss: 0.013683031871914863, cycled_y_loss: 0.07486887075006962, D_Y_loss: 0.2913880404829979\n",
      "[91:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:1100] Took 12.86s\n",
      "[91:1100] loss_idt_x: 0.10219527296721935, G_fool_loss: 0.013507566340267658, cycled_x_loss: 0.09681253299117089, D_X_loss: 0.2912495118379593\n",
      "[91:1100] loss_idt_y: 0.056754466239362956, F_fool_loss: 0.013508106134831905, cycled_y_loss: 0.059408169519156215, D_Y_loss: 0.2933968499302864\n",
      "[91:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[91:END] Completed epoch in 171.98588490486145s\n",
      "[91:1199] ep_loss_idt_x: 0.095 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.088 ep_D_X_loss: 0.292\n",
      "[91:1199] ep_loss_idt_y: 0.064 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.064 ep_D_Y_loss: 0.292\n",
      "[91:END] Completed eval in 1.99070405960083s\n",
      "Updated G_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated F_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated D_X_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated D_Y_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "[91:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[92:100] Took 14.83s\n",
      "[92:100] loss_idt_x: 0.0947670752927661, G_fool_loss: 0.013532867776229978, cycled_x_loss: 0.09193358618766069, D_X_loss: 0.29450601279735567\n",
      "[92:100] loss_idt_y: 0.058019428718835114, F_fool_loss: 0.01382098880596459, cycled_y_loss: 0.06121234338730574, D_Y_loss: 0.29522171527147295\n",
      "[92:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:200] Took 12.85s\n",
      "[92:200] loss_idt_x: 0.09928917560726404, G_fool_loss: 0.013597244694828987, cycled_x_loss: 0.08610341724008322, D_X_loss: 0.29264892637729645\n",
      "[92:200] loss_idt_y: 0.05838899131864309, F_fool_loss: 0.013611196111887693, cycled_y_loss: 0.05724709786474705, D_Y_loss: 0.2911060208082199\n",
      "[92:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:300] Took 12.85s\n",
      "[92:300] loss_idt_x: 0.09023355662822724, G_fool_loss: 0.013527638306841254, cycled_x_loss: 0.0856388496607542, D_X_loss: 0.2917531654238701\n",
      "[92:300] loss_idt_y: 0.06501544304192067, F_fool_loss: 0.013581333076581359, cycled_y_loss: 0.06644369948655367, D_Y_loss: 0.293355308175087\n",
      "[92:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:400] Took 12.87s\n",
      "[92:400] loss_idt_x: 0.10131130948662757, G_fool_loss: 0.013583326349034905, cycled_x_loss: 0.09539440881460905, D_X_loss: 0.2913339111208916\n",
      "[92:400] loss_idt_y: 0.06672875003889203, F_fool_loss: 0.01354504108428955, cycled_y_loss: 0.06474064763635397, D_Y_loss: 0.2914776647090912\n",
      "[92:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:500] Took 12.87s\n",
      "[92:500] loss_idt_x: 0.10808055281639099, G_fool_loss: 0.01363388117402792, cycled_x_loss: 0.10751880034804344, D_X_loss: 0.2927118998765945\n",
      "[92:500] loss_idt_y: 0.058766745030879974, F_fool_loss: 0.013645443506538868, cycled_y_loss: 0.05474159238860011, D_Y_loss: 0.29213700503110884\n",
      "[92:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:600] Took 12.87s\n",
      "[92:600] loss_idt_x: 0.09709013484418393, G_fool_loss: 0.013628844022750854, cycled_x_loss: 0.09004853382706642, D_X_loss: 0.2915072813630104\n",
      "[92:600] loss_idt_y: 0.06831171376630664, F_fool_loss: 0.013551911022514105, cycled_y_loss: 0.06603367503732444, D_Y_loss: 0.29020163774490354\n",
      "[92:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:700] Took 12.86s\n",
      "[92:700] loss_idt_x: 0.0823223622329533, G_fool_loss: 0.01356164887547493, cycled_x_loss: 0.07716290928423404, D_X_loss: 0.2928125387430191\n",
      "[92:700] loss_idt_y: 0.0724057505838573, F_fool_loss: 0.013600723100826145, cycled_y_loss: 0.06923858409747481, D_Y_loss: 0.29128767251968385\n",
      "[92:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:800] Took 12.86s\n",
      "[92:800] loss_idt_x: 0.10242280006408691, G_fool_loss: 0.013572893505916, cycled_x_loss: 0.09791947863996028, D_X_loss: 0.2926477015018463\n",
      "[92:800] loss_idt_y: 0.05821646520867944, F_fool_loss: 0.01360673103481531, cycled_y_loss: 0.058420613259077075, D_Y_loss: 0.29150603115558626\n",
      "[92:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:900] Took 12.87s\n",
      "[92:900] loss_idt_x: 0.09504563324153423, G_fool_loss: 0.013455887753516436, cycled_x_loss: 0.09063132368028164, D_X_loss: 0.29189854592084885\n",
      "[92:900] loss_idt_y: 0.056516589634120463, F_fool_loss: 0.013557296115905046, cycled_y_loss: 0.05587199030444026, D_Y_loss: 0.2905940881371498\n",
      "[92:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:1000] Took 12.87s\n",
      "[92:1000] loss_idt_x: 0.09615782175213099, G_fool_loss: 0.013681792002171279, cycled_x_loss: 0.08792718749493361, D_X_loss: 0.29121679067611694\n",
      "[92:1000] loss_idt_y: 0.0586536255478859, F_fool_loss: 0.01339184122160077, cycled_y_loss: 0.05844787878915667, D_Y_loss: 0.29234088480472564\n",
      "[92:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:1100] Took 12.86s\n",
      "[92:1100] loss_idt_x: 0.10460739769041538, G_fool_loss: 0.013524002796038985, cycled_x_loss: 0.10271316919475794, D_X_loss: 0.29185971826314927\n",
      "[92:1100] loss_idt_y: 0.06693105103448033, F_fool_loss: 0.013571096397936345, cycled_y_loss: 0.06435946576297283, D_Y_loss: 0.2919164764881134\n",
      "[92:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[92:END] Completed epoch in 171.78863334655762s\n",
      "[92:1199] ep_loss_idt_x: 0.097 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.092 ep_D_X_loss: 0.292\n",
      "[92:1199] ep_loss_idt_y: 0.063 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.061 ep_D_Y_loss: 0.292\n",
      "[92:END] Completed eval in 2.03954815864563s\n",
      "Updated G_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated F_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated D_X_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated D_Y_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "[92:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[93:100] Took 14.86s\n",
      "[93:100] loss_idt_x: 0.10579331126064062, G_fool_loss: 0.01364949146285653, cycled_x_loss: 0.09611976929008961, D_X_loss: 0.29603714287281035\n",
      "[93:100] loss_idt_y: 0.068441002946347, F_fool_loss: 0.013732751915231347, cycled_y_loss: 0.06954770600423217, D_Y_loss: 0.2937421330809593\n",
      "[93:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:200] Took 12.86s\n",
      "[93:200] loss_idt_x: 0.09459795404225588, G_fool_loss: 0.013588886372745038, cycled_x_loss: 0.08973593324422836, D_X_loss: 0.2913160634040832\n",
      "[93:200] loss_idt_y: 0.08017130259424449, F_fool_loss: 0.013436577757820487, cycled_y_loss: 0.07619859458878636, D_Y_loss: 0.29053437560796735\n",
      "[93:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:300] Took 12.86s\n",
      "[93:300] loss_idt_x: 0.09992787379771471, G_fool_loss: 0.01359347558580339, cycled_x_loss: 0.08928469438105821, D_X_loss: 0.29209836333990097\n",
      "[93:300] loss_idt_y: 0.05726252811029554, F_fool_loss: 0.01361690434627235, cycled_y_loss: 0.05654381142929196, D_Y_loss: 0.2910268408060074\n",
      "[93:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:400] Took 12.86s\n",
      "[93:400] loss_idt_x: 0.09281498853117227, G_fool_loss: 0.013659334471449257, cycled_x_loss: 0.08842529591172933, D_X_loss: 0.2926966562867165\n",
      "[93:400] loss_idt_y: 0.06910489041358232, F_fool_loss: 0.013652404816821218, cycled_y_loss: 0.06924490019679069, D_Y_loss: 0.2919085881114006\n",
      "[93:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:500] Took 12.86s\n",
      "[93:500] loss_idt_x: 0.09427918188273907, G_fool_loss: 0.013709052000194788, cycled_x_loss: 0.08769569169729947, D_X_loss: 0.29128622174263\n",
      "[93:500] loss_idt_y: 0.05895740170031786, F_fool_loss: 0.013561856681481004, cycled_y_loss: 0.057508053090423346, D_Y_loss: 0.2920758834481239\n",
      "[93:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:600] Took 12.89s\n",
      "[93:600] loss_idt_x: 0.0976141338609159, G_fool_loss: 0.013499886598438024, cycled_x_loss: 0.08690950121730566, D_X_loss: 0.29228299915790557\n",
      "[93:600] loss_idt_y: 0.06070963175967336, F_fool_loss: 0.013580447873100638, cycled_y_loss: 0.06109466649591923, D_Y_loss: 0.29108582317829135\n",
      "[93:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:700] Took 12.90s\n",
      "[93:700] loss_idt_x: 0.09273928713053464, G_fool_loss: 0.013670487804338336, cycled_x_loss: 0.08498121835291386, D_X_loss: 0.2914613601565361\n",
      "[93:700] loss_idt_y: 0.06998601714149118, F_fool_loss: 0.013627182953059673, cycled_y_loss: 0.07044056680053473, D_Y_loss: 0.29189760267734527\n",
      "[93:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:800] Took 12.86s\n",
      "[93:800] loss_idt_x: 0.08548631362617015, G_fool_loss: 0.01365688445046544, cycled_x_loss: 0.08295042950659991, D_X_loss: 0.29252701729536057\n",
      "[93:800] loss_idt_y: 0.06299626871943474, F_fool_loss: 0.013681667288765312, cycled_y_loss: 0.061481466069817546, D_Y_loss: 0.2908305025100708\n",
      "[93:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:900] Took 12.89s\n",
      "[93:900] loss_idt_x: 0.09062142258509993, G_fool_loss: 0.013590528247877955, cycled_x_loss: 0.08735704340040684, D_X_loss: 0.2915017661452293\n",
      "[93:900] loss_idt_y: 0.061989023480564356, F_fool_loss: 0.01356363257393241, cycled_y_loss: 0.06440893338993192, D_Y_loss: 0.29196577161550524\n",
      "[93:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:1000] Took 12.85s\n",
      "[93:1000] loss_idt_x: 0.09438099477440119, G_fool_loss: 0.013514883229508995, cycled_x_loss: 0.09221644204109908, D_X_loss: 0.2917676296830177\n",
      "[93:1000] loss_idt_y: 0.06631393481045961, F_fool_loss: 0.013477865066379309, cycled_y_loss: 0.06753919698297978, D_Y_loss: 0.2927371636033058\n",
      "[93:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:1100] Took 12.86s\n",
      "[93:1100] loss_idt_x: 0.08729829579591751, G_fool_loss: 0.013495251648128032, cycled_x_loss: 0.0836763060092926, D_X_loss: 0.29073474913835523\n",
      "[93:1100] loss_idt_y: 0.06854890864342451, F_fool_loss: 0.013438527267426252, cycled_y_loss: 0.06507689587771892, D_Y_loss: 0.2919665706157684\n",
      "[93:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[93:END] Completed epoch in 171.56080865859985s\n",
      "[93:1199] ep_loss_idt_x: 0.094 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.088 ep_D_X_loss: 0.292\n",
      "[93:1199] ep_loss_idt_y: 0.065 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.065 ep_D_Y_loss: 0.292\n",
      "[93:END] Completed eval in 2.014615297317505s\n",
      "Updated G_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated F_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated D_X_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated D_Y_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "[93:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[94:100] Took 14.81s\n",
      "[94:100] loss_idt_x: 0.08948392815887928, G_fool_loss: 0.013433062471449375, cycled_x_loss: 0.08488893978297711, D_X_loss: 0.2950362595915794\n",
      "[94:100] loss_idt_y: 0.06852919744327664, F_fool_loss: 0.013486912250518799, cycled_y_loss: 0.06990869130939245, D_Y_loss: 0.2948166197538376\n",
      "[94:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:200] Took 12.85s\n",
      "[94:200] loss_idt_x: 0.09093724271282554, G_fool_loss: 0.013564268676564097, cycled_x_loss: 0.08617520231753588, D_X_loss: 0.2929208460450172\n",
      "[94:200] loss_idt_y: 0.0674986770004034, F_fool_loss: 0.013455361649394036, cycled_y_loss: 0.06323900347575545, D_Y_loss: 0.29243799090385436\n",
      "[94:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:300] Took 12.87s\n",
      "[94:300] loss_idt_x: 0.09084749471396208, G_fool_loss: 0.01359059833921492, cycled_x_loss: 0.08435195580124855, D_X_loss: 0.29140846103429796\n",
      "[94:300] loss_idt_y: 0.0620422757230699, F_fool_loss: 0.01352483494207263, cycled_y_loss: 0.06066745817661286, D_Y_loss: 0.2914127424359322\n",
      "[94:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:400] Took 12.88s\n",
      "[94:400] loss_idt_x: 0.10102957263588905, G_fool_loss: 0.013531361883506178, cycled_x_loss: 0.09394515022635459, D_X_loss: 0.29230995118618014\n",
      "[94:400] loss_idt_y: 0.06500196503475308, F_fool_loss: 0.013468443509191274, cycled_y_loss: 0.06292790284380317, D_Y_loss: 0.29261272072792055\n",
      "[94:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:500] Took 12.88s\n",
      "[94:500] loss_idt_x: 0.09965103574097156, G_fool_loss: 0.013485374739393591, cycled_x_loss: 0.09099442824721336, D_X_loss: 0.29169405341148374\n",
      "[94:500] loss_idt_y: 0.0641592507250607, F_fool_loss: 0.0135148024559021, cycled_y_loss: 0.0640625685453415, D_Y_loss: 0.2925179976224899\n",
      "[94:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:600] Took 12.85s\n",
      "[94:600] loss_idt_x: 0.09648002449423075, G_fool_loss: 0.013441937817260623, cycled_x_loss: 0.0908232406526804, D_X_loss: 0.29226390600204466\n",
      "[94:600] loss_idt_y: 0.062030853126198056, F_fool_loss: 0.013387346714735031, cycled_y_loss: 0.06189660707488656, D_Y_loss: 0.2900253039598465\n",
      "[94:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:700] Took 12.86s\n",
      "[94:700] loss_idt_x: 0.08476902501657606, G_fool_loss: 0.013532164124771952, cycled_x_loss: 0.08505860682576895, D_X_loss: 0.2921421927213669\n",
      "[94:700] loss_idt_y: 0.06253362609073519, F_fool_loss: 0.013510108087211847, cycled_y_loss: 0.060187717452645305, D_Y_loss: 0.29099373281002044\n",
      "[94:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:800] Took 12.86s\n",
      "[94:800] loss_idt_x: 0.09422514811158181, G_fool_loss: 0.013468201756477356, cycled_x_loss: 0.08353376399725676, D_X_loss: 0.29226749032735827\n",
      "[94:800] loss_idt_y: 0.06146555284038186, F_fool_loss: 0.013639182122424244, cycled_y_loss: 0.06448703592643142, D_Y_loss: 0.29143077045679094\n",
      "[94:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:900] Took 12.86s\n",
      "[94:900] loss_idt_x: 0.09580447889864445, G_fool_loss: 0.013573332568630575, cycled_x_loss: 0.08615633165463805, D_X_loss: 0.2931437423825264\n",
      "[94:900] loss_idt_y: 0.06715265253558755, F_fool_loss: 0.013483438361436128, cycled_y_loss: 0.07333961874246597, D_Y_loss: 0.29077657967805864\n",
      "[94:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:1000] Took 12.85s\n",
      "[94:1000] loss_idt_x: 0.09748015444725752, G_fool_loss: 0.013669548314064741, cycled_x_loss: 0.09097067561000585, D_X_loss: 0.29273332089185716\n",
      "[94:1000] loss_idt_y: 0.07515064403414726, F_fool_loss: 0.01354847832582891, cycled_y_loss: 0.07043975986540317, D_Y_loss: 0.29098078042268755\n",
      "[94:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:1100] Took 12.86s\n",
      "[94:1100] loss_idt_x: 0.0915284295193851, G_fool_loss: 0.013559893760830164, cycled_x_loss: 0.08590556398034095, D_X_loss: 0.2919087141752243\n",
      "[94:1100] loss_idt_y: 0.05574638430029154, F_fool_loss: 0.013358338251709938, cycled_y_loss: 0.05474583435803652, D_Y_loss: 0.2920957118272781\n",
      "[94:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[94:END] Completed epoch in 170.7159869670868s\n",
      "[94:1199] ep_loss_idt_x: 0.093 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.087 ep_D_X_loss: 0.292\n",
      "[94:1199] ep_loss_idt_y: 0.064 ep_F_fool_loss: 0.013 ep_cycled_y_loss: 0.064 ep_D_Y_loss: 0.292\n",
      "[94:END] Completed eval in 1.914888620376587s\n",
      "Updated G_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated F_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated D_X_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated D_Y_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "[94:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[95:100] Took 24.30s\n",
      "[95:100] loss_idt_x: 0.08885962333530188, G_fool_loss: 0.013682155031710863, cycled_x_loss: 0.08775287516415119, D_X_loss: 0.2948528981208801\n",
      "[95:100] loss_idt_y: 0.055717214848846196, F_fool_loss: 0.01355518275871873, cycled_y_loss: 0.05554826995357871, D_Y_loss: 0.2945836317539215\n",
      "[95:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:200] Took 12.76s\n",
      "[95:200] loss_idt_x: 0.10027238748967647, G_fool_loss: 0.013431631848216058, cycled_x_loss: 0.09417493786662817, D_X_loss: 0.2907551115751266\n",
      "[95:200] loss_idt_y: 0.07070237731561065, F_fool_loss: 0.013536028536036611, cycled_y_loss: 0.06871334029361606, D_Y_loss: 0.29055272102355956\n",
      "[95:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:300] Took 12.82s\n",
      "[95:300] loss_idt_x: 0.09041684206575155, G_fool_loss: 0.013421901371330022, cycled_x_loss: 0.0821402582153678, D_X_loss: 0.29291441082954406\n",
      "[95:300] loss_idt_y: 0.05405963685363531, F_fool_loss: 0.013397355573251843, cycled_y_loss: 0.05671952404081822, D_Y_loss: 0.29075553715229036\n",
      "[95:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:400] Took 12.86s\n",
      "[95:400] loss_idt_x: 0.08226770475506782, G_fool_loss: 0.01358019576407969, cycled_x_loss: 0.07869533963501453, D_X_loss: 0.29162556111812593\n",
      "[95:400] loss_idt_y: 0.05914074255153537, F_fool_loss: 0.013498137956485152, cycled_y_loss: 0.059452021922916175, D_Y_loss: 0.2915410625934601\n",
      "[95:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:500] Took 12.87s\n",
      "[95:500] loss_idt_x: 0.08219149440526963, G_fool_loss: 0.013662126632407307, cycled_x_loss: 0.07934506874531508, D_X_loss: 0.29078160285949706\n",
      "[95:500] loss_idt_y: 0.0570002062804997, F_fool_loss: 0.01361250431276858, cycled_y_loss: 0.05755874464288354, D_Y_loss: 0.2915906110405922\n",
      "[95:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:600] Took 12.86s\n",
      "[95:600] loss_idt_x: 0.09659968314692378, G_fool_loss: 0.013427394405007363, cycled_x_loss: 0.09080539334565402, D_X_loss: 0.29116161704063415\n",
      "[95:600] loss_idt_y: 0.056650479473173615, F_fool_loss: 0.013455104948952794, cycled_y_loss: 0.055889962911605834, D_Y_loss: 0.2921127396821976\n",
      "[95:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:700] Took 12.86s\n",
      "[95:700] loss_idt_x: 0.08971990775316954, G_fool_loss: 0.013536869566887617, cycled_x_loss: 0.08399750582873822, D_X_loss: 0.29086330980062486\n",
      "[95:700] loss_idt_y: 0.060554800666868684, F_fool_loss: 0.013522856403142214, cycled_y_loss: 0.06260805994272232, D_Y_loss: 0.29148467659950256\n",
      "[95:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:800] Took 12.87s\n",
      "[95:800] loss_idt_x: 0.08778306210413575, G_fool_loss: 0.013417009562253952, cycled_x_loss: 0.08122825361788273, D_X_loss: 0.2927039083838463\n",
      "[95:800] loss_idt_y: 0.05999201403930783, F_fool_loss: 0.013510368270799518, cycled_y_loss: 0.05975192002952099, D_Y_loss: 0.29169661074876785\n",
      "[95:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:900] Took 12.86s\n",
      "[95:900] loss_idt_x: 0.09787991493940354, G_fool_loss: 0.013620463581755757, cycled_x_loss: 0.08744484866037965, D_X_loss: 0.2914889919757843\n",
      "[95:900] loss_idt_y: 0.07093911092728376, F_fool_loss: 0.013593276217579841, cycled_y_loss: 0.07022666411474347, D_Y_loss: 0.29231063187122347\n",
      "[95:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:1000] Took 12.88s\n",
      "[95:1000] loss_idt_x: 0.0976389591395855, G_fool_loss: 0.013490094449371099, cycled_x_loss: 0.09504424277693033, D_X_loss: 0.290246978700161\n",
      "[95:1000] loss_idt_y: 0.054667223505675794, F_fool_loss: 0.013493474377319216, cycled_y_loss: 0.05613484440371394, D_Y_loss: 0.29184308350086213\n",
      "[95:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:1100] Took 12.86s\n",
      "[95:1100] loss_idt_x: 0.1050256259739399, G_fool_loss: 0.013516329228878021, cycled_x_loss: 0.09979586508125067, D_X_loss: 0.2929057139158249\n",
      "[95:1100] loss_idt_y: 0.05634901382029057, F_fool_loss: 0.013474502759054303, cycled_y_loss: 0.056027048882097, D_Y_loss: 0.292540862262249\n",
      "[95:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[95:END] Completed epoch in 181.22913694381714s\n",
      "[95:1199] ep_loss_idt_x: 0.093 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.088 ep_D_X_loss: 0.292\n",
      "[95:1199] ep_loss_idt_y: 0.060 ep_F_fool_loss: 0.013 ep_cycled_y_loss: 0.060 ep_D_Y_loss: 0.292\n",
      "[95:END] Completed eval in 1.9178471565246582s\n",
      "Updated G_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated F_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated D_X_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated D_Y_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "[95:END] Saving models and training information permanently\n",
      "[96:100] Took 14.84s\n",
      "[96:100] loss_idt_x: 0.0898653418943286, G_fool_loss: 0.013784365337342024, cycled_x_loss: 0.08655301135033369, D_X_loss: 0.29573613435029983\n",
      "[96:100] loss_idt_y: 0.07784156255424023, F_fool_loss: 0.013579432517290116, cycled_y_loss: 0.07918177474290132, D_Y_loss: 0.294617038667202\n",
      "[96:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:200] Took 12.86s\n",
      "[96:200] loss_idt_x: 0.08486555157229304, G_fool_loss: 0.013610678110271692, cycled_x_loss: 0.07791268669068813, D_X_loss: 0.29219861686229703\n",
      "[96:200] loss_idt_y: 0.06020828824490309, F_fool_loss: 0.013504510130733251, cycled_y_loss: 0.05604598360136151, D_Y_loss: 0.2907181429862976\n",
      "[96:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:300] Took 12.88s\n",
      "[96:300] loss_idt_x: 0.08971888232976198, G_fool_loss: 0.013466048212721944, cycled_x_loss: 0.08255921356379986, D_X_loss: 0.29328918635845186\n",
      "[96:300] loss_idt_y: 0.0685486625134945, F_fool_loss: 0.013599834572523832, cycled_y_loss: 0.06898000437766313, D_Y_loss: 0.29213762491941453\n",
      "[96:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:400] Took 12.86s\n",
      "[96:400] loss_idt_x: 0.09219176616519689, G_fool_loss: 0.013294454896822572, cycled_x_loss: 0.0845760104432702, D_X_loss: 0.29262581378221514\n",
      "[96:400] loss_idt_y: 0.06259998682886363, F_fool_loss: 0.01355448853224516, cycled_y_loss: 0.0638155546411872, D_Y_loss: 0.2930136457085609\n",
      "[96:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:500] Took 12.86s\n",
      "[96:500] loss_idt_x: 0.09867941983044147, G_fool_loss: 0.013533869422972203, cycled_x_loss: 0.08772247664630413, D_X_loss: 0.2931026163697243\n",
      "[96:500] loss_idt_y: 0.0635302553139627, F_fool_loss: 0.013437288710847498, cycled_y_loss: 0.059834376387298105, D_Y_loss: 0.29167407542467116\n",
      "[96:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:600] Took 12.87s\n",
      "[96:600] loss_idt_x: 0.08946229167282581, G_fool_loss: 0.013568809060379862, cycled_x_loss: 0.0828953067958355, D_X_loss: 0.29022363007068636\n",
      "[96:600] loss_idt_y: 0.05296439278870821, F_fool_loss: 0.013552476363256573, cycled_y_loss: 0.05296504342928529, D_Y_loss: 0.29184791564941404\n",
      "[96:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:700] Took 12.86s\n",
      "[96:700] loss_idt_x: 0.08579852301627397, G_fool_loss: 0.013359187897294759, cycled_x_loss: 0.07513812411576509, D_X_loss: 0.2908737349510193\n",
      "[96:700] loss_idt_y: 0.05869777640327811, F_fool_loss: 0.01340476139448583, cycled_y_loss: 0.05759410450235009, D_Y_loss: 0.29128425031900407\n",
      "[96:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:800] Took 12.85s\n",
      "[96:800] loss_idt_x: 0.09322727378457785, G_fool_loss: 0.013507102830335498, cycled_x_loss: 0.08662598870694638, D_X_loss: 0.29241623252630233\n",
      "[96:800] loss_idt_y: 0.05595200968906283, F_fool_loss: 0.013465300453826785, cycled_y_loss: 0.05523139601573348, D_Y_loss: 0.2923806557059288\n",
      "[96:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:900] Took 12.86s\n",
      "[96:900] loss_idt_x: 0.09226764149963856, G_fool_loss: 0.013399637043476105, cycled_x_loss: 0.08779724862426519, D_X_loss: 0.2928427025675774\n",
      "[96:900] loss_idt_y: 0.06551478944718837, F_fool_loss: 0.013531952211633325, cycled_y_loss: 0.06425207579508424, D_Y_loss: 0.2914640960097313\n",
      "[96:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:1000] Took 12.85s\n",
      "[96:1000] loss_idt_x: 0.08985819224268198, G_fool_loss: 0.013595213871449232, cycled_x_loss: 0.08591136775910854, D_X_loss: 0.2919219556450844\n",
      "[96:1000] loss_idt_y: 0.07326249519363046, F_fool_loss: 0.01360265194438398, cycled_y_loss: 0.07279237944632769, D_Y_loss: 0.29269292533397673\n",
      "[96:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:1100] Took 12.86s\n",
      "[96:1100] loss_idt_x: 0.09038690587505699, G_fool_loss: 0.013549708062782884, cycled_x_loss: 0.08367912914603949, D_X_loss: 0.2919210022687912\n",
      "[96:1100] loss_idt_y: 0.058407304231077435, F_fool_loss: 0.013449065731838345, cycled_y_loss: 0.06207689438015222, D_Y_loss: 0.2914719843864441\n",
      "[96:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[96:END] Completed epoch in 171.42236471176147s\n",
      "[96:1199] ep_loss_idt_x: 0.091 ep_G_fool_loss: 0.014 ep_cycled_x_loss: 0.084 ep_D_X_loss: 0.292\n",
      "[96:1199] ep_loss_idt_y: 0.063 ep_F_fool_loss: 0.014 ep_cycled_y_loss: 0.063 ep_D_Y_loss: 0.292\n",
      "[96:END] Completed eval in 2.0305540561676025s\n",
      "Updated G_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated F_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated D_X_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated D_Y_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "[96:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[97:100] Took 14.82s\n",
      "[97:100] loss_idt_x: 0.0903815371543169, G_fool_loss: 0.01353233982808888, cycled_x_loss: 0.08462340172380209, D_X_loss: 0.2929787278175354\n",
      "[97:100] loss_idt_y: 0.056487352419644594, F_fool_loss: 0.013498668158426881, cycled_y_loss: 0.05686411242932081, D_Y_loss: 0.29515486776828764\n",
      "[97:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:200] Took 12.87s\n",
      "[97:200] loss_idt_x: 0.08330088151618838, G_fool_loss: 0.013379902224987745, cycled_x_loss: 0.07851138010621071, D_X_loss: 0.29048841148614885\n",
      "[97:200] loss_idt_y: 0.05530099993571639, F_fool_loss: 0.013429284933954478, cycled_y_loss: 0.05683851558715105, D_Y_loss: 0.29300408631563185\n",
      "[97:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:300] Took 12.86s\n",
      "[97:300] loss_idt_x: 0.09030463799834251, G_fool_loss: 0.013528701914474368, cycled_x_loss: 0.08090568911284209, D_X_loss: 0.2911727142333984\n",
      "[97:300] loss_idt_y: 0.05904261978343129, F_fool_loss: 0.013590560536831617, cycled_y_loss: 0.057258947435766455, D_Y_loss: 0.29187589436769484\n",
      "[97:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:400] Took 12.86s\n",
      "[97:400] loss_idt_x: 0.08957539927214384, G_fool_loss: 0.013460812671110035, cycled_x_loss: 0.08494294550269842, D_X_loss: 0.2927012327313423\n",
      "[97:400] loss_idt_y: 0.06309025825932622, F_fool_loss: 0.013398111443966626, cycled_y_loss: 0.06001476105302572, D_Y_loss: 0.2915752491354942\n",
      "[97:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:500] Took 12.85s\n",
      "[97:500] loss_idt_x: 0.08369592111557722, G_fool_loss: 0.01332857937552035, cycled_x_loss: 0.07995376572012901, D_X_loss: 0.2909195300936699\n",
      "[97:500] loss_idt_y: 0.05830980937927961, F_fool_loss: 0.013410340882837773, cycled_y_loss: 0.0581019277125597, D_Y_loss: 0.29196120202541354\n",
      "[97:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:600] Took 12.86s\n",
      "[97:600] loss_idt_x: 0.09664178885519505, G_fool_loss: 0.013607354192063213, cycled_x_loss: 0.08977749921381474, D_X_loss: 0.29285541623830796\n",
      "[97:600] loss_idt_y: 0.056732649262994525, F_fool_loss: 0.013366272682324052, cycled_y_loss: 0.054639123380184174, D_Y_loss: 0.2925965064764023\n",
      "[97:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:700] Took 12.86s\n",
      "[97:700] loss_idt_x: 0.09545451115816832, G_fool_loss: 0.013354211514815688, cycled_x_loss: 0.08840043198317289, D_X_loss: 0.2910176342725754\n",
      "[97:700] loss_idt_y: 0.05719470540061593, F_fool_loss: 0.013405633475631475, cycled_y_loss: 0.05723584799095988, D_Y_loss: 0.29171441346406934\n",
      "[97:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:800] Took 12.87s\n",
      "[97:800] loss_idt_x: 0.0844759501889348, G_fool_loss: 0.01338460267521441, cycled_x_loss: 0.07791366970166563, D_X_loss: 0.29209127932786944\n",
      "[97:800] loss_idt_y: 0.06862483600154519, F_fool_loss: 0.013256756979972124, cycled_y_loss: 0.0648095066472888, D_Y_loss: 0.29098652929067614\n",
      "[97:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:900] Took 12.85s\n",
      "[97:900] loss_idt_x: 0.10170078907161952, G_fool_loss: 0.013506258176639675, cycled_x_loss: 0.09216631531715393, D_X_loss: 0.29327838867902756\n",
      "[97:900] loss_idt_y: 0.06228257102891803, F_fool_loss: 0.013413382545113563, cycled_y_loss: 0.061172104477882384, D_Y_loss: 0.29274634897708895\n",
      "[97:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:1000] Took 12.86s\n",
      "[97:1000] loss_idt_x: 0.09814004570245743, G_fool_loss: 0.013412513872608542, cycled_x_loss: 0.08470324270427226, D_X_loss: 0.292607047855854\n",
      "[97:1000] loss_idt_y: 0.05768424673005938, F_fool_loss: 0.013515262547880411, cycled_y_loss: 0.06037011103704572, D_Y_loss: 0.2916137742996216\n",
      "[97:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:1100] Took 12.88s\n",
      "[97:1100] loss_idt_x: 0.09294901756569743, G_fool_loss: 0.013451333092525601, cycled_x_loss: 0.08799453716725111, D_X_loss: 0.2911557349562645\n",
      "[97:1100] loss_idt_y: 0.06788158291950822, F_fool_loss: 0.013456120574846863, cycled_y_loss: 0.06586236232891679, D_Y_loss: 0.29183502078056334\n",
      "[97:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[97:END] Completed epoch in 172.6016502380371s\n",
      "[97:1199] ep_loss_idt_x: 0.092 ep_G_fool_loss: 0.013 ep_cycled_x_loss: 0.085 ep_D_X_loss: 0.292\n",
      "[97:1199] ep_loss_idt_y: 0.060 ep_F_fool_loss: 0.013 ep_cycled_y_loss: 0.059 ep_D_Y_loss: 0.292\n",
      "[97:END] Completed eval in 1.9957232475280762s\n",
      "Updated G_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated F_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated D_X_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated D_Y_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "[97:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[98:100] Took 14.82s\n",
      "[98:100] loss_idt_x: 0.0930961636826396, G_fool_loss: 0.013763941675424576, cycled_x_loss: 0.08275850981473923, D_X_loss: 0.2950163796544075\n",
      "[98:100] loss_idt_y: 0.06364564090967179, F_fool_loss: 0.013675954621285201, cycled_y_loss: 0.06508322883397341, D_Y_loss: 0.2940587803721428\n",
      "[98:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:200] Took 12.86s\n",
      "[98:200] loss_idt_x: 0.10040977377444506, G_fool_loss: 0.01340838079340756, cycled_x_loss: 0.0943864307552576, D_X_loss: 0.2922655057907104\n",
      "[98:200] loss_idt_y: 0.06390372164547443, F_fool_loss: 0.013435782603919507, cycled_y_loss: 0.0643112044967711, D_Y_loss: 0.291729636490345\n",
      "[98:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:300] Took 12.85s\n",
      "[98:300] loss_idt_x: 0.10662288144230843, G_fool_loss: 0.013484257236123086, cycled_x_loss: 0.0972871857881546, D_X_loss: 0.29081749469041823\n",
      "[98:300] loss_idt_y: 0.061494627334177494, F_fool_loss: 0.013387550720945001, cycled_y_loss: 0.05705771636217832, D_Y_loss: 0.2929954412579536\n",
      "[98:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:400] Took 12.86s\n",
      "[98:400] loss_idt_x: 0.09011101759970189, G_fool_loss: 0.013407367132604122, cycled_x_loss: 0.08578252866864204, D_X_loss: 0.2903430363535881\n",
      "[98:400] loss_idt_y: 0.057762535978108646, F_fool_loss: 0.013446994218975305, cycled_y_loss: 0.055760892760008576, D_Y_loss: 0.29059285134077073\n",
      "[98:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:500] Took 12.86s\n",
      "[98:500] loss_idt_x: 0.08946120474487543, G_fool_loss: 0.013499878663569689, cycled_x_loss: 0.08183490118011832, D_X_loss: 0.29040115237236025\n",
      "[98:500] loss_idt_y: 0.0579729544557631, F_fool_loss: 0.013482475792989135, cycled_y_loss: 0.05758738461881876, D_Y_loss: 0.29066065400838853\n",
      "[98:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:600] Took 12.86s\n",
      "[98:600] loss_idt_x: 0.0887561721727252, G_fool_loss: 0.013447620170190931, cycled_x_loss: 0.07832393039017915, D_X_loss: 0.29154012829065323\n",
      "[98:600] loss_idt_y: 0.06722846709191799, F_fool_loss: 0.013465433698147535, cycled_y_loss: 0.06259789057075978, D_Y_loss: 0.2927578353881836\n",
      "[98:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:700] Took 12.88s\n",
      "[98:700] loss_idt_x: 0.10249765187501908, G_fool_loss: 0.013402152601629495, cycled_x_loss: 0.09393734831362963, D_X_loss: 0.2913878199458122\n",
      "[98:700] loss_idt_y: 0.0632979467511177, F_fool_loss: 0.013518522931262851, cycled_y_loss: 0.060887969173491, D_Y_loss: 0.29210593104362487\n",
      "[98:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:800] Took 12.86s\n",
      "[98:800] loss_idt_x: 0.08928093194961548, G_fool_loss: 0.013499876148998738, cycled_x_loss: 0.0848008694499731, D_X_loss: 0.292528361082077\n",
      "[98:800] loss_idt_y: 0.062138077709823845, F_fool_loss: 0.013400870533660054, cycled_y_loss: 0.06119347320869565, D_Y_loss: 0.2911052307486534\n",
      "[98:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:900] Took 12.85s\n",
      "[98:900] loss_idt_x: 0.09290215589106082, G_fool_loss: 0.013437257260084151, cycled_x_loss: 0.0882784252986312, D_X_loss: 0.29130179673433304\n",
      "[98:900] loss_idt_y: 0.06506561866030097, F_fool_loss: 0.013362896153703332, cycled_y_loss: 0.061625524517148735, D_Y_loss: 0.29125752955675127\n",
      "[98:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:1000] Took 12.84s\n",
      "[98:1000] loss_idt_x: 0.08664401102811098, G_fool_loss: 0.013280579326674343, cycled_x_loss: 0.08009512331336736, D_X_loss: 0.2932721140980721\n",
      "[98:1000] loss_idt_y: 0.06714272493496537, F_fool_loss: 0.013459451114758849, cycled_y_loss: 0.0649028737284243, D_Y_loss: 0.29063642531633377\n",
      "[98:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:1100] Took 12.86s\n",
      "[98:1100] loss_idt_x: 0.09475852413102985, G_fool_loss: 0.013456235900521278, cycled_x_loss: 0.08198461219668389, D_X_loss: 0.2930916601419449\n",
      "[98:1100] loss_idt_y: 0.05847946479916573, F_fool_loss: 0.0135573217459023, cycled_y_loss: 0.05749648490920663, D_Y_loss: 0.2903441482782364\n",
      "[98:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[98:END] Completed epoch in 173.07428288459778s\n",
      "[98:1199] ep_loss_idt_x: 0.094 ep_G_fool_loss: 0.013 ep_cycled_x_loss: 0.086 ep_D_X_loss: 0.292\n",
      "[98:1199] ep_loss_idt_y: 0.062 ep_F_fool_loss: 0.013 ep_cycled_y_loss: 0.061 ep_D_Y_loss: 0.291\n",
      "[98:END] Completed eval in 2.045563220977783s\n",
      "Updated G_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated F_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated D_X_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated D_Y_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "[98:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[99:100] Took 14.85s\n",
      "[99:100] loss_idt_x: 0.08248708594590426, G_fool_loss: 0.01370405632071197, cycled_x_loss: 0.07774987019598484, D_X_loss: 0.29358962446451187\n",
      "[99:100] loss_idt_y: 0.06998567633330822, F_fool_loss: 0.01361721315421164, cycled_y_loss: 0.06837402675300837, D_Y_loss: 0.29463575780391693\n",
      "[99:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:200] Took 12.85s\n",
      "[99:200] loss_idt_x: 0.09053603649139404, G_fool_loss: 0.013435767460614444, cycled_x_loss: 0.08064277218654752, D_X_loss: 0.29177903175354003\n",
      "[99:200] loss_idt_y: 0.059862558357417585, F_fool_loss: 0.013336021658033133, cycled_y_loss: 0.055464868247509, D_Y_loss: 0.29043222904205324\n",
      "[99:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:300] Took 12.88s\n",
      "[99:300] loss_idt_x: 0.08251879397779703, G_fool_loss: 0.013435514569282532, cycled_x_loss: 0.07349888376891613, D_X_loss: 0.29113705426454545\n",
      "[99:300] loss_idt_y: 0.055553961656987665, F_fool_loss: 0.013390079801902176, cycled_y_loss: 0.05594175865873694, D_Y_loss: 0.2921003118157387\n",
      "[99:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:400] Took 12.86s\n",
      "[99:400] loss_idt_x: 0.09397010508924723, G_fool_loss: 0.013425456751137972, cycled_x_loss: 0.08627170518040657, D_X_loss: 0.2923974999785423\n",
      "[99:400] loss_idt_y: 0.06542201343923808, F_fool_loss: 0.01345154813490808, cycled_y_loss: 0.0639681258238852, D_Y_loss: 0.2921587219834328\n",
      "[99:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:500] Took 12.86s\n",
      "[99:500] loss_idt_x: 0.09297175295650958, G_fool_loss: 0.013260490847751499, cycled_x_loss: 0.08624888151884079, D_X_loss: 0.2926599407196045\n",
      "[99:500] loss_idt_y: 0.060222192592918874, F_fool_loss: 0.013578208182007074, cycled_y_loss: 0.05376830408349633, D_Y_loss: 0.2921090340614319\n",
      "[99:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:600] Took 12.86s\n",
      "[99:600] loss_idt_x: 0.09361150167882443, G_fool_loss: 0.013375892899930478, cycled_x_loss: 0.08346201829612256, D_X_loss: 0.2922915470600128\n",
      "[99:600] loss_idt_y: 0.05852734323590994, F_fool_loss: 0.013366414504125713, cycled_y_loss: 0.058945888075977566, D_Y_loss: 0.29175764560699463\n",
      "[99:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:700] Took 12.85s\n",
      "[99:700] loss_idt_x: 0.09634221564978361, G_fool_loss: 0.013534499146044255, cycled_x_loss: 0.085865135230124, D_X_loss: 0.2921471056342125\n",
      "[99:700] loss_idt_y: 0.06378310795873404, F_fool_loss: 0.01325012918561697, cycled_y_loss: 0.0645062893629074, D_Y_loss: 0.2918033915758133\n",
      "[99:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:800] Took 12.86s\n",
      "[99:800] loss_idt_x: 0.08569234093651175, G_fool_loss: 0.013377592293545603, cycled_x_loss: 0.07640979275107383, D_X_loss: 0.2921154221892357\n",
      "[99:800] loss_idt_y: 0.06516360880807043, F_fool_loss: 0.013579974835738539, cycled_y_loss: 0.06497458575293422, D_Y_loss: 0.2919610825181007\n",
      "[99:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:900] Took 12.86s\n",
      "[99:900] loss_idt_x: 0.09399916283786297, G_fool_loss: 0.013321274109184742, cycled_x_loss: 0.08000114116817712, D_X_loss: 0.2914061886072159\n",
      "[99:900] loss_idt_y: 0.05391163626685738, F_fool_loss: 0.013451291779056192, cycled_y_loss: 0.05354273268952966, D_Y_loss: 0.29097786456346514\n",
      "[99:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:1000] Took 12.86s\n",
      "[99:1000] loss_idt_x: 0.08908752031624317, G_fool_loss: 0.013330026986077428, cycled_x_loss: 0.08335467349737882, D_X_loss: 0.2916774010658264\n",
      "[99:1000] loss_idt_y: 0.06259472735226154, F_fool_loss: 0.013502493416890502, cycled_y_loss: 0.06119443474337458, D_Y_loss: 0.2909013032913208\n",
      "[99:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:1100] Took 12.88s\n",
      "[99:1100] loss_idt_x: 0.09508914919570088, G_fool_loss: 0.013405196759849787, cycled_x_loss: 0.08820486102253199, D_X_loss: 0.2912184113264084\n",
      "[99:1100] loss_idt_y: 0.06649083152413368, F_fool_loss: 0.013462736960500479, cycled_y_loss: 0.06359914753586055, D_Y_loss: 0.2923492020368576\n",
      "[99:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[99:END] Completed epoch in 174.2895405292511s\n",
      "[99:1199] ep_loss_idt_x: 0.091 ep_G_fool_loss: 0.013 ep_cycled_x_loss: 0.082 ep_D_X_loss: 0.292\n",
      "[99:1199] ep_loss_idt_y: 0.062 ep_F_fool_loss: 0.013 ep_cycled_y_loss: 0.061 ep_D_Y_loss: 0.292\n",
      "[99:END] Completed eval in 1.9477770328521729s\n",
      "Updated G_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated F_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated D_X_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated D_Y_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "[99:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[100:100] Took 14.85s\n",
      "[100:100] loss_idt_x: 0.09911812981590629, G_fool_loss: 0.013635422522202133, cycled_x_loss: 0.08799825135618448, D_X_loss: 0.2955728513002396\n",
      "[100:100] loss_idt_y: 0.05841188259422779, F_fool_loss: 0.013572497898712755, cycled_y_loss: 0.057878732364624735, D_Y_loss: 0.2947315612435341\n",
      "[100:100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:200] Took 12.85s\n",
      "[100:200] loss_idt_x: 0.10239485610276461, G_fool_loss: 0.01329701928421855, cycled_x_loss: 0.09206990368664264, D_X_loss: 0.2916295775771141\n",
      "[100:200] loss_idt_y: 0.06255889190360904, F_fool_loss: 0.01338934624567628, cycled_y_loss: 0.062045370172709224, D_Y_loss: 0.2915390753746033\n",
      "[100:200] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:300] Took 12.86s\n",
      "[100:300] loss_idt_x: 0.08659988772124053, G_fool_loss: 0.013270004130899906, cycled_x_loss: 0.074776964597404, D_X_loss: 0.2917492538690567\n",
      "[100:300] loss_idt_y: 0.062442408986389634, F_fool_loss: 0.013485566666349768, cycled_y_loss: 0.06270605113357305, D_Y_loss: 0.2916066610813141\n",
      "[100:300] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:400] Took 12.86s\n",
      "[100:400] loss_idt_x: 0.08544282630085945, G_fool_loss: 0.013407967602834105, cycled_x_loss: 0.08178667532280087, D_X_loss: 0.2912522041797638\n",
      "[100:400] loss_idt_y: 0.06409885212779046, F_fool_loss: 0.013297770712524653, cycled_y_loss: 0.06196025304496288, D_Y_loss: 0.2927358415722847\n",
      "[100:400] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:500] Took 12.85s\n",
      "[100:500] loss_idt_x: 0.08870500864461064, G_fool_loss: 0.013307577604427934, cycled_x_loss: 0.08279322203248739, D_X_loss: 0.2909678065776825\n",
      "[100:500] loss_idt_y: 0.06654560644179583, F_fool_loss: 0.013426309395581483, cycled_y_loss: 0.06248065305873752, D_Y_loss: 0.2930577212572098\n",
      "[100:500] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:600] Took 12.86s\n",
      "[100:600] loss_idt_x: 0.09590895131230354, G_fool_loss: 0.013443619888275861, cycled_x_loss: 0.08493553057312965, D_X_loss: 0.291157086789608\n",
      "[100:600] loss_idt_y: 0.06539299879223108, F_fool_loss: 0.013266311837360262, cycled_y_loss: 0.06326191468164324, D_Y_loss: 0.29098735451698304\n",
      "[100:600] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:700] Took 12.87s\n",
      "[100:700] loss_idt_x: 0.0914009228721261, G_fool_loss: 0.01344653319567442, cycled_x_loss: 0.08105051916092634, D_X_loss: 0.2918803209066391\n",
      "[100:700] loss_idt_y: 0.05970673019066453, F_fool_loss: 0.013348995316773653, cycled_y_loss: 0.05729378735646606, D_Y_loss: 0.2911040589213371\n",
      "[100:700] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:800] Took 12.86s\n",
      "[100:800] loss_idt_x: 0.08935845866799355, G_fool_loss: 0.013448194190859795, cycled_x_loss: 0.08218696806579828, D_X_loss: 0.2911490693688393\n",
      "[100:800] loss_idt_y: 0.05587730336934328, F_fool_loss: 0.013524108147248626, cycled_y_loss: 0.05151994185522199, D_Y_loss: 0.29184194415807724\n",
      "[100:800] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:900] Took 12.86s\n",
      "[100:900] loss_idt_x: 0.09545584496110678, G_fool_loss: 0.013429217524826526, cycled_x_loss: 0.09057148080319166, D_X_loss: 0.2909810870885849\n",
      "[100:900] loss_idt_y: 0.05816668497398496, F_fool_loss: 0.013442487316206097, cycled_y_loss: 0.05415212513878941, D_Y_loss: 0.2904847118258476\n",
      "[100:900] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:1000] Took 12.85s\n",
      "[100:1000] loss_idt_x: 0.08722117710858583, G_fool_loss: 0.013286014832556248, cycled_x_loss: 0.0781627506762743, D_X_loss: 0.2931090995669365\n",
      "[100:1000] loss_idt_y: 0.05789545968174934, F_fool_loss: 0.013410137705504895, cycled_y_loss: 0.05672082554548979, D_Y_loss: 0.29184636384248736\n",
      "[100:1000] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:1100] Took 12.86s\n",
      "[100:1100] loss_idt_x: 0.09700645055621862, G_fool_loss: 0.013354856800287963, cycled_x_loss: 0.09126289047300816, D_X_loss: 0.29068680346012116\n",
      "[100:1100] loss_idt_y: 0.05483544303104281, F_fool_loss: 0.013229713179171085, cycled_y_loss: 0.05827791525050998, D_Y_loss: 0.2910891637206078\n",
      "[100:1100] fake_X_buffer: 50, fake_Y_buffer: 50\n",
      "[100:END] Completed epoch in 174.72127962112427s\n",
      "[100:1199] ep_loss_idt_x: 0.092 ep_G_fool_loss: 0.013 ep_cycled_x_loss: 0.084 ep_D_X_loss: 0.292\n",
      "[100:1199] ep_loss_idt_y: 0.061 ep_F_fool_loss: 0.013 ep_cycled_y_loss: 0.059 ep_D_Y_loss: 0.292\n",
      "[100:END] Completed eval in 2.068455457687378s\n",
      "Updated G_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated F_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated D_X_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated D_Y_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "[100:END] Saving models and training information permanently\n"
     ]
    }
   ],
   "source": [
    "if cyclegan.start_epoch != 0:\n",
    "    print(f\"Resuming training from epoch {cyclegan.start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "if vis is not None:\n",
    "    loss_plot = MultiLinePlot(vis, \"Losses\", \"Epoch\", \"Loss\")\n",
    "\n",
    "for epoch in range(cyclegan.start_epoch + 1, epochs + 1):\n",
    "    cyclegan.G.train()\n",
    "    cyclegan.F.train()\n",
    "    \n",
    "    cyclegan.D_X.train()\n",
    "    cyclegan.D_Y.train()\n",
    "\n",
    "    batch_start_time = time.time()\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    cum_loss_idt_x = 0\n",
    "    cum_loss_idt_y = 0\n",
    "    cum_G_fool_loss = 0\n",
    "    cum_F_fool_loss = 0\n",
    "    cum_cycled_x_loss = 0\n",
    "    cum_cycled_y_loss = 0\n",
    "    cum_D_X_loss = 0\n",
    "    cum_D_Y_loss = 0\n",
    "    \n",
    "    ep_loss_idt_x = 0\n",
    "    ep_loss_idt_y = 0\n",
    "    ep_G_fool_loss = 0\n",
    "    ep_F_fool_loss = 0\n",
    "    ep_cycled_x_loss = 0\n",
    "    ep_cycled_y_loss = 0\n",
    "    ep_D_X_loss = 0\n",
    "    ep_D_Y_loss = 0\n",
    "    \n",
    "    for batch_no, (x, y) in enumerate(dataloader):\n",
    "        # Load the sequence of frames to the GPU\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Firstly, generate fake images in domain Y using the x_t images\n",
    "        fake_y = cyclegan.G(x)\n",
    "        \n",
    "        # Then generate the fake images in domain X using the y_t images\n",
    "        fake_x = cyclegan.F(y)\n",
    "        \n",
    "        ### GENERATOR TRAINING\n",
    "        \n",
    "        # Freeze discriminator weights\n",
    "        for param in cyclegan.D_X.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in cyclegan.D_Y.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Zero the gradients for the generators and predictors\n",
    "        cyclegan.G_opt.zero_grad()\n",
    "        cyclegan.F_opt.zero_grad()\n",
    "        \n",
    "        # Calculate the identity loss, this tries to enforce that G(y) = I(y) = y i.e. the identity\n",
    "        idt_x = cyclegan.F(x)\n",
    "        loss_idt_x = cyclegan.identity_loss(idt_x, x)\n",
    "        \n",
    "        idt_y = cyclegan.G(y)\n",
    "        loss_idt_y = cyclegan.identity_loss(idt_y, y)\n",
    "        \n",
    "        # Now we try and fool the discriminators\n",
    "        # D_X tries to tell if an image is from X (1) or from F(Y) (0) so it takes input fake_x_t\n",
    "        # D_X is supposed to be 1 if the image is from X but here we are trying to get it to be 1 if it is from G(X) -> Y which is incorrect\n",
    "        G_fool = cyclegan.D_Y(fake_y) \n",
    "        # We want to tell if fake_y_0 has fooled D_X, so we measure how far from the output 1 it is \n",
    "        G_fool_loss = cyclegan.gan_loss(G_fool, generate_noisy_labels(G_fool.shape, True, device))\n",
    "        \n",
    "        # D_Y tries to tell if an image is from Y (1) or from G(X) (0) so it takes input fake_y_t\n",
    "        F_fool = cyclegan.D_X(fake_x)\n",
    "        # We want to tell if fake_x_0 has fooled D_Y, so we measure how far from the output 1 it is \n",
    "        F_fool_loss = cyclegan.gan_loss(F_fool, generate_noisy_labels(F_fool.shape, True, device))\n",
    "        \n",
    "        # Now do the cycle loss\n",
    "        cycled_x = cyclegan.F(fake_y)\n",
    "        cycled_loss_x = cyclegan.cycle_loss(cycled_x, x)\n",
    "        \n",
    "        cycled_y = cyclegan.G(fake_x)\n",
    "        cycled_loss_y = cyclegan.cycle_loss(cycled_y, y)\n",
    "        \n",
    "        # Backpropagate and step the gradients\n",
    "        generator_loss = G_fool_loss + F_fool_loss + lambda_weight * (cycled_loss_x + cycled_loss_y + lambda_idt_X * loss_idt_x + lambda_idt_Y * loss_idt_y)\n",
    "        generator_loss.backward()\n",
    "        \n",
    "        cyclegan.G_opt.step()\n",
    "        cyclegan.F_opt.step()\n",
    "        \n",
    "        ### DISCRIMINATOR TRAINING\n",
    "        # Unfreeze discriminator weights\n",
    "        for param in cyclegan.D_X.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in cyclegan.D_Y.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Zero the gradients\n",
    "        cyclegan.D_X_opt.zero_grad()\n",
    "        cyclegan.D_Y_opt.zero_grad()\n",
    "        \n",
    "        D_X_loss = get_discriminator_loss(x, fake_x, cyclegan.fake_X_buffer, cyclegan.D_X, cyclegan.gan_loss)\n",
    "        \n",
    "        D_Y_loss = get_discriminator_loss(y, fake_y, cyclegan.fake_Y_buffer, cyclegan.D_Y, cyclegan.gan_loss)\n",
    "        \n",
    "        # Backpropagate and step the gradients\n",
    "        D_loss = D_X_loss + D_Y_loss\n",
    "        D_loss.backward()\n",
    "        \n",
    "        cyclegan.D_X_opt.step()\n",
    "        cyclegan.D_Y_opt.step()\n",
    "        \n",
    "        ### UPDATE POOLS\n",
    "        cyclegan.fake_X_buffer.add(fake_x.detach())\n",
    "        cyclegan.fake_Y_buffer.add(fake_y.detach())\n",
    "        \n",
    "        ### TRACK LOSS\n",
    "        cum_loss_idt_x += loss_idt_x.item()\n",
    "        cum_loss_idt_y += loss_idt_y.item()\n",
    "        cum_G_fool_loss += G_fool_loss.item()\n",
    "        cum_F_fool_loss += F_fool_loss.item()\n",
    "        cum_cycled_x_loss += cycled_loss_x.item()\n",
    "        cum_cycled_y_loss += cycled_loss_y.item()\n",
    "        cum_D_X_loss += D_X_loss.item()\n",
    "        cum_D_Y_loss += D_Y_loss.item()\n",
    "        \n",
    "        ep_loss_idt_x += loss_idt_x.item()\n",
    "        ep_loss_idt_y += loss_idt_y.item()\n",
    "        ep_G_fool_loss += G_fool_loss.item()\n",
    "        ep_F_fool_loss += F_fool_loss.item()\n",
    "        ep_cycled_x_loss += cycled_loss_x.item()\n",
    "        ep_cycled_y_loss += cycled_loss_y.item()\n",
    "        ep_D_X_loss += D_X_loss.item()\n",
    "        ep_D_Y_loss += D_Y_loss.item()\n",
    "        \n",
    "        if epoch == 0 and batch_no < 55:\n",
    "            print(f\"[{epoch}:{batch_no}] fake_X_buffer: {len(cyclegan.fake_X_buffer)}, fake_Y_buffer: {len(cyclegan.fake_Y_buffer)}\")\n",
    "        \n",
    "        if batch_no % 100 == 0 and batch_no != 0: \n",
    "            duration = time.time() - batch_start_time\n",
    "            \n",
    "            updated_losses = {\n",
    "                \"loss_idt_x\": cum_loss_idt_x / 100,\n",
    "                \"loss_idt_y\": cum_loss_idt_y / 100,\n",
    "                \"G_fool_loss\": cum_G_fool_loss / 100,\n",
    "                \"F_fool_loss\": cum_F_fool_loss / 100,\n",
    "                \"cycled_x_loss\": cum_cycled_x_loss / 100,\n",
    "                \"cycled_y_loss\": cum_cycled_y_loss / 100,\n",
    "                \"D_X_loss\": cum_D_X_loss / 100,\n",
    "                \"D_Y_loss\": cum_D_Y_loss / 100\n",
    "            }\n",
    "            \n",
    "            x_loss_str = f\"[{epoch}:{batch_no}]\"\n",
    "            y_loss_str = f\"[{epoch}:{batch_no}]\"\n",
    "            \n",
    "            for i, (key, value) in enumerate(updated_losses.items()):\n",
    "                if i % 2 == 0:\n",
    "                    x_loss_str = f\"{x_loss_str} {key}: {value},\"\n",
    "                else:\n",
    "                    y_loss_str = f\"{y_loss_str} {key}: {value},\"\n",
    "            \n",
    "            x_loss_str = x_loss_str[:-1]\n",
    "            y_loss_str = y_loss_str[:-1]\n",
    "\n",
    "            print(f\"[{epoch}:{batch_no}] Took {duration:.2f}s\")\n",
    "            print(x_loss_str)\n",
    "            print(y_loss_str)\n",
    "            print(f\"[{epoch}:{batch_no}] fake_X_buffer: {len(cyclegan.fake_X_buffer)}, fake_Y_buffer: {len(cyclegan.fake_Y_buffer)}\")\n",
    "            \n",
    "            if vis is not None:\n",
    "                loss_plot.append_values(epoch + batch_no / len(dataloader), updated_losses)\n",
    "            \n",
    "            cum_loss_idt_x = 0\n",
    "            cum_loss_idt_y = 0\n",
    "            cum_G_fool_loss = 0\n",
    "            cum_F_fool_loss = 0\n",
    "            cum_cycled_x_loss = 0\n",
    "            cum_cycled_y_loss = 0\n",
    "            cum_D_X_loss = 0\n",
    "            cum_D_Y_loss = 0\n",
    "\n",
    "            batch_start_time = time.time()\n",
    "    \n",
    "    print(f\"[{epoch}:END] Completed epoch in {time.time() - epoch_start_time}s\")\n",
    "    \n",
    "    print(f\"[{epoch}:{batch_no}]\", \n",
    "          f\"ep_loss_idt_x: {ep_loss_idt_x / len(dataloader):.3f}\", \n",
    "          f\"ep_G_fool_loss: {ep_G_fool_loss / len(dataloader):.3f}\", \n",
    "          f\"ep_cycled_x_loss: {ep_cycled_x_loss / len(dataloader):.3f}\",\n",
    "          f\"ep_D_X_loss: {ep_D_X_loss / len(dataloader):.3f}\")\n",
    "    \n",
    "    print(f\"[{epoch}:{batch_no}]\", \n",
    "          f\"ep_loss_idt_y: {ep_loss_idt_y / len(dataloader):.3f}\", \n",
    "          f\"ep_F_fool_loss: {ep_F_fool_loss / len(dataloader):.3f}\", \n",
    "          f\"ep_cycled_y_loss: {ep_cycled_y_loss / len(dataloader):.3f}\",\n",
    "          f\"ep_D_Y_loss: {ep_D_Y_loss / len(dataloader):.3f}\")\n",
    "    \n",
    "    cyclegan.G.eval()\n",
    "    cyclegan.F.eval()\n",
    "    \n",
    "    if vis is not None:\n",
    "        eval_start_time = time.time()\n",
    "\n",
    "        G_eval_forward = cyclegan.apply(test_xs, x_to_y=True)\n",
    "        F_eval_forward = cyclegan.apply(test_ys, x_to_y=False)\n",
    "\n",
    "        G_rev = cyclegan.apply(G_eval_forward, x_to_y=False)\n",
    "        F_rev = cyclegan.apply(F_eval_forward, x_to_y=True)\n",
    "\n",
    "        G_eval_forward = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in G_eval_forward])\n",
    "        F_eval_forward = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in F_eval_forward])\n",
    "        G_rev = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in G_rev])\n",
    "        F_rev = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in F_rev])\n",
    "\n",
    "        G_eval_grid = torchvision.utils.make_grid(G_eval_forward, nrow=4)\n",
    "        F_eval_grid = torchvision.utils.make_grid(F_eval_forward, nrow=4)\n",
    "        G_rev_grid = torchvision.utils.make_grid(G_rev, nrow=4)\n",
    "        F_rev_grid = torchvision.utils.make_grid(F_rev, nrow=4)\n",
    "        \n",
    "        folder = f\"{cyclegan.save_folder}/{epoch}\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        \n",
    "        torchvision.utils.save_image(G_eval_grid, f\"{folder}/X_to_Y.png\")\n",
    "        torchvision.utils.save_image(F_eval_grid, f\"{folder}/Y_to_X.png\")\n",
    "        torchvision.utils.save_image(G_rev_grid, f\"{folder}/X_to_Y_to_X.png\")\n",
    "        torchvision.utils.save_image(F_rev_grid, f\"{folder}/Y_to_X_to_Y.png\")\n",
    "\n",
    "        vis.image(G_eval_grid, win=\"G_eval\", opts={\n",
    "            \"caption\": f\"X -> Y evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "\n",
    "        vis.image(F_eval_grid, win=\"F_eval\", opts={\n",
    "            \"caption\": f\"Y -> X evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "\n",
    "        vis.image(G_rev_grid, win=\"G_rev\", opts={\n",
    "            \"caption\": f\"X -> Y -> X evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "\n",
    "        vis.image(F_rev_grid, win=\"F_rev\", opts={\n",
    "            \"caption\": f\"Y -> X -> Y evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "\n",
    "        print(f\"[{epoch}:END] Completed eval in {time.time() - eval_start_time}s\")\n",
    "\n",
    "    cyclegan.G.train()\n",
    "    cyclegan.F.train()\n",
    "\n",
    "    cyclegan.step_learning_rates()\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"[{epoch}:END] Saving models and training information permanently\")\n",
    "        cyclegan.save(epoch, full_save=True)\n",
    "        cyclegan.save(epoch, full_save=True, folder=\"latest\")\n",
    "    else:\n",
    "        print(f\"[{epoch}:END] Saving models and training information temporarily to latest and saving generators permanently\")\n",
    "        cyclegan.save(epoch, full_save=True, folder=\"latest\")\n",
    "        cyclegan.save(epoch, full_save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8dbcb-a37c-4cf8-9f39-67f732e93bd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877f5b3-81d8-4927-b150-727b29ead81c",
   "metadata": {},
   "source": [
    "#### Segmentation Masks\n",
    "I start by using the test datasets with Mask-RCNN, the process is as follows:\n",
    "\n",
    "1. Use Mask-RCNN to get the predicted segmentation map for each test image\n",
    "2. Cycle each image such that an image from domain X is cycled from X->Y->X\n",
    "3. Use Mask-RCNN to get the predicted segmentation map for each cycled image\n",
    "4. Compute the per-pixel accuracy\n",
    "\n",
    "I repeat this for both domains to evaluate in both directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd8a84-b3ca-4942-b14e-a334eccbe7bf",
   "metadata": {},
   "source": [
    "I begin by cycling the images from each test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1855afe1-ec3a-489d-8224-7a99842ad031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_transfer_folder = \"./extracted_data/cyclegan_transferred\"\n",
    "test_input_folder = lambda base: f\"./extracted_data/cyclegan_training_data/{base}/Test\"\n",
    "\n",
    "model_parent_folder = \"./runs/CycleGAN/1680981254.7780375\"\n",
    "game_to_movie_path = f\"{model_parent_folder}/latest/G.pth\"\n",
    "movie_to_game_path = f\"{model_parent_folder}/latest/F.pth\"\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ed95801-9c6c-4043-8e7b-5913577cc89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def transfer_style_to_batch(cv2_images, model):\n",
    "    imgs = [preprocess_transform(img) for img in cv2_images]\n",
    "    imgs = torch.stack(imgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        imgs_transferred = model(imgs)\n",
    "    \n",
    "    imgs_transferred = [revert_normalisation(img_t.cpu()) for img_t in imgs_transferred]\n",
    "    return imgs_transferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99231acb-81e1-4b1b-8183-ac73890bf55f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325b37f8dee3454faa189d87db4a2b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d3c1c32eb848c9832ef3a2023e6486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f\"{model_parent_folder}/info_None.json\", \"r\") as fp:\n",
    "    model_info = json.load(fp)\n",
    "\n",
    "upsample_strategy = model_info[\"upsample_strategy\"]\n",
    "block_count = model_info[\"block_count\"]\n",
    "\n",
    "for base in [\"Game\", \"Movie\"]:\n",
    "    other_domain = \"Movie\" if base == \"Game\" else \"Game\"\n",
    "    model_path =  game_to_movie_path if base == \"Game\" else movie_to_game_path\n",
    "    test_folder = test_input_folder(base)\n",
    "    transferred_folder = f\"{base_transfer_folder}/{base}_to_{other_domain}\"\n",
    "    \n",
    "    os.makedirs(transferred_folder)\n",
    "    \n",
    "    model = Generator(block_count, upsample_strategy).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    file_names = [file_name for file_name in os.listdir(test_folder) if file_name.endswith(\".jpg\")]\n",
    "    batch_count = len(file_names) // batch_size + 1\n",
    "    \n",
    "    for batch_no in tqdm(range(batch_count)):\n",
    "        selected_files = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            real_i = batch_size * batch_no + i\n",
    "            \n",
    "            if real_i >= len(file_names):\n",
    "                break\n",
    "            \n",
    "            selected_files.append(file_names[real_i])\n",
    "        \n",
    "        if len(selected_files) == 0:\n",
    "            break\n",
    "            \n",
    "        batch_images = [cv2.cvtColor(cv2.imread(f\"{test_folder}/{file_name}\"), cv2.COLOR_BGR2RGB) for file_name in selected_files]\n",
    "        transferred = transfer_style_to_batch(batch_images, model)\n",
    "        \n",
    "        for file_name, transferred_image in zip(selected_files, transferred):\n",
    "            cv2.imwrite(f\"{transferred_folder}/{''.join(file_name.split('.')[:-1])}_transferred.jpg\", cv2.cvtColor((transferred_image.numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce980d01-e515-45f5-a194-c998ecee9029",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8016e9829fbd48fca443bc33bb5b2e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3de70f247f14db39d2a4037fec09b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f\"{model_parent_folder}/info_None.json\", \"r\") as fp:\n",
    "    model_info = json.load(fp)\n",
    "\n",
    "upsample_strategy = model_info[\"upsample_strategy\"]\n",
    "block_count = model_info[\"block_count\"]\n",
    "\n",
    "for base in [\"Game\", \"Movie\"]:\n",
    "    other_domain = \"Movie\" if base == \"Game\" else \"Game\"\n",
    "    model_path =  movie_to_game_path if base == \"Game\" else game_to_movie_path\n",
    "    test_folder = f\"{base_transfer_folder}/{base}_to_{other_domain}\"\n",
    "    transferred_folder = f\"{base_transfer_folder}/{base}_to_{other_domain}_to_{base}\"\n",
    "    \n",
    "    os.makedirs(transferred_folder)\n",
    "    \n",
    "    model = Generator(block_count, upsample_strategy).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    file_names = [file_name for file_name in os.listdir(test_folder) if file_name.endswith(\".jpg\")]\n",
    "    batch_count = len(file_names) // batch_size + 1\n",
    "    \n",
    "    for batch_no in tqdm(range(batch_count)):\n",
    "        selected_files = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            real_i = batch_size * batch_no + i\n",
    "            \n",
    "            if real_i >= len(file_names):\n",
    "                break\n",
    "            \n",
    "            selected_files.append(file_names[real_i])\n",
    "        \n",
    "        if len(selected_files) == 0:\n",
    "            break\n",
    "            \n",
    "        batch_images = [cv2.cvtColor(cv2.imread(f\"{test_folder}/{file_name}\"), cv2.COLOR_BGR2RGB) for file_name in selected_files]\n",
    "        transferred = transfer_style_to_batch(batch_images, model)\n",
    "        \n",
    "        for file_name, transferred_image in zip(selected_files, transferred):\n",
    "            cv2.imwrite(f\"{transferred_folder}/{''.join(file_name.split('.')[:-1])}_transferred.jpg\", cv2.cvtColor((transferred_image.numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199179a2-7e58-4d80-a5cf-6d5fcac57fb9",
   "metadata": {},
   "source": [
    "Now I pair the original image with the cycled image and compute their segmentation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34a3de8e-8c98-45b1-89ba-1edfbadeaad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_game_folder = \"./extracted_data/cyclegan_training_data/Game/Test\"\n",
    "cycled_game_folder = \"./extracted_data/cyclegan_transferred/Game_to_Movie_to_Game\"\n",
    "original_game_files = [f\"{original_game_folder}/{file_name}\" for file_name in os.listdir(original_game_folder) if file_name.endswith(\".jpg\")]\n",
    "cycled_game_files = [f\"{cycled_game_folder}/{file_name}\" for file_name in os.listdir(cycled_game_folder) if file_name.endswith(\".jpg\")]\n",
    "\n",
    "original_movie_folder = \"./extracted_data/cyclegan_training_data/Movie/Test\"\n",
    "cycled_movie_folder = \"./extracted_data/cyclegan_transferred/Movie_to_Game_to_Movie\"\n",
    "original_movie_files = [f\"{original_movie_folder}/{file_name}\" for file_name in os.listdir(original_movie_folder) if file_name.endswith(\".jpg\")]\n",
    "cycled_movie_files = [f\"{cycled_movie_folder}/{file_name}\" for file_name in os.listdir(cycled_movie_folder) if file_name.endswith(\".jpg\")]\n",
    "\n",
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84134521-daa8-4e35-9384-f97967d3d374",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskrcnn = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "maskrcnn.to(device).eval()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33591941-6f4b-479c-b7d7-1ace0c1df1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 91 COCO class names, directly from Semantic Segmentation Mask R-CNN.ipynb\n",
    "coco_names = ['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15ba50f6-6203-4f3a-b118-eaeaef703f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_segmentation_map(output, frame, threshold):\n",
    "    # Get the relevant model output on to the CPU in a usable format\n",
    "    scores = output[\"scores\"].detach().cpu().numpy()\n",
    "    boxes = output[\"boxes\"].detach().cpu().numpy().astype(int)\n",
    "    label_indices = output[\"labels\"].detach().cpu()\n",
    "    masks = (output[\"masks\"] > 0.5).detach().cpu()\n",
    "    \n",
    "    segmentation_maps = {label: np.zeros(frame.shape[:2]).astype(np.uint8) for label in coco_names[1:]}\n",
    "    \n",
    "    # Process each entry found by the model\n",
    "    for i, (confidence, box, label_idx, mask) in enumerate(zip(scores, boxes, label_indices, masks)):\n",
    "        label = coco_names[label_idx.item()]\n",
    "        \n",
    "        # The confidences are sorted high to low so stop once we're below the threshold\n",
    "        if confidence < threshold:\n",
    "            break\n",
    "        \n",
    "        segmentation_maps[label][(mask == 1).squeeze()] = 1\n",
    "    \n",
    "    return segmentation_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fab73127-6209-48a6-b35d-dd9765ce84a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def measure_segmentation_map_similarity(original_files, cycled_files):\n",
    "    tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mean_accuracies = []\n",
    "    \n",
    "    for original_file_name, cycled_file_name in tqdm(zip(original_files, cycled_files), total=len(original_files)):\n",
    "        original_file = cv2.imread(original_file_name, cv2.IMREAD_COLOR)\n",
    "        cycled_file = cv2.imread(cycled_file_name, cv2.IMREAD_COLOR)\n",
    "        maskrcnn_batch = torch.stack([tensor_transform(original_file), tensor_transform(cycled_file)]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = maskrcnn(maskrcnn_batch)\n",
    "            \n",
    "        original_seg_maps = retrieve_segmentation_map(outputs[0], original_file, threshold)\n",
    "        cycled_seg_maps = retrieve_segmentation_map(outputs[1], cycled_file, threshold)\n",
    "        \n",
    "        ins_accuracies = []\n",
    "        \n",
    "        for label in coco_names[1:]:\n",
    "            original_seg_map = original_seg_maps[label]\n",
    "            cycled_seg_map = cycled_seg_maps[label]\n",
    "            \n",
    "            assert original_seg_map.shape == cycled_seg_map.shape\n",
    "            \n",
    "            if not original_seg_map.any() and not cycled_seg_map.any():\n",
    "                continue\n",
    "            \n",
    "            correct_pixels = ((original_seg_map == 1) & (cycled_seg_map == 1)).sum()\n",
    "            total_pixels = (original_seg_map == 1).sum()\n",
    "            \n",
    "#             dupe_frame = original_file.copy()\n",
    "#             y = np.stack([original_seg_map, original_seg_map, original_seg_map], axis=2).astype(np.uint8)\n",
    "#             cv2.addWeighted(dupe_frame, 1.0, y * 200, 0.6, 0.0, dupe_frame)\n",
    "#             cv2.imwrite(f\"./test_{time.time()}_{label}_org.png\", dupe_frame)\n",
    "            \n",
    "#             dupe_frame = cycled_file.copy()\n",
    "#             y = np.stack([cycled_seg_map, cycled_seg_map, cycled_seg_map], axis=2).astype(np.uint8)\n",
    "#             cv2.addWeighted(dupe_frame, 1.0, y * 200, 0.6, 0.0, dupe_frame)\n",
    "#             cv2.imwrite(f\"./test_{time.time()}_{label}_cycled.png\", dupe_frame)\n",
    "            \n",
    "            if total_pixels == 0:\n",
    "                continue\n",
    "    \n",
    "            accuracy = correct_pixels / total_pixels\n",
    "            ins_accuracies.append(accuracy)\n",
    "            \n",
    "        if len(ins_accuracies) == 0:\n",
    "            continue\n",
    "        \n",
    "        mean_accuracy = sum(ins_accuracies) / len(ins_accuracies)\n",
    "        mean_accuracies.append(mean_accuracy)\n",
    "    \n",
    "    return sum(mean_accuracies) / len(mean_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9f982ba-5ba9-4313-ae44-2e33c65f13cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c7ba8b9de141e28d2c65817014fd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game_fcn = measure_segmentation_map_similarity(original_game_files, cycled_game_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76d56e66-42a1-4924-980d-65039005114d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17743528512730913"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c97258b8-9325-4b6e-9988-429ed75a07d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee75aa2600584d0fb258b924287888f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_fcn = measure_segmentation_map_similarity(original_movie_files, cycled_movie_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c8bfc36-ce5e-4a82-b6d0-b25cb9b50293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3148702631118269"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e07c68-8237-49f2-82ff-33cae1e92f64",
   "metadata": {},
   "source": [
    "#### FID Score\n",
    "Frechlet Inception Distance (FID) is a metric that compares images from the same domain. We can use it to compare real images and fake images that have been style transferred to the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e156aacc-be69-4ba4-bbc0-fc47043442eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cleanfid import fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee8e5dc7-2a63-4a86-9011-6fd3ef5f05e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute FID between two folders\n",
      "Found 208 images in the folder ./extracted_data/cyclegan_training_data/Movie/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Test :   0%|                                                                                 | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "FID Test :  14%|                                                              | 1/7 [00:00<00:01,  3.05it/s]\u001b[A\n",
      "FID Test :  29%|                                                    | 2/7 [00:00<00:01,  3.15it/s]\u001b[A\n",
      "FID Test :  43%|                                         | 3/7 [00:00<00:01,  3.80it/s]\u001b[A\n",
      "FID Test :  57%|                               | 4/7 [00:01<00:00,  4.20it/s]\u001b[A\n",
      "FID Test :  71%|                    | 5/7 [00:01<00:00,  4.46it/s]\u001b[A\n",
      "FID Test :  86%|          | 6/7 [00:01<00:00,  4.65it/s]\u001b[A\n",
      "FID Test : 100%|| 7/7 [00:01<00:00,  4.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images in the folder ./extracted_data/cyclegan_transferred/Game_to_Movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Game_to_Movie :   0%|                                                                       | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "FID Game_to_Movie :   6%|                                                           | 1/16 [00:00<00:02,  5.14it/s]\u001b[A\n",
      "FID Game_to_Movie :  12%|                                                       | 2/16 [00:00<00:02,  5.04it/s]\u001b[A\n",
      "FID Game_to_Movie :  19%|                                                   | 3/16 [00:00<00:02,  5.03it/s]\u001b[A\n",
      "FID Game_to_Movie :  25%|                                               | 4/16 [00:00<00:02,  5.03it/s]\u001b[A\n",
      "FID Game_to_Movie :  31%|                                           | 5/16 [00:00<00:02,  5.02it/s]\u001b[A\n",
      "FID Game_to_Movie :  38%|                                       | 6/16 [00:01<00:01,  5.03it/s]\u001b[A\n",
      "FID Game_to_Movie :  44%|                                   | 7/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      "FID Game_to_Movie :  50%|                               | 8/16 [00:01<00:01,  5.01it/s]\u001b[A\n",
      "FID Game_to_Movie :  56%|                           | 9/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      "FID Game_to_Movie :  62%|                       | 10/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      "FID Game_to_Movie :  69%|                   | 11/16 [00:02<00:00,  5.02it/s]\u001b[A\n",
      "FID Game_to_Movie :  75%|               | 12/16 [00:02<00:00,  5.01it/s]\u001b[A\n",
      "FID Game_to_Movie :  81%|           | 13/16 [00:02<00:00,  5.02it/s]\u001b[A\n",
      "FID Game_to_Movie :  88%|       | 14/16 [00:02<00:00,  5.01it/s]\u001b[A\n",
      "FID Game_to_Movie :  94%|   | 15/16 [00:02<00:00,  5.00it/s]\u001b[A\n",
      "FID Game_to_Movie : 100%|| 16/16 [00:03<00:00,  5.12it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_fid(test_input_folder(\"Movie\"), \"./extracted_data/cyclegan_transferred/Game_to_Movie\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "364be512-4df4-4995-a72e-beee52cc17f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203.8488544514551"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02cd1734-f75b-40d5-b019-02110a50de76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute KID between two folders\n",
      "Found 208 images in the folder ./extracted_data/cyclegan_training_data/Movie/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Test :   0%|                                                                                 | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "KID Test :  14%|                                                              | 1/7 [00:00<00:01,  3.81it/s]\u001b[A\n",
      "KID Test :  29%|                                                    | 2/7 [00:00<00:01,  3.49it/s]\u001b[A\n",
      "KID Test :  43%|                                         | 3/7 [00:00<00:00,  4.06it/s]\u001b[A\n",
      "KID Test :  57%|                               | 4/7 [00:00<00:00,  4.39it/s]\u001b[A\n",
      "KID Test :  71%|                    | 5/7 [00:01<00:00,  4.61it/s]\u001b[A\n",
      "KID Test :  86%|          | 6/7 [00:01<00:00,  4.75it/s]\u001b[A\n",
      "KID Test : 100%|| 7/7 [00:01<00:00,  4.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images in the folder ./extracted_data/cyclegan_transferred/Game_to_Movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Game_to_Movie :   0%|                                                                       | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "KID Game_to_Movie :   6%|                                                           | 1/16 [00:00<00:02,  5.09it/s]\u001b[A\n",
      "KID Game_to_Movie :  12%|                                                       | 2/16 [00:00<00:02,  5.06it/s]\u001b[A\n",
      "KID Game_to_Movie :  19%|                                                   | 3/16 [00:00<00:02,  4.73it/s]\u001b[A\n",
      "KID Game_to_Movie :  25%|                                               | 4/16 [00:00<00:02,  4.71it/s]\u001b[A\n",
      "KID Game_to_Movie :  31%|                                           | 5/16 [00:01<00:02,  4.82it/s]\u001b[A\n",
      "KID Game_to_Movie :  38%|                                       | 6/16 [00:01<00:02,  4.88it/s]\u001b[A\n",
      "KID Game_to_Movie :  44%|                                   | 7/16 [00:01<00:01,  4.93it/s]\u001b[A\n",
      "KID Game_to_Movie :  50%|                               | 8/16 [00:01<00:01,  4.97it/s]\u001b[A\n",
      "KID Game_to_Movie :  56%|                           | 9/16 [00:01<00:01,  4.99it/s]\u001b[A\n",
      "KID Game_to_Movie :  62%|                       | 10/16 [00:02<00:01,  5.01it/s]\u001b[A\n",
      "KID Game_to_Movie :  69%|                   | 11/16 [00:02<00:00,  5.01it/s]\u001b[A\n",
      "KID Game_to_Movie :  75%|               | 12/16 [00:02<00:00,  5.00it/s]\u001b[A\n",
      "KID Game_to_Movie :  81%|           | 13/16 [00:02<00:00,  5.01it/s]\u001b[A\n",
      "KID Game_to_Movie :  88%|       | 14/16 [00:02<00:00,  5.01it/s]\u001b[A\n",
      "KID Game_to_Movie :  94%|   | 15/16 [00:03<00:00,  5.02it/s]\u001b[A\n",
      "KID Game_to_Movie : 100%|| 16/16 [00:03<00:00,  5.06it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_kid(test_input_folder(\"Movie\"), \"./extracted_data/cyclegan_transferred/Game_to_Movie\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd7bb7ef-ea8d-4d81-b878-198e1ce04482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06530696913277523"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90d5db94-d105-4887-ab04-cdab640b4177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute FID between two folders\n",
      "Found 500 images in the folder ./extracted_data/cyclegan_training_data/Game/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Test :   0%|                                                                                | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "FID Test :   6%|                                                                   | 1/16 [00:00<00:03,  3.76it/s]\u001b[A\n",
      "FID Test :  12%|                                                               | 2/16 [00:00<00:04,  3.47it/s]\u001b[A\n",
      "FID Test :  19%|                                                          | 3/16 [00:00<00:03,  4.04it/s]\u001b[A\n",
      "FID Test :  25%|                                                      | 4/16 [00:00<00:02,  4.38it/s]\u001b[A\n",
      "FID Test :  31%|                                                 | 5/16 [00:01<00:02,  4.60it/s]\u001b[A\n",
      "FID Test :  38%|                                             | 6/16 [00:01<00:02,  4.75it/s]\u001b[A\n",
      "FID Test :  44%|                                        | 7/16 [00:01<00:01,  4.84it/s]\u001b[A\n",
      "FID Test :  50%|                                    | 8/16 [00:01<00:01,  4.91it/s]\u001b[A\n",
      "FID Test :  56%|                               | 9/16 [00:01<00:01,  4.96it/s]\u001b[A\n",
      "FID Test :  62%|                          | 10/16 [00:02<00:01,  4.99it/s]\u001b[A\n",
      "FID Test :  69%|                      | 11/16 [00:02<00:00,  5.00it/s]\u001b[A\n",
      "FID Test :  75%|                 | 12/16 [00:02<00:00,  5.01it/s]\u001b[A\n",
      "FID Test :  81%|             | 13/16 [00:02<00:00,  5.02it/s]\u001b[A\n",
      "FID Test :  88%|        | 14/16 [00:02<00:00,  5.04it/s]\u001b[A\n",
      "FID Test :  94%|    | 15/16 [00:03<00:00,  5.04it/s]\u001b[A\n",
      "FID Test : 100%|| 16/16 [00:03<00:00,  4.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 images in the folder ./extracted_data/cyclegan_transferred/Movie_to_Game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Movie_to_Game :   0%|                                                                        | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "FID Movie_to_Game :  14%|                                                      | 1/7 [00:00<00:01,  5.09it/s]\u001b[A\n",
      "FID Movie_to_Game :  29%|                                             | 2/7 [00:00<00:00,  5.01it/s]\u001b[A\n",
      "FID Movie_to_Game :  43%|                                    | 3/7 [00:00<00:00,  5.04it/s]\u001b[A\n",
      "FID Movie_to_Game :  57%|                           | 4/7 [00:00<00:00,  5.02it/s]\u001b[A\n",
      "FID Movie_to_Game :  71%|                  | 5/7 [00:00<00:00,  5.02it/s]\u001b[A\n",
      "FID Movie_to_Game :  86%|         | 6/7 [00:01<00:00,  5.03it/s]\u001b[A\n",
      "FID Movie_to_Game : 100%|| 7/7 [00:01<00:00,  5.38it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_fid(test_input_folder(\"Game\"), \"./extracted_data/cyclegan_transferred/Movie_to_Game\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1325cfab-ad2e-40b5-bffd-09785a22623c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.97430151011105"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c6696e2-74bb-46dd-8f1d-8d4a07c89a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute KID between two folders\n",
      "Found 500 images in the folder ./extracted_data/cyclegan_training_data/Game/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Test :   0%|                                                                                | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "KID Test :   6%|                                                                   | 1/16 [00:00<00:03,  3.76it/s]\u001b[A\n",
      "KID Test :  12%|                                                               | 2/16 [00:00<00:04,  3.47it/s]\u001b[A\n",
      "KID Test :  19%|                                                          | 3/16 [00:00<00:03,  4.05it/s]\u001b[A\n",
      "KID Test :  25%|                                                      | 4/16 [00:00<00:02,  4.40it/s]\u001b[A\n",
      "KID Test :  31%|                                                 | 5/16 [00:01<00:02,  4.60it/s]\u001b[A\n",
      "KID Test :  38%|                                             | 6/16 [00:01<00:02,  4.73it/s]\u001b[A\n",
      "KID Test :  44%|                                        | 7/16 [00:01<00:01,  4.84it/s]\u001b[A\n",
      "KID Test :  50%|                                    | 8/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      "KID Test :  56%|                               | 9/16 [00:01<00:01,  4.95it/s]\u001b[A\n",
      "KID Test :  62%|                          | 10/16 [00:02<00:01,  4.99it/s]\u001b[A\n",
      "KID Test :  69%|                      | 11/16 [00:02<00:00,  5.01it/s]\u001b[A\n",
      "KID Test :  75%|                 | 12/16 [00:02<00:00,  5.02it/s]\u001b[A\n",
      "KID Test :  81%|             | 13/16 [00:02<00:00,  5.03it/s]\u001b[A\n",
      "KID Test :  88%|        | 14/16 [00:02<00:00,  5.04it/s]\u001b[A\n",
      "KID Test :  94%|    | 15/16 [00:03<00:00,  5.05it/s]\u001b[A\n",
      "KID Test : 100%|| 16/16 [00:03<00:00,  4.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 images in the folder ./extracted_data/cyclegan_transferred/Movie_to_Game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Movie_to_Game :   0%|                                                                        | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "KID Movie_to_Game :  14%|                                                      | 1/7 [00:00<00:01,  5.14it/s]\u001b[A\n",
      "KID Movie_to_Game :  29%|                                             | 2/7 [00:00<00:00,  5.08it/s]\u001b[A\n",
      "KID Movie_to_Game :  43%|                                    | 3/7 [00:00<00:00,  5.06it/s]\u001b[A\n",
      "KID Movie_to_Game :  57%|                           | 4/7 [00:00<00:00,  5.05it/s]\u001b[A\n",
      "KID Movie_to_Game :  71%|                  | 5/7 [00:00<00:00,  5.05it/s]\u001b[A\n",
      "KID Movie_to_Game :  86%|         | 6/7 [00:01<00:00,  5.05it/s]\u001b[A\n",
      "KID Movie_to_Game : 100%|| 7/7 [00:01<00:00,  5.40it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_kid(test_input_folder(\"Game\"), \"./extracted_data/cyclegan_transferred/Movie_to_Game\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "769245a6-ac28-4ad1-8652-1b454a68130e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04745902568273118"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d6d6b-fae0-4c73-b560-f026ed9904cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Video Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0163f7f0-9dcc-49fe-b606-2101bea4e60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_video(video_path, save_loc, model, batch_size=4):\n",
    "    # Try to delete the existing saved file\n",
    "    try:\n",
    "        os.remove(save_loc)\n",
    "    except OSError:\n",
    "        pass \n",
    "    \n",
    "    video = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    success, frame = video.read()\n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    frame_buffer = []\n",
    "    video_out = cv2.VideoWriter(save_loc, -1, fps, (width, height))\n",
    "    \n",
    "    with tqdm(total=total_frames) as progress:\n",
    "        while success:\n",
    "            frame_buffer.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            if len(frame_buffer) == batch_size:\n",
    "                transferred_frames = transfer_style_to_batch(frame_buffer, model)\n",
    "\n",
    "                for out_frame in transferred_frames:\n",
    "                    coloured_out_frame = cv2.cvtColor((out_frame.numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "                    video_out.write(coloured_out_frame)\n",
    "\n",
    "                frame_buffer = []\n",
    "\n",
    "            success, frame = video.read()\n",
    "            progress.update(1)\n",
    "    \n",
    "    if len(frame_buffer) != 0:\n",
    "        # Process any additional final frames that don't make a full batch\n",
    "        transferred_frames = transfer_style_to_batch(frame_buffer, model)\n",
    "\n",
    "        for out_frame in transferred_frames:\n",
    "            coloured_out_frame = cv2.cvtColor((out_frame.numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "            video_out.write(coloured_out_frame)\n",
    "    \n",
    "    video_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ab9e22d-f9c6-4f4e-bd32-866e43d164cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_time = \"1680981254.7780375\"\n",
    "model_parent_directory = f\"./runs/CycleGAN/{model_time}\"\n",
    "epoch_directory = \"latest\"\n",
    "model_name = \"F.pth\" # F: Y -> X which is the style transfer we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0265f3d6-ba8b-45e7-b26a-60668fee48e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{model_parent_directory}/info_None.json\", \"r\") as fp:\n",
    "    model_info = json.load(fp)\n",
    "\n",
    "upsample_strategy = model_info[\"upsample_strategy\"]\n",
    "block_count = model_info[\"block_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81de7445-e038-41ed-90e9-3bba84193397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Generator(block_count, upsample_strategy).to(device)\n",
    "model.load_state_dict(torch.load(f\"{model_parent_directory}/{epoch_directory}/{model_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0abb0ca0-fb9e-4f1b-a5ed-4c5c169c44d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_video_path = \"./original_data/Test/Test Movie.mp4\"\n",
    "output_video_path = f\"./video_transfer/cyclegan_{model_time}.mp4\"\n",
    "batch_size = 4\n",
    "\n",
    "os.makedirs(\"./video_transfer\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58bae42e-83e9-4026-b02b-03bdee9bfffb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aad09e3f6bc40bfb65ec819589b7ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_video(input_video_path, output_video_path, model, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5627c870-ef8e-4dc9-9cab-73ce48b3db99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2: Local (temporal) Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b44cf89-80a9-4d27-9cf1-d7945b9fa747",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Generation\n",
    "Unlike CycleGAN, the data generated in Question 1 cannot be used directly with RecycleGAN. I firstly need to process the data from Q1.2 to create triplets. These are 3 consecutive human patches concatenated together. There is no overlap between triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2b10ce9-f7cf-4309-a96c-f72b0744ea21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456fc93ca405418aa875464ff6c09a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99070d39c9742c38e3c81fb266d7c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4011 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99aff778729a428dbda8552de3bfe7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fa695f09274062968cfac18a456b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb0eb4b6f2a4d8e9380696775d215c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b9c7c732904d46a0682a4a511c0061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0458c79a41954428980b8fae2a560c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5331 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1996df2d467d4723aa3d44de69ea0316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [\"Full Body Sitting\", \"Full Body Standing\", \"Half Body\", \"Head Only\"]\n",
    "base_pose_directory = \"./extracted_data/classified_human_patches\"\n",
    "cutoff = 8\n",
    "window = 5\n",
    "\n",
    "game_groups = group_classes(f\"{base_pose_directory}/Train/Game\", classes, cutoff, window) \n",
    "movie_groups = group_classes(f\"{base_pose_directory}/Train/Movie\", classes, cutoff, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "816db814-e3b7-4949-bb49-c7cc7ce93d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_test_count = 250\n",
    "target_train_count = 600\n",
    "min_triplets_from_clip = 3\n",
    "max_triplets_from_clip = 5\n",
    "output_size = 256\n",
    "min_size = 96\n",
    "\n",
    "train_output_directory = lambda base: f\"./extracted_data/recyclegan_training_data/{base}/Train\"\n",
    "test_output_directory = lambda base: f\"./extracted_data/recyclegan_training_data/{base}/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a036bb7-8a95-4ae4-9c5b-d8dbec54431f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_available_triplet_lengths(groups, min_triplets_from_clip):\n",
    "    lengths = {}\n",
    "    min_length = min_triplets_from_clip * 3\n",
    "    excluded_count = 0\n",
    "\n",
    "    for group in groups:\n",
    "        l = len(group)\n",
    "\n",
    "        if l < min_length:\n",
    "            excluded_count += l\n",
    "            continue\n",
    "\n",
    "        if l not in lengths.keys():\n",
    "            lengths[l] = 0\n",
    "\n",
    "        lengths[l] += 1\n",
    "    \n",
    "    return lengths, excluded_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8c34b137-5f3b-4d4f-919a-946dc7db3d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_recyclegan_train_test_split(groups, train_dir, test_dir, train_count, test_count, min_triplets_from_clip, max_triplets_from_clip):\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "    lengths, excluded_count = compute_available_triplet_lengths(groups, min_triplets_from_clip)\n",
    "    test_save_prob = test_count / excluded_count\n",
    "    min_length = min_triplets_from_clip * 3\n",
    "    \n",
    "    for group_no, group in enumerate(tqdm(groups)):\n",
    "        if len(group) < min_length:\n",
    "            for i in range(len(group)):\n",
    "                if random.uniform(0, 1) < test_save_prob:\n",
    "                    Image.open(group[i]).save(f\"{test_dir}/{group_no:05d}_{i:05d}.jpg\")\n",
    "\n",
    "            continue \n",
    "        \n",
    "        triplet_count = len(group) // 3\n",
    "        selection_count = min(triplet_count, max_triplets_from_clip)\n",
    "        selected_triplets = random.sample(range(triplet_count), k=selection_count)\n",
    "        \n",
    "        for i in selected_triplets:\n",
    "            triplet_image = Image.new(\"RGB\", (3 * output_size, output_size))\n",
    "\n",
    "            x = Image.open(group[3 * i])\n",
    "            y = Image.open(group[3 * i + 1])\n",
    "            z = Image.open(group[3 * i + 2])\n",
    "\n",
    "            if x.width < min_size or x.height < min_size:\n",
    "                continue\n",
    "\n",
    "            if y.width < min_size or y.height < min_size:\n",
    "                continue\n",
    "\n",
    "            if z.width < min_size or z.height < min_size:\n",
    "                continue\n",
    "\n",
    "            triplet_image.paste(x.resize((output_size, output_size)), (0, 0))\n",
    "            triplet_image.paste(y.resize((output_size, output_size)), (output_size, 0))\n",
    "            triplet_image.paste(z.resize((output_size, output_size)), (2 * output_size, 0))\n",
    "\n",
    "            triplet_image.save(f\"{train_dir}/{group_no:05d}_{i:05d}.jpg\")\n",
    "    \n",
    "    valid_input_files = [file_name for file_name in os.listdir(train_dir) if file_name.endswith(\".jpg\")]\n",
    "    print(\"Uncapped Train Size:\", len(valid_input_files))\n",
    "    \n",
    "    if len(valid_input_files) > train_count:\n",
    "        selected_for_delete = random.sample(valid_input_files, k=len(valid_input_files) - train_count)\n",
    "\n",
    "        for file_name in selected_for_delete:\n",
    "            os.remove(f\"{train_dir}/{file_name}\")\n",
    "\n",
    "        print(\"Deleted\", len(selected_for_delete), \"files\")\n",
    "    \n",
    "    print(\"Capped Train Size:\", len([file_name for file_name in os.listdir(train_dir) if file_name.endswith(\".jpg\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "114cec97-7ac9-48e7-86d1-050b7d99db04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479a7eb6d39f4a4dbab63ed691add358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncapped Train Size: 1299\n",
      "Deleted 699 files\n",
      "Capped Train Size: 600\n"
     ]
    }
   ],
   "source": [
    "create_recyclegan_train_test_split(game_groups, train_output_directory(\"Game\"), test_output_directory(\"Game\"), target_train_count, target_test_count, min_triplets_from_clip, max_triplets_from_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c27f2d7-cfe1-4787-a439-b941fdbd4729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e7fb64a08240649c516a5e75958e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncapped Train Size: 688\n",
      "Deleted 88 files\n",
      "Capped Train Size: 600\n"
     ]
    }
   ],
   "source": [
    "create_recyclegan_train_test_split(movie_groups, train_output_directory(\"Movie\"), test_output_directory(\"Movie\"), target_train_count, target_test_count, min_triplets_from_clip, max_triplets_from_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631a0033-fdea-409f-8969-977ba273d586",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e26624e2-4f41-4674-b40e-2b08380f0325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using_google_gpus = False\n",
    "\n",
    "train_X_loc = \"./extracted_data/recyclegan_training_data/Game/Train\" \n",
    "test_X_loc = \"./extracted_data/recyclegan_training_data/Game/Test\" \n",
    "\n",
    "train_Y_loc = \"./extracted_data/recyclegan_training_data/Movie/Train\" \n",
    "test_Y_loc = \"./extracted_data/recyclegan_training_data/Movie/Test\" \n",
    "\n",
    "run_data_directory = \"./runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e49bb616-39f9-49d2-9f69-ec617524b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "if using_google_gpus:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    vis = None\n",
    "else:\n",
    "    import visdom\n",
    "    vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a2cb104-c5c2-45f8-828e-190864efe112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: 'drive/MyDrive/cyclegan'\n",
      "F:\\Documents\\Development\\GitHub\\advanced-computer-vision-y4\\code\\submission_test\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/cyclegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a0d6745-5b4c-4393-b14f-f785d696ce17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = JointDomainTripletDataset(train_X_loc, train_Y_loc, train=True, img_size=256)\n",
    "test_dataset = JointDomainImageDataset(test_X_loc, test_Y_loc, train=False, img_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e01f3307-79a8-4b5a-8a59-509326530f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs = []\n",
    "test_ys = []\n",
    "\n",
    "for i in random.sample(range(0, len(test_dataset)), 16):\n",
    "    x, y = test_dataset[i]\n",
    "    test_xs.append(x)\n",
    "    test_ys.append(y)\n",
    "\n",
    "test_xs = torch.stack(test_xs)\n",
    "test_ys = torch.stack(test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5e53467f-44bb-44a5-b5cc-d0044cff8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis is not None:\n",
    "    vis.images(torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in test_xs]), nrow=4, opts={\"title\": \"X_test originals\"})\n",
    "    vis.images(torch.stack([revert_normalisation(y).permute(2, 0, 1) for y in test_ys]), nrow=4, opts={\"title\": \"Y_test originals\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04515947-c0d7-4c18-9bef-e13c1c346751",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_dataset[random.randint(0, len(test_dataset))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47f8e894-58f5-4ffc-9e57-8b696be0d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9608) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(test_img.min(), test_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56e79b33-6f23-483e-99ac-d9e5b0255d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1755e2ab8b0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c64e8195-d39d-4d75-9a5e-9afbb456fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x174bcd9a230>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(revert_normalisation(test_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a713bdd-a544-45a1-988c-d2449219011d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8eeadc15-172b-4213-8dd7-595c6c1e04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 100\n",
    "lambda_weight = 5\n",
    "lambda_idt_X = 0.5\n",
    "lambda_idt_Y = 0.5\n",
    "\n",
    "blocks = 6\n",
    "upsample_strategy = [\"upsample\", \"conv_transpose\", \"pixel_shuffle\"][0]\n",
    "pool_size = 20\n",
    "opt_scheduler_type = \"linear_decay_with_warmup\"\n",
    "\n",
    "checkpoint_instance_dir = None\n",
    "checkpoint_epoch_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0658f697-ca61-4a6f-ba1f-abd9cc485f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f88c31e2-fe43-420a-ac7f-094a3559ce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save folder: ./runs/RecycleGAN/1681138017.3112457\n",
      "Initialised weights\n"
     ]
    }
   ],
   "source": [
    "if checkpoint_instance_dir is not None and checkpoint_epoch_dir is not None:\n",
    "    cyclegan = RecycleGAN.load(f\"{run_data_directory}/{checkpoint_instance_dir}\", f\"{checkpoint_epoch_dir}\", device, blocks)\n",
    "else:\n",
    "    cyclegan = RecycleGAN(blocks, upsample_strategy, device, pool_size, opt_scheduler_type, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c442bcbf-8ac7-4a62-a1a1-31bc35b7d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{cyclegan.save_folder}/info_{checkpoint_epoch_dir}.json\", \"w+\") as fp:\n",
    "    json.dump({\n",
    "        \"block_count\": cyclegan.resnet_block_count,\n",
    "        \"upsample_strategy\": upsample_strategy,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"opt_scheduler_type\": opt_scheduler_type,\n",
    "        \"data_folders\": {\n",
    "            \"train_X\": train_X_loc,\n",
    "            \"test_X\": test_X_loc,\n",
    "            \"train_Y\": train_Y_loc,\n",
    "            \"test_Y\": test_Y_loc\n",
    "        },\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_epochs\": epochs,\n",
    "        \"start_epoch\": cyclegan.start_epoch,\n",
    "        \"lambda_weight\": lambda_weight,\n",
    "        \"lambda_idt_X\": lambda_idt_X,\n",
    "        \"lambda_idt_Y\": lambda_idt_Y,\n",
    "        \"checkpoint\": {\n",
    "            \"instance\": checkpoint_instance_dir,\n",
    "            \"epoch\": checkpoint_epoch_dir\n",
    "        }\n",
    "    }, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d092986-28a4-48d2-8f29-a8eacb55eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could also enable random flipping\n",
    "def generate_noisy_labels(shape, real, device):\n",
    "    # Randomly generated between 0 and 1\n",
    "    labels = torch.rand(shape, device=device)\n",
    "    \n",
    "    if real:\n",
    "        # Now they are between 0.7 and 1.1\n",
    "        labels = (2 * labels / 5) + 0.7\n",
    "    else:\n",
    "        # Now they are between 0 and 0.3\n",
    "        labels = (labels * 3) / 10\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e7e8713a-f86c-4c3a-894b-c12a4a5e97ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_loss(real, fake, pool, discriminator, loss_func):\n",
    "    # Discriminator should give (1) for a real image and (0) for a fake\n",
    "    real_pred = discriminator(real)\n",
    "    real_loss = loss_func(real_pred, generate_noisy_labels(real_pred.shape, True, device)) # Should dampen?\n",
    "    \n",
    "    # We draw from the history buffer\n",
    "    pool_fake = pool.randomise_existing_batch(fake)\n",
    "    fake_pred = discriminator(pool_fake)\n",
    "    # Fake images should not fool the discriminator\n",
    "    fake_loss = loss_func(fake_pred.detach(), generate_noisy_labels(fake_pred.shape, False, device))\n",
    "    \n",
    "    avg_loss = (real_loss + fake_loss) * 0.5\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3a462990-62f3-4551-9681-8866c0d5f57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch\n",
      "[1:100] Took 128.80s\n",
      "[1:100] loss_idt_x: 0.5541572569310665, G_fool_loss: 1.2144887962937354, predictor_x_loss: 0.5378934526443482, cycled_x_loss: 0.5712447628378868, D_X_loss: 2.9364376056194303\n",
      "[1:100] loss_idt_y: 0.5900187434256077, F_fool_loss: 1.1524032039940357, predictor_y_loss: 0.6516065680980683, cycled_y_loss: 0.6338832598924636, D_Y_loss: 2.9707430136203765\n",
      "[1:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[1:200] Took 115.73s\n",
      "[1:200] loss_idt_x: 0.4161659163236618, G_fool_loss: 0.24905044183135033, predictor_x_loss: 0.3754124814271927, cycled_x_loss: 0.43967310324311254, D_X_loss: 1.4462473320960998\n",
      "[1:200] loss_idt_y: 0.4895300783216953, F_fool_loss: 0.2763815892487764, predictor_y_loss: 0.4596289026737213, cycled_y_loss: 0.5378765086829662, D_Y_loss: 1.3951566183567048\n",
      "[1:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[1:300] Took 115.53s\n",
      "[1:300] loss_idt_x: 0.42299161195755003, G_fool_loss: 0.16848139703273773, predictor_x_loss: 0.35075939163565634, cycled_x_loss: 0.44194781959056856, D_X_loss: 1.303431876897812\n",
      "[1:300] loss_idt_y: 0.4049713583290577, F_fool_loss: 0.1680648285895586, predictor_y_loss: 0.38386145159602164, cycled_y_loss: 0.44329635217785834, D_Y_loss: 1.270789338350296\n",
      "[1:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[1:400] Took 115.90s\n",
      "[1:400] loss_idt_x: 0.39949522286653516, G_fool_loss: 0.12235473532229663, predictor_x_loss: 0.32327586725354196, cycled_x_loss: 0.4202415293455124, D_X_loss: 1.2775896400213242\n",
      "[1:400] loss_idt_y: 0.36992462530732156, F_fool_loss: 0.15645324729382992, predictor_y_loss: 0.35465271085500716, cycled_y_loss: 0.42205185920000077, D_Y_loss: 1.2085845112800597\n",
      "[1:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[1:500] Took 118.36s\n",
      "[1:500] loss_idt_x: 0.414029787927866, G_fool_loss: 0.18849867407232523, predictor_x_loss: 0.3262491223216057, cycled_x_loss: 0.4390807376801968, D_X_loss: 1.2891690087318421\n",
      "[1:500] loss_idt_y: 0.3668980322778225, F_fool_loss: 0.15737695522606374, predictor_y_loss: 0.35168762266635895, cycled_y_loss: 0.40926281705498696, D_Y_loss: 1.2771394598484038\n",
      "[1:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[1:END] Completed epoch in 714.546900510788s\n",
      "[1:599] ep_loss_idt_x: 0.436 ep_G_fool_loss: 0.367 ep_predictor_x_loss: 0.369 ep_cycled_x_loss: 0.454 ep_D_X_loss: 1.609\n",
      "[1:599] ep_loss_idt_y: 0.421 ep_F_fool_loss: 0.353 ep_predictor_y_loss: 0.420 ep_cycled_y_loss: 0.464 ep_D_Y_loss: 1.583\n",
      "[1:END] Completed eval in 4.0159101486206055s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[1:END] Saving models and training information permanently\n",
      "[2:100] Took 122.56s\n",
      "[2:100] loss_idt_x: 0.37981444984674456, G_fool_loss: 0.18489602662622928, predictor_x_loss: 0.2966231882572174, cycled_x_loss: 0.4008539481461048, D_X_loss: 1.2903371846675873\n",
      "[2:100] loss_idt_y: 0.3044941484183073, F_fool_loss: 0.12113097067922354, predictor_y_loss: 0.3009776829183102, cycled_y_loss: 0.3211897432804108, D_Y_loss: 1.2887738978862762\n",
      "[2:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[2:200] Took 115.29s\n",
      "[2:200] loss_idt_x: 0.38230681031942365, G_fool_loss: 0.12440819650888443, predictor_x_loss: 0.2940587528049946, cycled_x_loss: 0.40037849962711336, D_X_loss: 1.2795087188482284\n",
      "[2:200] loss_idt_y: 0.2753062500059605, F_fool_loss: 0.13933739487081767, predictor_y_loss: 0.30626972660422325, cycled_y_loss: 0.3065044030547142, D_Y_loss: 1.2038887947797776\n",
      "[2:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[2:300] Took 114.78s\n",
      "[2:300] loss_idt_x: 0.39695427715778353, G_fool_loss: 0.17608457460999488, predictor_x_loss: 0.3002462139725685, cycled_x_loss: 0.40781624391675, D_X_loss: 1.3095639890432358\n",
      "[2:300] loss_idt_y: 0.27500190027058125, F_fool_loss: 0.14203383930027486, predictor_y_loss: 0.2956050372123718, cycled_y_loss: 0.30832576483488083, D_Y_loss: 1.2732991629838943\n",
      "[2:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[2:400] Took 114.79s\n",
      "[2:400] loss_idt_x: 0.4128225617110729, G_fool_loss: 0.1705954936146736, predictor_x_loss: 0.29979800671339035, cycled_x_loss: 0.4296533937752247, D_X_loss: 1.3247327756881715\n",
      "[2:400] loss_idt_y: 0.26282991111278536, F_fool_loss: 0.16011916253715752, predictor_y_loss: 0.27756986320018767, cycled_y_loss: 0.30059745609760286, D_Y_loss: 1.2638836354017258\n",
      "[2:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[2:500] Took 113.64s\n",
      "[2:500] loss_idt_x: 0.36388067916035655, G_fool_loss: 0.1781208748370409, predictor_x_loss: 0.27480324521660804, cycled_x_loss: 0.3712975898385048, D_X_loss: 1.4469488370418548\n",
      "[2:500] loss_idt_y: 0.25717737786471845, F_fool_loss: 0.2824617784842849, predictor_y_loss: 0.2739641259610653, cycled_y_loss: 0.2873384004831314, D_Y_loss: 1.3011565256118773\n",
      "[2:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[2:END] Completed epoch in 694.58012342453s\n",
      "[2:599] ep_loss_idt_x: 0.381 ep_G_fool_loss: 0.158 ep_predictor_x_loss: 0.289 ep_cycled_x_loss: 0.395 ep_D_X_loss: 1.320\n",
      "[2:599] ep_loss_idt_y: 0.272 ep_F_fool_loss: 0.161 ep_predictor_y_loss: 0.290 ep_cycled_y_loss: 0.301 ep_D_Y_loss: 1.253\n",
      "[2:END] Completed eval in 3.866661310195923s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[2:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[3:100] Took 122.25s\n",
      "[3:100] loss_idt_x: 0.36567504569888115, G_fool_loss: 0.09643359303474426, predictor_x_loss: 0.2803066538274288, cycled_x_loss: 0.37391812771558763, D_X_loss: 1.301884736418724\n",
      "[3:100] loss_idt_y: 0.24836583577096463, F_fool_loss: 0.1169790517538786, predictor_y_loss: 0.27652580946683886, cycled_y_loss: 0.2881274449825287, D_Y_loss: 1.1746455305814743\n",
      "[3:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[3:200] Took 134.47s\n",
      "[3:200] loss_idt_x: 0.3518437221646309, G_fool_loss: 0.17158770497888326, predictor_x_loss: 0.259387541860342, cycled_x_loss: 0.3618892629444599, D_X_loss: 1.2771224230527878\n",
      "[3:200] loss_idt_y: 0.26081936158239843, F_fool_loss: 0.13635542042553425, predictor_y_loss: 0.27312648557126523, cycled_y_loss: 0.27953727066516876, D_Y_loss: 1.2871971386671066\n",
      "[3:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[3:300] Took 111.55s\n",
      "[3:300] loss_idt_x: 0.3468095216155052, G_fool_loss: 0.16914989586919546, predictor_x_loss: 0.27113245069980624, cycled_x_loss: 0.360842464864254, D_X_loss: 1.2990126526355743\n",
      "[3:300] loss_idt_y: 0.28054183185100556, F_fool_loss: 0.14163403164595365, predictor_y_loss: 0.28216007083654404, cycled_y_loss: 0.29215836301445963, D_Y_loss: 1.2656030368804931\n",
      "[3:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[3:400] Took 123.59s\n",
      "[3:400] loss_idt_x: 0.34450981959700583, G_fool_loss: 0.16247335132211446, predictor_x_loss: 0.26285992622375487, cycled_x_loss: 0.3554223942756653, D_X_loss: 1.3058390641212463\n",
      "[3:400] loss_idt_y: 0.23039669953286648, F_fool_loss: 0.14064686439931393, predictor_y_loss: 0.2765432487428188, cycled_y_loss: 0.23809556245803834, D_Y_loss: 1.2994556879997254\n",
      "[3:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[3:500] Took 151.49s\n",
      "[3:500] loss_idt_x: 0.35481930926442146, G_fool_loss: 0.13471934042870998, predictor_x_loss: 0.26939553692936896, cycled_x_loss: 0.36912110209465027, D_X_loss: 1.2994977754354478\n",
      "[3:500] loss_idt_y: 0.2608072169870138, F_fool_loss: 0.14781817574054001, predictor_y_loss: 0.274975094795227, cycled_y_loss: 0.277555510699749, D_Y_loss: 1.2372521024942398\n",
      "[3:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[3:END] Completed epoch in 840.7131388187408s\n",
      "[3:599] ep_loss_idt_x: 0.354 ep_G_fool_loss: 0.144 ep_predictor_x_loss: 0.267 ep_cycled_x_loss: 0.362 ep_D_X_loss: 1.292\n",
      "[3:599] ep_loss_idt_y: 0.255 ep_F_fool_loss: 0.133 ep_predictor_y_loss: 0.274 ep_cycled_y_loss: 0.272 ep_D_Y_loss: 1.242\n",
      "[3:END] Completed eval in 4.035855531692505s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[3:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[4:100] Took 133.50s\n",
      "[4:100] loss_idt_x: 0.3433039779961109, G_fool_loss: 0.18061096530407666, predictor_x_loss: 0.26342199727892873, cycled_x_loss: 0.34939447924494743, D_X_loss: 1.3452811276912688\n",
      "[4:100] loss_idt_y: 0.22160718888044356, F_fool_loss: 0.17696927834302187, predictor_y_loss: 0.2599813197553158, cycled_y_loss: 0.24390724509954453, D_Y_loss: 1.2999521702528\n",
      "[4:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[4:200] Took 127.63s\n",
      "[4:200] loss_idt_x: 0.34421329736709594, G_fool_loss: 0.15936167195439338, predictor_x_loss: 0.25603827089071274, cycled_x_loss: 0.3429273125529289, D_X_loss: 1.3386510199308395\n",
      "[4:200] loss_idt_y: 0.22590716399252414, F_fool_loss: 0.15870002571493388, predictor_y_loss: 0.2748377302289009, cycled_y_loss: 0.2358508774638176, D_Y_loss: 1.2304508680105208\n",
      "[4:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[4:300] Took 121.52s\n",
      "[4:300] loss_idt_x: 0.3441206428408623, G_fool_loss: 0.13810592509806155, predictor_x_loss: 0.2606853070855141, cycled_x_loss: 0.3524257481098175, D_X_loss: 1.208654259443283\n",
      "[4:300] loss_idt_y: 0.23065852746367455, F_fool_loss: 0.09574934460222721, predictor_y_loss: 0.24999829389154912, cycled_y_loss: 0.24622614815831184, D_Y_loss: 1.2250210386514664\n",
      "[4:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[4:400] Took 116.50s\n",
      "[4:400] loss_idt_x: 0.3319228295981884, G_fool_loss: 0.09010136999189854, predictor_x_loss: 0.2505534927546978, cycled_x_loss: 0.33797774016857146, D_X_loss: 1.2705911910533905\n",
      "[4:400] loss_idt_y: 0.2270587521791458, F_fool_loss: 0.12734114348888398, predictor_y_loss: 0.2633306819200516, cycled_y_loss: 0.24168776728212835, D_Y_loss: 1.1611397463083266\n",
      "[4:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[4:500] Took 119.35s\n",
      "[4:500] loss_idt_x: 0.31076372288167475, G_fool_loss: 0.10844444531947374, predictor_x_loss: 0.24238644868135453, cycled_x_loss: 0.32424751624464987, D_X_loss: 1.2656739091873168\n",
      "[4:500] loss_idt_y: 0.20915442071855067, F_fool_loss: 0.12307640045881271, predictor_y_loss: 0.26073782831430437, cycled_y_loss: 0.2369918379932642, D_Y_loss: 1.20679239153862\n",
      "[4:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[4:END] Completed epoch in 735.4848258495331s\n",
      "[4:599] ep_loss_idt_x: 0.335 ep_G_fool_loss: 0.133 ep_predictor_x_loss: 0.254 ep_cycled_x_loss: 0.340 ep_D_X_loss: 1.290\n",
      "[4:599] ep_loss_idt_y: 0.224 ep_F_fool_loss: 0.142 ep_predictor_y_loss: 0.262 ep_cycled_y_loss: 0.240 ep_D_Y_loss: 1.222\n",
      "[4:END] Completed eval in 3.9853367805480957s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[4:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[5:100] Took 118.17s\n",
      "[5:100] loss_idt_x: 0.33531699374318125, G_fool_loss: 0.15192074820399284, predictor_x_loss: 0.2528191539645195, cycled_x_loss: 0.3472704483568668, D_X_loss: 1.2787848401069641\n",
      "[5:100] loss_idt_y: 0.2090588253736496, F_fool_loss: 0.11238800492137671, predictor_y_loss: 0.2559341265261173, cycled_y_loss: 0.23453409358859062, D_Y_loss: 1.286666271686554\n",
      "[5:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[5:200] Took 111.67s\n",
      "[5:200] loss_idt_x: 0.35413203313946723, G_fool_loss: 0.08521836303174496, predictor_x_loss: 0.26615383177995683, cycled_x_loss: 0.3488525566458702, D_X_loss: 1.261764959692955\n",
      "[5:200] loss_idt_y: 0.21897288367152215, F_fool_loss: 0.11462474532425404, predictor_y_loss: 0.27741168811917305, cycled_y_loss: 0.2642289137095213, D_Y_loss: 1.1769220983982087\n",
      "[5:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[5:300] Took 111.69s\n",
      "[5:300] loss_idt_x: 0.31475096426904203, G_fool_loss: 0.12702083829790353, predictor_x_loss: 0.24098891004920006, cycled_x_loss: 0.3136938366293907, D_X_loss: 1.3559500825405122\n",
      "[5:300] loss_idt_y: 0.21898443527519704, F_fool_loss: 0.18596735760569572, predictor_y_loss: 0.2629774463921785, cycled_y_loss: 0.2393871584534645, D_Y_loss: 1.2224785280227661\n",
      "[5:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[5:400] Took 111.70s\n",
      "[5:400] loss_idt_x: 0.31509758189320564, G_fool_loss: 0.12839984368532897, predictor_x_loss: 0.25054113909602166, cycled_x_loss: 0.3260557125508785, D_X_loss: 1.2323219168186188\n",
      "[5:400] loss_idt_y: 0.2301722215116024, F_fool_loss: 0.0864158271625638, predictor_y_loss: 0.2525587165355682, cycled_y_loss: 0.24833276242017746, D_Y_loss: 1.2290683370828628\n",
      "[5:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[5:500] Took 114.94s\n",
      "[5:500] loss_idt_x: 0.328476684987545, G_fool_loss: 0.1485554339364171, predictor_x_loss: 0.24268504805862903, cycled_x_loss: 0.32605304062366486, D_X_loss: 1.2519213485717773\n",
      "[5:500] loss_idt_y: 0.2505161924660206, F_fool_loss: 0.0918046247214079, predictor_y_loss: 0.2596269215643406, cycled_y_loss: 0.2554258572310209, D_Y_loss: 1.260716689825058\n",
      "[5:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[5:END] Completed epoch in 679.5754058361053s\n",
      "[5:599] ep_loss_idt_x: 0.325 ep_G_fool_loss: 0.128 ep_predictor_x_loss: 0.247 ep_cycled_x_loss: 0.328 ep_D_X_loss: 1.278\n",
      "[5:599] ep_loss_idt_y: 0.222 ep_F_fool_loss: 0.120 ep_predictor_y_loss: 0.259 ep_cycled_y_loss: 0.243 ep_D_Y_loss: 1.229\n",
      "[5:END] Completed eval in 3.9561350345611572s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[5:END] Saving models and training information permanently\n",
      "[6:100] Took 115.87s\n",
      "[6:100] loss_idt_x: 0.3204331760108471, G_fool_loss: 0.10066787105053664, predictor_x_loss: 0.2464910401403904, cycled_x_loss: 0.3204184670746326, D_X_loss: 1.3053841853141785\n",
      "[6:100] loss_idt_y: 0.20721920095384122, F_fool_loss: 0.1413100641593337, predictor_y_loss: 0.23796040557324885, cycled_y_loss: 0.22263108722865582, D_Y_loss: 1.1974102354049683\n",
      "[6:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[6:200] Took 111.23s\n",
      "[6:200] loss_idt_x: 0.270543492436409, G_fool_loss: 0.10657851759344339, predictor_x_loss: 0.22007222026586531, cycled_x_loss: 0.28222366973757745, D_X_loss: 1.30033123254776\n",
      "[6:200] loss_idt_y: 0.19255233444273473, F_fool_loss: 0.13576392713934182, predictor_y_loss: 0.24630943417549134, cycled_y_loss: 0.20343821465969086, D_Y_loss: 1.211258771419525\n",
      "[6:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[6:300] Took 111.23s\n",
      "[6:300] loss_idt_x: 0.31799454040825365, G_fool_loss: 0.11448617089539766, predictor_x_loss: 0.2494116000086069, cycled_x_loss: 0.329006854146719, D_X_loss: 1.2374173319339752\n",
      "[6:300] loss_idt_y: 0.20659194841980935, F_fool_loss: 0.08850070409476757, predictor_y_loss: 0.25978497698903086, cycled_y_loss: 0.22872994102537633, D_Y_loss: 1.1994295507669448\n",
      "[6:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[6:400] Took 111.70s\n",
      "[6:400] loss_idt_x: 0.2798733826726675, G_fool_loss: 0.13077108800411225, predictor_x_loss: 0.2286298818141222, cycled_x_loss: 0.2928575284779072, D_X_loss: 1.2340304094552994\n",
      "[6:400] loss_idt_y: 0.20160017766058444, F_fool_loss: 0.0919736247882247, predictor_y_loss: 0.2335685157775879, cycled_y_loss: 0.2107299939543009, D_Y_loss: 1.2286978620290756\n",
      "[6:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[6:500] Took 111.40s\n",
      "[6:500] loss_idt_x: 0.32992210909724234, G_fool_loss: 0.11161304116249085, predictor_x_loss: 0.24513836085796356, cycled_x_loss: 0.3351538887619972, D_X_loss: 1.335515522956848\n",
      "[6:500] loss_idt_y: 0.20323179453611373, F_fool_loss: 0.16279694195836783, predictor_y_loss: 0.25586258232593534, cycled_y_loss: 0.24322578825056554, D_Y_loss: 1.2242600685358047\n",
      "[6:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[6:END] Completed epoch in 672.7237801551819s\n",
      "[6:599] ep_loss_idt_x: 0.305 ep_G_fool_loss: 0.112 ep_predictor_x_loss: 0.239 ep_cycled_x_loss: 0.312 ep_D_X_loss: 1.271\n",
      "[6:599] ep_loss_idt_y: 0.206 ep_F_fool_loss: 0.120 ep_predictor_y_loss: 0.246 ep_cycled_y_loss: 0.225 ep_D_Y_loss: 1.210\n",
      "[6:END] Completed eval in 4.002889156341553s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[6:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[7:100] Took 115.22s\n",
      "[7:100] loss_idt_x: 0.3007527782022953, G_fool_loss: 0.11466306418180466, predictor_x_loss: 0.23234669953584672, cycled_x_loss: 0.3005086727440357, D_X_loss: 1.3311397236585618\n",
      "[7:100] loss_idt_y: 0.18822833478450776, F_fool_loss: 0.17599456429481505, predictor_y_loss: 0.2522116393595934, cycled_y_loss: 0.19815803356468678, D_Y_loss: 1.2094732701778412\n",
      "[7:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[7:200] Took 110.72s\n",
      "[7:200] loss_idt_x: 0.3053543904423714, G_fool_loss: 0.1007674765586853, predictor_x_loss: 0.23451376646757127, cycled_x_loss: 0.30704334437847136, D_X_loss: 1.2290287816524506\n",
      "[7:200] loss_idt_y: 0.20046521268785, F_fool_loss: 0.07733133506029845, predictor_y_loss: 0.2694920713454485, cycled_y_loss: 0.22711698159575464, D_Y_loss: 1.1939596724510193\n",
      "[7:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[7:300] Took 110.63s\n",
      "[7:300] loss_idt_x: 0.31032404422760007, G_fool_loss: 0.15955294776707887, predictor_x_loss: 0.24243689253926276, cycled_x_loss: 0.31269312486052514, D_X_loss: 1.2754725742340087\n",
      "[7:300] loss_idt_y: 0.18091862447559834, F_fool_loss: 0.11732249818742276, predictor_y_loss: 0.22595271445810794, cycled_y_loss: 0.19154836669564246, D_Y_loss: 1.259260774254799\n",
      "[7:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[7:400] Took 110.79s\n",
      "[7:400] loss_idt_x: 0.29215639173984526, G_fool_loss: 0.10117878392338753, predictor_x_loss: 0.23220718763768672, cycled_x_loss: 0.3004126477986574, D_X_loss: 1.4108729374408722\n",
      "[7:400] loss_idt_y: 0.18300202272832394, F_fool_loss: 0.20570284709334374, predictor_y_loss: 0.2389770161360502, cycled_y_loss: 0.19172620713710786, D_Y_loss: 1.1660494959354402\n",
      "[7:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[7:500] Took 110.72s\n",
      "[7:500] loss_idt_x: 0.27192406937479974, G_fool_loss: 0.12028873771429062, predictor_x_loss: 0.22518145434558393, cycled_x_loss: 0.28472342833876607, D_X_loss: 1.2265338575839997\n",
      "[7:500] loss_idt_y: 0.17757534869015218, F_fool_loss: 0.08571106348186731, predictor_y_loss: 0.22506882399320602, cycled_y_loss: 0.1791949936747551, D_Y_loss: 1.2210418748855592\n",
      "[7:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[7:END] Completed epoch in 668.6824536323547s\n",
      "[7:599] ep_loss_idt_x: 0.295 ep_G_fool_loss: 0.119 ep_predictor_x_loss: 0.232 ep_cycled_x_loss: 0.298 ep_D_X_loss: 1.280\n",
      "[7:599] ep_loss_idt_y: 0.187 ep_F_fool_loss: 0.124 ep_predictor_y_loss: 0.242 ep_cycled_y_loss: 0.198 ep_D_Y_loss: 1.209\n",
      "[7:END] Completed eval in 4.293763875961304s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[7:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[8:100] Took 110.36s\n",
      "[8:100] loss_idt_x: 0.3080990631878376, G_fool_loss: 0.13698965791612863, predictor_x_loss: 0.24331482425332068, cycled_x_loss: 0.3133473527431488, D_X_loss: 1.265926103591919\n",
      "[8:100] loss_idt_y: 0.18338203877210618, F_fool_loss: 0.114043272100389, predictor_y_loss: 0.24482672169804573, cycled_y_loss: 0.19443625703454018, D_Y_loss: 1.2448877054452896\n",
      "[8:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[8:200] Took 106.38s\n",
      "[8:200] loss_idt_x: 0.28184677951037884, G_fool_loss: 0.09361597657203674, predictor_x_loss: 0.22568126410245895, cycled_x_loss: 0.28996129259467124, D_X_loss: 1.2230443966388702\n",
      "[8:200] loss_idt_y: 0.18162365742027758, F_fool_loss: 0.07243682816624641, predictor_y_loss: 0.2372140245139599, cycled_y_loss: 0.19540298357605934, D_Y_loss: 1.1742803639173507\n",
      "[8:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[8:300] Took 107.85s\n",
      "[8:300] loss_idt_x: 0.27482761241495607, G_fool_loss: 0.10394109923392535, predictor_x_loss: 0.22086083248257637, cycled_x_loss: 0.276803597509861, D_X_loss: 1.2871053445339202\n",
      "[8:300] loss_idt_y: 0.1878632941842079, F_fool_loss: 0.13742757860571145, predictor_y_loss: 0.22399707622826098, cycled_y_loss: 0.19296375036239624, D_Y_loss: 1.1819331634044647\n",
      "[8:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[8:400] Took 108.03s\n",
      "[8:400] loss_idt_x: 0.3057837478071451, G_fool_loss: 0.09880666457116603, predictor_x_loss: 0.24100886464118956, cycled_x_loss: 0.31039566799998286, D_X_loss: 1.2976405727863312\n",
      "[8:400] loss_idt_y: 0.18815547853708267, F_fool_loss: 0.1331354285031557, predictor_y_loss: 0.252162631303072, cycled_y_loss: 0.2015793716162443, D_Y_loss: 1.1763549721240998\n",
      "[8:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[8:500] Took 108.09s\n",
      "[8:500] loss_idt_x: 0.3024363867938519, G_fool_loss: 0.18074339374899864, predictor_x_loss: 0.2394706615805626, cycled_x_loss: 0.3008131183683872, D_X_loss: 1.2314632785320283\n",
      "[8:500] loss_idt_y: 0.17281163893640042, F_fool_loss: 0.0883891785889864, predictor_y_loss: 0.23880218796432018, cycled_y_loss: 0.18483410380780696, D_Y_loss: 1.2717549782991409\n",
      "[8:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[8:END] Completed epoch in 649.2273507118225s\n",
      "[8:599] ep_loss_idt_x: 0.294 ep_G_fool_loss: 0.118 ep_predictor_x_loss: 0.232 ep_cycled_x_loss: 0.297 ep_D_X_loss: 1.257\n",
      "[8:599] ep_loss_idt_y: 0.183 ep_F_fool_loss: 0.109 ep_predictor_y_loss: 0.240 ep_cycled_y_loss: 0.196 ep_D_Y_loss: 1.203\n",
      "[8:END] Completed eval in 4.043762445449829s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[8:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[9:100] Took 113.01s\n",
      "[9:100] loss_idt_x: 0.3095750579237938, G_fool_loss: 0.08408887203782797, predictor_x_loss: 0.23491882145404816, cycled_x_loss: 0.3079283697903156, D_X_loss: 1.2530668902397155\n",
      "[9:100] loss_idt_y: 0.20157789587974548, F_fool_loss: 0.09190704893320799, predictor_y_loss: 0.24957041673362254, cycled_y_loss: 0.22985500425100328, D_Y_loss: 1.1664390218257905\n",
      "[9:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[9:200] Took 110.94s\n",
      "[9:200] loss_idt_x: 0.2672375637292862, G_fool_loss: 0.12503931298851967, predictor_x_loss: 0.22131343401968478, cycled_x_loss: 0.27318679824471476, D_X_loss: 1.259882129430771\n",
      "[9:200] loss_idt_y: 0.1734516951441765, F_fool_loss: 0.10368010066449643, predictor_y_loss: 0.23855881787836553, cycled_y_loss: 0.18477865286171435, D_Y_loss: 1.2117948496341706\n",
      "[9:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[9:300] Took 110.46s\n",
      "[9:300] loss_idt_x: 0.3049532553553581, G_fool_loss: 0.09083072058856487, predictor_x_loss: 0.2351619140803814, cycled_x_loss: 0.3003167946636677, D_X_loss: 1.2927000653743743\n",
      "[9:300] loss_idt_y: 0.19923021651804448, F_fool_loss: 0.1289491956681013, predictor_y_loss: 0.2558801458775997, cycled_y_loss: 0.22166816525161268, D_Y_loss: 1.175211620926857\n",
      "[9:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[9:400] Took 110.44s\n",
      "[9:400] loss_idt_x: 0.2736608599126339, G_fool_loss: 0.07237132396548987, predictor_x_loss: 0.21394655093550682, cycled_x_loss: 0.2690441121160984, D_X_loss: 1.312283621430397\n",
      "[9:400] loss_idt_y: 0.1594156540185213, F_fool_loss: 0.1713047869876027, predictor_y_loss: 0.2372874501347542, cycled_y_loss: 0.1698259162157774, D_Y_loss: 1.1417036336660384\n",
      "[9:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[9:500] Took 110.59s\n",
      "[9:500] loss_idt_x: 0.2900985795259476, G_fool_loss: 0.12115606404840946, predictor_x_loss: 0.22489673271775246, cycled_x_loss: 0.2911411365866661, D_X_loss: 1.2369462037086487\n",
      "[9:500] loss_idt_y: 0.17536110423505305, F_fool_loss: 0.08349969632923603, predictor_y_loss: 0.22778077445924283, cycled_y_loss: 0.18498540088534354, D_Y_loss: 1.1993949156999588\n",
      "[9:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[9:END] Completed epoch in 665.9326064586639s\n",
      "[9:599] ep_loss_idt_x: 0.289 ep_G_fool_loss: 0.096 ep_predictor_x_loss: 0.226 ep_cycled_x_loss: 0.290 ep_D_X_loss: 1.267\n",
      "[9:599] ep_loss_idt_y: 0.181 ep_F_fool_loss: 0.114 ep_predictor_y_loss: 0.240 ep_cycled_y_loss: 0.196 ep_D_Y_loss: 1.172\n",
      "[9:END] Completed eval in 4.451433420181274s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[9:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[10:100] Took 115.48s\n",
      "[10:100] loss_idt_x: 0.290348624587059, G_fool_loss: 0.18170617189258337, predictor_x_loss: 0.22357969261705876, cycled_x_loss: 0.29731132976710795, D_X_loss: 1.2685415208339692\n",
      "[10:100] loss_idt_y: 0.19306757040321826, F_fool_loss: 0.1103614630177617, predictor_y_loss: 0.24322445936501025, cycled_y_loss: 0.2069056461006403, D_Y_loss: 1.2902116841077804\n",
      "[10:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[10:200] Took 110.63s\n",
      "[10:200] loss_idt_x: 0.26863438926637173, G_fool_loss: 0.1277235497534275, predictor_x_loss: 0.21841464817523956, cycled_x_loss: 0.2707231776416302, D_X_loss: 1.2861466479301453\n",
      "[10:200] loss_idt_y: 0.17130620181560516, F_fool_loss: 0.12570572055876256, predictor_y_loss: 0.2339193256944418, cycled_y_loss: 0.19202089481055737, D_Y_loss: 1.2223526871204375\n",
      "[10:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[10:300] Took 110.57s\n",
      "[10:300] loss_idt_x: 0.2678008808195591, G_fool_loss: 0.07598340902477503, predictor_x_loss: 0.2152669996768236, cycled_x_loss: 0.2639996828138828, D_X_loss: 1.2739740812778473\n",
      "[10:300] loss_idt_y: 0.18050595186650753, F_fool_loss: 0.1213060787320137, predictor_y_loss: 0.2541183953732252, cycled_y_loss: 0.20197040252387524, D_Y_loss: 1.1418744659423827\n",
      "[10:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[10:400] Took 111.11s\n",
      "[10:400] loss_idt_x: 0.2714581736177206, G_fool_loss: 0.10303101297467947, predictor_x_loss: 0.2146318069845438, cycled_x_loss: 0.28102340549230576, D_X_loss: 1.235392958521843\n",
      "[10:400] loss_idt_y: 0.17804718904197217, F_fool_loss: 0.09160982474684715, predictor_y_loss: 0.23967290557920934, cycled_y_loss: 0.18325875915586948, D_Y_loss: 1.1881248342990876\n",
      "[10:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[10:500] Took 111.13s\n",
      "[10:500] loss_idt_x: 0.2723254146426916, G_fool_loss: 0.07150165036320687, predictor_x_loss: 0.22101640000939368, cycled_x_loss: 0.2692694231122732, D_X_loss: 1.2439827793836593\n",
      "[10:500] loss_idt_y: 0.16614960998296738, F_fool_loss: 0.10580549776554107, predictor_y_loss: 0.23426121048629284, cycled_y_loss: 0.17916001200675966, D_Y_loss: 1.1512590569257737\n",
      "[10:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[10:END] Completed epoch in 670.2315576076508s\n",
      "[10:599] ep_loss_idt_x: 0.274 ep_G_fool_loss: 0.112 ep_predictor_x_loss: 0.219 ep_cycled_x_loss: 0.276 ep_D_X_loss: 1.259\n",
      "[10:599] ep_loss_idt_y: 0.177 ep_F_fool_loss: 0.109 ep_predictor_y_loss: 0.241 ep_cycled_y_loss: 0.190 ep_D_Y_loss: 1.197\n",
      "[10:END] Completed eval in 4.085075378417969s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[10:END] Saving models and training information permanently\n",
      "[11:100] Took 116.97s\n",
      "[11:100] loss_idt_x: 0.2812473110854626, G_fool_loss: 0.1362575478106737, predictor_x_loss: 0.2307410252839327, cycled_x_loss: 0.27924757182598114, D_X_loss: 1.2443561512231827\n",
      "[11:100] loss_idt_y: 0.18350833415985107, F_fool_loss: 0.084933364354074, predictor_y_loss: 0.23999514654278756, cycled_y_loss: 0.21728173665702344, D_Y_loss: 1.2444912546873093\n",
      "[11:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[11:200] Took 110.70s\n",
      "[11:200] loss_idt_x: 0.3362919932603836, G_fool_loss: 0.0914221528545022, predictor_x_loss: 0.2544415944814682, cycled_x_loss: 0.3389067590236664, D_X_loss: 1.221705681681633\n",
      "[11:200] loss_idt_y: 0.2009812381118536, F_fool_loss: 0.08930139631032943, predictor_y_loss: 0.2682009903341532, cycled_y_loss: 0.2875020780414343, D_Y_loss: 1.166389361023903\n",
      "[11:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[11:300] Took 110.64s\n",
      "[11:300] loss_idt_x: 0.3181964080780745, G_fool_loss: 0.1050485646352172, predictor_x_loss: 0.2424598879367113, cycled_x_loss: 0.31708491772413255, D_X_loss: 1.2736979484558106\n",
      "[11:300] loss_idt_y: 0.19391873031854628, F_fool_loss: 0.12203221850097179, predictor_y_loss: 0.2538572125136852, cycled_y_loss: 0.23973467476665974, D_Y_loss: 1.1929038298130035\n",
      "[11:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[11:400] Took 110.67s\n",
      "[11:400] loss_idt_x: 0.2895729184150696, G_fool_loss: 0.09095488514751196, predictor_x_loss: 0.2274430987238884, cycled_x_loss: 0.2953094883263111, D_X_loss: 1.2681028646230699\n",
      "[11:400] loss_idt_y: 0.18023562133312226, F_fool_loss: 0.1089377249404788, predictor_y_loss: 0.23924412027001382, cycled_y_loss: 0.20324115127325057, D_Y_loss: 1.1558409363031388\n",
      "[11:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[11:500] Took 110.67s\n",
      "[11:500] loss_idt_x: 0.30276143439114095, G_fool_loss: 0.08944044321775436, predictor_x_loss: 0.22434473872184754, cycled_x_loss: 0.2978545345366001, D_X_loss: 1.2344778579473497\n",
      "[11:500] loss_idt_y: 0.18690614119172097, F_fool_loss: 0.09737433895468711, predictor_y_loss: 0.2545422437041998, cycled_y_loss: 0.2179329938441515, D_Y_loss: 1.1793739736080169\n",
      "[11:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[11:END] Completed epoch in 670.616649389267s\n",
      "[11:599] ep_loss_idt_x: 0.302 ep_G_fool_loss: 0.109 ep_predictor_x_loss: 0.233 ep_cycled_x_loss: 0.301 ep_D_X_loss: 1.255\n",
      "[11:599] ep_loss_idt_y: 0.186 ep_F_fool_loss: 0.106 ep_predictor_y_loss: 0.247 ep_cycled_y_loss: 0.225 ep_D_Y_loss: 1.191\n",
      "[11:END] Completed eval in 4.158189535140991s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[11:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[12:100] Took 115.71s\n",
      "[12:100] loss_idt_x: 0.28735610857605937, G_fool_loss: 0.10385899908840657, predictor_x_loss: 0.22636478029191495, cycled_x_loss: 0.2829522603750229, D_X_loss: 1.2668577933311462\n",
      "[12:100] loss_idt_y: 0.18023425057530404, F_fool_loss: 0.09764187511056661, predictor_y_loss: 0.250191206485033, cycled_y_loss: 0.20568689726293088, D_Y_loss: 1.1709217780828476\n",
      "[12:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[12:200] Took 110.08s\n",
      "[12:200] loss_idt_x: 0.28748361103236675, G_fool_loss: 0.0782214117795229, predictor_x_loss: 0.22551422648131847, cycled_x_loss: 0.2858468063175678, D_X_loss: 1.236445739865303\n",
      "[12:200] loss_idt_y: 0.1830833388864994, F_fool_loss: 0.09542609855532647, predictor_y_loss: 0.23716442875564098, cycled_y_loss: 0.2011102057993412, D_Y_loss: 1.1445820772647857\n",
      "[12:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[12:300] Took 110.03s\n",
      "[12:300] loss_idt_x: 0.3152736249566078, G_fool_loss: 0.11282322090119123, predictor_x_loss: 0.2331410863250494, cycled_x_loss: 0.30504010200500487, D_X_loss: 1.3593110221624374\n",
      "[12:300] loss_idt_y: 0.18718894891440868, F_fool_loss: 0.170136260651052, predictor_y_loss: 0.25593392878770826, cycled_y_loss: 0.21878233306109907, D_Y_loss: 1.1990871214866639\n",
      "[12:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[12:400] Took 110.20s\n",
      "[12:400] loss_idt_x: 0.2948975865542889, G_fool_loss: 0.12295415721833707, predictor_x_loss: 0.22795731775462627, cycled_x_loss: 0.29673511907458305, D_X_loss: 1.2186421394348144\n",
      "[12:400] loss_idt_y: 0.19743325039744378, F_fool_loss: 0.07896982133388519, predictor_y_loss: 0.2397990470379591, cycled_y_loss: 0.22513339035212993, D_Y_loss: 1.2428185153007507\n",
      "[12:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[12:500] Took 110.06s\n",
      "[12:500] loss_idt_x: 0.28463020488619806, G_fool_loss: 0.09067659392952919, predictor_x_loss: 0.2182065484672785, cycled_x_loss: 0.28044782891869546, D_X_loss: 1.2254624378681183\n",
      "[12:500] loss_idt_y: 0.16823844827711582, F_fool_loss: 0.07690435826778412, predictor_y_loss: 0.23111439280211926, cycled_y_loss: 0.19090558119118214, D_Y_loss: 1.1758132290840149\n",
      "[12:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[12:END] Completed epoch in 666.8373391628265s\n",
      "[12:599] ep_loss_idt_x: 0.287 ep_G_fool_loss: 0.100 ep_predictor_x_loss: 0.223 ep_cycled_x_loss: 0.284 ep_D_X_loss: 1.252\n",
      "[12:599] ep_loss_idt_y: 0.177 ep_F_fool_loss: 0.100 ep_predictor_y_loss: 0.242 ep_cycled_y_loss: 0.201 ep_D_Y_loss: 1.179\n",
      "[12:END] Completed eval in 4.179860353469849s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[12:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[13:100] Took 117.92s\n",
      "[13:100] loss_idt_x: 0.2558449383080006, G_fool_loss: 0.10788006715476513, predictor_x_loss: 0.2152780867367983, cycled_x_loss: 0.26663786590099336, D_X_loss: 1.2097924649715424\n",
      "[13:100] loss_idt_y: 0.15436745069921018, F_fool_loss: 0.07717699602246285, predictor_y_loss: 0.2249635497480631, cycled_y_loss: 0.16953044064342976, D_Y_loss: 1.2119699710607528\n",
      "[13:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[13:200] Took 113.84s\n",
      "[13:200] loss_idt_x: 0.29526555620133876, G_fool_loss: 0.12161959853023291, predictor_x_loss: 0.22568110980093478, cycled_x_loss: 0.2899018380045891, D_X_loss: 1.4113608080148696\n",
      "[13:200] loss_idt_y: 0.17661530576646328, F_fool_loss: 0.2509249298647046, predictor_y_loss: 0.23865365967154503, cycled_y_loss: 0.19981404803693295, D_Y_loss: 1.1850887036323547\n",
      "[13:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[13:300] Took 113.67s\n",
      "[13:300] loss_idt_x: 0.2555062173306942, G_fool_loss: 0.08471616171300411, predictor_x_loss: 0.21089447483420373, cycled_x_loss: 0.2634017691016197, D_X_loss: 1.233819534778595\n",
      "[13:300] loss_idt_y: 0.1613110438734293, F_fool_loss: 0.09162679944187403, predictor_y_loss: 0.23059145271778106, cycled_y_loss: 0.1791310989111662, D_Y_loss: 1.1330040150880814\n",
      "[13:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[13:400] Took 113.59s\n",
      "[13:400] loss_idt_x: 0.25348571307957174, G_fool_loss: 0.08049791201949119, predictor_x_loss: 0.21205417215824127, cycled_x_loss: 0.25911141514778135, D_X_loss: 1.1941235315799714\n",
      "[13:400] loss_idt_y: 0.16586446329951288, F_fool_loss: 0.0682444842159748, predictor_y_loss: 0.2260082843899727, cycled_y_loss: 0.17508553959429263, D_Y_loss: 1.128957542181015\n",
      "[13:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[13:500] Took 113.65s\n",
      "[13:500] loss_idt_x: 0.2654452003538609, G_fool_loss: 0.10721951935440302, predictor_x_loss: 0.21160361036658287, cycled_x_loss: 0.26598081067204477, D_X_loss: 1.2207042479515076\n",
      "[13:500] loss_idt_y: 0.16243002444505691, F_fool_loss: 0.08883827809244395, predictor_y_loss: 0.2530524494498968, cycled_y_loss: 0.17579813912510872, D_Y_loss: 1.1615729558467864\n",
      "[13:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[13:END] Completed epoch in 687.0326869487762s\n",
      "[13:599] ep_loss_idt_x: 0.269 ep_G_fool_loss: 0.097 ep_predictor_x_loss: 0.216 ep_cycled_x_loss: 0.272 ep_D_X_loss: 1.258\n",
      "[13:599] ep_loss_idt_y: 0.164 ep_F_fool_loss: 0.119 ep_predictor_y_loss: 0.232 ep_cycled_y_loss: 0.181 ep_D_Y_loss: 1.161\n",
      "[13:END] Completed eval in 4.233558177947998s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[13:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[14:100] Took 117.25s\n",
      "[14:100] loss_idt_x: 0.28649331003427503, G_fool_loss: 0.10455345969647169, predictor_x_loss: 0.22128870755434035, cycled_x_loss: 0.2757084798067808, D_X_loss: 1.22180381834507\n",
      "[14:100] loss_idt_y: 0.1633124066889286, F_fool_loss: 0.07953242432326078, predictor_y_loss: 0.24425899118185043, cycled_y_loss: 0.18853724844753741, D_Y_loss: 1.200651313662529\n",
      "[14:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[14:200] Took 112.25s\n",
      "[14:200] loss_idt_x: 0.2509361708164215, G_fool_loss: 0.11460708353668451, predictor_x_loss: 0.20629203379154204, cycled_x_loss: 0.25692271173000336, D_X_loss: 1.2098890548944474\n",
      "[14:200] loss_idt_y: 0.13749354623258114, F_fool_loss: 0.07969691336154938, predictor_y_loss: 0.23889011286199094, cycled_y_loss: 0.1559749983996153, D_Y_loss: 1.1808247166872023\n",
      "[14:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[14:300] Took 113.11s\n",
      "[14:300] loss_idt_x: 0.28458973698318, G_fool_loss: 0.08304587729275227, predictor_x_loss: 0.21730481058359147, cycled_x_loss: 0.27941434644162655, D_X_loss: 1.234411392211914\n",
      "[14:300] loss_idt_y: 0.15059194698929787, F_fool_loss: 0.09046300124377012, predictor_y_loss: 0.22053945064544678, cycled_y_loss: 0.16394327782094478, D_Y_loss: 1.1325032937526702\n",
      "[14:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[14:400] Took 112.02s\n",
      "[14:400] loss_idt_x: 0.26586702942848206, G_fool_loss: 0.09417810343205929, predictor_x_loss: 0.20838024601340294, cycled_x_loss: 0.2488705438375473, D_X_loss: 1.237740939259529\n",
      "[14:400] loss_idt_y: 0.16372041888535022, F_fool_loss: 0.09007446371018886, predictor_y_loss: 0.2369127608090639, cycled_y_loss: 0.18294805258512498, D_Y_loss: 1.1691207087039948\n",
      "[14:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[14:500] Took 119.98s\n",
      "[14:500] loss_idt_x: 0.24735315956175327, G_fool_loss: 0.10549190621823072, predictor_x_loss: 0.2029161136597395, cycled_x_loss: 0.25382021322846415, D_X_loss: 1.5043510508537292\n",
      "[14:500] loss_idt_y: 0.16639211535453796, F_fool_loss: 0.2786579279974103, predictor_y_loss: 0.24340935848653317, cycled_y_loss: 0.19896096892654896, D_Y_loss: 1.1446826976537705\n",
      "[14:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[14:END] Completed epoch in 689.2799544334412s\n",
      "[14:599] ep_loss_idt_x: 0.270 ep_G_fool_loss: 0.099 ep_predictor_x_loss: 0.213 ep_cycled_x_loss: 0.267 ep_D_X_loss: 1.280\n",
      "[14:599] ep_loss_idt_y: 0.158 ep_F_fool_loss: 0.121 ep_predictor_y_loss: 0.237 ep_cycled_y_loss: 0.180 ep_D_Y_loss: 1.159\n",
      "[14:END] Completed eval in 4.159442901611328s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[14:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[15:100] Took 114.75s\n",
      "[15:100] loss_idt_x: 0.2439807575941086, G_fool_loss: 0.08264276217669249, predictor_x_loss: 0.2082050584256649, cycled_x_loss: 0.25219565100967883, D_X_loss: 1.2711486846208573\n",
      "[15:100] loss_idt_y: 0.16605321649461985, F_fool_loss: 0.09251015707850456, predictor_y_loss: 0.23252674087882041, cycled_y_loss: 0.1793516308069229, D_Y_loss: 1.1341268968582154\n",
      "[15:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[15:200] Took 110.09s\n",
      "[15:200] loss_idt_x: 0.23872759699821472, G_fool_loss: 0.0982151048257947, predictor_x_loss: 0.1998035154491663, cycled_x_loss: 0.2521221961081028, D_X_loss: 1.2297718358039855\n",
      "[15:200] loss_idt_y: 0.1479340621083975, F_fool_loss: 0.07754118021577597, predictor_y_loss: 0.2271299286931753, cycled_y_loss: 0.15834361508488656, D_Y_loss: 1.137643559575081\n",
      "[15:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[15:300] Took 110.37s\n",
      "[15:300] loss_idt_x: 0.26208723306655884, G_fool_loss: 0.08124529778957366, predictor_x_loss: 0.21249191269278525, cycled_x_loss: 0.2660223301500082, D_X_loss: 1.2382699394226073\n",
      "[15:300] loss_idt_y: 0.16223748236894608, F_fool_loss: 0.07809236824512482, predictor_y_loss: 0.230392929315567, cycled_y_loss: 0.17657635375857353, D_Y_loss: 1.1538089674711227\n",
      "[15:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[15:400] Took 110.10s\n",
      "[15:400] loss_idt_x: 0.2656529952585697, G_fool_loss: 0.09654951378703118, predictor_x_loss: 0.2055708585679531, cycled_x_loss: 0.2569067987054586, D_X_loss: 1.2296164095401765\n",
      "[15:400] loss_idt_y: 0.1341744939237833, F_fool_loss: 0.07695238906890153, predictor_y_loss: 0.22333809241652489, cycled_y_loss: 0.1487981528043747, D_Y_loss: 1.1825553631782533\n",
      "[15:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[15:500] Took 110.58s\n",
      "[15:500] loss_idt_x: 0.2676946385204792, G_fool_loss: 0.11723932344466448, predictor_x_loss: 0.2219819027930498, cycled_x_loss: 0.27091498523950575, D_X_loss: 1.3165189719200134\n",
      "[15:500] loss_idt_y: 0.14593539834022523, F_fool_loss: 0.14196124501526355, predictor_y_loss: 0.2283487965911627, cycled_y_loss: 0.16066273503005504, D_Y_loss: 1.1673029065132141\n",
      "[15:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[15:END] Completed epoch in 666.9495580196381s\n",
      "[15:599] ep_loss_idt_x: 0.254 ep_G_fool_loss: 0.092 ep_predictor_x_loss: 0.207 ep_cycled_x_loss: 0.256 ep_D_X_loss: 1.255\n",
      "[15:599] ep_loss_idt_y: 0.148 ep_F_fool_loss: 0.091 ep_predictor_y_loss: 0.230 ep_cycled_y_loss: 0.162 ep_D_Y_loss: 1.148\n",
      "[15:END] Completed eval in 4.297791481018066s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[15:END] Saving models and training information permanently\n",
      "[16:100] Took 117.95s\n",
      "[16:100] loss_idt_x: 0.25938382886350153, G_fool_loss: 0.08772563926875591, predictor_x_loss: 0.2116034246236086, cycled_x_loss: 0.26238305158913133, D_X_loss: 1.2671054738759995\n",
      "[16:100] loss_idt_y: 0.13742172971367836, F_fool_loss: 0.08585455067455769, predictor_y_loss: 0.22553640745580197, cycled_y_loss: 0.1561669011414051, D_Y_loss: 1.1530322712659835\n",
      "[16:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[16:200] Took 113.40s\n",
      "[16:200] loss_idt_x: 0.2446698047965765, G_fool_loss: 0.0991429816558957, predictor_x_loss: 0.2018468176573515, cycled_x_loss: 0.24327444657683372, D_X_loss: 1.2472083604335784\n",
      "[16:200] loss_idt_y: 0.1348307428508997, F_fool_loss: 0.08177236303687095, predictor_y_loss: 0.21817121654748917, cycled_y_loss: 0.15188354842364787, D_Y_loss: 1.1467665010690689\n",
      "[16:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[16:300] Took 113.13s\n",
      "[16:300] loss_idt_x: 0.21954830624163152, G_fool_loss: 0.10810960792005062, predictor_x_loss: 0.19090993337333204, cycled_x_loss: 0.22994039580225945, D_X_loss: 1.2637397098541259\n",
      "[16:300] loss_idt_y: 0.16864575274288654, F_fool_loss: 0.09842069488018751, predictor_y_loss: 0.24295755065977573, cycled_y_loss: 0.17845257796347141, D_Y_loss: 1.1730167651176453\n",
      "[16:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[16:400] Took 113.22s\n",
      "[16:400] loss_idt_x: 0.25501075059175493, G_fool_loss: 0.11853114988654852, predictor_x_loss: 0.1974061269313097, cycled_x_loss: 0.25316771052777765, D_X_loss: 1.255749644637108\n",
      "[16:400] loss_idt_y: 0.1448176822811365, F_fool_loss: 0.08561465945094823, predictor_y_loss: 0.22728925682604312, cycled_y_loss: 0.15787443950772284, D_Y_loss: 1.184058358669281\n",
      "[16:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[16:500] Took 113.03s\n",
      "[16:500] loss_idt_x: 0.2580318071693182, G_fool_loss: 0.10057480629533529, predictor_x_loss: 0.20725009329617022, cycled_x_loss: 0.25302570044994355, D_X_loss: 1.265645682811737\n",
      "[16:500] loss_idt_y: 0.15349806316196918, F_fool_loss: 0.11607152197510004, predictor_y_loss: 0.22680469803512096, cycled_y_loss: 0.16521328665316104, D_Y_loss: 1.1639618897438049\n",
      "[16:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[16:END] Completed epoch in 684.8926160335541s\n",
      "[16:599] ep_loss_idt_x: 0.249 ep_G_fool_loss: 0.170 ep_predictor_x_loss: 0.202 ep_cycled_x_loss: 0.247 ep_D_X_loss: 1.256\n",
      "[16:599] ep_loss_idt_y: 0.148 ep_F_fool_loss: 0.093 ep_predictor_y_loss: 0.228 ep_cycled_y_loss: 0.163 ep_D_Y_loss: 1.243\n",
      "[16:END] Completed eval in 4.522944688796997s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[16:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[17:100] Took 119.23s\n",
      "[17:100] loss_idt_x: 0.25935982204973695, G_fool_loss: 0.10179372187703847, predictor_x_loss: 0.20624784730374812, cycled_x_loss: 0.2558413417637348, D_X_loss: 1.2709694910049438\n",
      "[17:100] loss_idt_y: 0.1383796938508749, F_fool_loss: 0.09680725254118443, predictor_y_loss: 0.22933145999908447, cycled_y_loss: 0.1523961541056633, D_Y_loss: 1.1127939838171006\n",
      "[17:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[17:200] Took 114.03s\n",
      "[17:200] loss_idt_x: 0.23051375664770604, G_fool_loss: 0.07078315287828446, predictor_x_loss: 0.195160593688488, cycled_x_loss: 0.2355222100764513, D_X_loss: 1.2498435997962951\n",
      "[17:200] loss_idt_y: 0.14432027474045753, F_fool_loss: 0.08741030879318715, predictor_y_loss: 0.2375225757807493, cycled_y_loss: 0.16800764337182045, D_Y_loss: 1.087056549191475\n",
      "[17:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[17:300] Took 114.04s\n",
      "[17:300] loss_idt_x: 0.2718775129318237, G_fool_loss: 0.08149793796241284, predictor_x_loss: 0.20768368802964687, cycled_x_loss: 0.2544330133497715, D_X_loss: 1.2622604811191558\n",
      "[17:300] loss_idt_y: 0.13151007659733296, F_fool_loss: 0.0990848521143198, predictor_y_loss: 0.21672129042446614, cycled_y_loss: 0.14084284350275994, D_Y_loss: 1.1103525310754776\n",
      "[17:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[17:400] Took 114.09s\n",
      "[17:400] loss_idt_x: 0.22158423200249672, G_fool_loss: 0.06718554221093655, predictor_x_loss: 0.18803575195372105, cycled_x_loss: 0.21730531692504884, D_X_loss: 1.2889423328638077\n",
      "[17:400] loss_idt_y: 0.1420533049851656, F_fool_loss: 0.10708702526986599, predictor_y_loss: 0.22727232865989208, cycled_y_loss: 0.15301184929907322, D_Y_loss: 1.1040873801708222\n",
      "[17:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[17:500] Took 114.22s\n",
      "[17:500] loss_idt_x: 0.2468891516327858, G_fool_loss: 0.0663221201300621, predictor_x_loss: 0.2019650787115097, cycled_x_loss: 0.24014682382345198, D_X_loss: 1.2186251085996629\n",
      "[17:500] loss_idt_y: 0.15212725669145585, F_fool_loss: 0.07107885479927063, predictor_y_loss: 0.22946389883756638, cycled_y_loss: 0.1654499437659979, D_Y_loss: 1.103703482747078\n",
      "[17:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[17:END] Completed epoch in 690.5034070014954s\n",
      "[17:599] ep_loss_idt_x: 0.246 ep_G_fool_loss: 0.076 ep_predictor_x_loss: 0.200 ep_cycled_x_loss: 0.242 ep_D_X_loss: 1.250\n",
      "[17:599] ep_loss_idt_y: 0.141 ep_F_fool_loss: 0.088 ep_predictor_y_loss: 0.225 ep_cycled_y_loss: 0.155 ep_D_Y_loss: 1.103\n",
      "[17:END] Completed eval in 4.3694679737091064s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[17:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[18:100] Took 132.80s\n",
      "[18:100] loss_idt_x: 0.23181501038372518, G_fool_loss: 0.07823316894471645, predictor_x_loss: 0.20161084033548832, cycled_x_loss: 0.23219107046723367, D_X_loss: 1.2690509736537934\n",
      "[18:100] loss_idt_y: 0.1400467535108328, F_fool_loss: 0.10160178214311599, predictor_y_loss: 0.24026441611349583, cycled_y_loss: 0.15748232237994672, D_Y_loss: 1.1453518790006638\n",
      "[18:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[18:200] Took 113.27s\n",
      "[18:200] loss_idt_x: 0.22940115317702292, G_fool_loss: 0.06897290628403425, predictor_x_loss: 0.19054076187312602, cycled_x_loss: 0.2288478649407625, D_X_loss: 1.6069937312602998\n",
      "[18:200] loss_idt_y: 0.12770160779356957, F_fool_loss: 0.3727583659812808, predictor_y_loss: 0.21635706335306168, cycled_y_loss: 0.1452430048584938, D_Y_loss: 1.0925404083728791\n",
      "[18:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[18:300] Took 114.01s\n",
      "[18:300] loss_idt_x: 0.25219342194497585, G_fool_loss: 0.07397460736334324, predictor_x_loss: 0.20104734160006046, cycled_x_loss: 0.23665614776313304, D_X_loss: 1.2735866570472718\n",
      "[18:300] loss_idt_y: 0.1337579496949911, F_fool_loss: 0.08480095710605383, predictor_y_loss: 0.2244912615418434, cycled_y_loss: 0.14664071306586265, D_Y_loss: 1.1011265563964843\n",
      "[18:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[18:400] Took 113.39s\n",
      "[18:400] loss_idt_x: 0.23908825762569905, G_fool_loss: 0.08371977660804987, predictor_x_loss: 0.1950396939367056, cycled_x_loss: 0.2388047931343317, D_X_loss: 1.2130389976501466\n",
      "[18:400] loss_idt_y: 0.13990171149373054, F_fool_loss: 0.06552078310400247, predictor_y_loss: 0.21911173567175865, cycled_y_loss: 0.15499766543507576, D_Y_loss: 1.1464251726865768\n",
      "[18:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[18:500] Took 113.28s\n",
      "[18:500] loss_idt_x: 0.23452867373824118, G_fool_loss: 0.07193483661860228, predictor_x_loss: 0.18614376202225685, cycled_x_loss: 0.22977261424064635, D_X_loss: 1.2407987308502197\n",
      "[18:500] loss_idt_y: 0.13917512089014053, F_fool_loss: 0.0654524302855134, predictor_y_loss: 0.23322247147560118, cycled_y_loss: 0.1528077907860279, D_Y_loss: 1.094450768828392\n",
      "[18:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[18:END] Completed epoch in 701.2544422149658s\n",
      "[18:599] ep_loss_idt_x: 0.238 ep_G_fool_loss: 0.076 ep_predictor_x_loss: 0.195 ep_cycled_x_loss: 0.235 ep_D_X_loss: 1.306\n",
      "[18:599] ep_loss_idt_y: 0.136 ep_F_fool_loss: 0.126 ep_predictor_y_loss: 0.226 ep_cycled_y_loss: 0.151 ep_D_Y_loss: 1.116\n",
      "[18:END] Completed eval in 4.370805263519287s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[18:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[19:100] Took 115.53s\n",
      "[19:100] loss_idt_x: 0.22754030652344226, G_fool_loss: 0.08916717164218425, predictor_x_loss: 0.19157199159264565, cycled_x_loss: 0.22327758088707925, D_X_loss: 1.2483542096614837\n",
      "[19:100] loss_idt_y: 0.14110913187265395, F_fool_loss: 0.07588601280003786, predictor_y_loss: 0.2264566372334957, cycled_y_loss: 0.15677539981901645, D_Y_loss: 1.1571161937713623\n",
      "[19:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[19:200] Took 110.45s\n",
      "[19:200] loss_idt_x: 0.2559745560586453, G_fool_loss: 0.08443836648017168, predictor_x_loss: 0.20382740147411824, cycled_x_loss: 0.25581569105386737, D_X_loss: 1.2319192206859588\n",
      "[19:200] loss_idt_y: 0.15369232058525084, F_fool_loss: 0.0769427002966404, predictor_y_loss: 0.23338929325342178, cycled_y_loss: 0.16979622676968575, D_Y_loss: 1.1333932942152023\n",
      "[19:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[19:300] Took 110.14s\n",
      "[19:300] loss_idt_x: 0.23026383727788924, G_fool_loss: 0.08231085568666457, predictor_x_loss: 0.19264912679791452, cycled_x_loss: 0.23147859878838062, D_X_loss: 1.237533938884735\n",
      "[19:300] loss_idt_y: 0.14357057608664037, F_fool_loss: 0.07500242460519076, predictor_y_loss: 0.22043588511645795, cycled_y_loss: 0.1572977165132761, D_Y_loss: 1.1462252515554427\n",
      "[19:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[19:400] Took 111.18s\n",
      "[19:400] loss_idt_x: 0.2363439068198204, G_fool_loss: 0.0915850293636322, predictor_x_loss: 0.18851327434182166, cycled_x_loss: 0.2382768490165472, D_X_loss: 1.2529871565103532\n",
      "[19:400] loss_idt_y: 0.14466325789690018, F_fool_loss: 0.07864961009472608, predictor_y_loss: 0.23161845058202743, cycled_y_loss: 0.16026297517120838, D_Y_loss: 1.126117330789566\n",
      "[19:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[19:500] Took 111.59s\n",
      "[19:500] loss_idt_x: 0.2234104724228382, G_fool_loss: 0.10014277845621108, predictor_x_loss: 0.19149049751460553, cycled_x_loss: 0.21149888552725316, D_X_loss: 1.2613718795776367\n",
      "[19:500] loss_idt_y: 0.12839192248880862, F_fool_loss: 0.08891707148402929, predictor_y_loss: 0.23100300446152688, cycled_y_loss: 0.138272525370121, D_Y_loss: 1.137747346162796\n",
      "[19:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[19:END] Completed epoch in 671.4398050308228s\n",
      "[19:599] ep_loss_idt_x: 0.233 ep_G_fool_loss: 0.094 ep_predictor_x_loss: 0.193 ep_cycled_x_loss: 0.230 ep_D_X_loss: 1.244\n",
      "[19:599] ep_loss_idt_y: 0.139 ep_F_fool_loss: 0.079 ep_predictor_y_loss: 0.226 ep_cycled_y_loss: 0.153 ep_D_Y_loss: 1.143\n",
      "[19:END] Completed eval in 4.4487810134887695s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[19:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[20:100] Took 114.64s\n",
      "[20:100] loss_idt_x: 0.22057032629847526, G_fool_loss: 0.09519166871905327, predictor_x_loss: 0.17766547501087188, cycled_x_loss: 0.21042805045843124, D_X_loss: 1.2591604954004287\n",
      "[20:100] loss_idt_y: 0.12648682437837125, F_fool_loss: 0.08112892262637615, predictor_y_loss: 0.20292843773961067, cycled_y_loss: 0.13951366506516932, D_Y_loss: 1.1406365191936494\n",
      "[20:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[20:200] Took 108.09s\n",
      "[20:200] loss_idt_x: 0.23518635004758834, G_fool_loss: 0.0935992780700326, predictor_x_loss: 0.19091305300593375, cycled_x_loss: 0.22859560459852218, D_X_loss: 1.24200026512146\n",
      "[20:200] loss_idt_y: 0.14257438823580743, F_fool_loss: 0.07890445981174707, predictor_y_loss: 0.22001396477222443, cycled_y_loss: 0.1548023147881031, D_Y_loss: 1.1456189578771592\n",
      "[20:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[20:300] Took 108.25s\n",
      "[20:300] loss_idt_x: 0.2261989776045084, G_fool_loss: 0.10271204736083746, predictor_x_loss: 0.18621786996722223, cycled_x_loss: 0.21587676517665386, D_X_loss: 1.3009115082025529\n",
      "[20:300] loss_idt_y: 0.125895172059536, F_fool_loss: 0.1307477978616953, predictor_y_loss: 0.22121635682880877, cycled_y_loss: 0.13937348671257496, D_Y_loss: 1.160167651772499\n",
      "[20:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[20:400] Took 108.17s\n",
      "[20:400] loss_idt_x: 0.22818322874605657, G_fool_loss: 0.07642472002655268, predictor_x_loss: 0.1935634308308363, cycled_x_loss: 0.22589562758803367, D_X_loss: 1.2702028524875641\n",
      "[20:400] loss_idt_y: 0.1289216663688421, F_fool_loss: 0.09629356402903795, predictor_y_loss: 0.22350678659975529, cycled_y_loss: 0.13819473944604396, D_Y_loss: 1.1162131077051163\n",
      "[20:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[20:500] Took 108.29s\n",
      "[20:500] loss_idt_x: 0.21896031491458415, G_fool_loss: 0.08075384683907032, predictor_x_loss: 0.19168890990316867, cycled_x_loss: 0.2250340524315834, D_X_loss: 1.2272089999914169\n",
      "[20:500] loss_idt_y: 0.1203614417091012, F_fool_loss: 0.07555088810622693, predictor_y_loss: 0.20752331376075744, cycled_y_loss: 0.13392685361206533, D_Y_loss: 1.1050817626714706\n",
      "[20:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[20:END] Completed epoch in 657.6020233631134s\n",
      "[20:599] ep_loss_idt_x: 0.224 ep_G_fool_loss: 0.088 ep_predictor_x_loss: 0.187 ep_cycled_x_loss: 0.219 ep_D_X_loss: 1.253\n",
      "[20:599] ep_loss_idt_y: 0.127 ep_F_fool_loss: 0.089 ep_predictor_y_loss: 0.214 ep_cycled_y_loss: 0.139 ep_D_Y_loss: 1.128\n",
      "[20:END] Completed eval in 4.3986735343933105s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[20:END] Saving models and training information permanently\n",
      "[21:100] Took 116.54s\n",
      "[21:100] loss_idt_x: 0.23226511262357236, G_fool_loss: 0.08608930941671133, predictor_x_loss: 0.19205666616559028, cycled_x_loss: 0.21807454474270344, D_X_loss: 1.2573966509103776\n",
      "[21:100] loss_idt_y: 0.13280685000121595, F_fool_loss: 0.0901891827583313, predictor_y_loss: 0.21623056322336198, cycled_y_loss: 0.14900594063103198, D_Y_loss: 1.1444744837284089\n",
      "[21:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[21:200] Took 110.66s\n",
      "[21:200] loss_idt_x: 0.21775976292788982, G_fool_loss: 0.15579701974987983, predictor_x_loss: 0.1858272009342909, cycled_x_loss: 0.22503259882330895, D_X_loss: 1.2648797613382339\n",
      "[21:200] loss_idt_y: 0.13293118327856063, F_fool_loss: 0.09076485686004161, predictor_y_loss: 0.22050403118133544, cycled_y_loss: 0.14998073898255826, D_Y_loss: 1.2117049366235733\n",
      "[21:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[21:300] Took 110.44s\n",
      "[21:300] loss_idt_x: 0.22894307382404805, G_fool_loss: 0.09149370357394218, predictor_x_loss: 0.19080794289708136, cycled_x_loss: 0.2203792691230774, D_X_loss: 1.281593861579895\n",
      "[21:300] loss_idt_y: 0.15425070222467185, F_fool_loss: 0.10501297023147345, predictor_y_loss: 0.22267891168594361, cycled_y_loss: 0.1613480868935585, D_Y_loss: 1.1687378591299058\n",
      "[21:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[21:400] Took 110.72s\n",
      "[21:400] loss_idt_x: 0.2015886267274618, G_fool_loss: 0.06617080576717854, predictor_x_loss: 0.18846534356474876, cycled_x_loss: 0.20681714341044427, D_X_loss: 1.2226746273040772\n",
      "[21:400] loss_idt_y: 0.12064508192241191, F_fool_loss: 0.07705131102353334, predictor_y_loss: 0.21358131647109985, cycled_y_loss: 0.13295855164527892, D_Y_loss: 1.1068726974725722\n",
      "[21:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[21:500] Took 110.59s\n",
      "[21:500] loss_idt_x: 0.2434339478611946, G_fool_loss: 0.07756562050431967, predictor_x_loss: 0.1940197815746069, cycled_x_loss: 0.2338931143283844, D_X_loss: 1.2513988310098647\n",
      "[21:500] loss_idt_y: 0.12269804634153843, F_fool_loss: 0.09111252456903457, predictor_y_loss: 0.21128227978944777, cycled_y_loss: 0.1376865442097187, D_Y_loss: 1.1202234703302383\n",
      "[21:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[21:END] Completed epoch in 670.5842232704163s\n",
      "[21:599] ep_loss_idt_x: 0.223 ep_G_fool_loss: 0.091 ep_predictor_x_loss: 0.189 ep_cycled_x_loss: 0.219 ep_D_X_loss: 1.248\n",
      "[21:599] ep_loss_idt_y: 0.131 ep_F_fool_loss: 0.089 ep_predictor_y_loss: 0.218 ep_cycled_y_loss: 0.145 ep_D_Y_loss: 1.143\n",
      "[21:END] Completed eval in 4.424456596374512s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[21:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[22:100] Took 116.22s\n",
      "[22:100] loss_idt_x: 0.2359199222177267, G_fool_loss: 0.07656010661274194, predictor_x_loss: 0.19185357943177223, cycled_x_loss: 0.22816044837236404, D_X_loss: 1.2569827729463576\n",
      "[22:100] loss_idt_y: 0.12988101042807101, F_fool_loss: 0.08270148277282714, predictor_y_loss: 0.2156753522902727, cycled_y_loss: 0.13717226415872574, D_Y_loss: 1.153607639670372\n",
      "[22:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[22:200] Took 110.71s\n",
      "[22:200] loss_idt_x: 0.21498207941651346, G_fool_loss: 0.07254824128001928, predictor_x_loss: 0.19307311050593853, cycled_x_loss: 0.22093573912978173, D_X_loss: 1.257390569448471\n",
      "[22:200] loss_idt_y: 0.13049584187567234, F_fool_loss: 0.08963566463440657, predictor_y_loss: 0.22516689531505107, cycled_y_loss: 0.14417000710964203, D_Y_loss: 1.1149342864751817\n",
      "[22:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[22:300] Took 110.86s\n",
      "[22:300] loss_idt_x: 0.2078632812947035, G_fool_loss: 0.07674393441528082, predictor_x_loss: 0.181024237126112, cycled_x_loss: 0.2063797728717327, D_X_loss: 1.223836101293564\n",
      "[22:300] loss_idt_y: 0.11260543715208769, F_fool_loss: 0.07059657782316207, predictor_y_loss: 0.2126241923868656, cycled_y_loss: 0.1277090185880661, D_Y_loss: 1.1109009116888047\n",
      "[22:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[22:400] Took 111.09s\n",
      "[22:400] loss_idt_x: 0.20420379959046842, G_fool_loss: 0.1414052688702941, predictor_x_loss: 0.17737751118838788, cycled_x_loss: 0.1996026536077261, D_X_loss: 1.2818336302042008\n",
      "[22:400] loss_idt_y: 0.12823200106620788, F_fool_loss: 0.10972798727452755, predictor_y_loss: 0.21714513562619686, cycled_y_loss: 0.14382366135716437, D_Y_loss: 1.2326390880346298\n",
      "[22:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[22:500] Took 110.85s\n",
      "[22:500] loss_idt_x: 0.21413516670465468, G_fool_loss: 0.0760305182263255, predictor_x_loss: 0.16930836461484433, cycled_x_loss: 0.2007702062278986, D_X_loss: 1.2511377555131913\n",
      "[22:500] loss_idt_y: 0.12166794754564762, F_fool_loss: 0.091888014562428, predictor_y_loss: 0.21171624228358268, cycled_y_loss: 0.13602034121751785, D_Y_loss: 1.1145275932550431\n",
      "[22:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[22:END] Completed epoch in 671.9208559989929s\n",
      "[22:599] ep_loss_idt_x: 0.217 ep_G_fool_loss: 0.086 ep_predictor_x_loss: 0.182 ep_cycled_x_loss: 0.211 ep_D_X_loss: 1.257\n",
      "[22:599] ep_loss_idt_y: 0.123 ep_F_fool_loss: 0.091 ep_predictor_y_loss: 0.214 ep_cycled_y_loss: 0.136 ep_D_Y_loss: 1.138\n",
      "[22:END] Completed eval in 4.590032339096069s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[22:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[23:100] Took 117.76s\n",
      "[23:100] loss_idt_x: 0.21949180766940116, G_fool_loss: 0.09025544304400683, predictor_x_loss: 0.182314645498991, cycled_x_loss: 0.21107795767486096, D_X_loss: 1.257822933793068\n",
      "[23:100] loss_idt_y: 0.11999649375677109, F_fool_loss: 0.0861150412261486, predictor_y_loss: 0.22624216742813588, cycled_y_loss: 0.13222715251147746, D_Y_loss: 1.1520464128255845\n",
      "[23:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[23:200] Took 112.18s\n",
      "[23:200] loss_idt_x: 0.18337307535111905, G_fool_loss: 0.09763498142361642, predictor_x_loss: 0.17264613635838033, cycled_x_loss: 0.19843449860811233, D_X_loss: 1.2314900940656661\n",
      "[23:200] loss_idt_y: 0.12696453742682934, F_fool_loss: 0.0741991562768817, predictor_y_loss: 0.21579417116940022, cycled_y_loss: 0.1458193952590227, D_Y_loss: 1.1474408400058747\n",
      "[23:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[23:300] Took 112.07s\n",
      "[23:300] loss_idt_x: 0.21063835285604, G_fool_loss: 0.07401528168469668, predictor_x_loss: 0.18479166083037854, cycled_x_loss: 0.1977826087921858, D_X_loss: 1.2380513733625411\n",
      "[23:300] loss_idt_y: 0.11845586843788623, F_fool_loss: 0.07488663755357265, predictor_y_loss: 0.22283195935189723, cycled_y_loss: 0.1279993199557066, D_Y_loss: 1.1061189836263656\n",
      "[23:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[23:400] Took 112.14s\n",
      "[23:400] loss_idt_x: 0.2172000654786825, G_fool_loss: 0.07161295507103205, predictor_x_loss: 0.19127691581845283, cycled_x_loss: 0.2131421174108982, D_X_loss: 1.2538861536979675\n",
      "[23:400] loss_idt_y: 0.12509079061448575, F_fool_loss: 0.08076251350343228, predictor_y_loss: 0.2254880876839161, cycled_y_loss: 0.13546247497200967, D_Y_loss: 1.1040733444690705\n",
      "[23:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[23:500] Took 111.63s\n",
      "[23:500] loss_idt_x: 0.22136789247393607, G_fool_loss: 0.09166970681399107, predictor_x_loss: 0.18121846608817577, cycled_x_loss: 0.21180677510797977, D_X_loss: 1.2821069955825806\n",
      "[23:500] loss_idt_y: 0.11414699420332909, F_fool_loss: 0.10725246585905551, predictor_y_loss: 0.21488272607326508, cycled_y_loss: 0.12839202091097832, D_Y_loss: 1.127055367231369\n",
      "[23:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[23:END] Completed epoch in 679.573037147522s\n",
      "[23:599] ep_loss_idt_x: 0.212 ep_G_fool_loss: 0.085 ep_predictor_x_loss: 0.182 ep_cycled_x_loss: 0.205 ep_D_X_loss: 1.252\n",
      "[23:599] ep_loss_idt_y: 0.119 ep_F_fool_loss: 0.087 ep_predictor_y_loss: 0.219 ep_cycled_y_loss: 0.131 ep_D_Y_loss: 1.122\n",
      "[23:END] Completed eval in 4.532604694366455s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[23:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[24:100] Took 119.24s\n",
      "[24:100] loss_idt_x: 0.2071268381923437, G_fool_loss: 0.10324653685092926, predictor_x_loss: 0.18986046060919762, cycled_x_loss: 0.20587963201105594, D_X_loss: 1.271554895043373\n",
      "[24:100] loss_idt_y: 0.12505176391452552, F_fool_loss: 0.08606726959347726, predictor_y_loss: 0.21190112978219985, cycled_y_loss: 0.14442764237523079, D_Y_loss: 1.150962119102478\n",
      "[24:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[24:200] Took 113.22s\n",
      "[24:200] loss_idt_x: 0.20875221110880374, G_fool_loss: 0.06915062315762042, predictor_x_loss: 0.18628543511033058, cycled_x_loss: 0.2156565061956644, D_X_loss: 1.2366939210891723\n",
      "[24:200] loss_idt_y: 0.150266949608922, F_fool_loss: 0.08329073708504438, predictor_y_loss: 0.22862611822783946, cycled_y_loss: 0.1680516653507948, D_Y_loss: 1.128503497838974\n",
      "[24:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[24:300] Took 113.18s\n",
      "[24:300] loss_idt_x: 0.2153845439851284, G_fool_loss: 0.07640995036810637, predictor_x_loss: 0.1771199634671211, cycled_x_loss: 0.2093535650521517, D_X_loss: 1.2456093740463257\n",
      "[24:300] loss_idt_y: 0.12802609082311392, F_fool_loss: 0.0786937091499567, predictor_y_loss: 0.22103452555835246, cycled_y_loss: 0.1463709631562233, D_Y_loss: 1.107383643388748\n",
      "[24:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[24:400] Took 113.23s\n",
      "[24:400] loss_idt_x: 0.22311411269009113, G_fool_loss: 0.07865600492805243, predictor_x_loss: 0.1894186969846487, cycled_x_loss: 0.2065493531525135, D_X_loss: 1.2456228297948837\n",
      "[24:400] loss_idt_y: 0.12070301089435816, F_fool_loss: 0.06846728645265103, predictor_y_loss: 0.2152002763748169, cycled_y_loss: 0.13597788833081723, D_Y_loss: 1.1220111030340194\n",
      "[24:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[24:500] Took 113.30s\n",
      "[24:500] loss_idt_x: 0.20459778986871244, G_fool_loss: 0.13037564419209957, predictor_x_loss: 0.17940880611538887, cycled_x_loss: 0.20771206095814704, D_X_loss: 1.2451503813266753\n",
      "[24:500] loss_idt_y: 0.12834371231496333, F_fool_loss: 0.08937266740947962, predictor_y_loss: 0.217356061860919, cycled_y_loss: 0.1399898476153612, D_Y_loss: 1.1742090344429017\n",
      "[24:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[24:END] Completed epoch in 687.9782485961914s\n",
      "[24:599] ep_loss_idt_x: 0.210 ep_G_fool_loss: 0.090 ep_predictor_x_loss: 0.183 ep_cycled_x_loss: 0.206 ep_D_X_loss: 1.253\n",
      "[24:599] ep_loss_idt_y: 0.126 ep_F_fool_loss: 0.087 ep_predictor_y_loss: 0.218 ep_cycled_y_loss: 0.142 ep_D_Y_loss: 1.132\n",
      "[24:END] Completed eval in 4.534316539764404s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[24:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[25:100] Took 115.90s\n",
      "[25:100] loss_idt_x: 0.2044379173219204, G_fool_loss: 0.06384615059942007, predictor_x_loss: 0.17312039583921432, cycled_x_loss: 0.1947258624434471, D_X_loss: 1.2761328989267349\n",
      "[25:100] loss_idt_y: 0.11710301622748374, F_fool_loss: 0.08746976520866155, predictor_y_loss: 0.21322200544178485, cycled_y_loss: 0.12535484790802, D_Y_loss: 1.1289825254678727\n",
      "[25:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[25:200] Took 111.08s\n",
      "[25:200] loss_idt_x: 0.20387682639062404, G_fool_loss: 0.07198372907936573, predictor_x_loss: 0.1784472331404686, cycled_x_loss: 0.1967473618686199, D_X_loss: 1.4058274817466736\n",
      "[25:200] loss_idt_y: 0.12245500445365906, F_fool_loss: 0.1806284310296178, predictor_y_loss: 0.21856457531452178, cycled_y_loss: 0.1326365876197815, D_Y_loss: 1.1064763885736466\n",
      "[25:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[25:300] Took 111.09s\n",
      "[25:300] loss_idt_x: 0.20903267845511436, G_fool_loss: 0.12731365278363227, predictor_x_loss: 0.187435697093606, cycled_x_loss: 0.2116359965503216, D_X_loss: 1.2812571012973786\n",
      "[25:300] loss_idt_y: 0.12117819629609584, F_fool_loss: 0.1028429265320301, predictor_y_loss: 0.22648559533059598, cycled_y_loss: 0.13470303647220136, D_Y_loss: 1.1989956378936768\n",
      "[25:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[25:400] Took 111.00s\n",
      "[25:400] loss_idt_x: 0.199247105717659, G_fool_loss: 0.10984754748642445, predictor_x_loss: 0.16668568395078182, cycled_x_loss: 0.19389570206403733, D_X_loss: 1.2532619017362594\n",
      "[25:400] loss_idt_y: 0.1196170412749052, F_fool_loss: 0.06715282786637544, predictor_y_loss: 0.20986666820943356, cycled_y_loss: 0.1299874973297119, D_Y_loss: 1.1301802206039429\n",
      "[25:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[25:500] Took 110.90s\n",
      "[25:500] loss_idt_x: 0.19261897422373295, G_fool_loss: 0.06898502212017775, predictor_x_loss: 0.171686437651515, cycled_x_loss: 0.17930562689900398, D_X_loss: 1.2148660629987718\n",
      "[25:500] loss_idt_y: 0.10515556160360574, F_fool_loss: 0.06072521686553955, predictor_y_loss: 0.19416806235909462, cycled_y_loss: 0.11606975816190243, D_Y_loss: 1.1119681429862975\n",
      "[25:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[25:END] Completed epoch in 672.3361370563507s\n",
      "[25:599] ep_loss_idt_x: 0.202 ep_G_fool_loss: 0.085 ep_predictor_x_loss: 0.177 ep_cycled_x_loss: 0.196 ep_D_X_loss: 1.272\n",
      "[25:599] ep_loss_idt_y: 0.117 ep_F_fool_loss: 0.095 ep_predictor_y_loss: 0.212 ep_cycled_y_loss: 0.128 ep_D_Y_loss: 1.130\n",
      "[25:END] Completed eval in 4.582376003265381s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[25:END] Saving models and training information permanently\n",
      "[26:100] Took 116.57s\n",
      "[26:100] loss_idt_x: 0.20881861962378026, G_fool_loss: 0.06138669185340404, predictor_x_loss: 0.17316084988415242, cycled_x_loss: 0.20750484645366668, D_X_loss: 1.2847192066907882\n",
      "[26:100] loss_idt_y: 0.11737028509378433, F_fool_loss: 0.10945099327713251, predictor_y_loss: 0.2209773785620928, cycled_y_loss: 0.12930382877588273, D_Y_loss: 1.1113602846860886\n",
      "[26:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[26:200] Took 111.39s\n",
      "[26:200] loss_idt_x: 0.20961917005479336, G_fool_loss: 0.06843728821724654, predictor_x_loss: 0.18448199458420278, cycled_x_loss: 0.19816605240106583, D_X_loss: 1.2407408678531646\n",
      "[26:200] loss_idt_y: 0.11028813391923904, F_fool_loss: 0.07278932001441717, predictor_y_loss: 0.21712986022233963, cycled_y_loss: 0.12017088539898396, D_Y_loss: 1.098229891061783\n",
      "[26:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[26:300] Took 111.03s\n",
      "[26:300] loss_idt_x: 0.20228782653808594, G_fool_loss: 0.07531911917030812, predictor_x_loss: 0.1826832616329193, cycled_x_loss: 0.19594034999608995, D_X_loss: 1.2581904280185698\n",
      "[26:300] loss_idt_y: 0.11759518016129732, F_fool_loss: 0.07231662373989821, predictor_y_loss: 0.2069813658297062, cycled_y_loss: 0.1373883495479822, D_Y_loss: 1.100175947546959\n",
      "[26:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[26:400] Took 110.93s\n",
      "[26:400] loss_idt_x: 0.1944887888431549, G_fool_loss: 0.07301302373409271, predictor_x_loss: 0.176012312322855, cycled_x_loss: 0.1903512578457594, D_X_loss: 1.237169653773308\n",
      "[26:400] loss_idt_y: 0.12148272760212421, F_fool_loss: 0.06630806863307953, predictor_y_loss: 0.2330529808998108, cycled_y_loss: 0.13320804104208947, D_Y_loss: 1.1238837838172913\n",
      "[26:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[26:500] Took 111.02s\n",
      "[26:500] loss_idt_x: 0.20577826529741286, G_fool_loss: 0.1431318750977516, predictor_x_loss: 0.1755614160746336, cycled_x_loss: 0.20253168925642967, D_X_loss: 1.2350826042890548\n",
      "[26:500] loss_idt_y: 0.12801573932170868, F_fool_loss: 0.08266183473169804, predictor_y_loss: 0.21815215513110162, cycled_y_loss: 0.14547851212322713, D_Y_loss: 1.1931162995100022\n",
      "[26:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[26:END] Completed epoch in 673.2715585231781s\n",
      "[26:599] ep_loss_idt_x: 0.203 ep_G_fool_loss: 0.083 ep_predictor_x_loss: 0.177 ep_cycled_x_loss: 0.197 ep_D_X_loss: 1.247\n",
      "[26:599] ep_loss_idt_y: 0.118 ep_F_fool_loss: 0.079 ep_predictor_y_loss: 0.218 ep_cycled_y_loss: 0.132 ep_D_Y_loss: 1.119\n",
      "[26:END] Completed eval in 4.593998670578003s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[26:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[27:100] Took 116.22s\n",
      "[27:100] loss_idt_x: 0.21127768069505692, G_fool_loss: 0.1118119066953659, predictor_x_loss: 0.1788936623185873, cycled_x_loss: 0.20309280328452586, D_X_loss: 1.2347589099407197\n",
      "[27:100] loss_idt_y: 0.13350693456828594, F_fool_loss: 0.06516101628541947, predictor_y_loss: 0.21692257396876813, cycled_y_loss: 0.14978682227432727, D_Y_loss: 1.1544077545404434\n",
      "[27:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[27:200] Took 110.60s\n",
      "[27:200] loss_idt_x: 0.20676906146109103, G_fool_loss: 0.0738486709818244, predictor_x_loss: 0.1933908522129059, cycled_x_loss: 0.21043867066502572, D_X_loss: 1.204818389415741\n",
      "[27:200] loss_idt_y: 0.11626449223607778, F_fool_loss: 0.06627666503190995, predictor_y_loss: 0.2123199909925461, cycled_y_loss: 0.12948325663805008, D_Y_loss: 1.1188054722547531\n",
      "[27:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[27:300] Took 110.45s\n",
      "[27:300] loss_idt_x: 0.19998312830924989, G_fool_loss: 0.06905322276055813, predictor_x_loss: 0.17248777478933333, cycled_x_loss: 0.18318856187164784, D_X_loss: 1.2753480011224747\n",
      "[27:300] loss_idt_y: 0.11638757333159447, F_fool_loss: 0.11368733618408441, predictor_y_loss: 0.21909351661801338, cycled_y_loss: 0.13578978784382342, D_Y_loss: 1.0884653675556182\n",
      "[27:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[27:400] Took 111.17s\n",
      "[27:400] loss_idt_x: 0.18495469160377978, G_fool_loss: 0.06935644805431367, predictor_x_loss: 0.16441087439656257, cycled_x_loss: 0.183197181224823, D_X_loss: 1.2366602087020875\n",
      "[27:400] loss_idt_y: 0.11983759198337793, F_fool_loss: 0.08697502978146077, predictor_y_loss: 0.20794930323958397, cycled_y_loss: 0.13445083573460578, D_Y_loss: 1.1123309415578841\n",
      "[27:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[27:500] Took 110.71s\n",
      "[27:500] loss_idt_x: 0.20731432430446148, G_fool_loss: 0.08091777373105287, predictor_x_loss: 0.17622691817581654, cycled_x_loss: 0.19393815882503987, D_X_loss: 1.2694642078876495\n",
      "[27:500] loss_idt_y: 0.11912887338548898, F_fool_loss: 0.09932928569614888, predictor_y_loss: 0.21964224576950073, cycled_y_loss: 0.13192093893885612, D_Y_loss: 1.0931586855649948\n",
      "[27:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[27:END] Completed epoch in 671.1215605735779s\n",
      "[27:599] ep_loss_idt_x: 0.203 ep_G_fool_loss: 0.079 ep_predictor_x_loss: 0.176 ep_cycled_x_loss: 0.194 ep_D_X_loss: 1.242\n",
      "[27:599] ep_loss_idt_y: 0.119 ep_F_fool_loss: 0.084 ep_predictor_y_loss: 0.216 ep_cycled_y_loss: 0.134 ep_D_Y_loss: 1.109\n",
      "[27:END] Completed eval in 4.650871992111206s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[27:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[28:100] Took 114.47s\n",
      "[28:100] loss_idt_x: 0.19988968551158906, G_fool_loss: 0.0915606464445591, predictor_x_loss: 0.1790100011974573, cycled_x_loss: 0.19244850173592568, D_X_loss: 1.3274182188510895\n",
      "[28:100] loss_idt_y: 0.11130363285541535, F_fool_loss: 0.13590060740709306, predictor_y_loss: 0.211257106885314, cycled_y_loss: 0.12117795713245869, D_Y_loss: 1.1190201407670974\n",
      "[28:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[28:200] Took 108.46s\n",
      "[28:200] loss_idt_x: 0.18606555536389352, G_fool_loss: 0.0732300353050232, predictor_x_loss: 0.16343038842082025, cycled_x_loss: 0.1766391286253929, D_X_loss: 1.2282889395952226\n",
      "[28:200] loss_idt_y: 0.10390197984874248, F_fool_loss: 0.07168108683079481, predictor_y_loss: 0.20285781502723693, cycled_y_loss: 0.1169130852818489, D_Y_loss: 1.0967019921541215\n",
      "[28:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[28:300] Took 108.43s\n",
      "[28:300] loss_idt_x: 0.18165515951812267, G_fool_loss: 0.07783012069761754, predictor_x_loss: 0.16948195293545723, cycled_x_loss: 0.18310456991195678, D_X_loss: 1.224357351064682\n",
      "[28:300] loss_idt_y: 0.10444826014339924, F_fool_loss: 0.0643859388306737, predictor_y_loss: 0.21359759904444217, cycled_y_loss: 0.11804674446582794, D_Y_loss: 1.1180568373203277\n",
      "[28:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[28:400] Took 108.45s\n",
      "[28:400] loss_idt_x: 0.18227694980800152, G_fool_loss: 0.08671604957431554, predictor_x_loss: 0.17810231424868106, cycled_x_loss: 0.17895730070769786, D_X_loss: 1.2307325619459153\n",
      "[28:400] loss_idt_y: 0.11798482041805983, F_fool_loss: 0.0605982281640172, predictor_y_loss: 0.20655246786773204, cycled_y_loss: 0.13152876026928426, D_Y_loss: 1.1113648796081543\n",
      "[28:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[28:500] Took 108.67s\n",
      "[28:500] loss_idt_x: 0.20849224589765072, G_fool_loss: 0.6309776897355914, predictor_x_loss: 0.17538794353604317, cycled_x_loss: 0.19461370952427387, D_X_loss: 1.247137975692749\n",
      "[28:500] loss_idt_y: 0.1220922850444913, F_fool_loss: 0.08357481952756643, predictor_y_loss: 0.22160092391073705, cycled_y_loss: 0.13546978324651718, D_Y_loss: 1.7655016732215882\n",
      "[28:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[28:END] Completed epoch in 659.9486682415009s\n",
      "[28:599] ep_loss_idt_x: 0.191 ep_G_fool_loss: 0.180 ep_predictor_x_loss: 0.172 ep_cycled_x_loss: 0.184 ep_D_X_loss: 1.244\n",
      "[28:599] ep_loss_idt_y: 0.113 ep_F_fool_loss: 0.080 ep_predictor_y_loss: 0.209 ep_cycled_y_loss: 0.125 ep_D_Y_loss: 1.206\n",
      "[28:END] Completed eval in 4.704006195068359s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[28:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[29:100] Took 112.48s\n",
      "[29:100] loss_idt_x: 0.1898631137609482, G_fool_loss: 0.08772883288562298, predictor_x_loss: 0.16909357614815235, cycled_x_loss: 0.17766860917210578, D_X_loss: 1.2962281048297881\n",
      "[29:100] loss_idt_y: 0.10915385529398919, F_fool_loss: 0.104599693082273, predictor_y_loss: 0.2112657368183136, cycled_y_loss: 0.12040492758154869, D_Y_loss: 1.0106211286783218\n",
      "[29:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[29:200] Took 107.47s\n",
      "[29:200] loss_idt_x: 0.1801556731760502, G_fool_loss: 0.06974568836390972, predictor_x_loss: 0.16301606863737106, cycled_x_loss: 0.1838306971639395, D_X_loss: 1.243532794713974\n",
      "[29:200] loss_idt_y: 0.1127947697788477, F_fool_loss: 0.0865123150870204, predictor_y_loss: 0.21350437313318252, cycled_y_loss: 0.127127538472414, D_Y_loss: 1.064758648276329\n",
      "[29:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[29:300] Took 107.51s\n",
      "[29:300] loss_idt_x: 0.18034702979028225, G_fool_loss: 0.0723042206466198, predictor_x_loss: 0.17033311747014523, cycled_x_loss: 0.18411555908620358, D_X_loss: 1.2748982578516006\n",
      "[29:300] loss_idt_y: 0.10640573058277368, F_fool_loss: 0.09503138214349746, predictor_y_loss: 0.21530874140560627, cycled_y_loss: 0.11611255388706923, D_Y_loss: 1.0711734038591385\n",
      "[29:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[29:400] Took 107.43s\n",
      "[29:400] loss_idt_x: 0.18838763691484928, G_fool_loss: 0.06998841810971498, predictor_x_loss: 0.1686682540923357, cycled_x_loss: 0.18495478816330432, D_X_loss: 1.2431363624334335\n",
      "[29:400] loss_idt_y: 0.10533052153885364, F_fool_loss: 0.08099197033792734, predictor_y_loss: 0.2125291284173727, cycled_y_loss: 0.11370716400444508, D_Y_loss: 1.077391929626465\n",
      "[29:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[29:500] Took 107.50s\n",
      "[29:500] loss_idt_x: 0.193889839053154, G_fool_loss: 0.06544348020106554, predictor_x_loss: 0.17065299920737742, cycled_x_loss: 0.17848241947591303, D_X_loss: 1.2525526040792465\n",
      "[29:500] loss_idt_y: 0.10443032801151275, F_fool_loss: 0.11980141386389732, predictor_y_loss: 0.20998355716466904, cycled_y_loss: 0.1164337857067585, D_Y_loss: 1.0823104494810105\n",
      "[29:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[29:END] Completed epoch in 651.3372709751129s\n",
      "[29:599] ep_loss_idt_x: 0.185 ep_G_fool_loss: 0.072 ep_predictor_x_loss: 0.169 ep_cycled_x_loss: 0.180 ep_D_X_loss: 1.278\n",
      "[29:599] ep_loss_idt_y: 0.107 ep_F_fool_loss: 0.115 ep_predictor_y_loss: 0.212 ep_cycled_y_loss: 0.118 ep_D_Y_loss: 1.062\n",
      "[29:END] Completed eval in 4.619432687759399s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[29:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[30:100] Took 117.80s\n",
      "[30:100] loss_idt_x: 0.17733904622495175, G_fool_loss: 0.06586168471723795, predictor_x_loss: 0.16119793690741063, cycled_x_loss: 0.16982120625674724, D_X_loss: 1.2468313616514206\n",
      "[30:100] loss_idt_y: 0.1039934217184782, F_fool_loss: 0.0700741607695818, predictor_y_loss: 0.19506640806794168, cycled_y_loss: 0.10896448507905006, D_Y_loss: 1.0916104704141616\n",
      "[30:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[30:200] Took 112.50s\n",
      "[30:200] loss_idt_x: 0.18644112952053546, G_fool_loss: 0.0615001992881298, predictor_x_loss: 0.18124233730137349, cycled_x_loss: 0.1833993500471115, D_X_loss: 1.218824275135994\n",
      "[30:200] loss_idt_y: 0.10641876552253962, F_fool_loss: 0.06125861432403326, predictor_y_loss: 0.20994075238704682, cycled_y_loss: 0.11826242618262768, D_Y_loss: 1.0986116009950637\n",
      "[30:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[30:300] Took 113.70s\n",
      "[30:300] loss_idt_x: 0.1894937976449728, G_fool_loss: 0.07216894216835498, predictor_x_loss: 0.16459315069019795, cycled_x_loss: 0.1844572276622057, D_X_loss: 1.2067696636915206\n",
      "[30:300] loss_idt_y: 0.11036521300673485, F_fool_loss: 0.0640036851912737, predictor_y_loss: 0.21053968779742718, cycled_y_loss: 0.11780956976115703, D_Y_loss: 1.1109195160865784\n",
      "[30:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[30:400] Took 113.82s\n",
      "[30:400] loss_idt_x: 0.1918952839076519, G_fool_loss: 0.07710534490644932, predictor_x_loss: 0.16181874826550482, cycled_x_loss: 0.18256386056542395, D_X_loss: 1.230280065536499\n",
      "[30:400] loss_idt_y: 0.103718181848526, F_fool_loss: 0.06761087074875832, predictor_y_loss: 0.20938960283994676, cycled_y_loss: 0.11850398562848569, D_Y_loss: 1.1061703199148178\n",
      "[30:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[30:500] Took 113.68s\n",
      "[30:500] loss_idt_x: 0.18382366620004176, G_fool_loss: 0.0671699595451355, predictor_x_loss: 0.17596007235348224, cycled_x_loss: 0.1813927311450243, D_X_loss: 1.2239485436677933\n",
      "[30:500] loss_idt_y: 0.11010245334357023, F_fool_loss: 0.06969182379543781, predictor_y_loss: 0.20297440372407435, cycled_y_loss: 0.12506203956902026, D_Y_loss: 1.1122386407852174\n",
      "[30:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[30:END] Completed epoch in 687.2415442466736s\n",
      "[30:599] ep_loss_idt_x: 0.182 ep_G_fool_loss: 0.070 ep_predictor_x_loss: 0.167 ep_cycled_x_loss: 0.177 ep_D_X_loss: 1.226\n",
      "[30:599] ep_loss_idt_y: 0.106 ep_F_fool_loss: 0.067 ep_predictor_y_loss: 0.205 ep_cycled_y_loss: 0.116 ep_D_Y_loss: 1.102\n",
      "[30:END] Completed eval in 4.696044921875s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[30:END] Saving models and training information permanently\n",
      "[31:100] Took 120.53s\n",
      "[31:100] loss_idt_x: 0.1773082923144102, G_fool_loss: 0.09598444186151028, predictor_x_loss: 0.17390065878629685, cycled_x_loss: 0.18292397603392602, D_X_loss: 1.2383156579732895\n",
      "[31:100] loss_idt_y: 0.11099047645926476, F_fool_loss: 0.06744950536638498, predictor_y_loss: 0.21416783906519413, cycled_y_loss: 0.12937983058393002, D_Y_loss: 1.158605472445488\n",
      "[31:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[31:200] Took 114.23s\n",
      "[31:200] loss_idt_x: 0.17469486378133298, G_fool_loss: 0.06961577467620372, predictor_x_loss: 0.1718159395456314, cycled_x_loss: 0.17308745242655277, D_X_loss: 1.2376106971502303\n",
      "[31:200] loss_idt_y: 0.10357963860034942, F_fool_loss: 0.09568684961646795, predictor_y_loss: 0.21814536064863205, cycled_y_loss: 0.11316214814782143, D_Y_loss: 1.1318607115745545\n",
      "[31:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[31:300] Took 114.13s\n",
      "[31:300] loss_idt_x: 0.1813390151411295, G_fool_loss: 0.0658754925429821, predictor_x_loss: 0.16405447892844677, cycled_x_loss: 0.17377671644091605, D_X_loss: 1.2163671737909316\n",
      "[31:300] loss_idt_y: 0.10211777657270432, F_fool_loss: 0.06210335835814476, predictor_y_loss: 0.19747606471180915, cycled_y_loss: 0.11270983517169952, D_Y_loss: 1.1085149937868117\n",
      "[31:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[31:400] Took 113.95s\n",
      "[31:400] loss_idt_x: 0.1854276868700981, G_fool_loss: 0.06688110526651143, predictor_x_loss: 0.15503744713962078, cycled_x_loss: 0.16898076549172403, D_X_loss: 1.2483814293146134\n",
      "[31:400] loss_idt_y: 0.11089665554463864, F_fool_loss: 0.07029459215700626, predictor_y_loss: 0.21438755862414838, cycled_y_loss: 0.12525573678314686, D_Y_loss: 1.1028765690326692\n",
      "[31:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[31:500] Took 114.10s\n",
      "[31:500] loss_idt_x: 0.19459094367921353, G_fool_loss: 0.07917930249124766, predictor_x_loss: 0.16524971559643745, cycled_x_loss: 0.18844876304268837, D_X_loss: 1.236621845960617\n",
      "[31:500] loss_idt_y: 0.11161382392048835, F_fool_loss: 0.08046154987066984, predictor_y_loss: 0.21387508533895017, cycled_y_loss: 0.12098698981106282, D_Y_loss: 1.1363198339939118\n",
      "[31:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[31:END] Completed epoch in 692.817444562912s\n",
      "[31:599] ep_loss_idt_x: 0.180 ep_G_fool_loss: 0.076 ep_predictor_x_loss: 0.167 ep_cycled_x_loss: 0.176 ep_D_X_loss: 1.238\n",
      "[31:599] ep_loss_idt_y: 0.105 ep_F_fool_loss: 0.079 ep_predictor_y_loss: 0.209 ep_cycled_y_loss: 0.117 ep_D_Y_loss: 1.127\n",
      "[31:END] Completed eval in 4.776616334915161s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[31:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[32:100] Took 120.17s\n",
      "[32:100] loss_idt_x: 0.17762267380952834, G_fool_loss: 0.06869516719132662, predictor_x_loss: 0.1636004725843668, cycled_x_loss: 0.17775666393339634, D_X_loss: 1.2418796944618224\n",
      "[32:100] loss_idt_y: 0.10672051552683115, F_fool_loss: 0.07766703598201274, predictor_y_loss: 0.21068967550992965, cycled_y_loss: 0.11447343584150076, D_Y_loss: 1.1611964339017868\n",
      "[32:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[32:200] Took 113.59s\n",
      "[32:200] loss_idt_x: 0.16883143573999404, G_fool_loss: 0.07205756064504384, predictor_x_loss: 0.16216908536851407, cycled_x_loss: 0.16725115850567818, D_X_loss: 1.2368691158294678\n",
      "[32:200] loss_idt_y: 0.09499833188951015, F_fool_loss: 0.07363124158233404, predictor_y_loss: 0.19788906529545783, cycled_y_loss: 0.10636262468993664, D_Y_loss: 1.1046857744455338\n",
      "[32:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[32:300] Took 114.21s\n",
      "[32:300] loss_idt_x: 0.1780023067444563, G_fool_loss: 0.06927479822188616, predictor_x_loss: 0.17843931630253793, cycled_x_loss: 0.17575674250721932, D_X_loss: 1.2546585839986801\n",
      "[32:300] loss_idt_y: 0.11515065960586071, F_fool_loss: 0.09968447033315897, predictor_y_loss: 0.1987318032234907, cycled_y_loss: 0.11897983618080615, D_Y_loss: 1.1348196583986283\n",
      "[32:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[32:400] Took 114.07s\n",
      "[32:400] loss_idt_x: 0.1948958072811365, G_fool_loss: 0.06597467325627804, predictor_x_loss: 0.16239819273352624, cycled_x_loss: 0.18069708600640297, D_X_loss: 1.2228516292572023\n",
      "[32:400] loss_idt_y: 0.10194655172526837, F_fool_loss: 0.06872132059186697, predictor_y_loss: 0.21052993260324002, cycled_y_loss: 0.10850057646632194, D_Y_loss: 1.1235818004608153\n",
      "[32:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[32:500] Took 114.05s\n",
      "[32:500] loss_idt_x: 0.16474249392747878, G_fool_loss: 0.09344423796981573, predictor_x_loss: 0.16202382385730743, cycled_x_loss: 0.16340385988354683, D_X_loss: 1.2230357825756073\n",
      "[32:500] loss_idt_y: 0.10711980193853378, F_fool_loss: 0.07598919115960598, predictor_y_loss: 0.21232554346323013, cycled_y_loss: 0.11652510829269885, D_Y_loss: 1.148053748011589\n",
      "[32:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[32:END] Completed epoch in 693.1502532958984s\n",
      "[32:599] ep_loss_idt_x: 0.175 ep_G_fool_loss: 0.073 ep_predictor_x_loss: 0.165 ep_cycled_x_loss: 0.170 ep_D_X_loss: 1.233\n",
      "[32:599] ep_loss_idt_y: 0.103 ep_F_fool_loss: 0.079 ep_predictor_y_loss: 0.206 ep_cycled_y_loss: 0.112 ep_D_Y_loss: 1.128\n",
      "[32:END] Completed eval in 4.740237712860107s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[32:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[33:100] Took 116.09s\n",
      "[33:100] loss_idt_x: 0.17688650332391262, G_fool_loss: 0.07065740834921598, predictor_x_loss: 0.16396966002881527, cycled_x_loss: 0.16734761327505113, D_X_loss: 1.2463697016239166\n",
      "[33:100] loss_idt_y: 0.10702407144010068, F_fool_loss: 0.07455191612243653, predictor_y_loss: 0.21520375184714793, cycled_y_loss: 0.11612318657338619, D_Y_loss: 1.1252281641960145\n",
      "[33:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[33:200] Took 112.38s\n",
      "[33:200] loss_idt_x: 0.158724033087492, G_fool_loss: 0.06638819225132465, predictor_x_loss: 0.16584813162684442, cycled_x_loss: 0.15746167086064816, D_X_loss: 1.2147195810079574\n",
      "[33:200] loss_idt_y: 0.10049175813794137, F_fool_loss: 0.06235302235931158, predictor_y_loss: 0.19695304900407792, cycled_y_loss: 0.10872375823557377, D_Y_loss: 1.110391463637352\n",
      "[33:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[33:300] Took 112.20s\n",
      "[33:300] loss_idt_x: 0.18273914240300657, G_fool_loss: 0.10350026421248913, predictor_x_loss: 0.16883296251296998, cycled_x_loss: 0.18219063878059388, D_X_loss: 2.3845112615823747\n",
      "[33:300] loss_idt_y: 0.0970393780246377, F_fool_loss: 1.013485409989953, predictor_y_loss: 0.2206677145510912, cycled_y_loss: 0.11587179634720086, D_Y_loss: 1.1567115318775176\n",
      "[33:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[33:400] Took 112.22s\n",
      "[33:400] loss_idt_x: 0.17276007637381555, G_fool_loss: 0.07487014498561621, predictor_x_loss: 0.15323282063007354, cycled_x_loss: 0.16850928626954556, D_X_loss: 1.2129126596450805\n",
      "[33:400] loss_idt_y: 0.1000549453124404, F_fool_loss: 0.07673134364187717, predictor_y_loss: 0.2111155542731285, cycled_y_loss: 0.11014203164726495, D_Y_loss: 1.091634500026703\n",
      "[33:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[33:500] Took 112.68s\n",
      "[33:500] loss_idt_x: 0.18235640965402125, G_fool_loss: 0.07454075329005719, predictor_x_loss: 0.17985986217856406, cycled_x_loss: 0.17329103082418443, D_X_loss: 1.1883503592014313\n",
      "[33:500] loss_idt_y: 0.11234634745866061, F_fool_loss: 0.07121008567512035, predictor_y_loss: 0.2038922180980444, cycled_y_loss: 0.11584909927099943, D_Y_loss: 1.1201679277420045\n",
      "[33:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[33:END] Completed epoch in 679.7269806861877s\n",
      "[33:599] ep_loss_idt_x: 0.174 ep_G_fool_loss: 0.077 ep_predictor_x_loss: 0.165 ep_cycled_x_loss: 0.168 ep_D_X_loss: 1.410\n",
      "[33:599] ep_loss_idt_y: 0.101 ep_F_fool_loss: 0.228 ep_predictor_y_loss: 0.207 ep_cycled_y_loss: 0.111 ep_D_Y_loss: 1.116\n",
      "[33:END] Completed eval in 4.862411737442017s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[33:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[34:100] Took 118.68s\n",
      "[34:100] loss_idt_x: 0.1706944464892149, G_fool_loss: 0.06570323772728442, predictor_x_loss: 0.16058902405202388, cycled_x_loss: 0.16201726332306862, D_X_loss: 1.2160401421785354\n",
      "[34:100] loss_idt_y: 0.09995831694453955, F_fool_loss: 0.06034476149827242, predictor_y_loss: 0.19943667992949485, cycled_y_loss: 0.10943977449089289, D_Y_loss: 1.125423789024353\n",
      "[34:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[34:200] Took 111.41s\n",
      "[34:200] loss_idt_x: 0.17424387358129023, G_fool_loss: 0.0816418768465519, predictor_x_loss: 0.16761581987142563, cycled_x_loss: 0.17125023521482943, D_X_loss: 1.2011296969652177\n",
      "[34:200] loss_idt_y: 0.10994927156716586, F_fool_loss: 0.062292060330510136, predictor_y_loss: 0.20946478530764578, cycled_y_loss: 0.12125074759125709, D_Y_loss: 1.135685332417488\n",
      "[34:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[34:300] Took 111.60s\n",
      "[34:300] loss_idt_x: 0.1684188151359558, G_fool_loss: 0.07184253182262182, predictor_x_loss: 0.16297150768339633, cycled_x_loss: 0.16510699436068535, D_X_loss: 1.2117355591058732\n",
      "[34:300] loss_idt_y: 0.10914227217435837, F_fool_loss: 0.0580388206243515, predictor_y_loss: 0.21834801994264125, cycled_y_loss: 0.11774586454033852, D_Y_loss: 1.097617866396904\n",
      "[34:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[34:400] Took 111.37s\n",
      "[34:400] loss_idt_x: 0.1721886008232832, G_fool_loss: 0.13939333032816648, predictor_x_loss: 0.1682522327452898, cycled_x_loss: 0.17106638118624687, D_X_loss: 1.2144970285892487\n",
      "[34:400] loss_idt_y: 0.10543400090187788, F_fool_loss: 0.06147202406078577, predictor_y_loss: 0.19812659226357937, cycled_y_loss: 0.11743576131761074, D_Y_loss: 1.1999866682291032\n",
      "[34:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[34:500] Took 111.45s\n",
      "[34:500] loss_idt_x: 0.17161760568618775, G_fool_loss: 0.0672093677520752, predictor_x_loss: 0.1691662535071373, cycled_x_loss: 0.17018327131867408, D_X_loss: 1.231742092370987\n",
      "[34:500] loss_idt_y: 0.10532282169908286, F_fool_loss: 0.06286691669374704, predictor_y_loss: 0.2210737482458353, cycled_y_loss: 0.11683360874652862, D_Y_loss: 1.1080696111917496\n",
      "[34:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[34:END] Completed epoch in 679.3570387363434s\n",
      "[34:599] ep_loss_idt_x: 0.170 ep_G_fool_loss: 0.082 ep_predictor_x_loss: 0.165 ep_cycled_x_loss: 0.167 ep_D_X_loss: 1.211\n",
      "[34:599] ep_loss_idt_y: 0.105 ep_F_fool_loss: 0.061 ep_predictor_y_loss: 0.209 ep_cycled_y_loss: 0.115 ep_D_Y_loss: 1.130\n",
      "[34:END] Completed eval in 4.781275272369385s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[34:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[35:100] Took 117.30s\n",
      "[35:100] loss_idt_x: 0.15382519185543062, G_fool_loss: 0.06427534457296133, predictor_x_loss: 0.16583992347121237, cycled_x_loss: 0.1599104544520378, D_X_loss: 1.2228205746412277\n",
      "[35:100] loss_idt_y: 0.10505009986460209, F_fool_loss: 0.07131161451339722, predictor_y_loss: 0.20498705692589284, cycled_y_loss: 0.11528761725872755, D_Y_loss: 1.1032332456111908\n",
      "[35:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[35:200] Took 111.24s\n",
      "[35:200] loss_idt_x: 0.16692232459783554, G_fool_loss: 0.06371424239128828, predictor_x_loss: 0.15903920255601406, cycled_x_loss: 0.16168585136532784, D_X_loss: 1.2114052921533585\n",
      "[35:200] loss_idt_y: 0.09967063263058662, F_fool_loss: 0.06925293259322643, predictor_y_loss: 0.20631369411945344, cycled_y_loss: 0.11180840507149696, D_Y_loss: 1.1228951340913773\n",
      "[35:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[35:300] Took 111.38s\n",
      "[35:300] loss_idt_x: 0.16477481588721277, G_fool_loss: 0.0714729830995202, predictor_x_loss: 0.1627997225522995, cycled_x_loss: 0.1546002747118473, D_X_loss: 1.2258132541179656\n",
      "[35:300] loss_idt_y: 0.10370813466608525, F_fool_loss: 0.08287027731537819, predictor_y_loss: 0.21253889925777913, cycled_y_loss: 0.11563888773322105, D_Y_loss: 1.129890130162239\n",
      "[35:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[35:400] Took 111.24s\n",
      "[35:400] loss_idt_x: 0.15222614631056786, G_fool_loss: 0.07658862132579088, predictor_x_loss: 0.15652486003935337, cycled_x_loss: 0.14766524098813533, D_X_loss: 1.2320546478033065\n",
      "[35:400] loss_idt_y: 0.09072805631905795, F_fool_loss: 0.06735298734158278, predictor_y_loss: 0.19788475301116704, cycled_y_loss: 0.09899812173098325, D_Y_loss: 1.134289761185646\n",
      "[35:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[35:500] Took 111.19s\n",
      "[35:500] loss_idt_x: 0.17028978746384382, G_fool_loss: 0.07248625699430704, predictor_x_loss: 0.1617934251576662, cycled_x_loss: 0.1567240596562624, D_X_loss: 1.2376250040531158\n",
      "[35:500] loss_idt_y: 0.10277497820556164, F_fool_loss: 0.06505894184112548, predictor_y_loss: 0.19945556364953518, cycled_y_loss: 0.11239879950881004, D_Y_loss: 1.1164323806762695\n",
      "[35:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[35:END] Completed epoch in 676.5336575508118s\n",
      "[35:599] ep_loss_idt_x: 0.165 ep_G_fool_loss: 0.068 ep_predictor_x_loss: 0.162 ep_cycled_x_loss: 0.160 ep_D_X_loss: 1.224\n",
      "[35:599] ep_loss_idt_y: 0.103 ep_F_fool_loss: 0.070 ep_predictor_y_loss: 0.207 ep_cycled_y_loss: 0.113 ep_D_Y_loss: 1.117\n",
      "[35:END] Completed eval in 4.837191343307495s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[35:END] Saving models and training information permanently\n",
      "[36:100] Took 117.19s\n",
      "[36:100] loss_idt_x: 0.16070225290954113, G_fool_loss: 0.12361557904630899, predictor_x_loss: 0.1563819132000208, cycled_x_loss: 0.15103114299476147, D_X_loss: 1.2624798548221587\n",
      "[36:100] loss_idt_y: 0.09978915870189667, F_fool_loss: 0.07996288679540157, predictor_y_loss: 0.2261218599230051, cycled_y_loss: 0.10915381859987974, D_Y_loss: 1.2027459794282913\n",
      "[36:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[36:200] Took 111.78s\n",
      "[36:200] loss_idt_x: 0.1569407417997718, G_fool_loss: 0.0776989422366023, predictor_x_loss: 0.16412133291363717, cycled_x_loss: 0.16283868804574012, D_X_loss: 1.2214531624317169\n",
      "[36:200] loss_idt_y: 0.0941391995921731, F_fool_loss: 0.06272293478250504, predictor_y_loss: 0.2104556791484356, cycled_y_loss: 0.10386627089232206, D_Y_loss: 1.139894762635231\n",
      "[36:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[36:300] Took 111.44s\n",
      "[36:300] loss_idt_x: 0.1607797211408615, G_fool_loss: 0.07023178536444902, predictor_x_loss: 0.1658839573711157, cycled_x_loss: 0.15772587954998016, D_X_loss: 1.2236451196670532\n",
      "[36:300] loss_idt_y: 0.09790897373110057, F_fool_loss: 0.06944489188492298, predictor_y_loss: 0.20772203899919986, cycled_y_loss: 0.10895887278020382, D_Y_loss: 1.0934025806188583\n",
      "[36:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[36:400] Took 111.31s\n",
      "[36:400] loss_idt_x: 0.17083068937063217, G_fool_loss: 0.06352404695004225, predictor_x_loss: 0.16217323429882527, cycled_x_loss: 0.1655529846251011, D_X_loss: 1.2401587349176406\n",
      "[36:400] loss_idt_y: 0.09234372437000275, F_fool_loss: 0.08077355612069369, predictor_y_loss: 0.21125870034098626, cycled_y_loss: 0.10001132614910603, D_Y_loss: 1.1250149142742156\n",
      "[36:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[36:500] Took 111.44s\n",
      "[36:500] loss_idt_x: 0.16320767670869826, G_fool_loss: 0.06572298213839531, predictor_x_loss: 0.15126029416918754, cycled_x_loss: 0.15281512312591075, D_X_loss: 1.2384909796714783\n",
      "[36:500] loss_idt_y: 0.09488354902714491, F_fool_loss: 0.0680882865563035, predictor_y_loss: 0.20314354583621025, cycled_y_loss: 0.10425425946712494, D_Y_loss: 1.1012207382917405\n",
      "[36:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[36:END] Completed epoch in 674.4348247051239s\n",
      "[36:599] ep_loss_idt_x: 0.163 ep_G_fool_loss: 0.129 ep_predictor_x_loss: 0.160 ep_cycled_x_loss: 0.159 ep_D_X_loss: 1.234\n",
      "[36:599] ep_loss_idt_y: 0.096 ep_F_fool_loss: 0.071 ep_predictor_y_loss: 0.212 ep_cycled_y_loss: 0.106 ep_D_Y_loss: 1.206\n",
      "[36:END] Completed eval in 4.854501724243164s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[36:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[37:100] Took 118.21s\n",
      "[37:100] loss_idt_x: 0.16915152825415133, G_fool_loss: 0.07354853350669145, predictor_x_loss: 0.1591425532847643, cycled_x_loss: 0.16416516222059727, D_X_loss: 1.2630396246910096\n",
      "[37:100] loss_idt_y: 0.1013040528446436, F_fool_loss: 0.07269886396825313, predictor_y_loss: 0.19924373120069505, cycled_y_loss: 0.10907513827085495, D_Y_loss: 1.0996882140636444\n",
      "[37:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[37:200] Took 111.04s\n",
      "[37:200] loss_idt_x: 0.1606221816688776, G_fool_loss: 0.06499747052788735, predictor_x_loss: 0.1584015430510044, cycled_x_loss: 0.15221386641263962, D_X_loss: 1.2163078862428665\n",
      "[37:200] loss_idt_y: 0.09763010907918215, F_fool_loss: 0.06547931287437678, predictor_y_loss: 0.18443135067820549, cycled_y_loss: 0.1009109527617693, D_Y_loss: 1.0882466411590577\n",
      "[37:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[37:300] Took 111.09s\n",
      "[37:300] loss_idt_x: 0.1657563129067421, G_fool_loss: 0.0604550988972187, predictor_x_loss: 0.15658601015806198, cycled_x_loss: 0.15399295829236506, D_X_loss: 1.2308281499147415\n",
      "[37:300] loss_idt_y: 0.09647698540240526, F_fool_loss: 0.07214364495128393, predictor_y_loss: 0.21017624005675317, cycled_y_loss: 0.10547328256070614, D_Y_loss: 1.1036336797475814\n",
      "[37:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[37:400] Took 111.61s\n",
      "[37:400] loss_idt_x: 0.1568988175690174, G_fool_loss: 0.05726268079131842, predictor_x_loss: 0.16419644899666308, cycled_x_loss: 0.1591004841029644, D_X_loss: 1.2319497644901276\n",
      "[37:400] loss_idt_y: 0.10527154590934515, F_fool_loss: 0.07588453717529774, predictor_y_loss: 0.20529625996947287, cycled_y_loss: 0.11103341341018677, D_Y_loss: 1.0938158649206162\n",
      "[37:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[37:500] Took 111.25s\n",
      "[37:500] loss_idt_x: 0.15124993041157722, G_fool_loss: 0.062285148166120054, predictor_x_loss: 0.15308234438300133, cycled_x_loss: 0.15194459557533263, D_X_loss: 1.235059455037117\n",
      "[37:500] loss_idt_y: 0.0961477756127715, F_fool_loss: 0.0815232041105628, predictor_y_loss: 0.20101103022694589, cycled_y_loss: 0.10213986806571483, D_Y_loss: 1.10175237596035\n",
      "[37:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[37:END] Completed epoch in 677.8557455539703s\n",
      "[37:599] ep_loss_idt_x: 0.159 ep_G_fool_loss: 0.063 ep_predictor_x_loss: 0.158 ep_cycled_x_loss: 0.155 ep_D_X_loss: 1.230\n",
      "[37:599] ep_loss_idt_y: 0.097 ep_F_fool_loss: 0.072 ep_predictor_y_loss: 0.199 ep_cycled_y_loss: 0.104 ep_D_Y_loss: 1.094\n",
      "[37:END] Completed eval in 4.959973096847534s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[37:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[38:100] Took 116.90s\n",
      "[38:100] loss_idt_x: 0.15827732816338538, G_fool_loss: 0.06002776011824608, predictor_x_loss: 0.15788151420652866, cycled_x_loss: 0.15243096716701984, D_X_loss: 1.2374521154165268\n",
      "[38:100] loss_idt_y: 0.09262651830911636, F_fool_loss: 0.07052549589425325, predictor_y_loss: 0.2146012333035469, cycled_y_loss: 0.10283550910651684, D_Y_loss: 1.1127346968650818\n",
      "[38:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[38:200] Took 110.99s\n",
      "[38:200] loss_idt_x: 0.15283098824322225, G_fool_loss: 0.06081127554178238, predictor_x_loss: 0.1523039960116148, cycled_x_loss: 0.14805136024951934, D_X_loss: 1.2262756097316743\n",
      "[38:200] loss_idt_y: 0.09466749258339405, F_fool_loss: 0.07111280161887407, predictor_y_loss: 0.20580977872014045, cycled_y_loss: 0.10332278616726398, D_Y_loss: 1.1006479918956757\n",
      "[38:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[38:300] Took 110.97s\n",
      "[38:300] loss_idt_x: 0.1505388493090868, G_fool_loss: 0.06385379284620285, predictor_x_loss: 0.1543601844459772, cycled_x_loss: 0.13959207437932492, D_X_loss: 1.2521255558729172\n",
      "[38:300] loss_idt_y: 0.09171962402760983, F_fool_loss: 0.08244869347661733, predictor_y_loss: 0.20291752092540263, cycled_y_loss: 0.1028357957303524, D_Y_loss: 1.1018507337570191\n",
      "[38:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[38:400] Took 111.20s\n",
      "[38:400] loss_idt_x: 0.17699181385338306, G_fool_loss: 0.06481991428881884, predictor_x_loss: 0.1658810494840145, cycled_x_loss: 0.17355439625680447, D_X_loss: 1.2292369425296783\n",
      "[38:400] loss_idt_y: 0.1097838469222188, F_fool_loss: 0.06816261168569326, predictor_y_loss: 0.20865195088088512, cycled_y_loss: 0.11850611992180347, D_Y_loss: 1.0990602219104766\n",
      "[38:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[38:500] Took 111.21s\n",
      "[38:500] loss_idt_x: 0.15553826712071894, G_fool_loss: 0.0626475515961647, predictor_x_loss: 0.15376018822193147, cycled_x_loss: 0.14813956521451474, D_X_loss: 1.240449808239937\n",
      "[38:500] loss_idt_y: 0.08760458752512931, F_fool_loss: 0.06486985579133034, predictor_y_loss: 0.2056926390528679, cycled_y_loss: 0.09866462722420692, D_Y_loss: 1.0880980974435805\n",
      "[38:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[38:END] Completed epoch in 673.9101512432098s\n",
      "[38:599] ep_loss_idt_x: 0.156 ep_G_fool_loss: 0.063 ep_predictor_x_loss: 0.157 ep_cycled_x_loss: 0.152 ep_D_X_loss: 1.236\n",
      "[38:599] ep_loss_idt_y: 0.095 ep_F_fool_loss: 0.073 ep_predictor_y_loss: 0.206 ep_cycled_y_loss: 0.105 ep_D_Y_loss: 1.099\n",
      "[38:END] Completed eval in 4.958043575286865s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[38:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[39:100] Took 112.99s\n",
      "[39:100] loss_idt_x: 0.15130707822740078, G_fool_loss: 0.07012260288000106, predictor_x_loss: 0.15962808184325694, cycled_x_loss: 0.14128975108265876, D_X_loss: 1.2622613501548767\n",
      "[39:100] loss_idt_y: 0.10014122761785985, F_fool_loss: 0.07465299602597952, predictor_y_loss: 0.21117310024797917, cycled_y_loss: 0.11127223111689091, D_Y_loss: 1.096026446223259\n",
      "[39:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[39:200] Took 108.23s\n",
      "[39:200] loss_idt_x: 0.15597267858684064, G_fool_loss: 0.06854836337268352, predictor_x_loss: 0.15689038068056108, cycled_x_loss: 0.1616058151423931, D_X_loss: 1.2363850390911102\n",
      "[39:200] loss_idt_y: 0.10114314120262861, F_fool_loss: 0.07023474231362342, predictor_y_loss: 0.20442437127232552, cycled_y_loss: 0.10691042426973581, D_Y_loss: 1.1031710660457612\n",
      "[39:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[39:300] Took 108.09s\n",
      "[39:300] loss_idt_x: 0.1434119712561369, G_fool_loss: 0.079545563980937, predictor_x_loss: 0.15074581243097782, cycled_x_loss: 0.14383404441177844, D_X_loss: 1.2161200642585754\n",
      "[39:300] loss_idt_y: 0.08868186667561531, F_fool_loss: 0.06250197019428015, predictor_y_loss: 0.19652377344667912, cycled_y_loss: 0.09789852894842625, D_Y_loss: 1.1089235883951187\n",
      "[39:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[39:400] Took 108.00s\n",
      "[39:400] loss_idt_x: 0.1466392084211111, G_fool_loss: 0.06661838877946138, predictor_x_loss: 0.15540534138679504, cycled_x_loss: 0.14754041731357576, D_X_loss: 1.2301751720905303\n",
      "[39:400] loss_idt_y: 0.10797209557145834, F_fool_loss: 0.06895182646811009, predictor_y_loss: 0.21236919328570367, cycled_y_loss: 0.1136388973146677, D_Y_loss: 1.1026333951950074\n",
      "[39:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[39:500] Took 108.23s\n",
      "[39:500] loss_idt_x: 0.16098189640790225, G_fool_loss: 0.06445219732820988, predictor_x_loss: 0.15462943717837332, cycled_x_loss: 0.15445043124258517, D_X_loss: 1.224959326982498\n",
      "[39:500] loss_idt_y: 0.09648475140333175, F_fool_loss: 0.07013786859810352, predictor_y_loss: 0.20249943025410175, cycled_y_loss: 0.10311847768723964, D_Y_loss: 1.1111293679475784\n",
      "[39:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[39:END] Completed epoch in 654.3971734046936s\n",
      "[39:599] ep_loss_idt_x: 0.151 ep_G_fool_loss: 0.069 ep_predictor_x_loss: 0.156 ep_cycled_x_loss: 0.148 ep_D_X_loss: 1.230\n",
      "[39:599] ep_loss_idt_y: 0.097 ep_F_fool_loss: 0.071 ep_predictor_y_loss: 0.204 ep_cycled_y_loss: 0.105 ep_D_Y_loss: 1.106\n",
      "[39:END] Completed eval in 5.03856348991394s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[39:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[40:100] Took 115.14s\n",
      "[40:100] loss_idt_x: 0.1541399033367634, G_fool_loss: 0.08010465420782566, predictor_x_loss: 0.159766838401556, cycled_x_loss: 0.14671750225126742, D_X_loss: 1.2451195240020752\n",
      "[40:100] loss_idt_y: 0.09415400430560111, F_fool_loss: 0.06896500360220671, predictor_y_loss: 0.21533623859286308, cycled_y_loss: 0.1092061997950077, D_Y_loss: 1.1152312964200974\n",
      "[40:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[40:200] Took 109.20s\n",
      "[40:200] loss_idt_x: 0.14765758454799652, G_fool_loss: 0.11854417335242033, predictor_x_loss: 0.15378160573542118, cycled_x_loss: 0.1486811225116253, D_X_loss: 1.22823239505291\n",
      "[40:200] loss_idt_y: 0.09490880616009235, F_fool_loss: 0.0738341836258769, predictor_y_loss: 0.20668069519102572, cycled_y_loss: 0.10059940189123154, D_Y_loss: 1.2011224466562271\n",
      "[40:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[40:300] Took 109.24s\n",
      "[40:300] loss_idt_x: 0.15650621995329858, G_fool_loss: 0.06433436069637537, predictor_x_loss: 0.15099283657968043, cycled_x_loss: 0.14721667185425757, D_X_loss: 1.236065217256546\n",
      "[40:300] loss_idt_y: 0.09690174255520105, F_fool_loss: 0.07136549718677998, predictor_y_loss: 0.20432219482958316, cycled_y_loss: 0.10346039153635501, D_Y_loss: 1.0836005860567093\n",
      "[40:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[40:400] Took 109.10s\n",
      "[40:400] loss_idt_x: 0.152316305488348, G_fool_loss: 0.06320230927318335, predictor_x_loss: 0.1607689744234085, cycled_x_loss: 0.155752846673131, D_X_loss: 1.2573554939031601\n",
      "[40:400] loss_idt_y: 0.0967753592133522, F_fool_loss: 0.08150375012308358, predictor_y_loss: 0.205301121994853, cycled_y_loss: 0.10463731259107589, D_Y_loss: 1.1106359302997588\n",
      "[40:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[40:500] Took 109.18s\n",
      "[40:500] loss_idt_x: 0.15126309014856815, G_fool_loss: 0.06556927725672722, predictor_x_loss: 0.15480248346924783, cycled_x_loss: 0.14614458963274957, D_X_loss: 1.2319162046909333\n",
      "[40:500] loss_idt_y: 0.09909971959888936, F_fool_loss: 0.0729471593350172, predictor_y_loss: 0.2234257309138775, cycled_y_loss: 0.10739069249480963, D_Y_loss: 1.1107274216413499\n",
      "[40:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[40:END] Completed epoch in 666.0345847606659s\n",
      "[40:599] ep_loss_idt_x: 0.151 ep_G_fool_loss: 0.077 ep_predictor_x_loss: 0.156 ep_cycled_x_loss: 0.149 ep_D_X_loss: 1.239\n",
      "[40:599] ep_loss_idt_y: 0.095 ep_F_fool_loss: 0.073 ep_predictor_y_loss: 0.207 ep_cycled_y_loss: 0.103 ep_D_Y_loss: 1.121\n",
      "[40:END] Completed eval in 4.962083578109741s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[40:END] Saving models and training information permanently\n",
      "[41:100] Took 118.41s\n",
      "[41:100] loss_idt_x: 0.1484793819487095, G_fool_loss: 0.06595667105168104, predictor_x_loss: 0.1492953158915043, cycled_x_loss: 0.1416487132757902, D_X_loss: 1.262289091348648\n",
      "[41:100] loss_idt_y: 0.08875540148466826, F_fool_loss: 0.07163580253720284, predictor_y_loss: 0.21505618147552014, cycled_y_loss: 0.09643413793295622, D_Y_loss: 1.1206878834962846\n",
      "[41:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[41:200] Took 111.68s\n",
      "[41:200] loss_idt_x: 0.1443322067707777, G_fool_loss: 0.0619767851382494, predictor_x_loss: 0.1531281555444002, cycled_x_loss: 0.1471363154053688, D_X_loss: 1.2722276604175569\n",
      "[41:200] loss_idt_y: 0.0972128026559949, F_fool_loss: 0.10079331208020449, predictor_y_loss: 0.19527601547539233, cycled_y_loss: 0.10533941946923733, D_Y_loss: 1.1317471653223037\n",
      "[41:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[41:300] Took 111.79s\n",
      "[41:300] loss_idt_x: 0.1547877114266157, G_fool_loss: 0.07811361927539111, predictor_x_loss: 0.15380740776658058, cycled_x_loss: 0.14267189756035806, D_X_loss: 1.2329761570692062\n",
      "[41:300] loss_idt_y: 0.09584373869001865, F_fool_loss: 0.07181341666728258, predictor_y_loss: 0.19197869345545768, cycled_y_loss: 0.10486614264547825, D_Y_loss: 1.1307913130521774\n",
      "[41:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[41:400] Took 112.04s\n",
      "[41:400] loss_idt_x: 0.15117554411292075, G_fool_loss: 0.06827360518276691, predictor_x_loss: 0.15218840278685092, cycled_x_loss: 0.1415398244559765, D_X_loss: 1.2287464934587478\n",
      "[41:400] loss_idt_y: 0.08836727257817983, F_fool_loss: 0.06612838830798864, predictor_y_loss: 0.20221643537282943, cycled_y_loss: 0.09486782796680927, D_Y_loss: 1.1161933237314223\n",
      "[41:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[41:500] Took 111.87s\n",
      "[41:500] loss_idt_x: 0.14166485860943795, G_fool_loss: 0.06819022830575705, predictor_x_loss: 0.15765282906591893, cycled_x_loss: 0.13451202265918255, D_X_loss: 1.232360606789589\n",
      "[41:500] loss_idt_y: 0.09816852662712336, F_fool_loss: 0.07117383506149054, predictor_y_loss: 0.18922239858657122, cycled_y_loss: 0.0965190451964736, D_Y_loss: 1.1267542886734008\n",
      "[41:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[41:END] Completed epoch in 678.5878279209137s\n",
      "[41:599] ep_loss_idt_x: 0.147 ep_G_fool_loss: 0.069 ep_predictor_x_loss: 0.153 ep_cycled_x_loss: 0.141 ep_D_X_loss: 1.245\n",
      "[41:599] ep_loss_idt_y: 0.093 ep_F_fool_loss: 0.077 ep_predictor_y_loss: 0.199 ep_cycled_y_loss: 0.099 ep_D_Y_loss: 1.123\n",
      "[41:END] Completed eval in 5.080597639083862s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[41:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[42:100] Took 117.59s\n",
      "[42:100] loss_idt_x: 0.15127679981291295, G_fool_loss: 0.06972073379904031, predictor_x_loss: 0.16205696761608124, cycled_x_loss: 0.14658570051193237, D_X_loss: 1.2438449466228485\n",
      "[42:100] loss_idt_y: 0.08685064032673835, F_fool_loss: 0.06632873382419348, predictor_y_loss: 0.20467635847628116, cycled_y_loss: 0.09976322788745165, D_Y_loss: 1.1409993159770966\n",
      "[42:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[42:200] Took 110.69s\n",
      "[42:200] loss_idt_x: 0.15227398879826068, G_fool_loss: 0.07932025998830795, predictor_x_loss: 0.1552500019222498, cycled_x_loss: 0.15542356379330158, D_X_loss: 1.2432026553153992\n",
      "[42:200] loss_idt_y: 0.089950784817338, F_fool_loss: 0.06962907429784536, predictor_y_loss: 0.20312867879867555, cycled_y_loss: 0.09730487830936908, D_Y_loss: 1.121705926656723\n",
      "[42:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[42:300] Took 110.82s\n",
      "[42:300] loss_idt_x: 0.1455659708380699, G_fool_loss: 0.06716659680008888, predictor_x_loss: 0.1498752672970295, cycled_x_loss: 0.14482777178287506, D_X_loss: 1.2349849987030028\n",
      "[42:300] loss_idt_y: 0.0944037327542901, F_fool_loss: 0.07016254425048828, predictor_y_loss: 0.1958314736932516, cycled_y_loss: 0.1014531722664833, D_Y_loss: 1.111819767355919\n",
      "[42:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[42:400] Took 110.74s\n",
      "[42:400] loss_idt_x: 0.14135670498013497, G_fool_loss: 0.06831251051276922, predictor_x_loss: 0.15851637944579125, cycled_x_loss: 0.1459028235077858, D_X_loss: 1.2606550115346908\n",
      "[42:400] loss_idt_y: 0.1041861478984356, F_fool_loss: 0.074687807187438, predictor_y_loss: 0.210994843095541, cycled_y_loss: 0.10515359818935394, D_Y_loss: 1.1148368638753892\n",
      "[42:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[42:500] Took 110.73s\n",
      "[42:500] loss_idt_x: 0.14321786820888519, G_fool_loss: 0.06832117017358541, predictor_x_loss: 0.14632906921207905, cycled_x_loss: 0.13579241529107094, D_X_loss: 1.2499968546628952\n",
      "[42:500] loss_idt_y: 0.08779295850545168, F_fool_loss: 0.06837836354970932, predictor_y_loss: 0.20134159326553344, cycled_y_loss: 0.09802914440631866, D_Y_loss: 1.0997813671827317\n",
      "[42:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[42:END] Completed epoch in 673.7397525310516s\n",
      "[42:599] ep_loss_idt_x: 0.144 ep_G_fool_loss: 0.070 ep_predictor_x_loss: 0.154 ep_cycled_x_loss: 0.144 ep_D_X_loss: 1.246\n",
      "[42:599] ep_loss_idt_y: 0.094 ep_F_fool_loss: 0.071 ep_predictor_y_loss: 0.201 ep_cycled_y_loss: 0.100 ep_D_Y_loss: 1.118\n",
      "[42:END] Completed eval in 5.069728851318359s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[42:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[43:100] Took 115.93s\n",
      "[43:100] loss_idt_x: 0.13135038331151008, G_fool_loss: 0.06715234126895667, predictor_x_loss: 0.15444305829703808, cycled_x_loss: 0.14140188448131086, D_X_loss: 1.2566099900007248\n",
      "[43:100] loss_idt_y: 0.09522152367979288, F_fool_loss: 0.07366080820560456, predictor_y_loss: 0.21960350036621093, cycled_y_loss: 0.10802871722728014, D_Y_loss: 1.126115248799324\n",
      "[43:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[43:200] Took 111.54s\n",
      "[43:200] loss_idt_x: 0.15193731538951397, G_fool_loss: 0.07076090939342976, predictor_x_loss: 0.15491967253386973, cycled_x_loss: 0.15383370250463485, D_X_loss: 1.2375539058446885\n",
      "[43:200] loss_idt_y: 0.08944124836474657, F_fool_loss: 0.08083896033465862, predictor_y_loss: 0.2112835492938757, cycled_y_loss: 0.09631714556366205, D_Y_loss: 1.13850357234478\n",
      "[43:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[43:300] Took 111.91s\n",
      "[43:300] loss_idt_x: 0.14186021469533444, G_fool_loss: 0.07971202325075864, predictor_x_loss: 0.15310276068747045, cycled_x_loss: 0.142926180139184, D_X_loss: 1.246148419380188\n",
      "[43:300] loss_idt_y: 0.0897999806329608, F_fool_loss: 0.07577309980988503, predictor_y_loss: 0.19912016808986663, cycled_y_loss: 0.09882635250687599, D_Y_loss: 1.1278094625473023\n",
      "[43:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[43:400] Took 111.94s\n",
      "[43:400] loss_idt_x: 0.1531090771406889, G_fool_loss: 0.08622352365404368, predictor_x_loss: 0.1495349022746086, cycled_x_loss: 0.14984356731176376, D_X_loss: 1.2428322035074233\n",
      "[43:400] loss_idt_y: 0.09170648138970136, F_fool_loss: 0.06917436756193637, predictor_y_loss: 0.1895139968395233, cycled_y_loss: 0.10291508708149194, D_Y_loss: 1.167223408818245\n",
      "[43:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[43:500] Took 112.13s\n",
      "[43:500] loss_idt_x: 0.15136401653289794, G_fool_loss: 0.08080249495804309, predictor_x_loss: 0.15750784181058408, cycled_x_loss: 0.14013079345226287, D_X_loss: 1.243866040110588\n",
      "[43:500] loss_idt_y: 0.09203305330127477, F_fool_loss: 0.08101810041815043, predictor_y_loss: 0.1925971905887127, cycled_y_loss: 0.09895587481558323, D_Y_loss: 1.1254341912269592\n",
      "[43:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[43:END] Completed epoch in 677.9511144161224s\n",
      "[43:599] ep_loss_idt_x: 0.144 ep_G_fool_loss: 0.075 ep_predictor_x_loss: 0.153 ep_cycled_x_loss: 0.144 ep_D_X_loss: 1.244\n",
      "[43:599] ep_loss_idt_y: 0.091 ep_F_fool_loss: 0.076 ep_predictor_y_loss: 0.202 ep_cycled_y_loss: 0.100 ep_D_Y_loss: 1.132\n",
      "[43:END] Completed eval in 5.07210898399353s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[43:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[44:100] Took 116.98s\n",
      "[44:100] loss_idt_x: 0.14490847989916802, G_fool_loss: 0.06773938525468111, predictor_x_loss: 0.15518446177244186, cycled_x_loss: 0.14018716655671595, D_X_loss: 1.2313591206073762\n",
      "[44:100] loss_idt_y: 0.08740285784006119, F_fool_loss: 0.06411679301410914, predictor_y_loss: 0.201683392226696, cycled_y_loss: 0.09575029876083135, D_Y_loss: 1.1311033320426942\n",
      "[44:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[44:200] Took 111.88s\n",
      "[44:200] loss_idt_x: 0.11947174031287432, G_fool_loss: 0.05763407088816166, predictor_x_loss: 0.13608088001608848, cycled_x_loss: 0.12061570517718792, D_X_loss: 1.2313446253538132\n",
      "[44:200] loss_idt_y: 0.08719207029789686, F_fool_loss: 0.07130101427435875, predictor_y_loss: 0.20772216141223906, cycled_y_loss: 0.09414833951741457, D_Y_loss: 1.1145246249437333\n",
      "[44:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[44:300] Took 111.85s\n",
      "[44:300] loss_idt_x: 0.1476468052715063, G_fool_loss: 0.062259373739361766, predictor_x_loss: 0.1487630547583103, cycled_x_loss: 0.146843845769763, D_X_loss: 1.238861449956894\n",
      "[44:300] loss_idt_y: 0.09343833886086941, F_fool_loss: 0.07207615159451962, predictor_y_loss: 0.192461806088686, cycled_y_loss: 0.09716074861586094, D_Y_loss: 1.1167524868249894\n",
      "[44:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[44:400] Took 111.87s\n",
      "[44:400] loss_idt_x: 0.14231107622385025, G_fool_loss: 0.06844133365899324, predictor_x_loss: 0.16681921154260634, cycled_x_loss: 0.1458903256803751, D_X_loss: 1.2555506861209869\n",
      "[44:400] loss_idt_y: 0.08598856020718813, F_fool_loss: 0.07299158222973347, predictor_y_loss: 0.19907242394983768, cycled_y_loss: 0.09791013039648533, D_Y_loss: 1.0990538609027862\n",
      "[44:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[44:500] Took 112.37s\n",
      "[44:500] loss_idt_x: 0.15341344356536865, G_fool_loss: 0.07789215933531522, predictor_x_loss: 0.15848258830606937, cycled_x_loss: 0.1541674703359604, D_X_loss: 1.247033720612526\n",
      "[44:500] loss_idt_y: 0.10341336082667113, F_fool_loss: 0.06937037501484156, predictor_y_loss: 0.20189993731677533, cycled_y_loss: 0.10793970800936221, D_Y_loss: 1.1269920033216476\n",
      "[44:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[44:END] Completed epoch in 679.3386886119843s\n",
      "[44:599] ep_loss_idt_x: 0.141 ep_G_fool_loss: 0.066 ep_predictor_x_loss: 0.152 ep_cycled_x_loss: 0.141 ep_D_X_loss: 1.242\n",
      "[44:599] ep_loss_idt_y: 0.091 ep_F_fool_loss: 0.071 ep_predictor_y_loss: 0.202 ep_cycled_y_loss: 0.098 ep_D_Y_loss: 1.116\n",
      "[44:END] Completed eval in 5.137016773223877s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[44:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[45:100] Took 113.58s\n",
      "[45:100] loss_idt_x: 0.141927975602448, G_fool_loss: 0.07832874864339828, predictor_x_loss: 0.1571264486759901, cycled_x_loss: 0.14348230957984925, D_X_loss: 1.255018528699875\n",
      "[45:100] loss_idt_y: 0.08515222683548927, F_fool_loss: 0.06928343541920184, predictor_y_loss: 0.20014600068330765, cycled_y_loss: 0.09428527612239122, D_Y_loss: 1.1310498595237732\n",
      "[45:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[45:200] Took 107.40s\n",
      "[45:200] loss_idt_x: 0.13456753000617028, G_fool_loss: 0.5446518996730447, predictor_x_loss: 0.14428028248250485, cycled_x_loss: 0.13017529360949992, D_X_loss: 1.2601417702436448\n",
      "[45:200] loss_idt_y: 0.0890433620288968, F_fool_loss: 0.08486486468464136, predictor_y_loss: 0.20085969232022763, cycled_y_loss: 0.09639927919954061, D_Y_loss: 1.8022176718711853\n",
      "[45:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[45:300] Took 107.35s\n",
      "[45:300] loss_idt_x: 0.1296958538517356, G_fool_loss: 0.06937937952578067, predictor_x_loss: 0.15448239289224147, cycled_x_loss: 0.13507920168340207, D_X_loss: 1.238656696677208\n",
      "[45:300] loss_idt_y: 0.0865558199211955, F_fool_loss: 0.07679994214326143, predictor_y_loss: 0.18643940292298794, cycled_y_loss: 0.09528613664209842, D_Y_loss: 1.1252267903089523\n",
      "[45:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[45:400] Took 107.30s\n",
      "[45:400] loss_idt_x: 0.14813357822597026, G_fool_loss: 0.06205492701381445, predictor_x_loss: 0.14770237825810908, cycled_x_loss: 0.1408512622117996, D_X_loss: 1.2410479539632797\n",
      "[45:400] loss_idt_y: 0.08638535562902688, F_fool_loss: 0.06532462321221828, predictor_y_loss: 0.20016692869365216, cycled_y_loss: 0.09802522771060466, D_Y_loss: 1.1052523386478423\n",
      "[45:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[45:500] Took 107.21s\n",
      "[45:500] loss_idt_x: 0.15282249607145787, G_fool_loss: 0.06300005860626698, predictor_x_loss: 0.15199258476495742, cycled_x_loss: 0.15250926412642002, D_X_loss: 1.2558264368772507\n",
      "[45:500] loss_idt_y: 0.10053242694586516, F_fool_loss: 0.07031122751533986, predictor_y_loss: 0.2192773736268282, cycled_y_loss: 0.11531748346984387, D_Y_loss: 1.0987829071283342\n",
      "[45:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[45:END] Completed epoch in 652.5849645137787s\n",
      "[45:599] ep_loss_idt_x: 0.142 ep_G_fool_loss: 0.148 ep_predictor_x_loss: 0.152 ep_cycled_x_loss: 0.141 ep_D_X_loss: 1.248\n",
      "[45:599] ep_loss_idt_y: 0.091 ep_F_fool_loss: 0.072 ep_predictor_y_loss: 0.200 ep_cycled_y_loss: 0.101 ep_D_Y_loss: 1.228\n",
      "[45:END] Completed eval in 5.181556701660156s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[45:END] Saving models and training information permanently\n",
      "[46:100] Took 120.46s\n",
      "[46:100] loss_idt_x: 0.13758286848664283, G_fool_loss: 0.062177291698753835, predictor_x_loss: 0.15162676356732846, cycled_x_loss: 0.12359892137348652, D_X_loss: 1.2805573272705078\n",
      "[46:100] loss_idt_y: 0.08913602527230978, F_fool_loss: 0.08017308078706264, predictor_y_loss: 0.18665687553584576, cycled_y_loss: 0.09926686353981495, D_Y_loss: 1.121349185705185\n",
      "[46:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[46:200] Took 113.31s\n",
      "[46:200] loss_idt_x: 0.13779278710484505, G_fool_loss: 0.06288893066346646, predictor_x_loss: 0.15080792404711246, cycled_x_loss: 0.13450179301202297, D_X_loss: 1.289023947119713\n",
      "[46:200] loss_idt_y: 0.08770492702722549, F_fool_loss: 0.10633671194314957, predictor_y_loss: 0.20675006732344628, cycled_y_loss: 0.09695165481418372, D_Y_loss: 1.0866427022218703\n",
      "[46:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[46:300] Took 113.12s\n",
      "[46:300] loss_idt_x: 0.13052826978266238, G_fool_loss: 0.06555971331894397, predictor_x_loss: 0.1495380598306656, cycled_x_loss: 0.1301138062030077, D_X_loss: 1.2437825572490693\n",
      "[46:300] loss_idt_y: 0.08904798150062561, F_fool_loss: 0.06382870156317949, predictor_y_loss: 0.20045906014740467, cycled_y_loss: 0.09576007004827261, D_Y_loss: 1.1084076941013337\n",
      "[46:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[46:400] Took 113.32s\n",
      "[46:400] loss_idt_x: 0.1282604696601629, G_fool_loss: 0.05947177670896053, predictor_x_loss: 0.1426826488226652, cycled_x_loss: 0.12679487586021423, D_X_loss: 1.2222725796699523\n",
      "[46:400] loss_idt_y: 0.0813338229060173, F_fool_loss: 0.06067901935428381, predictor_y_loss: 0.18218576915562154, cycled_y_loss: 0.0901044062897563, D_Y_loss: 1.1018122112751008\n",
      "[46:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[46:500] Took 113.11s\n",
      "[46:500] loss_idt_x: 0.15054340966045857, G_fool_loss: 0.06224547617137432, predictor_x_loss: 0.15518560796976089, cycled_x_loss: 0.1426978462934494, D_X_loss: 1.2389452791213988\n",
      "[46:500] loss_idt_y: 0.09555151928216218, F_fool_loss: 0.05973631281405687, predictor_y_loss: 0.19334778927266597, cycled_y_loss: 0.10450456131249666, D_Y_loss: 1.0978107672929764\n",
      "[46:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[46:END] Completed epoch in 690.7609949111938s\n",
      "[46:599] ep_loss_idt_x: 0.136 ep_G_fool_loss: 0.062 ep_predictor_x_loss: 0.149 ep_cycled_x_loss: 0.132 ep_D_X_loss: 1.253\n",
      "[46:599] ep_loss_idt_y: 0.089 ep_F_fool_loss: 0.076 ep_predictor_y_loss: 0.195 ep_cycled_y_loss: 0.097 ep_D_Y_loss: 1.106\n",
      "[46:END] Completed eval in 5.202211856842041s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[46:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[47:100] Took 119.51s\n",
      "[47:100] loss_idt_x: 0.13434683419764043, G_fool_loss: 0.07233508072793483, predictor_x_loss: 0.15898819282650947, cycled_x_loss: 0.13914312101900578, D_X_loss: 1.255208632349968\n",
      "[47:100] loss_idt_y: 0.08971755813807249, F_fool_loss: 0.0757420476526022, predictor_y_loss: 0.21228429064154625, cycled_y_loss: 0.0942958089709282, D_Y_loss: 1.108631165623665\n",
      "[47:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[47:200] Took 113.31s\n",
      "[47:200] loss_idt_x: 0.12913586772978305, G_fool_loss: 0.059936695545911786, predictor_x_loss: 0.14592075161635876, cycled_x_loss: 0.1276230928301811, D_X_loss: 1.2304083114862443\n",
      "[47:200] loss_idt_y: 0.08424195066094399, F_fool_loss: 0.0641886619478464, predictor_y_loss: 0.20222897887229918, cycled_y_loss: 0.09149522364139556, D_Y_loss: 1.1018922716379165\n",
      "[47:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[47:300] Took 113.90s\n",
      "[47:300] loss_idt_x: 0.14074289590120315, G_fool_loss: 0.06415146935731172, predictor_x_loss: 0.1543584145605564, cycled_x_loss: 0.13871831119060515, D_X_loss: 1.224630760550499\n",
      "[47:300] loss_idt_y: 0.08034509625285864, F_fool_loss: 0.06912567541003227, predictor_y_loss: 0.2140726125240326, cycled_y_loss: 0.0860596589371562, D_Y_loss: 1.1097613734006881\n",
      "[47:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[47:400] Took 113.33s\n",
      "[47:400] loss_idt_x: 0.133091649338603, G_fool_loss: 0.07042142651975154, predictor_x_loss: 0.14909399561583997, cycled_x_loss: 0.1377330543845892, D_X_loss: 1.2213023447990417\n",
      "[47:400] loss_idt_y: 0.08788853034377098, F_fool_loss: 0.06923604544252157, predictor_y_loss: 0.1994627568870783, cycled_y_loss: 0.09343850895762444, D_Y_loss: 1.115843203663826\n",
      "[47:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[47:500] Took 113.47s\n",
      "[47:500] loss_idt_x: 0.130381403490901, G_fool_loss: 0.06911339811980724, predictor_x_loss: 0.14714081563055514, cycled_x_loss: 0.1348997015506029, D_X_loss: 1.2441990566253662\n",
      "[47:500] loss_idt_y: 0.08695446468889713, F_fool_loss: 0.06543389447033406, predictor_y_loss: 0.1894447523355484, cycled_y_loss: 0.09607134357094765, D_Y_loss: 1.0997186285257339\n",
      "[47:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[47:END] Completed epoch in 688.2345094680786s\n",
      "[47:599] ep_loss_idt_x: 0.133 ep_G_fool_loss: 0.067 ep_predictor_x_loss: 0.150 ep_cycled_x_loss: 0.135 ep_D_X_loss: 1.241\n",
      "[47:599] ep_loss_idt_y: 0.085 ep_F_fool_loss: 0.075 ep_predictor_y_loss: 0.201 ep_cycled_y_loss: 0.092 ep_D_Y_loss: 1.106\n",
      "[47:END] Completed eval in 5.227257013320923s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[47:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[48:100] Took 112.49s\n",
      "[48:100] loss_idt_x: 0.12913081355392933, G_fool_loss: 0.07881816562265158, predictor_x_loss: 0.14284903325140477, cycled_x_loss: 0.12799759544432163, D_X_loss: 1.2900007951259613\n",
      "[48:100] loss_idt_y: 0.08768037524074317, F_fool_loss: 0.09629663344472647, predictor_y_loss: 0.2082385592907667, cycled_y_loss: 0.0942352881655097, D_Y_loss: 1.1157578992843629\n",
      "[48:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[48:200] Took 106.68s\n",
      "[48:200] loss_idt_x: 0.12711210049688815, G_fool_loss: 0.06861968878656625, predictor_x_loss: 0.14066311918199062, cycled_x_loss: 0.12570867851376533, D_X_loss: 1.2390704762935638\n",
      "[48:200] loss_idt_y: 0.08203281953930855, F_fool_loss: 0.06815546192228794, predictor_y_loss: 0.20594007417559623, cycled_y_loss: 0.08914475653320551, D_Y_loss: 1.1101193410158157\n",
      "[48:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[48:300] Took 106.85s\n",
      "[48:300] loss_idt_x: 0.1381176672130823, G_fool_loss: 0.07822717446833849, predictor_x_loss: 0.15830447018146515, cycled_x_loss: 0.14425517834722995, D_X_loss: 1.2366132634878158\n",
      "[48:300] loss_idt_y: 0.09377992454916238, F_fool_loss: 0.06418442197144031, predictor_y_loss: 0.2007737173140049, cycled_y_loss: 0.09961335800588131, D_Y_loss: 1.1225691026449203\n",
      "[48:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[48:400] Took 106.89s\n",
      "[48:400] loss_idt_x: 0.151485053896904, G_fool_loss: 0.07646181866526604, predictor_x_loss: 0.15678252875804902, cycled_x_loss: 0.1450892360508442, D_X_loss: 1.227524065375328\n",
      "[48:400] loss_idt_y: 0.08728200301527977, F_fool_loss: 0.05934798255562782, predictor_y_loss: 0.18980720028281212, cycled_y_loss: 0.09827602796256542, D_Y_loss: 1.105942234992981\n",
      "[48:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[48:500] Took 108.14s\n",
      "[48:500] loss_idt_x: 0.1323585993424058, G_fool_loss: 0.08806805472820997, predictor_x_loss: 0.14716639026999473, cycled_x_loss: 0.1311153656989336, D_X_loss: 1.230312727689743\n",
      "[48:500] loss_idt_y: 0.0834031442180276, F_fool_loss: 0.05935640968382359, predictor_y_loss: 0.20010708533227445, cycled_y_loss: 0.0905922358110547, D_Y_loss: 1.0917926251888275\n",
      "[48:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[48:END] Completed epoch in 652.235583782196s\n",
      "[48:599] ep_loss_idt_x: 0.135 ep_G_fool_loss: 0.077 ep_predictor_x_loss: 0.149 ep_cycled_x_loss: 0.134 ep_D_X_loss: 1.240\n",
      "[48:599] ep_loss_idt_y: 0.087 ep_F_fool_loss: 0.069 ep_predictor_y_loss: 0.198 ep_cycled_y_loss: 0.094 ep_D_Y_loss: 1.108\n",
      "[48:END] Completed eval in 5.20590353012085s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[48:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[49:100] Took 114.65s\n",
      "[49:100] loss_idt_x: 0.12236959021538496, G_fool_loss: 0.08305645179003478, predictor_x_loss: 0.1461751499027014, cycled_x_loss: 0.12733283638954163, D_X_loss: 1.2584970724582671\n",
      "[49:100] loss_idt_y: 0.08852581784129143, F_fool_loss: 0.06913739446550608, predictor_y_loss: 0.20872044041752816, cycled_y_loss: 0.09295009255409241, D_Y_loss: 1.1156818187236786\n",
      "[49:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[49:200] Took 108.38s\n",
      "[49:200] loss_idt_x: 0.12108961407095194, G_fool_loss: 0.08248817402869463, predictor_x_loss: 0.1404063268750906, cycled_x_loss: 0.12736907593905925, D_X_loss: 1.2392427128553392\n",
      "[49:200] loss_idt_y: 0.08776379175484181, F_fool_loss: 0.06569045323878527, predictor_y_loss: 0.21168348141014576, cycled_y_loss: 0.094291509129107, D_Y_loss: 1.095040546655655\n",
      "[49:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[49:300] Took 108.34s\n",
      "[49:300] loss_idt_x: 0.12461840368807316, G_fool_loss: 0.06944321673363447, predictor_x_loss: 0.1541879577189684, cycled_x_loss: 0.12502327956259252, D_X_loss: 1.2230512744188309\n",
      "[49:300] loss_idt_y: 0.08139149971306324, F_fool_loss: 0.0670959110930562, predictor_y_loss: 0.20174186825752258, cycled_y_loss: 0.08888656552881002, D_Y_loss: 1.118047279715538\n",
      "[49:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[49:400] Took 108.36s\n",
      "[49:400] loss_idt_x: 0.13855287455022336, G_fool_loss: 0.07455916203558445, predictor_x_loss: 0.14855970181524752, cycled_x_loss: 0.1362769490480423, D_X_loss: 1.239944753050804\n",
      "[49:400] loss_idt_y: 0.08603695318102837, F_fool_loss: 0.0672070650011301, predictor_y_loss: 0.19633894700556995, cycled_y_loss: 0.09401712287217379, D_Y_loss: 1.0992957270145416\n",
      "[49:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[49:500] Took 108.50s\n",
      "[49:500] loss_idt_x: 0.12657861467450857, G_fool_loss: 0.07586120788007975, predictor_x_loss: 0.1415712706744671, cycled_x_loss: 0.12256916251033545, D_X_loss: 1.2688602584600448\n",
      "[49:500] loss_idt_y: 0.079601007476449, F_fool_loss: 0.10394933614879846, predictor_y_loss: 0.19742134742438794, cycled_y_loss: 0.0854873225837946, D_Y_loss: 1.0903728467226028\n",
      "[49:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[49:END] Completed epoch in 659.50363945961s\n",
      "[49:599] ep_loss_idt_x: 0.127 ep_G_fool_loss: 0.077 ep_predictor_x_loss: 0.147 ep_cycled_x_loss: 0.128 ep_D_X_loss: 1.246\n",
      "[49:599] ep_loss_idt_y: 0.083 ep_F_fool_loss: 0.075 ep_predictor_y_loss: 0.201 ep_cycled_y_loss: 0.090 ep_D_Y_loss: 1.102\n",
      "[49:END] Completed eval in 5.232030153274536s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[49:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[50:100] Took 117.85s\n",
      "[50:100] loss_idt_x: 0.12862453199923038, G_fool_loss: 0.09846328664571047, predictor_x_loss: 0.14622322350740433, cycled_x_loss: 0.12638507671654226, D_X_loss: 1.275071869492531\n",
      "[50:100] loss_idt_y: 0.08012566912919283, F_fool_loss: 0.07107047092169523, predictor_y_loss: 0.19722687818109988, cycled_y_loss: 0.08729088820517063, D_Y_loss: 1.1298909920454026\n",
      "[50:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[50:200] Took 111.90s\n",
      "[50:200] loss_idt_x: 0.1183627975732088, G_fool_loss: 0.07639850273728371, predictor_x_loss: 0.14227520257234574, cycled_x_loss: 0.12454327464103698, D_X_loss: 1.238551555275917\n",
      "[50:200] loss_idt_y: 0.08226223286241292, F_fool_loss: 0.06045456830412149, predictor_y_loss: 0.17808425456285476, cycled_y_loss: 0.09022286731749773, D_Y_loss: 1.087687103152275\n",
      "[50:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[50:300] Took 111.83s\n",
      "[50:300] loss_idt_x: 0.12966481685638429, G_fool_loss: 0.07858069583773614, predictor_x_loss: 0.14855889469385147, cycled_x_loss: 0.13044064819812776, D_X_loss: 1.2143275147676469\n",
      "[50:300] loss_idt_y: 0.08573248010128737, F_fool_loss: 0.061849105581641195, predictor_y_loss: 0.19205886654555798, cycled_y_loss: 0.09467116083949804, D_Y_loss: 1.1031328594684602\n",
      "[50:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[50:400] Took 111.80s\n",
      "[50:400] loss_idt_x: 0.13748477309942245, G_fool_loss: 0.06711126670241356, predictor_x_loss: 0.15602848269045352, cycled_x_loss: 0.13795387476682663, D_X_loss: 1.22727101624012\n",
      "[50:400] loss_idt_y: 0.08636304125189781, F_fool_loss: 0.06820358026772738, predictor_y_loss: 0.19020061522722245, cycled_y_loss: 0.0936008583381772, D_Y_loss: 1.0843546110391618\n",
      "[50:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[50:500] Took 111.82s\n",
      "[50:500] loss_idt_x: 0.12491294667124749, G_fool_loss: 0.07429640986025333, predictor_x_loss: 0.1400511421263218, cycled_x_loss: 0.12902436919510366, D_X_loss: 1.2363728308677673\n",
      "[50:500] loss_idt_y: 0.08850916139781476, F_fool_loss: 0.06774078760296107, predictor_y_loss: 0.18077707797288894, cycled_y_loss: 0.09422063384205102, D_Y_loss: 1.0929825514554978\n",
      "[50:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[50:END] Completed epoch in 681.2239470481873s\n",
      "[50:599] ep_loss_idt_x: 0.128 ep_G_fool_loss: 0.079 ep_predictor_x_loss: 0.147 ep_cycled_x_loss: 0.130 ep_D_X_loss: 1.235\n",
      "[50:599] ep_loss_idt_y: 0.083 ep_F_fool_loss: 0.067 ep_predictor_y_loss: 0.188 ep_cycled_y_loss: 0.091 ep_D_Y_loss: 1.099\n",
      "[50:END] Completed eval in 5.230000257492065s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[50:END] Saving models and training information permanently\n",
      "[51:100] Took 117.26s\n",
      "[51:100] loss_idt_x: 0.11837726961821318, G_fool_loss: 0.07762358531355858, predictor_x_loss: 0.14570536553859711, cycled_x_loss: 0.12305423490703106, D_X_loss: 1.2485833048820496\n",
      "[51:100] loss_idt_y: 0.08271017786115407, F_fool_loss: 0.0641609401255846, predictor_y_loss: 0.19892262578010558, cycled_y_loss: 0.09228941533714533, D_Y_loss: 1.1102211928367616\n",
      "[51:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[51:200] Took 110.84s\n",
      "[51:200] loss_idt_x: 0.1206460276991129, G_fool_loss: 0.08109864886850118, predictor_x_loss: 0.14432652562856674, cycled_x_loss: 0.11992525786161423, D_X_loss: 1.2363257646560668\n",
      "[51:200] loss_idt_y: 0.08244963862001896, F_fool_loss: 0.0708178349211812, predictor_y_loss: 0.2045402093231678, cycled_y_loss: 0.0890133985877037, D_Y_loss: 1.1230327087640761\n",
      "[51:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[51:300] Took 111.49s\n",
      "[51:300] loss_idt_x: 0.12315246932208539, G_fool_loss: 0.0695697308704257, predictor_x_loss: 0.14694910019636154, cycled_x_loss: 0.12389937497675418, D_X_loss: 1.234298300743103\n",
      "[51:300] loss_idt_y: 0.08242700353264809, F_fool_loss: 0.06578292604535818, predictor_y_loss: 0.1864115546643734, cycled_y_loss: 0.08650022689253092, D_Y_loss: 1.090267214179039\n",
      "[51:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[51:400] Took 111.07s\n",
      "[51:400] loss_idt_x: 0.13599508091807366, G_fool_loss: 0.07000625293701887, predictor_x_loss: 0.14482581481337548, cycled_x_loss: 0.1328799132630229, D_X_loss: 1.2275446629524231\n",
      "[51:400] loss_idt_y: 0.08192500106990337, F_fool_loss: 0.07038160316646098, predictor_y_loss: 0.18959868103265762, cycled_y_loss: 0.08700218558311462, D_Y_loss: 1.134730280637741\n",
      "[51:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[51:500] Took 111.11s\n",
      "[51:500] loss_idt_x: 0.12523357205092908, G_fool_loss: 0.07658173598349094, predictor_x_loss: 0.1500301230698824, cycled_x_loss: 0.12857194766402244, D_X_loss: 1.2189492398500443\n",
      "[51:500] loss_idt_y: 0.07957788903266191, F_fool_loss: 0.06376785960048437, predictor_y_loss: 0.19113217115402223, cycled_y_loss: 0.08801475133746862, D_Y_loss: 1.1147526544332504\n",
      "[51:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[51:END] Completed epoch in 678.6728341579437s\n",
      "[51:599] ep_loss_idt_x: 0.128 ep_G_fool_loss: 0.079 ep_predictor_x_loss: 0.146 ep_cycled_x_loss: 0.128 ep_D_X_loss: 1.232\n",
      "[51:599] ep_loss_idt_y: 0.082 ep_F_fool_loss: 0.067 ep_predictor_y_loss: 0.192 ep_cycled_y_loss: 0.089 ep_D_Y_loss: 1.113\n",
      "[51:END] Completed eval in 5.418543577194214s\n",
      "Updated G_opt learning rate from 0.0002 to 0.0002\n",
      "Updated F_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.0002\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.0002\n",
      "[51:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[52:100] Took 115.62s\n",
      "[52:100] loss_idt_x: 0.13141469981521367, G_fool_loss: 0.09516235955059528, predictor_x_loss: 0.14256277740001677, cycled_x_loss: 0.12423602379858494, D_X_loss: 1.282996751666069\n",
      "[52:100] loss_idt_y: 0.08623434834182263, F_fool_loss: 0.08117347557097673, predictor_y_loss: 0.20093146421015262, cycled_y_loss: 0.09302179258316755, D_Y_loss: 1.0985029047727586\n",
      "[52:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[52:200] Took 108.89s\n",
      "[52:200] loss_idt_x: 0.12586313590407372, G_fool_loss: 0.0768650745600462, predictor_x_loss: 0.14773680560290814, cycled_x_loss: 0.12691351681947707, D_X_loss: 1.259872486591339\n",
      "[52:200] loss_idt_y: 0.08708570837974548, F_fool_loss: 0.08345195826143026, predictor_y_loss: 0.19130392327904702, cycled_y_loss: 0.09346360381692648, D_Y_loss: 1.1065872609615326\n",
      "[52:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[52:300] Took 108.88s\n",
      "[52:300] loss_idt_x: 0.12597781892865897, G_fool_loss: 0.08046909023076296, predictor_x_loss: 0.1490491182357073, cycled_x_loss: 0.1252822183072567, D_X_loss: 1.2505912864208222\n",
      "[52:300] loss_idt_y: 0.0858883536234498, F_fool_loss: 0.0675693866237998, predictor_y_loss: 0.20086949989199637, cycled_y_loss: 0.0935729880258441, D_Y_loss: 1.1063575196266173\n",
      "[52:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[52:400] Took 109.08s\n",
      "[52:400] loss_idt_x: 0.11535587832331658, G_fool_loss: 0.10271240152418613, predictor_x_loss: 0.13484454534947873, cycled_x_loss: 0.11546036809682846, D_X_loss: 1.2345759689807891\n",
      "[52:400] loss_idt_y: 0.08458374291658402, F_fool_loss: 0.05820789244025946, predictor_y_loss: 0.19242502190172672, cycled_y_loss: 0.09137414921075106, D_Y_loss: 1.1437423706054688\n",
      "[52:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[52:500] Took 108.77s\n",
      "[52:500] loss_idt_x: 0.14106245692819358, G_fool_loss: 0.07130361314862967, predictor_x_loss: 0.1566123692691326, cycled_x_loss: 0.14193863783031702, D_X_loss: 1.2356013196706772\n",
      "[52:500] loss_idt_y: 0.08577074889093637, F_fool_loss: 0.06442155692726374, predictor_y_loss: 0.2067368959635496, cycled_y_loss: 0.09590335629880428, D_Y_loss: 1.0988886839151382\n",
      "[52:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[52:END] Completed epoch in 663.1429979801178s\n",
      "[52:599] ep_loss_idt_x: 0.127 ep_G_fool_loss: 0.083 ep_predictor_x_loss: 0.146 ep_cycled_x_loss: 0.127 ep_D_X_loss: 1.249\n",
      "[52:599] ep_loss_idt_y: 0.085 ep_F_fool_loss: 0.071 ep_predictor_y_loss: 0.196 ep_cycled_y_loss: 0.093 ep_D_Y_loss: 1.111\n",
      "[52:END] Completed eval in 5.280536413192749s\n",
      "Updated G_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated F_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated D_X_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated D_Y_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated P_X_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "Updated P_Y_opt learning rate from 0.0002 to 0.000196078431372549\n",
      "[52:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[53:100] Took 113.53s\n",
      "[53:100] loss_idt_x: 0.11936317037791014, G_fool_loss: 0.06399109922349452, predictor_x_loss: 0.13763865046203136, cycled_x_loss: 0.11759485106915235, D_X_loss: 1.2308188253641128\n",
      "[53:100] loss_idt_y: 0.08757112476974725, F_fool_loss: 0.06318087495863438, predictor_y_loss: 0.18619158774614333, cycled_y_loss: 0.08862521525472403, D_Y_loss: 1.0863573336601258\n",
      "[53:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[53:200] Took 108.80s\n",
      "[53:200] loss_idt_x: 0.12193437036126852, G_fool_loss: 0.07275152314454317, predictor_x_loss: 0.15267942987382413, cycled_x_loss: 0.12419960573315621, D_X_loss: 1.2351932060718536\n",
      "[53:200] loss_idt_y: 0.08584962572902441, F_fool_loss: 0.06508324962109327, predictor_y_loss: 0.2031039572507143, cycled_y_loss: 0.09604972682893276, D_Y_loss: 1.139789353609085\n",
      "[53:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[53:300] Took 109.08s\n",
      "[53:300] loss_idt_x: 0.13525397151708604, G_fool_loss: 0.06633673887699842, predictor_x_loss: 0.14509515888988972, cycled_x_loss: 0.13199769839644432, D_X_loss: 1.2397951954603195\n",
      "[53:300] loss_idt_y: 0.0857639617472887, F_fool_loss: 0.06341244772076607, predictor_y_loss: 0.19480286009609699, cycled_y_loss: 0.09157785575836896, D_Y_loss: 1.072288240790367\n",
      "[53:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[53:400] Took 108.71s\n",
      "[53:400] loss_idt_x: 0.12044068589806557, G_fool_loss: 0.07296022523194551, predictor_x_loss: 0.15065630413591863, cycled_x_loss: 0.1257071439921856, D_X_loss: 1.2618295681476592\n",
      "[53:400] loss_idt_y: 0.07808955289423465, F_fool_loss: 0.08705767404288053, predictor_y_loss: 0.20355105087161063, cycled_y_loss: 0.08498438272625208, D_Y_loss: 1.1027924120426178\n",
      "[53:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[53:500] Took 108.84s\n",
      "[53:500] loss_idt_x: 0.12524887796491385, G_fool_loss: 0.06916581645607948, predictor_x_loss: 0.14757610529661178, cycled_x_loss: 0.12479516983032227, D_X_loss: 1.2026964980363846\n",
      "[53:500] loss_idt_y: 0.07765482880175113, F_fool_loss: 0.06187261611223221, predictor_y_loss: 0.19902049928903578, cycled_y_loss: 0.08521346859633923, D_Y_loss: 1.0899106884002685\n",
      "[53:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[53:END] Completed epoch in 661.8498997688293s\n",
      "[53:599] ep_loss_idt_x: 0.124 ep_G_fool_loss: 0.074 ep_predictor_x_loss: 0.145 ep_cycled_x_loss: 0.124 ep_D_X_loss: 1.231\n",
      "[53:599] ep_loss_idt_y: 0.082 ep_F_fool_loss: 0.066 ep_predictor_y_loss: 0.197 ep_cycled_y_loss: 0.089 ep_D_Y_loss: 1.098\n",
      "[53:END] Completed eval in 5.621452569961548s\n",
      "Updated G_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated F_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated D_X_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated D_Y_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated P_X_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "Updated P_Y_opt learning rate from 0.000196078431372549 to 0.00019215686274509807\n",
      "[53:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[54:100] Took 116.55s\n",
      "[54:100] loss_idt_x: 0.11882713470607996, G_fool_loss: 0.07058380622416735, predictor_x_loss: 0.1430209183692932, cycled_x_loss: 0.11926286395639181, D_X_loss: 1.21202008664608\n",
      "[54:100] loss_idt_y: 0.08156643282622099, F_fool_loss: 0.055863692462444305, predictor_y_loss: 0.18950308740139007, cycled_y_loss: 0.08918478611856699, D_Y_loss: 1.1223760122060775\n",
      "[54:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[54:200] Took 111.46s\n",
      "[54:200] loss_idt_x: 0.10766094755381346, G_fool_loss: 0.07304532438516617, predictor_x_loss: 0.13522456660866738, cycled_x_loss: 0.11078684970736503, D_X_loss: 1.216859992146492\n",
      "[54:200] loss_idt_y: 0.07690106224268675, F_fool_loss: 0.0634706735238433, predictor_y_loss: 0.1867619214951992, cycled_y_loss: 0.08436283089220524, D_Y_loss: 1.119390469789505\n",
      "[54:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[54:300] Took 111.92s\n",
      "[54:300] loss_idt_x: 0.11966895040124655, G_fool_loss: 0.07216172449290753, predictor_x_loss: 0.13895130693912505, cycled_x_loss: 0.11715151056647301, D_X_loss: 1.216050901412964\n",
      "[54:300] loss_idt_y: 0.0759408612176776, F_fool_loss: 0.05568915527313947, predictor_y_loss: 0.18269986122846604, cycled_y_loss: 0.08135660879313945, D_Y_loss: 1.0830168133974076\n",
      "[54:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[54:400] Took 111.82s\n",
      "[54:400] loss_idt_x: 0.11661272708326578, G_fool_loss: 0.0734319918975234, predictor_x_loss: 0.13909933485090734, cycled_x_loss: 0.11494482532143593, D_X_loss: 1.2061994397640228\n",
      "[54:400] loss_idt_y: 0.0738643190637231, F_fool_loss: 0.056596035212278364, predictor_y_loss: 0.1911687010526657, cycled_y_loss: 0.08489209704101086, D_Y_loss: 1.0855778694152831\n",
      "[54:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[54:500] Took 112.68s\n",
      "[54:500] loss_idt_x: 0.12754357438534497, G_fool_loss: 0.06524960983544588, predictor_x_loss: 0.14711955938488244, cycled_x_loss: 0.12030221775174141, D_X_loss: 1.224179700613022\n",
      "[54:500] loss_idt_y: 0.0820611409842968, F_fool_loss: 0.07814722869545221, predictor_y_loss: 0.1901902473717928, cycled_y_loss: 0.08904196251183748, D_Y_loss: 1.1060450977087022\n",
      "[54:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[54:END] Completed epoch in 680.0538415908813s\n",
      "[54:599] ep_loss_idt_x: 0.118 ep_G_fool_loss: 0.070 ep_predictor_x_loss: 0.142 ep_cycled_x_loss: 0.117 ep_D_X_loss: 1.214\n",
      "[54:599] ep_loss_idt_y: 0.078 ep_F_fool_loss: 0.062 ep_predictor_y_loss: 0.190 ep_cycled_y_loss: 0.085 ep_D_Y_loss: 1.098\n",
      "[54:END] Completed eval in 5.407240867614746s\n",
      "Updated G_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated F_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated D_X_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated D_Y_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated P_X_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "Updated P_Y_opt learning rate from 0.00019215686274509807 to 0.00018823529411764707\n",
      "[54:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[55:100] Took 118.57s\n",
      "[55:100] loss_idt_x: 0.11675618886947632, G_fool_loss: 0.06098890285938978, predictor_x_loss: 0.13771128676831723, cycled_x_loss: 0.11538121446967126, D_X_loss: 1.2195500493049622\n",
      "[55:100] loss_idt_y: 0.07925845433026552, F_fool_loss: 0.057321509532630446, predictor_y_loss: 0.18959797792136668, cycled_y_loss: 0.08537658855319023, D_Y_loss: 1.10724365234375\n",
      "[55:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[55:200] Took 112.24s\n",
      "[55:200] loss_idt_x: 0.12224523287266492, G_fool_loss: 0.09131337605416774, predictor_x_loss: 0.1427821373939514, cycled_x_loss: 0.11876483380794525, D_X_loss: 1.2157925128936768\n",
      "[55:200] loss_idt_y: 0.08067737359553576, F_fool_loss: 0.05844855859875679, predictor_y_loss: 0.1929433263838291, cycled_y_loss: 0.08985089614987374, D_Y_loss: 1.1078829020261765\n",
      "[55:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[55:300] Took 112.29s\n",
      "[55:300] loss_idt_x: 0.12367883954197169, G_fool_loss: 0.07089999221265315, predictor_x_loss: 0.14021377839148044, cycled_x_loss: 0.13153750389814378, D_X_loss: 1.2299503833055496\n",
      "[55:300] loss_idt_y: 0.08305798664689064, F_fool_loss: 0.06131736386567354, predictor_y_loss: 0.1934557905048132, cycled_y_loss: 0.08960436142981053, D_Y_loss: 1.0992078310251236\n",
      "[55:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[55:400] Took 112.38s\n",
      "[55:400] loss_idt_x: 0.12888894394040107, G_fool_loss: 0.0905499005317688, predictor_x_loss: 0.13865890599787234, cycled_x_loss: 0.12824637718498708, D_X_loss: 1.2047611391544342\n",
      "[55:400] loss_idt_y: 0.08247472103685141, F_fool_loss: 0.05478203855454922, predictor_y_loss: 0.20094852678477765, cycled_y_loss: 0.08990923020988703, D_Y_loss: 1.1311935597658158\n",
      "[55:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[55:500] Took 112.40s\n",
      "[55:500] loss_idt_x: 0.11367102757096291, G_fool_loss: 0.06836343809962273, predictor_x_loss: 0.1508429142832756, cycled_x_loss: 0.1157316642999649, D_X_loss: 1.2205071204900741\n",
      "[55:500] loss_idt_y: 0.0782284715399146, F_fool_loss: 0.07635471604764461, predictor_y_loss: 0.1837162920832634, cycled_y_loss: 0.08329041641205549, D_Y_loss: 1.1251325738430022\n",
      "[55:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[55:END] Completed epoch in 681.789128780365s\n",
      "[55:599] ep_loss_idt_x: 0.119 ep_G_fool_loss: 0.075 ep_predictor_x_loss: 0.142 ep_cycled_x_loss: 0.121 ep_D_X_loss: 1.215\n",
      "[55:599] ep_loss_idt_y: 0.080 ep_F_fool_loss: 0.061 ep_predictor_y_loss: 0.190 ep_cycled_y_loss: 0.087 ep_D_Y_loss: 1.108\n",
      "[55:END] Completed eval in 5.445038557052612s\n",
      "Updated G_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated F_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated D_X_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated D_Y_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated P_X_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "Updated P_Y_opt learning rate from 0.00018823529411764707 to 0.0001843137254901961\n",
      "[55:END] Saving models and training information permanently\n",
      "[56:100] Took 118.47s\n",
      "[56:100] loss_idt_x: 0.11669988200068473, G_fool_loss: 0.06517514247447252, predictor_x_loss: 0.13850806314498187, cycled_x_loss: 0.11526821635663509, D_X_loss: 1.2135814255475998\n",
      "[56:100] loss_idt_y: 0.07637887321412563, F_fool_loss: 0.05484620094299317, predictor_y_loss: 0.1821186327189207, cycled_y_loss: 0.08218579947948455, D_Y_loss: 1.1170900255441665\n",
      "[56:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[56:200] Took 111.71s\n",
      "[56:200] loss_idt_x: 0.1044761535525322, G_fool_loss: 0.06447111837565898, predictor_x_loss: 0.13561306089162828, cycled_x_loss: 0.10498391404747963, D_X_loss: 1.219989333152771\n",
      "[56:200] loss_idt_y: 0.07321731489151716, F_fool_loss: 0.08072709690779448, predictor_y_loss: 0.1948678544908762, cycled_y_loss: 0.07957515567541122, D_Y_loss: 1.101888855099678\n",
      "[56:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[56:300] Took 111.57s\n",
      "[56:300] loss_idt_x: 0.11637254782021046, G_fool_loss: 0.07472181357443333, predictor_x_loss: 0.14384607441723346, cycled_x_loss: 0.11658128656446934, D_X_loss: 1.233830336332321\n",
      "[56:300] loss_idt_y: 0.0773508221283555, F_fool_loss: 0.07008419066667557, predictor_y_loss: 0.18168336279690267, cycled_y_loss: 0.08241350810974836, D_Y_loss: 1.115500693321228\n",
      "[56:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[56:400] Took 111.63s\n",
      "[56:400] loss_idt_x: 0.12412962790578604, G_fool_loss: 0.06980660609900952, predictor_x_loss: 0.14419233210384846, cycled_x_loss: 0.12037780467420817, D_X_loss: 1.191105090379715\n",
      "[56:400] loss_idt_y: 0.07782174061983824, F_fool_loss: 0.05331430751830339, predictor_y_loss: 0.19085410945117473, cycled_y_loss: 0.0854406001418829, D_Y_loss: 1.0866423094272613\n",
      "[56:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[56:500] Took 111.61s\n",
      "[56:500] loss_idt_x: 0.11534774038940668, G_fool_loss: 0.07586297810077668, predictor_x_loss: 0.13797261387109758, cycled_x_loss: 0.11419961735606193, D_X_loss: 1.2127035188674926\n",
      "[56:500] loss_idt_y: 0.07658191412687301, F_fool_loss: 0.05989270243793726, predictor_y_loss: 0.1928831548243761, cycled_y_loss: 0.08051196958869695, D_Y_loss: 1.0938135981559753\n",
      "[56:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[56:END] Completed epoch in 682.8450767993927s\n",
      "[56:599] ep_loss_idt_x: 0.117 ep_G_fool_loss: 0.070 ep_predictor_x_loss: 0.140 ep_cycled_x_loss: 0.115 ep_D_X_loss: 1.221\n",
      "[56:599] ep_loss_idt_y: 0.075 ep_F_fool_loss: 0.069 ep_predictor_y_loss: 0.187 ep_cycled_y_loss: 0.081 ep_D_Y_loss: 1.102\n",
      "[56:END] Completed eval in 5.547727584838867s\n",
      "Updated G_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated F_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated D_X_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated D_Y_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated P_X_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "Updated P_Y_opt learning rate from 0.0001843137254901961 to 0.0001803921568627451\n",
      "[56:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[57:100] Took 117.35s\n",
      "[57:100] loss_idt_x: 0.11764333102852106, G_fool_loss: 0.06451941642910242, predictor_x_loss: 0.1434351532906294, cycled_x_loss: 0.11453606076538562, D_X_loss: 2.051660066843033\n",
      "[57:100] loss_idt_y: 0.08159518022090197, F_fool_loss: 0.666675814986229, predictor_y_loss: 0.19817569881677627, cycled_y_loss: 0.09390887696295977, D_Y_loss: 1.108361033797264\n",
      "[57:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[57:200] Took 111.86s\n",
      "[57:200] loss_idt_x: 0.11157809231430292, G_fool_loss: 0.0788681510463357, predictor_x_loss: 0.13677691414952278, cycled_x_loss: 0.11005057245492936, D_X_loss: 1.2951350688934327\n",
      "[57:200] loss_idt_y: 0.08229672119021415, F_fool_loss: 0.10442801680415868, predictor_y_loss: 0.19910882942378522, cycled_y_loss: 0.08689770225435495, D_Y_loss: 1.071427258849144\n",
      "[57:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[57:300] Took 111.97s\n",
      "[57:300] loss_idt_x: 0.1227026154473424, G_fool_loss: 0.0778794390708208, predictor_x_loss: 0.1402046175301075, cycled_x_loss: 0.12289192751049996, D_X_loss: 1.2617003637552262\n",
      "[57:300] loss_idt_y: 0.07279584165662527, F_fool_loss: 0.08021980311721563, predictor_y_loss: 0.18519193653017282, cycled_y_loss: 0.07870130017399787, D_Y_loss: 1.1128438252210617\n",
      "[57:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[57:400] Took 112.03s\n",
      "[57:400] loss_idt_x: 0.11499637126922607, G_fool_loss: 0.06603601101785898, predictor_x_loss: 0.14415627732872963, cycled_x_loss: 0.11592537056654692, D_X_loss: 1.2616017246246338\n",
      "[57:400] loss_idt_y: 0.08218738935887814, F_fool_loss: 0.06933058939874172, predictor_y_loss: 0.18813498064875603, cycled_y_loss: 0.08605353578925133, D_Y_loss: 1.078945790529251\n",
      "[57:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[57:500] Took 111.90s\n",
      "[57:500] loss_idt_x: 0.11740545272827148, G_fool_loss: 0.07169603440910578, predictor_x_loss: 0.1421356128156185, cycled_x_loss: 0.1122396469861269, D_X_loss: 1.2268800771236419\n",
      "[57:500] loss_idt_y: 0.07765547797083855, F_fool_loss: 0.06338357742875815, predictor_y_loss: 0.19883451655507087, cycled_y_loss: 0.08496733728796244, D_Y_loss: 1.0772555994987487\n",
      "[57:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[57:END] Completed epoch in 680.2275757789612s\n",
      "[57:599] ep_loss_idt_x: 0.116 ep_G_fool_loss: 0.072 ep_predictor_x_loss: 0.141 ep_cycled_x_loss: 0.114 ep_D_X_loss: 1.383\n",
      "[57:599] ep_loss_idt_y: 0.079 ep_F_fool_loss: 0.174 ep_predictor_y_loss: 0.191 ep_cycled_y_loss: 0.085 ep_D_Y_loss: 1.089\n",
      "[57:END] Completed eval in 5.375145435333252s\n",
      "Updated G_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated F_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated D_X_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated D_Y_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated P_X_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "Updated P_Y_opt learning rate from 0.0001803921568627451 to 0.00017647058823529413\n",
      "[57:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[58:100] Took 117.71s\n",
      "[58:100] loss_idt_x: 0.11725522145628929, G_fool_loss: 0.0684554523229599, predictor_x_loss: 0.14213795304298402, cycled_x_loss: 0.11832080397754907, D_X_loss: 1.2391719734668731\n",
      "[58:100] loss_idt_y: 0.08208777826279402, F_fool_loss: 0.058892422430217264, predictor_y_loss: 0.18024062469601632, cycled_y_loss: 0.08913385786116124, D_Y_loss: 1.1108511507511138\n",
      "[58:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[58:200] Took 111.13s\n",
      "[58:200] loss_idt_x: 0.11743622772395611, G_fool_loss: 0.06810384940356017, predictor_x_loss: 0.14441534116864205, cycled_x_loss: 0.11210431098937988, D_X_loss: 1.2211305749416352\n",
      "[58:200] loss_idt_y: 0.0763932803273201, F_fool_loss: 0.054897071234881877, predictor_y_loss: 0.18543506897985934, cycled_y_loss: 0.08230856720358133, D_Y_loss: 1.0855730593204498\n",
      "[58:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[58:300] Took 111.08s\n",
      "[58:300] loss_idt_x: 0.10175973102450371, G_fool_loss: 0.0712374259904027, predictor_x_loss: 0.13155031599104405, cycled_x_loss: 0.10718990784138441, D_X_loss: 1.213251987695694\n",
      "[58:300] loss_idt_y: 0.0706340454518795, F_fool_loss: 0.05681773666292429, predictor_y_loss: 0.1821815346926451, cycled_y_loss: 0.07872151590883732, D_Y_loss: 1.08806789457798\n",
      "[58:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[58:400] Took 112.48s\n",
      "[58:400] loss_idt_x: 0.11581086751073599, G_fool_loss: 0.06774669416248798, predictor_x_loss: 0.14951438941061496, cycled_x_loss: 0.11585392884910106, D_X_loss: 1.2177878081798554\n",
      "[58:400] loss_idt_y: 0.08008609592914581, F_fool_loss: 0.05833660390228033, predictor_y_loss: 0.176328062415123, cycled_y_loss: 0.08199804402887821, D_Y_loss: 1.085972410440445\n",
      "[58:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[58:500] Took 113.84s\n",
      "[58:500] loss_idt_x: 0.11400502428412437, G_fool_loss: 0.07507038347423077, predictor_x_loss: 0.12944448225200175, cycled_x_loss: 0.11424715720117092, D_X_loss: 1.203813180923462\n",
      "[58:500] loss_idt_y: 0.07760614112019538, F_fool_loss: 0.05799088776111603, predictor_y_loss: 0.1976716474443674, cycled_y_loss: 0.08125077176839113, D_Y_loss: 1.0878206026554107\n",
      "[58:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[58:END] Completed epoch in 686.6435904502869s\n",
      "[58:599] ep_loss_idt_x: 0.113 ep_G_fool_loss: 0.073 ep_predictor_x_loss: 0.139 ep_cycled_x_loss: 0.113 ep_D_X_loss: 1.214\n",
      "[58:599] ep_loss_idt_y: 0.079 ep_F_fool_loss: 0.057 ep_predictor_y_loss: 0.186 ep_cycled_y_loss: 0.084 ep_D_Y_loss: 1.090\n",
      "[58:END] Completed eval in 5.486139297485352s\n",
      "Updated G_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated F_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated D_X_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated D_Y_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated P_X_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "Updated P_Y_opt learning rate from 0.00017647058823529413 to 0.00017254901960784316\n",
      "[58:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[59:100] Took 117.66s\n",
      "[59:100] loss_idt_x: 0.11078841757029295, G_fool_loss: 0.07881176155060529, predictor_x_loss: 0.13931773290038107, cycled_x_loss: 0.11066930077970027, D_X_loss: 1.2149818205833436\n",
      "[59:100] loss_idt_y: 0.07855047155171632, F_fool_loss: 0.05600631713867187, predictor_y_loss: 0.19037814237177372, cycled_y_loss: 0.08409434922039509, D_Y_loss: 1.1235693025588989\n",
      "[59:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[59:200] Took 111.71s\n",
      "[59:200] loss_idt_x: 0.11044470980763435, G_fool_loss: 0.06342132192105054, predictor_x_loss: 0.13423969238996505, cycled_x_loss: 0.11068338043987751, D_X_loss: 1.2000668138265609\n",
      "[59:200] loss_idt_y: 0.07212394505739211, F_fool_loss: 0.054375272952020166, predictor_y_loss: 0.1796968362480402, cycled_y_loss: 0.07770561996847392, D_Y_loss: 1.0836465555429458\n",
      "[59:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[59:300] Took 111.74s\n",
      "[59:300] loss_idt_x: 0.1068521462008357, G_fool_loss: 0.06605544712394476, predictor_x_loss: 0.1397074780613184, cycled_x_loss: 0.10747379787266255, D_X_loss: 1.2186837780475617\n",
      "[59:300] loss_idt_y: 0.07394966226071119, F_fool_loss: 0.06632213994860649, predictor_y_loss: 0.1844309490546584, cycled_y_loss: 0.08097801230847836, D_Y_loss: 1.0808777731657029\n",
      "[59:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[59:400] Took 111.81s\n",
      "[59:400] loss_idt_x: 0.10863885495811701, G_fool_loss: 0.06324020870029927, predictor_x_loss: 0.13970031090080737, cycled_x_loss: 0.11053756542503834, D_X_loss: 1.201137397289276\n",
      "[59:400] loss_idt_y: 0.07134832192212343, F_fool_loss: 0.05904190968722105, predictor_y_loss: 0.1842826122790575, cycled_y_loss: 0.07588722497224808, D_Y_loss: 1.0879946041107178\n",
      "[59:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[59:500] Took 111.78s\n",
      "[59:500] loss_idt_x: 0.11608708940446377, G_fool_loss: 0.06932395353913307, predictor_x_loss: 0.13562410719692708, cycled_x_loss: 0.11140353765338659, D_X_loss: 1.2187785708904266\n",
      "[59:500] loss_idt_y: 0.07641544856131077, F_fool_loss: 0.05481551997363567, predictor_y_loss: 0.18159316740930082, cycled_y_loss: 0.08050792086869478, D_Y_loss: 1.074655824303627\n",
      "[59:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[59:END] Completed epoch in 703.3336117267609s\n",
      "[59:599] ep_loss_idt_x: 0.111 ep_G_fool_loss: 0.067 ep_predictor_x_loss: 0.137 ep_cycled_x_loss: 0.110 ep_D_X_loss: 1.208\n",
      "[59:599] ep_loss_idt_y: 0.073 ep_F_fool_loss: 0.057 ep_predictor_y_loss: 0.185 ep_cycled_y_loss: 0.079 ep_D_Y_loss: 1.086\n",
      "[59:END] Completed eval in 5.684160947799683s\n",
      "Updated G_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated F_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated D_X_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated D_Y_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated P_X_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "Updated P_Y_opt learning rate from 0.00017254901960784316 to 0.00016862745098039216\n",
      "[59:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[60:100] Took 117.08s\n",
      "[60:100] loss_idt_x: 0.10636600017547608, G_fool_loss: 0.06755500540137291, predictor_x_loss: 0.13415483839809894, cycled_x_loss: 0.1079382960125804, D_X_loss: 1.226033383011818\n",
      "[60:100] loss_idt_y: 0.07366128318011761, F_fool_loss: 0.06311366245150567, predictor_y_loss: 0.19418437778949738, cycled_y_loss: 0.0773336024582386, D_Y_loss: 1.095701698064804\n",
      "[60:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[60:200] Took 112.18s\n",
      "[60:200] loss_idt_x: 0.11312444034963846, G_fool_loss: 0.07606654603034257, predictor_x_loss: 0.13785736985504626, cycled_x_loss: 0.10682319819927216, D_X_loss: 1.2090272408723832\n",
      "[60:200] loss_idt_y: 0.07200858384370803, F_fool_loss: 0.06241276055574417, predictor_y_loss: 0.1786974422633648, cycled_y_loss: 0.07746454861015081, D_Y_loss: 1.1084630632400512\n",
      "[60:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[60:300] Took 112.12s\n",
      "[60:300] loss_idt_x: 0.10340784631669521, G_fool_loss: 0.06481326896697283, predictor_x_loss: 0.13588191665709018, cycled_x_loss: 0.10733663190156222, D_X_loss: 1.2106025445461273\n",
      "[60:300] loss_idt_y: 0.07195645712316036, F_fool_loss: 0.05459343027323484, predictor_y_loss: 0.18590057164430618, cycled_y_loss: 0.07580789435654879, D_Y_loss: 1.0630979323387146\n",
      "[60:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[60:400] Took 112.14s\n",
      "[60:400] loss_idt_x: 0.10535411011427641, G_fool_loss: 0.06171082753688097, predictor_x_loss: 0.14211267434060573, cycled_x_loss: 0.11479731999337674, D_X_loss: 1.1948444336652755\n",
      "[60:400] loss_idt_y: 0.07750811178237199, F_fool_loss: 0.05339879777282477, predictor_y_loss: 0.193197453096509, cycled_y_loss: 0.08174830891191959, D_Y_loss: 1.092139137983322\n",
      "[60:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[60:500] Took 112.19s\n",
      "[60:500] loss_idt_x: 0.111097990013659, G_fool_loss: 0.062466665096580984, predictor_x_loss: 0.1354873898625374, cycled_x_loss: 0.1099637558683753, D_X_loss: 1.2288512003421783\n",
      "[60:500] loss_idt_y: 0.06859602190554143, F_fool_loss: 0.07267159894108773, predictor_y_loss: 0.1876690014451742, cycled_y_loss: 0.07499357383698226, D_Y_loss: 1.095008682012558\n",
      "[60:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[60:END] Completed epoch in 681.4938750267029s\n",
      "[60:599] ep_loss_idt_x: 0.109 ep_G_fool_loss: 0.068 ep_predictor_x_loss: 0.136 ep_cycled_x_loss: 0.110 ep_D_X_loss: 1.210\n",
      "[60:599] ep_loss_idt_y: 0.073 ep_F_fool_loss: 0.061 ep_predictor_y_loss: 0.185 ep_cycled_y_loss: 0.077 ep_D_Y_loss: 1.091\n",
      "[60:END] Completed eval in 5.810027837753296s\n",
      "Updated G_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated F_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated D_X_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated D_Y_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated P_X_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "Updated P_Y_opt learning rate from 0.00016862745098039216 to 0.0001647058823529412\n",
      "[60:END] Saving models and training information permanently\n",
      "[61:100] Took 119.39s\n",
      "[61:100] loss_idt_x: 0.11277118287980556, G_fool_loss: 0.06567491207271814, predictor_x_loss: 0.132162108682096, cycled_x_loss: 0.10841582614928484, D_X_loss: 1.2161583280563355\n",
      "[61:100] loss_idt_y: 0.07406854867935181, F_fool_loss: 0.053121085725724694, predictor_y_loss: 0.1720839611440897, cycled_y_loss: 0.0778622629120946, D_Y_loss: 1.0945583790540696\n",
      "[61:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[61:200] Took 114.82s\n",
      "[61:200] loss_idt_x: 0.1143441379442811, G_fool_loss: 0.06685454320162534, predictor_x_loss: 0.14501598820090295, cycled_x_loss: 0.10587640885263681, D_X_loss: 1.196340131163597\n",
      "[61:200] loss_idt_y: 0.06778325997292996, F_fool_loss: 0.05335027396678924, predictor_y_loss: 0.17808889880776405, cycled_y_loss: 0.07435197867453099, D_Y_loss: 1.0956060570478439\n",
      "[61:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[61:300] Took 114.95s\n",
      "[61:300] loss_idt_x: 0.1044154516234994, G_fool_loss: 0.06974250853061675, predictor_x_loss: 0.13285894073545934, cycled_x_loss: 0.10158135216683149, D_X_loss: 1.1997173231840135\n",
      "[61:300] loss_idt_y: 0.07146832745522261, F_fool_loss: 0.05912504278123379, predictor_y_loss: 0.171730542704463, cycled_y_loss: 0.0765534322336316, D_Y_loss: 1.1017229807376863\n",
      "[61:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[61:400] Took 115.25s\n",
      "[61:400] loss_idt_x: 0.10490526419132948, G_fool_loss: 0.08979154489934445, predictor_x_loss: 0.12890225503593683, cycled_x_loss: 0.10945513173937797, D_X_loss: 1.2143370133638383\n",
      "[61:400] loss_idt_y: 0.0704768067598343, F_fool_loss: 0.06753785632550717, predictor_y_loss: 0.19059365168213843, cycled_y_loss: 0.07699547056108713, D_Y_loss: 1.1251462560892105\n",
      "[61:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[61:500] Took 115.06s\n",
      "[61:500] loss_idt_x: 0.10646254520863295, G_fool_loss: 0.06185725953429937, predictor_x_loss: 0.13658928893506528, cycled_x_loss: 0.10624476194381714, D_X_loss: 1.210336446762085\n",
      "[61:500] loss_idt_y: 0.07549666784703732, F_fool_loss: 0.05943105112761259, predictor_y_loss: 0.1681385014951229, cycled_y_loss: 0.07942335661500692, D_Y_loss: 1.0718322551250459\n",
      "[61:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[61:END] Completed epoch in 701.4687068462372s\n",
      "[61:599] ep_loss_idt_x: 0.107 ep_G_fool_loss: 0.070 ep_predictor_x_loss: 0.135 ep_cycled_x_loss: 0.106 ep_D_X_loss: 1.210\n",
      "[61:599] ep_loss_idt_y: 0.071 ep_F_fool_loss: 0.064 ep_predictor_y_loss: 0.177 ep_cycled_y_loss: 0.076 ep_D_Y_loss: 1.094\n",
      "[61:END] Completed eval in 5.570699214935303s\n",
      "Updated G_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated F_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated D_X_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated D_Y_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated P_X_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "Updated P_Y_opt learning rate from 0.0001647058823529412 to 0.00016078431372549022\n",
      "[61:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[62:100] Took 118.23s\n",
      "[62:100] loss_idt_x: 0.102261075489223, G_fool_loss: 0.05643753726035357, predictor_x_loss: 0.1307766219973564, cycled_x_loss: 0.09780834820121527, D_X_loss: 1.2159542989730836\n",
      "[62:100] loss_idt_y: 0.07128117512911558, F_fool_loss: 0.05964351423084736, predictor_y_loss: 0.18467420481145383, cycled_y_loss: 0.07401487566530704, D_Y_loss: 1.1048082506656647\n",
      "[62:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[62:200] Took 112.10s\n",
      "[62:200] loss_idt_x: 0.10815110959112645, G_fool_loss: 0.08439982235431671, predictor_x_loss: 0.14299620546400546, cycled_x_loss: 0.11167431447654963, D_X_loss: 1.207069934606552\n",
      "[62:200] loss_idt_y: 0.07781559728085995, F_fool_loss: 0.05577824998646975, predictor_y_loss: 0.1857586219161749, cycled_y_loss: 0.08072982758283614, D_Y_loss: 1.0989271587133407\n",
      "[62:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[62:300] Took 112.09s\n",
      "[62:300] loss_idt_x: 0.10559059269726276, G_fool_loss: 0.05948066685348749, predictor_x_loss: 0.13321010902523994, cycled_x_loss: 0.10378206621855497, D_X_loss: 1.1975845676660537\n",
      "[62:300] loss_idt_y: 0.06847150240093469, F_fool_loss: 0.054446679316461084, predictor_y_loss: 0.1753570519387722, cycled_y_loss: 0.0740444266423583, D_Y_loss: 1.1206336498260498\n",
      "[62:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[62:400] Took 112.21s\n",
      "[62:400] loss_idt_x: 0.10602940712124109, G_fool_loss: 0.06361684415489435, predictor_x_loss: 0.13376747511327267, cycled_x_loss: 0.10589420489966869, D_X_loss: 1.1956807333230972\n",
      "[62:400] loss_idt_y: 0.07112270761281252, F_fool_loss: 0.05618232771754265, predictor_y_loss: 0.18293243572115897, cycled_y_loss: 0.07537759769707918, D_Y_loss: 1.09633602976799\n",
      "[62:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[62:500] Took 112.23s\n",
      "[62:500] loss_idt_x: 0.10312424991279841, G_fool_loss: 0.063627351783216, predictor_x_loss: 0.13254134118556976, cycled_x_loss: 0.10643358908593654, D_X_loss: 1.1968351256847383\n",
      "[62:500] loss_idt_y: 0.07757960293442011, F_fool_loss: 0.05180577497929335, predictor_y_loss: 0.18789004996418954, cycled_y_loss: 0.08287231586873531, D_Y_loss: 1.0828794318437576\n",
      "[62:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[62:END] Completed epoch in 686.4452383518219s\n",
      "[62:599] ep_loss_idt_x: 0.106 ep_G_fool_loss: 0.064 ep_predictor_x_loss: 0.134 ep_cycled_x_loss: 0.105 ep_D_X_loss: 1.202\n",
      "[62:599] ep_loss_idt_y: 0.072 ep_F_fool_loss: 0.057 ep_predictor_y_loss: 0.184 ep_cycled_y_loss: 0.077 ep_D_Y_loss: 1.099\n",
      "[62:END] Completed eval in 5.649277448654175s\n",
      "Updated G_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated F_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated D_X_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated D_Y_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated P_X_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "Updated P_Y_opt learning rate from 0.00016078431372549022 to 0.00015686274509803922\n",
      "[62:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[63:100] Took 116.90s\n",
      "[63:100] loss_idt_x: 0.09852896515280009, G_fool_loss: 0.059519396349787715, predictor_x_loss: 0.12877754431217908, cycled_x_loss: 0.09858934491872788, D_X_loss: 1.2108893358707429\n",
      "[63:100] loss_idt_y: 0.0711573202908039, F_fool_loss: 0.0558795166015625, predictor_y_loss: 0.181025972366333, cycled_y_loss: 0.07464696526527405, D_Y_loss: 1.1086999249458314\n",
      "[63:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[63:200] Took 111.79s\n",
      "[63:200] loss_idt_x: 0.10557594899088145, G_fool_loss: 0.0628775692731142, predictor_x_loss: 0.1320598792657256, cycled_x_loss: 0.11021490767598152, D_X_loss: 1.2191688853502274\n",
      "[63:200] loss_idt_y: 0.07381274115294217, F_fool_loss: 0.07087419226765633, predictor_y_loss: 0.17669932693243026, cycled_y_loss: 0.07641477912664413, D_Y_loss: 1.0868155443668366\n",
      "[63:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[63:300] Took 111.61s\n",
      "[63:300] loss_idt_x: 0.10698906380683183, G_fool_loss: 0.06015706244856119, predictor_x_loss: 0.1393831495195627, cycled_x_loss: 0.10675561293959618, D_X_loss: 1.1980480521917343\n",
      "[63:300] loss_idt_y: 0.07040698599070311, F_fool_loss: 0.05278216253966093, predictor_y_loss: 0.19620298601686956, cycled_y_loss: 0.07607644192874431, D_Y_loss: 1.0807781314849854\n",
      "[63:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[63:400] Took 111.90s\n",
      "[63:400] loss_idt_x: 0.09708594534546137, G_fool_loss: 0.06289106067270041, predictor_x_loss: 0.12497359231114387, cycled_x_loss: 0.09452338002622128, D_X_loss: 1.197623272538185\n",
      "[63:400] loss_idt_y: 0.06623190261423588, F_fool_loss: 0.06444970894604922, predictor_y_loss: 0.17904460910707712, cycled_y_loss: 0.07275748871266842, D_Y_loss: 1.0957203447818755\n",
      "[63:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[63:500] Took 111.65s\n",
      "[63:500] loss_idt_x: 0.0974166340380907, G_fool_loss: 0.06138875108212233, predictor_x_loss: 0.13191196478903294, cycled_x_loss: 0.09859512075781822, D_X_loss: 1.2090532273054122\n",
      "[63:500] loss_idt_y: 0.06739794995635748, F_fool_loss: 0.06557124987244606, predictor_y_loss: 0.17438906136900187, cycled_y_loss: 0.07270338509231805, D_Y_loss: 1.1101220273971557\n",
      "[63:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[63:END] Completed epoch in 681.9903135299683s\n",
      "[63:599] ep_loss_idt_x: 0.102 ep_G_fool_loss: 0.062 ep_predictor_x_loss: 0.132 ep_cycled_x_loss: 0.102 ep_D_X_loss: 1.202\n",
      "[63:599] ep_loss_idt_y: 0.071 ep_F_fool_loss: 0.061 ep_predictor_y_loss: 0.182 ep_cycled_y_loss: 0.075 ep_D_Y_loss: 1.092\n",
      "[63:END] Completed eval in 5.7373316287994385s\n",
      "Updated G_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated F_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated D_X_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated D_Y_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated P_X_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "Updated P_Y_opt learning rate from 0.00015686274509803922 to 0.00015294117647058822\n",
      "[63:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[64:100] Took 114.95s\n",
      "[64:100] loss_idt_x: 0.0966031002253294, G_fool_loss: 0.06529395025223493, predictor_x_loss: 0.12591416269540787, cycled_x_loss: 0.09184461113065481, D_X_loss: 1.2008159947395325\n",
      "[64:100] loss_idt_y: 0.06776766162365674, F_fool_loss: 0.05428683068603277, predictor_y_loss: 0.1620359627902508, cycled_y_loss: 0.07222215607762336, D_Y_loss: 1.098195605278015\n",
      "[64:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[64:200] Took 111.44s\n",
      "[64:200] loss_idt_x: 0.09892713088542222, G_fool_loss: 0.06232296705245972, predictor_x_loss: 0.12980290535837413, cycled_x_loss: 0.0949452868849039, D_X_loss: 1.1842071866989137\n",
      "[64:200] loss_idt_y: 0.07501611649990082, F_fool_loss: 0.050835850536823275, predictor_y_loss: 0.19421081863343714, cycled_y_loss: 0.07789143770933152, D_Y_loss: 1.099770815372467\n",
      "[64:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[64:300] Took 110.97s\n",
      "[64:300] loss_idt_x: 0.10837216179817916, G_fool_loss: 0.06304108988493681, predictor_x_loss: 0.1319593610614538, cycled_x_loss: 0.10596994742751122, D_X_loss: 1.1752681988477707\n",
      "[64:300] loss_idt_y: 0.06910326018929482, F_fool_loss: 0.05338195815682411, predictor_y_loss: 0.17404200345277787, cycled_y_loss: 0.0721423014998436, D_Y_loss: 1.0942738956212998\n",
      "[64:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[64:400] Took 110.96s\n",
      "[64:400] loss_idt_x: 0.09535639140754938, G_fool_loss: 0.0609333585202694, predictor_x_loss: 0.13127326272428036, cycled_x_loss: 0.09639176681637764, D_X_loss: 1.1782988429069519\n",
      "[64:400] loss_idt_y: 0.0632990962639451, F_fool_loss: 0.052748842984437945, predictor_y_loss: 0.16390316091477872, cycled_y_loss: 0.06784330945461989, D_Y_loss: 1.0835046350955964\n",
      "[64:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[64:500] Took 110.81s\n",
      "[64:500] loss_idt_x: 0.09789052251726389, G_fool_loss: 0.05595986682921648, predictor_x_loss: 0.1258473376184702, cycled_x_loss: 0.09485498618334531, D_X_loss: 1.187743188738823\n",
      "[64:500] loss_idt_y: 0.06872188203036785, F_fool_loss: 0.05667923472821713, predictor_y_loss: 0.165064712241292, cycled_y_loss: 0.07434173610061406, D_Y_loss: 1.089357323050499\n",
      "[64:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[64:END] Completed epoch in 680.4619510173798s\n",
      "[64:599] ep_loss_idt_x: 0.100 ep_G_fool_loss: 0.061 ep_predictor_x_loss: 0.130 ep_cycled_x_loss: 0.098 ep_D_X_loss: 1.189\n",
      "[64:599] ep_loss_idt_y: 0.068 ep_F_fool_loss: 0.057 ep_predictor_y_loss: 0.172 ep_cycled_y_loss: 0.072 ep_D_Y_loss: 1.091\n",
      "[64:END] Completed eval in 5.8688273429870605s\n",
      "Updated G_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated F_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated D_X_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated D_Y_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated P_X_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "Updated P_Y_opt learning rate from 0.00015294117647058822 to 0.00014901960784313728\n",
      "[64:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[65:100] Took 116.64s\n",
      "[65:100] loss_idt_x: 0.09744237828999758, G_fool_loss: 0.06945170059800149, predictor_x_loss: 0.13105931751430033, cycled_x_loss: 0.09522565256804227, D_X_loss: 1.2125287532806397\n",
      "[65:100] loss_idt_y: 0.06944765377789736, F_fool_loss: 0.05485578373074532, predictor_y_loss: 0.17819753520190715, cycled_y_loss: 0.07242934223264456, D_Y_loss: 1.0998955583572387\n",
      "[65:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[65:200] Took 110.48s\n",
      "[65:200] loss_idt_x: 0.10483415234833955, G_fool_loss: 0.06307348940521479, predictor_x_loss: 0.12142854131758213, cycled_x_loss: 0.09746678844094277, D_X_loss: 1.1912530201673508\n",
      "[65:200] loss_idt_y: 0.06897239964455366, F_fool_loss: 0.05168113734573126, predictor_y_loss: 0.18873483255505563, cycled_y_loss: 0.07326889321208001, D_Y_loss: 1.0703199756145478\n",
      "[65:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[65:300] Took 110.56s\n",
      "[65:300] loss_idt_x: 0.09321642145514489, G_fool_loss: 0.06802848361432552, predictor_x_loss: 0.1303301278501749, cycled_x_loss: 0.09460964046418667, D_X_loss: 1.1921533036231995\n",
      "[65:300] loss_idt_y: 0.06421895641833544, F_fool_loss: 0.05859291940927505, predictor_y_loss: 0.1843369012698531, cycled_y_loss: 0.0684827795997262, D_Y_loss: 1.1031459861993789\n",
      "[65:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[65:400] Took 110.95s\n",
      "[65:400] loss_idt_x: 0.10025861613452434, G_fool_loss: 0.056657239720225336, predictor_x_loss: 0.13423272028565406, cycled_x_loss: 0.1032663169875741, D_X_loss: 1.199319281578064\n",
      "[65:400] loss_idt_y: 0.06706460699439049, F_fool_loss: 0.08434295330196619, predictor_y_loss: 0.18047883108258247, cycled_y_loss: 0.07258477475494146, D_Y_loss: 1.1044116908311843\n",
      "[65:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[65:500] Took 110.73s\n",
      "[65:500] loss_idt_x: 0.10207612082362175, G_fool_loss: 0.06210082933306694, predictor_x_loss: 0.1283340435475111, cycled_x_loss: 0.09586011651903391, D_X_loss: 1.1799084562063218\n",
      "[65:500] loss_idt_y: 0.061911202222108844, F_fool_loss: 0.052066535763442515, predictor_y_loss: 0.17112384885549545, cycled_y_loss: 0.06831015817821026, D_Y_loss: 1.0956728941202163\n",
      "[65:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[65:END] Completed epoch in 675.7620346546173s\n",
      "[65:599] ep_loss_idt_x: 0.099 ep_G_fool_loss: 0.063 ep_predictor_x_loss: 0.130 ep_cycled_x_loss: 0.098 ep_D_X_loss: 1.193\n",
      "[65:599] ep_loss_idt_y: 0.066 ep_F_fool_loss: 0.060 ep_predictor_y_loss: 0.177 ep_cycled_y_loss: 0.071 ep_D_Y_loss: 1.091\n",
      "[65:END] Completed eval in 5.645015001296997s\n",
      "Updated G_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated F_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated D_X_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated D_Y_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated P_X_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "Updated P_Y_opt learning rate from 0.00014901960784313728 to 0.00014509803921568628\n",
      "[65:END] Saving models and training information permanently\n",
      "[66:100] Took 112.82s\n",
      "[66:100] loss_idt_x: 0.10391484424471856, G_fool_loss: 0.05831640522927046, predictor_x_loss: 0.12943234138190746, cycled_x_loss: 0.1022845333442092, D_X_loss: 1.1866282385587692\n",
      "[66:100] loss_idt_y: 0.06604453939944506, F_fool_loss: 0.051895976476371286, predictor_y_loss: 0.1595109620690346, cycled_y_loss: 0.07163506157696248, D_Y_loss: 1.103997209072113\n",
      "[66:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[66:200] Took 106.78s\n",
      "[66:200] loss_idt_x: 0.11047208201140166, G_fool_loss: 0.05948391888290644, predictor_x_loss: 0.13575566794723273, cycled_x_loss: 0.10183603562414646, D_X_loss: 1.1877584260702134\n",
      "[66:200] loss_idt_y: 0.06681573238223791, F_fool_loss: 0.06348015788942575, predictor_y_loss: 0.16982937306165696, cycled_y_loss: 0.07045555848628282, D_Y_loss: 1.0964732366800307\n",
      "[66:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[66:300] Took 106.73s\n",
      "[66:300] loss_idt_x: 0.09567346800118685, G_fool_loss: 0.05671681221574545, predictor_x_loss: 0.12231123801320791, cycled_x_loss: 0.09647335305809975, D_X_loss: 1.175762823820114\n",
      "[66:300] loss_idt_y: 0.0633890513330698, F_fool_loss: 0.05202795583754778, predictor_y_loss: 0.17539542227983473, cycled_y_loss: 0.06801705352962018, D_Y_loss: 1.0974703866243363\n",
      "[66:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[66:400] Took 106.79s\n",
      "[66:400] loss_idt_x: 0.0941044507175684, G_fool_loss: 0.06590666502714157, predictor_x_loss: 0.12828236415982247, cycled_x_loss: 0.09466973770409823, D_X_loss: 1.201322513818741\n",
      "[66:400] loss_idt_y: 0.06580548107624054, F_fool_loss: 0.06599736783653498, predictor_y_loss: 0.1665534220263362, cycled_y_loss: 0.06944182451814412, D_Y_loss: 1.1016195434331895\n",
      "[66:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[66:500] Took 106.58s\n",
      "[66:500] loss_idt_x: 0.09784171301871539, G_fool_loss: 0.06780011605471373, predictor_x_loss: 0.1346060386672616, cycled_x_loss: 0.1041092748567462, D_X_loss: 1.189026827812195\n",
      "[66:500] loss_idt_y: 0.06641882099211216, F_fool_loss: 0.05298161886632442, predictor_y_loss: 0.1692907678335905, cycled_y_loss: 0.07242477227002382, D_Y_loss: 1.1246735763549804\n",
      "[66:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[66:END] Completed epoch in 656.7306668758392s\n",
      "[66:599] ep_loss_idt_x: 0.100 ep_G_fool_loss: 0.062 ep_predictor_x_loss: 0.129 ep_cycled_x_loss: 0.098 ep_D_X_loss: 1.188\n",
      "[66:599] ep_loss_idt_y: 0.066 ep_F_fool_loss: 0.058 ep_predictor_y_loss: 0.168 ep_cycled_y_loss: 0.071 ep_D_Y_loss: 1.098\n",
      "[66:END] Completed eval in 5.758566617965698s\n",
      "Updated G_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated F_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated D_X_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated D_Y_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated P_X_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "Updated P_Y_opt learning rate from 0.00014509803921568628 to 0.00014117647058823528\n",
      "[66:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[67:100] Took 113.36s\n",
      "[67:100] loss_idt_x: 0.0982327638193965, G_fool_loss: 0.059183672703802585, predictor_x_loss: 0.13330752663314344, cycled_x_loss: 0.10184977803379297, D_X_loss: 1.184290943145752\n",
      "[67:100] loss_idt_y: 0.06420534525066614, F_fool_loss: 0.04767667427659035, predictor_y_loss: 0.18651144333183767, cycled_y_loss: 0.06648271761834622, D_Y_loss: 1.0965856897830963\n",
      "[67:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[67:200] Took 106.72s\n",
      "[67:200] loss_idt_x: 0.09433418165892363, G_fool_loss: 0.05796773988753557, predictor_x_loss: 0.116347716152668, cycled_x_loss: 0.09367603983730077, D_X_loss: 1.1781248557567596\n",
      "[67:200] loss_idt_y: 0.06595992371439933, F_fool_loss: 0.05176342401653528, predictor_y_loss: 0.1845387078076601, cycled_y_loss: 0.07317085374146699, D_Y_loss: 1.1149846160411834\n",
      "[67:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[67:300] Took 106.71s\n",
      "[67:300] loss_idt_x: 0.09785855337977409, G_fool_loss: 0.06378770556300878, predictor_x_loss: 0.12871016178280115, cycled_x_loss: 0.09661219496279955, D_X_loss: 1.2630802935361862\n",
      "[67:300] loss_idt_y: 0.06872767727822066, F_fool_loss: 0.12147505018860101, predictor_y_loss: 0.17322839725762607, cycled_y_loss: 0.07186154037714004, D_Y_loss: 1.0956134712696075\n",
      "[67:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[67:400] Took 106.83s\n",
      "[67:400] loss_idt_x: 0.09990780010819435, G_fool_loss: 0.05412622217088938, predictor_x_loss: 0.13966550514101983, cycled_x_loss: 0.09500936921685935, D_X_loss: 1.2156537407636643\n",
      "[67:400] loss_idt_y: 0.06653256930410861, F_fool_loss: 0.06494980800896882, predictor_y_loss: 0.16634007699787617, cycled_y_loss: 0.0697442253306508, D_Y_loss: 1.0859249174594878\n",
      "[67:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[67:500] Took 106.97s\n",
      "[67:500] loss_idt_x: 0.09680747866630554, G_fool_loss: 0.058684999532997606, predictor_x_loss: 0.1260409704223275, cycled_x_loss: 0.09588194463402033, D_X_loss: 1.2035527271032334\n",
      "[67:500] loss_idt_y: 0.07026136066764593, F_fool_loss: 0.05388911530375481, predictor_y_loss: 0.16962253354489804, cycled_y_loss: 0.07439226698130369, D_Y_loss: 1.08616479575634\n",
      "[67:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[67:END] Completed epoch in 654.4241783618927s\n",
      "[67:599] ep_loss_idt_x: 0.096 ep_G_fool_loss: 0.060 ep_predictor_x_loss: 0.128 ep_cycled_x_loss: 0.095 ep_D_X_loss: 1.203\n",
      "[67:599] ep_loss_idt_y: 0.066 ep_F_fool_loss: 0.065 ep_predictor_y_loss: 0.175 ep_cycled_y_loss: 0.070 ep_D_Y_loss: 1.096\n",
      "[67:END] Completed eval in 5.728757619857788s\n",
      "Updated G_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated F_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated D_X_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated D_Y_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated P_X_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "Updated P_Y_opt learning rate from 0.00014117647058823528 to 0.0001372549019607843\n",
      "[67:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[68:100] Took 113.61s\n",
      "[68:100] loss_idt_x: 0.0990510407462716, G_fool_loss: 0.0555407152697444, predictor_x_loss: 0.12705722704529762, cycled_x_loss: 0.09412693411111832, D_X_loss: 1.1914218473434448\n",
      "[68:100] loss_idt_y: 0.07127734486013651, F_fool_loss: 0.04974398300051689, predictor_y_loss: 0.1700277291983366, cycled_y_loss: 0.07396186701953411, D_Y_loss: 1.1182035386562348\n",
      "[68:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[68:200] Took 109.51s\n",
      "[68:200] loss_idt_x: 0.09186037369072438, G_fool_loss: 0.060243258625268935, predictor_x_loss: 0.12177239052951336, cycled_x_loss: 0.09186185289174319, D_X_loss: 1.178904259800911\n",
      "[68:200] loss_idt_y: 0.06371297426521778, F_fool_loss: 0.04816633004695177, predictor_y_loss: 0.16853285372257232, cycled_y_loss: 0.066447579190135, D_Y_loss: 1.0856372040510178\n",
      "[68:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[68:300] Took 109.03s\n",
      "[68:300] loss_idt_x: 0.0917332772165537, G_fool_loss: 0.05975382208824158, predictor_x_loss: 0.12668365094810724, cycled_x_loss: 0.09271685540676117, D_X_loss: 1.184227795600891\n",
      "[68:300] loss_idt_y: 0.06718030210584403, F_fool_loss: 0.047634330168366434, predictor_y_loss: 0.16785838842391967, cycled_y_loss: 0.07128671646118163, D_Y_loss: 1.09713532269001\n",
      "[68:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[68:400] Took 109.11s\n",
      "[68:400] loss_idt_x: 0.09521369498223066, G_fool_loss: 0.06312266696244478, predictor_x_loss: 0.12140829466283322, cycled_x_loss: 0.09294307179749012, D_X_loss: 1.1985743194818497\n",
      "[68:400] loss_idt_y: 0.06561636351048947, F_fool_loss: 0.06086792342364788, predictor_y_loss: 0.16287183359265328, cycled_y_loss: 0.06697695337235927, D_Y_loss: 1.1117519646883012\n",
      "[68:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[68:500] Took 109.15s\n",
      "[68:500] loss_idt_x: 0.09142141006886959, G_fool_loss: 0.055834997221827505, predictor_x_loss: 0.12652241844683887, cycled_x_loss: 0.09261621728539467, D_X_loss: 1.1842704117298126\n",
      "[68:500] loss_idt_y: 0.05764479208737612, F_fool_loss: 0.0479043847322464, predictor_y_loss: 0.163366816341877, cycled_y_loss: 0.06285471685230731, D_Y_loss: 1.0985628563165664\n",
      "[68:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[68:END] Completed epoch in 671.4795925617218s\n",
      "[68:599] ep_loss_idt_x: 0.095 ep_G_fool_loss: 0.058 ep_predictor_x_loss: 0.126 ep_cycled_x_loss: 0.093 ep_D_X_loss: 1.185\n",
      "[68:599] ep_loss_idt_y: 0.065 ep_F_fool_loss: 0.051 ep_predictor_y_loss: 0.167 ep_cycled_y_loss: 0.068 ep_D_Y_loss: 1.102\n",
      "[68:END] Completed eval in 5.713441371917725s\n",
      "Updated G_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated F_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated D_X_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated D_Y_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated P_X_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "Updated P_Y_opt learning rate from 0.0001372549019607843 to 0.00013333333333333337\n",
      "[68:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[69:100] Took 115.72s\n",
      "[69:100] loss_idt_x: 0.09881164252758026, G_fool_loss: 0.05428916554898024, predictor_x_loss: 0.12939435042440892, cycled_x_loss: 0.09503552723675966, D_X_loss: 1.1816953438520432\n",
      "[69:100] loss_idt_y: 0.06270804505795241, F_fool_loss: 0.051472126021981236, predictor_y_loss: 0.16462583474814893, cycled_y_loss: 0.06690950728952885, D_Y_loss: 1.1247033715248107\n",
      "[69:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[69:200] Took 108.46s\n",
      "[69:200] loss_idt_x: 0.08441567778587342, G_fool_loss: 0.05631497133523226, predictor_x_loss: 0.12447711490094662, cycled_x_loss: 0.08499464906752109, D_X_loss: 1.1747782301902772\n",
      "[69:200] loss_idt_y: 0.06187576338648796, F_fool_loss: 0.04794588603079319, predictor_y_loss: 0.17079002320766448, cycled_y_loss: 0.0648554066568613, D_Y_loss: 1.1015073382854461\n",
      "[69:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[69:300] Took 108.65s\n",
      "[69:300] loss_idt_x: 0.09444376852363348, G_fool_loss: 0.05845216579735279, predictor_x_loss: 0.1161186858266592, cycled_x_loss: 0.09111770566552878, D_X_loss: 1.1700436860322951\n",
      "[69:300] loss_idt_y: 0.060537715032696726, F_fool_loss: 0.05172635287046432, predictor_y_loss: 0.16521563217043878, cycled_y_loss: 0.06494559407234192, D_Y_loss: 1.1070486390590668\n",
      "[69:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[69:400] Took 109.49s\n",
      "[69:400] loss_idt_x: 0.09522718749940395, G_fool_loss: 0.06050399411469698, predictor_x_loss: 0.11818571735173464, cycled_x_loss: 0.09249993912875652, D_X_loss: 1.208617559671402\n",
      "[69:400] loss_idt_y: 0.06189262330532074, F_fool_loss: 0.06821209613233804, predictor_y_loss: 0.160848156735301, cycled_y_loss: 0.06590845752507449, D_Y_loss: 1.1096397465467454\n",
      "[69:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[69:500] Took 109.07s\n",
      "[69:500] loss_idt_x: 0.0995907025039196, G_fool_loss: 0.059890760742127895, predictor_x_loss: 0.13481666184961796, cycled_x_loss: 0.0985725599899888, D_X_loss: 1.217380183339119\n",
      "[69:500] loss_idt_y: 0.06385256383568048, F_fool_loss: 0.07427712764590978, predictor_y_loss: 0.16191080026328564, cycled_y_loss: 0.06904898926615716, D_Y_loss: 1.0845606988668441\n",
      "[69:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[69:END] Completed epoch in 669.7236106395721s\n",
      "[69:599] ep_loss_idt_x: 0.093 ep_G_fool_loss: 0.057 ep_predictor_x_loss: 0.125 ep_cycled_x_loss: 0.092 ep_D_X_loss: 1.186\n",
      "[69:599] ep_loss_idt_y: 0.063 ep_F_fool_loss: 0.057 ep_predictor_y_loss: 0.162 ep_cycled_y_loss: 0.067 ep_D_Y_loss: 1.100\n",
      "[69:END] Completed eval in 5.780779838562012s\n",
      "Updated G_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated F_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated D_X_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated D_Y_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated P_X_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "Updated P_Y_opt learning rate from 0.00013333333333333337 to 0.00012941176470588234\n",
      "[69:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[70:100] Took 117.72s\n",
      "[70:100] loss_idt_x: 0.09464068658649921, G_fool_loss: 0.057486031018197534, predictor_x_loss: 0.12585973102599382, cycled_x_loss: 0.09339526530355215, D_X_loss: 1.1925503408908844\n",
      "[70:100] loss_idt_y: 0.06563960541039705, F_fool_loss: 0.052401027828454974, predictor_y_loss: 0.16757230952382088, cycled_y_loss: 0.07131502710282803, D_Y_loss: 1.1243367791175842\n",
      "[70:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[70:200] Took 111.33s\n",
      "[70:200] loss_idt_x: 0.0943340141698718, G_fool_loss: 0.056299993880093095, predictor_x_loss: 0.1133547991886735, cycled_x_loss: 0.08831354010850191, D_X_loss: 1.1918698757886887\n",
      "[70:200] loss_idt_y: 0.06325777620077133, F_fool_loss: 0.05401600513607264, predictor_y_loss: 0.1611404464393854, cycled_y_loss: 0.06837769210338593, D_Y_loss: 1.0951684707403182\n",
      "[70:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[70:300] Took 111.33s\n",
      "[70:300] loss_idt_x: 0.08943352434784174, G_fool_loss: 0.05713883776217699, predictor_x_loss: 0.12496290124952793, cycled_x_loss: 0.08779219426214695, D_X_loss: 1.2296462261676788\n",
      "[70:300] loss_idt_y: 0.06336613036692143, F_fool_loss: 0.0823072600364685, predictor_y_loss: 0.156965484470129, cycled_y_loss: 0.06699877325445414, D_Y_loss: 1.089244288802147\n",
      "[70:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[70:400] Took 111.44s\n",
      "[70:400] loss_idt_x: 0.088556775636971, G_fool_loss: 0.055760813653469084, predictor_x_loss: 0.12602026283740997, cycled_x_loss: 0.08996164951473475, D_X_loss: 1.1753025949001312\n",
      "[70:400] loss_idt_y: 0.062173845060169694, F_fool_loss: 0.049034895487129686, predictor_y_loss: 0.1526729343831539, cycled_y_loss: 0.06618099685758352, D_Y_loss: 1.0972358250617982\n",
      "[70:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[70:500] Took 111.82s\n",
      "[70:500] loss_idt_x: 0.08825959898531437, G_fool_loss: 0.06141844991594553, predictor_x_loss: 0.12283617690205574, cycled_x_loss: 0.09259985193610192, D_X_loss: 1.179361664056778\n",
      "[70:500] loss_idt_y: 0.06392799217253924, F_fool_loss: 0.048970443196594715, predictor_y_loss: 0.1718543291091919, cycled_y_loss: 0.07045843958854675, D_Y_loss: 1.0976906150579453\n",
      "[70:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[70:END] Completed epoch in 687.1332414150238s\n",
      "[70:599] ep_loss_idt_x: 0.092 ep_G_fool_loss: 0.057 ep_predictor_x_loss: 0.124 ep_cycled_x_loss: 0.091 ep_D_X_loss: 1.188\n",
      "[70:599] ep_loss_idt_y: 0.063 ep_F_fool_loss: 0.056 ep_predictor_y_loss: 0.163 ep_cycled_y_loss: 0.068 ep_D_Y_loss: 1.102\n",
      "[70:END] Completed eval in 5.830324411392212s\n",
      "Updated G_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated F_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated D_X_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated D_Y_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated P_X_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "Updated P_Y_opt learning rate from 0.00012941176470588234 to 0.00012549019607843137\n",
      "[70:END] Saving models and training information permanently\n",
      "[71:100] Took 120.34s\n",
      "[71:100] loss_idt_x: 0.09195100776851177, G_fool_loss: 0.05591931764036417, predictor_x_loss: 0.12284957893192767, cycled_x_loss: 0.08710993818938732, D_X_loss: 1.1704199612140656\n",
      "[71:100] loss_idt_y: 0.059867690093815325, F_fool_loss: 0.04888104226440191, predictor_y_loss: 0.1610072672367096, cycled_y_loss: 0.06317241206765174, D_Y_loss: 1.0912532430887223\n",
      "[71:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[71:200] Took 114.41s\n",
      "[71:200] loss_idt_x: 0.08970181055366994, G_fool_loss: 0.053607934638857845, predictor_x_loss: 0.12721733801066876, cycled_x_loss: 0.08644499201327563, D_X_loss: 1.171987043619156\n",
      "[71:200] loss_idt_y: 0.0627579614520073, F_fool_loss: 0.04893071860074997, predictor_y_loss: 0.1608286889642477, cycled_y_loss: 0.06690349388867617, D_Y_loss: 1.1055108815431596\n",
      "[71:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[71:300] Took 224.81s\n",
      "[71:300] loss_idt_x: 0.09790683966130018, G_fool_loss: 0.05504033111035824, predictor_x_loss: 0.12267625980079173, cycled_x_loss: 0.0967948903515935, D_X_loss: 1.1814047133922576\n",
      "[71:300] loss_idt_y: 0.06602358777076006, F_fool_loss: 0.050215422473847866, predictor_y_loss: 0.16253147747367622, cycled_y_loss: 0.06903835102915763, D_Y_loss: 1.0904821288585662\n",
      "[71:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[71:400] Took 124.63s\n",
      "[71:400] loss_idt_x: 0.08464569963514805, G_fool_loss: 0.054887910895049574, predictor_x_loss: 0.1217473616451025, cycled_x_loss: 0.08652868088334799, D_X_loss: 1.172441041469574\n",
      "[71:400] loss_idt_y: 0.06300362184643746, F_fool_loss: 0.0521445232629776, predictor_y_loss: 0.16436010114848615, cycled_y_loss: 0.0659887033700943, D_Y_loss: 1.0982132309675217\n",
      "[71:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[71:500] Took 115.31s\n",
      "[71:500] loss_idt_x: 0.08917487733066082, G_fool_loss: 0.06011322651058435, predictor_x_loss: 0.11821990419179201, cycled_x_loss: 0.0881168282777071, D_X_loss: 1.1660038447380066\n",
      "[71:500] loss_idt_y: 0.06101833771914244, F_fool_loss: 0.04779420539736748, predictor_y_loss: 0.1546933762356639, cycled_y_loss: 0.06439693260937929, D_Y_loss: 1.0971730268001556\n",
      "[71:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[71:END] Completed epoch in 819.435314655304s\n",
      "[71:599] ep_loss_idt_x: 0.090 ep_G_fool_loss: 0.056 ep_predictor_x_loss: 0.122 ep_cycled_x_loss: 0.089 ep_D_X_loss: 1.174\n",
      "[71:599] ep_loss_idt_y: 0.062 ep_F_fool_loss: 0.053 ep_predictor_y_loss: 0.161 ep_cycled_y_loss: 0.065 ep_D_Y_loss: 1.095\n",
      "[71:END] Completed eval in 6.198127031326294s\n",
      "Updated G_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated F_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated D_X_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated D_Y_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated P_X_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "Updated P_Y_opt learning rate from 0.00012549019607843137 to 0.00012156862745098041\n",
      "[71:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[72:100] Took 114.15s\n",
      "[72:100] loss_idt_x: 0.09181963454931974, G_fool_loss: 0.05549480315297842, predictor_x_loss: 0.1293503922224045, cycled_x_loss: 0.0963041153922677, D_X_loss: 1.1794844663143158\n",
      "[72:100] loss_idt_y: 0.06381788466125726, F_fool_loss: 0.05209277626127005, predictor_y_loss: 0.1654751916974783, cycled_y_loss: 0.06820790261030198, D_Y_loss: 1.1069116258621217\n",
      "[72:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[72:200] Took 113.44s\n",
      "[72:200] loss_idt_x: 0.09200273044407367, G_fool_loss: 0.05117955785244703, predictor_x_loss: 0.12061047092080117, cycled_x_loss: 0.09015649978071451, D_X_loss: 1.1741272336244584\n",
      "[72:200] loss_idt_y: 0.06266200352460145, F_fool_loss: 0.04851515155285597, predictor_y_loss: 0.16843671672046184, cycled_y_loss: 0.06603347957134247, D_Y_loss: 1.1054805314540863\n",
      "[72:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[72:300] Took 111.66s\n",
      "[72:300] loss_idt_x: 0.09203851990401744, G_fool_loss: 0.05266835130751133, predictor_x_loss: 0.12089489474892616, cycled_x_loss: 0.09204407542943954, D_X_loss: 1.1661454772949218\n",
      "[72:300] loss_idt_y: 0.06186472620815039, F_fool_loss: 0.0468525816872716, predictor_y_loss: 0.15886238612234593, cycled_y_loss: 0.06818674497306347, D_Y_loss: 1.1070003420114518\n",
      "[72:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[72:400] Took 108.10s\n",
      "[72:400] loss_idt_x: 0.08689879450947047, G_fool_loss: 0.057018926963210106, predictor_x_loss: 0.11615149606019258, cycled_x_loss: 0.08544597573578358, D_X_loss: 1.1772985589504241\n",
      "[72:400] loss_idt_y: 0.059823038205504414, F_fool_loss: 0.04732551231980324, predictor_y_loss: 0.1609749675914645, cycled_y_loss: 0.06241484843194485, D_Y_loss: 1.0945915275812148\n",
      "[72:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[72:500] Took 110.04s\n",
      "[72:500] loss_idt_x: 0.08836647402495146, G_fool_loss: 0.05828627824783325, predictor_x_loss: 0.12771710611879825, cycled_x_loss: 0.08407619632780552, D_X_loss: 1.1713431948423385\n",
      "[72:500] loss_idt_y: 0.0599898911640048, F_fool_loss: 0.047583611384034157, predictor_y_loss: 0.16436965826898814, cycled_y_loss: 0.06325916271656752, D_Y_loss: 1.1039706981182098\n",
      "[72:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[72:END] Completed epoch in 665.521030664444s\n",
      "[72:599] ep_loss_idt_x: 0.089 ep_G_fool_loss: 0.056 ep_predictor_x_loss: 0.122 ep_cycled_x_loss: 0.088 ep_D_X_loss: 1.178\n",
      "[72:599] ep_loss_idt_y: 0.061 ep_F_fool_loss: 0.052 ep_predictor_y_loss: 0.164 ep_cycled_y_loss: 0.065 ep_D_Y_loss: 1.103\n",
      "[72:END] Completed eval in 5.873041152954102s\n",
      "Updated G_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated F_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated D_X_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated D_Y_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated P_X_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "Updated P_Y_opt learning rate from 0.00012156862745098041 to 0.00011764705882352942\n",
      "[72:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[73:100] Took 124.09s\n",
      "[73:100] loss_idt_x: 0.08858008667826653, G_fool_loss: 0.053805497512221336, predictor_x_loss: 0.11841169260442257, cycled_x_loss: 0.08309305060654879, D_X_loss: 1.1714903372526169\n",
      "[73:100] loss_idt_y: 0.059412134364247325, F_fool_loss: 0.047782386168837544, predictor_y_loss: 0.16526594556868077, cycled_y_loss: 0.06293838616460562, D_Y_loss: 1.1045793747901917\n",
      "[73:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[73:200] Took 146.70s\n",
      "[73:200] loss_idt_x: 0.08663544770330191, G_fool_loss: 0.053463803827762606, predictor_x_loss: 0.11973244830965996, cycled_x_loss: 0.08392795525491238, D_X_loss: 1.1793015241622924\n",
      "[73:200] loss_idt_y: 0.06126729927957058, F_fool_loss: 0.046980665400624275, predictor_y_loss: 0.15339167527854441, cycled_y_loss: 0.06345711007714272, D_Y_loss: 1.0857715553045273\n",
      "[73:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[73:300] Took 110.44s\n",
      "[73:300] loss_idt_x: 0.08370348319411278, G_fool_loss: 0.05165801335126161, predictor_x_loss: 0.12382772509008647, cycled_x_loss: 0.0850764261931181, D_X_loss: 1.1686356800794602\n",
      "[73:300] loss_idt_y: 0.060113743655383585, F_fool_loss: 0.046938501745462415, predictor_y_loss: 0.1493866115808487, cycled_y_loss: 0.06242929246276617, D_Y_loss: 1.1151986032724381\n",
      "[73:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[73:400] Took 110.35s\n",
      "[73:400] loss_idt_x: 0.08725854471325874, G_fool_loss: 0.05333020884543657, predictor_x_loss: 0.12201401866972446, cycled_x_loss: 0.08684876251965762, D_X_loss: 1.1705417984724045\n",
      "[73:400] loss_idt_y: 0.06087345950305462, F_fool_loss: 0.04829972099512816, predictor_y_loss: 0.1612755361944437, cycled_y_loss: 0.06392489667981863, D_Y_loss: 1.0980805045366286\n",
      "[73:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[73:500] Took 110.37s\n",
      "[73:500] loss_idt_x: 0.08604995727539062, G_fool_loss: 0.06691626589745284, predictor_x_loss: 0.11251759506762028, cycled_x_loss: 0.08524261813610792, D_X_loss: 1.1732972115278244\n",
      "[73:500] loss_idt_y: 0.05716032478958368, F_fool_loss: 0.049931765720248225, predictor_y_loss: 0.14860396455973388, cycled_y_loss: 0.06074192602187395, D_Y_loss: 1.0965094113349914\n",
      "[73:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[73:END] Completed epoch in 715.4215321540833s\n",
      "[73:599] ep_loss_idt_x: 0.086 ep_G_fool_loss: 0.056 ep_predictor_x_loss: 0.119 ep_cycled_x_loss: 0.084 ep_D_X_loss: 1.174\n",
      "[73:599] ep_loss_idt_y: 0.059 ep_F_fool_loss: 0.049 ep_predictor_y_loss: 0.154 ep_cycled_y_loss: 0.062 ep_D_Y_loss: 1.098\n",
      "[73:END] Completed eval in 5.948353290557861s\n",
      "Updated G_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated F_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated D_X_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated D_Y_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated P_X_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "Updated P_Y_opt learning rate from 0.00011764705882352942 to 0.00011372549019607843\n",
      "[73:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[74:100] Took 135.18s\n",
      "[74:100] loss_idt_x: 0.08404734503477812, G_fool_loss: 0.053768392167985436, predictor_x_loss: 0.11827296297997236, cycled_x_loss: 0.08355523817241192, D_X_loss: 1.1774266898632049\n",
      "[74:100] loss_idt_y: 0.058841101862490176, F_fool_loss: 0.047798205465078354, predictor_y_loss: 0.15964737832546233, cycled_y_loss: 0.06224441703408957, D_Y_loss: 1.1234260195493697\n",
      "[74:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[74:200] Took 111.40s\n",
      "[74:200] loss_idt_x: 0.0857379387691617, G_fool_loss: 0.05190642688423395, predictor_x_loss: 0.12282952647656202, cycled_x_loss: 0.08519736152142286, D_X_loss: 1.173840239048004\n",
      "[74:200] loss_idt_y: 0.05807343546301127, F_fool_loss: 0.04800424229353666, predictor_y_loss: 0.1499476331472397, cycled_y_loss: 0.06252570029348135, D_Y_loss: 1.0984561508893966\n",
      "[74:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[74:300] Took 113.36s\n",
      "[74:300] loss_idt_x: 0.09313185267150402, G_fool_loss: 0.05136200241744518, predictor_x_loss: 0.12620529420673848, cycled_x_loss: 0.08806856993585825, D_X_loss: 1.1700927889347077\n",
      "[74:300] loss_idt_y: 0.05877392537891865, F_fool_loss: 0.04881817504763603, predictor_y_loss: 0.156163250207901, cycled_y_loss: 0.062351664565503596, D_Y_loss: 1.098367367386818\n",
      "[74:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[74:400] Took 110.70s\n",
      "[74:400] loss_idt_x: 0.08052993778139353, G_fool_loss: 0.054273757673799994, predictor_x_loss: 0.11793348491191864, cycled_x_loss: 0.0797033928334713, D_X_loss: 1.1764993727207185\n",
      "[74:400] loss_idt_y: 0.05851968873292208, F_fool_loss: 0.04962826538830996, predictor_y_loss: 0.1627149633318186, cycled_y_loss: 0.06030536510050297, D_Y_loss: 1.0899676525592803\n",
      "[74:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[74:500] Took 113.08s\n",
      "[74:500] loss_idt_x: 0.08550078738480807, G_fool_loss: 0.05254859238862991, predictor_x_loss: 0.11120607778429985, cycled_x_loss: 0.08074073109775781, D_X_loss: 1.1930474013090133\n",
      "[74:500] loss_idt_y: 0.05425446838140488, F_fool_loss: 0.06476695142686367, predictor_y_loss: 0.1544741066545248, cycled_y_loss: 0.05760642293840647, D_Y_loss: 1.094706706404686\n",
      "[74:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[74:END] Completed epoch in 731.8494579792023s\n",
      "[74:599] ep_loss_idt_x: 0.085 ep_G_fool_loss: 0.053 ep_predictor_x_loss: 0.118 ep_cycled_x_loss: 0.083 ep_D_X_loss: 1.175\n",
      "[74:599] ep_loss_idt_y: 0.058 ep_F_fool_loss: 0.051 ep_predictor_y_loss: 0.156 ep_cycled_y_loss: 0.061 ep_D_Y_loss: 1.098\n",
      "[74:END] Completed eval in 5.881856441497803s\n",
      "Updated G_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated F_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated D_X_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated D_Y_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated P_X_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "Updated P_Y_opt learning rate from 0.00011372549019607843 to 0.00010980392156862746\n",
      "[74:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[75:100] Took 120.16s\n",
      "[75:100] loss_idt_x: 0.08517268747091293, G_fool_loss: 0.051651195399463175, predictor_x_loss: 0.12037817608565092, cycled_x_loss: 0.08545412167906762, D_X_loss: 1.1813441997766494\n",
      "[75:100] loss_idt_y: 0.05967668294906616, F_fool_loss: 0.05134619947522879, predictor_y_loss: 0.1518562962859869, cycled_y_loss: 0.061964840330183506, D_Y_loss: 1.1084284007549285\n",
      "[75:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[75:200] Took 134.62s\n",
      "[75:200] loss_idt_x: 0.08542991761118174, G_fool_loss: 0.052960401326417925, predictor_x_loss: 0.11675627052783966, cycled_x_loss: 0.08583961177617311, D_X_loss: 1.1670011204481125\n",
      "[75:200] loss_idt_y: 0.057592512518167494, F_fool_loss: 0.047458122037351134, predictor_y_loss: 0.15343729600310327, cycled_y_loss: 0.06188173696398735, D_Y_loss: 1.1023428517580032\n",
      "[75:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[75:300] Took 153.24s\n",
      "[75:300] loss_idt_x: 0.0902752210199833, G_fool_loss: 0.05258160654455423, predictor_x_loss: 0.12668453879654407, cycled_x_loss: 0.08310640346258878, D_X_loss: 1.1711416399478913\n",
      "[75:300] loss_idt_y: 0.058653239905834195, F_fool_loss: 0.0453715081140399, predictor_y_loss: 0.15068817045539618, cycled_y_loss: 0.06238223694264889, D_Y_loss: 1.091305387020111\n",
      "[75:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[75:400] Took 115.30s\n",
      "[75:400] loss_idt_x: 0.08364716332405805, G_fool_loss: 0.05473343044519424, predictor_x_loss: 0.11557485710829496, cycled_x_loss: 0.08147961061447859, D_X_loss: 1.190965424180031\n",
      "[75:400] loss_idt_y: 0.05629084471613169, F_fool_loss: 0.060223975069820884, predictor_y_loss: 0.1601276722550392, cycled_y_loss: 0.060706482641398905, D_Y_loss: 1.0990640437602996\n",
      "[75:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[75:500] Took 115.31s\n",
      "[75:500] loss_idt_x: 0.0846969872713089, G_fool_loss: 0.0563378943875432, predictor_x_loss: 0.1156973110884428, cycled_x_loss: 0.08295024618506432, D_X_loss: 1.1721506631374359\n",
      "[75:500] loss_idt_y: 0.05808382570743561, F_fool_loss: 0.04874257888644934, predictor_y_loss: 0.14997645862400533, cycled_y_loss: 0.06253198433667422, D_Y_loss: 1.1093612349033355\n",
      "[75:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[75:END] Completed epoch in 763.38192486763s\n",
      "[75:599] ep_loss_idt_x: 0.085 ep_G_fool_loss: 0.053 ep_predictor_x_loss: 0.119 ep_cycled_x_loss: 0.083 ep_D_X_loss: 1.173\n",
      "[75:599] ep_loss_idt_y: 0.058 ep_F_fool_loss: 0.050 ep_predictor_y_loss: 0.153 ep_cycled_y_loss: 0.062 ep_D_Y_loss: 1.100\n",
      "[75:END] Completed eval in 5.910788297653198s\n",
      "Updated G_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated F_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated D_X_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated D_Y_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated P_X_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "Updated P_Y_opt learning rate from 0.00010980392156862746 to 0.00010588235294117647\n",
      "[75:END] Saving models and training information permanently\n",
      "[76:100] Took 133.49s\n",
      "[76:100] loss_idt_x: 0.08408079478889703, G_fool_loss: 0.050574763156473634, predictor_x_loss: 0.1212446117028594, cycled_x_loss: 0.08033168569207191, D_X_loss: 1.17616250872612\n",
      "[76:100] loss_idt_y: 0.055623076893389224, F_fool_loss: 0.04642343334853649, predictor_y_loss: 0.1399315881356597, cycled_y_loss: 0.05871880833059549, D_Y_loss: 1.1172520101070404\n",
      "[76:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[76:200] Took 119.13s\n",
      "[76:200] loss_idt_x: 0.08437560483813286, G_fool_loss: 0.05111089870333672, predictor_x_loss: 0.12212542124092579, cycled_x_loss: 0.08274328589439392, D_X_loss: 1.1771755802631378\n",
      "[76:200] loss_idt_y: 0.05682870902121067, F_fool_loss: 0.046278499104082584, predictor_y_loss: 0.15392847388982772, cycled_y_loss: 0.060017538890242576, D_Y_loss: 1.096577051281929\n",
      "[76:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[76:300] Took 116.83s\n",
      "[76:300] loss_idt_x: 0.083020208068192, G_fool_loss: 0.053457126468420026, predictor_x_loss: 0.11937122959643602, cycled_x_loss: 0.08424480643123389, D_X_loss: 1.17088010430336\n",
      "[76:300] loss_idt_y: 0.06023936256766319, F_fool_loss: 0.047203433364629746, predictor_y_loss: 0.15706105560064315, cycled_y_loss: 0.06263484373688698, D_Y_loss: 1.1077991664409637\n",
      "[76:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[76:400] Took 114.67s\n",
      "[76:400] loss_idt_x: 0.0821722825244069, G_fool_loss: 0.051924237087368964, predictor_x_loss: 0.11047708116471767, cycled_x_loss: 0.08183763060718775, D_X_loss: 1.196803176999092\n",
      "[76:400] loss_idt_y: 0.05953224368393421, F_fool_loss: 0.058451373614370826, predictor_y_loss: 0.15166573248803616, cycled_y_loss: 0.060695939809083936, D_Y_loss: 1.0937194263935088\n",
      "[76:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[76:500] Took 115.54s\n",
      "[76:500] loss_idt_x: 0.0794387163221836, G_fool_loss: 0.05257145304232836, predictor_x_loss: 0.1151679015904665, cycled_x_loss: 0.0782789959385991, D_X_loss: 1.1779266619682311\n",
      "[76:500] loss_idt_y: 0.05892161458730698, F_fool_loss: 0.04872204158455133, predictor_y_loss: 0.16145359694957734, cycled_y_loss: 0.0609578113257885, D_Y_loss: 1.1073433583974839\n",
      "[76:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[76:END] Completed epoch in 731.1976025104523s\n",
      "[76:599] ep_loss_idt_x: 0.083 ep_G_fool_loss: 0.052 ep_predictor_x_loss: 0.117 ep_cycled_x_loss: 0.082 ep_D_X_loss: 1.175\n",
      "[76:599] ep_loss_idt_y: 0.058 ep_F_fool_loss: 0.049 ep_predictor_y_loss: 0.153 ep_cycled_y_loss: 0.060 ep_D_Y_loss: 1.102\n",
      "[76:END] Completed eval in 6.942656517028809s\n",
      "Updated G_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated F_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated D_X_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated D_Y_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated P_X_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "Updated P_Y_opt learning rate from 0.00010588235294117647 to 0.00010196078431372549\n",
      "[76:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[77:100] Took 122.29s\n",
      "[77:100] loss_idt_x: 0.08079432480037213, G_fool_loss: 0.05125138528645039, predictor_x_loss: 0.11913706991821528, cycled_x_loss: 0.07794564429670572, D_X_loss: 1.1732916194200516\n",
      "[77:100] loss_idt_y: 0.06165018294006586, F_fool_loss: 0.04967919524759054, predictor_y_loss: 0.15218893606215717, cycled_y_loss: 0.06447310846298933, D_Y_loss: 1.1195330327749253\n",
      "[77:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[77:200] Took 114.77s\n",
      "[77:200] loss_idt_x: 0.0772933541238308, G_fool_loss: 0.0523010903224349, predictor_x_loss: 0.1148920164629817, cycled_x_loss: 0.07759256813675165, D_X_loss: 1.1699767500162124\n",
      "[77:200] loss_idt_y: 0.05516011282801628, F_fool_loss: 0.04805104732513428, predictor_y_loss: 0.1551003422960639, cycled_y_loss: 0.05951121870428324, D_Y_loss: 1.1074707925319671\n",
      "[77:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[77:300] Took 114.69s\n",
      "[77:300] loss_idt_x: 0.07814436744898558, G_fool_loss: 0.053738119453191756, predictor_x_loss: 0.1162770739942789, cycled_x_loss: 0.07773639548569918, D_X_loss: 1.1696694147586824\n",
      "[77:300] loss_idt_y: 0.0547649360448122, F_fool_loss: 0.04525867510586977, predictor_y_loss: 0.14782070375978948, cycled_y_loss: 0.05859732247889042, D_Y_loss: 1.094540131688118\n",
      "[77:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[77:400] Took 114.72s\n",
      "[77:400] loss_idt_x: 0.08550538677722215, G_fool_loss: 0.05088214412331581, predictor_x_loss: 0.11764084283262491, cycled_x_loss: 0.08309331540018321, D_X_loss: 1.1807371109724045\n",
      "[77:400] loss_idt_y: 0.05808290597051382, F_fool_loss: 0.06484432466328144, predictor_y_loss: 0.15150272104889154, cycled_y_loss: 0.06098438613116741, D_Y_loss: 1.1097266924381257\n",
      "[77:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[77:500] Took 114.77s\n",
      "[77:500] loss_idt_x: 0.08355696711689234, G_fool_loss: 0.05137367561459541, predictor_x_loss: 0.11454593066126108, cycled_x_loss: 0.08125956818461418, D_X_loss: 1.1719640350341798\n",
      "[77:500] loss_idt_y: 0.05759322252124548, F_fool_loss: 0.04632396850734949, predictor_y_loss: 0.15197138246148825, cycled_y_loss: 0.06045701619237662, D_Y_loss: 1.0975672316551208\n",
      "[77:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[77:END] Completed epoch in 696.3261125087738s\n",
      "[77:599] ep_loss_idt_x: 0.081 ep_G_fool_loss: 0.052 ep_predictor_x_loss: 0.116 ep_cycled_x_loss: 0.079 ep_D_X_loss: 1.171\n",
      "[77:599] ep_loss_idt_y: 0.057 ep_F_fool_loss: 0.050 ep_predictor_y_loss: 0.151 ep_cycled_y_loss: 0.061 ep_D_Y_loss: 1.104\n",
      "[77:END] Completed eval in 5.9352405071258545s\n",
      "Updated G_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated F_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated D_X_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated D_Y_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated P_X_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "Updated P_Y_opt learning rate from 0.00010196078431372549 to 9.803921568627452e-05\n",
      "[77:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[78:100] Took 120.63s\n",
      "[78:100] loss_idt_x: 0.0787440974265337, G_fool_loss: 0.052569593377411364, predictor_x_loss: 0.11455184768885374, cycled_x_loss: 0.07718576237559319, D_X_loss: 1.1679102843999862\n",
      "[78:100] loss_idt_y: 0.057526996284723284, F_fool_loss: 0.045952761210501195, predictor_y_loss: 0.1545357907935977, cycled_y_loss: 0.05963136415928602, D_Y_loss: 1.1087885177135468\n",
      "[78:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[78:200] Took 114.47s\n",
      "[78:200] loss_idt_x: 0.07495737746357918, G_fool_loss: 0.05331904333084822, predictor_x_loss: 0.11117900524288415, cycled_x_loss: 0.074175985455513, D_X_loss: 1.153990040421486\n",
      "[78:200] loss_idt_y: 0.053472614102065566, F_fool_loss: 0.04578908506780863, predictor_y_loss: 0.1368493738025427, cycled_y_loss: 0.05590276893228292, D_Y_loss: 1.0992531847953797\n",
      "[78:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[78:300] Took 116.82s\n",
      "[78:300] loss_idt_x: 0.0846541727334261, G_fool_loss: 0.05077588003128767, predictor_x_loss: 0.120745552405715, cycled_x_loss: 0.08219357043504714, D_X_loss: 1.1771870505809785\n",
      "[78:300] loss_idt_y: 0.05779347311705351, F_fool_loss: 0.05406073961406946, predictor_y_loss: 0.15224042043089867, cycled_y_loss: 0.060781020037829876, D_Y_loss: 1.0919393640756607\n",
      "[78:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[78:400] Took 120.84s\n",
      "[78:400] loss_idt_x: 0.08174031745642424, G_fool_loss: 0.051007970571517944, predictor_x_loss: 0.1161339032649994, cycled_x_loss: 0.0786898486316204, D_X_loss: 1.1684992039203643\n",
      "[78:400] loss_idt_y: 0.054889899007976056, F_fool_loss: 0.04711440049111843, predictor_y_loss: 0.1518194456398487, cycled_y_loss: 0.05849542494863272, D_Y_loss: 1.097711164355278\n",
      "[78:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[78:500] Took 114.62s\n",
      "[78:500] loss_idt_x: 0.08381642438471318, G_fool_loss: 0.05255792908370495, predictor_x_loss: 0.11228382293134928, cycled_x_loss: 0.08155878245830536, D_X_loss: 1.1564655387401581\n",
      "[78:500] loss_idt_y: 0.05406797092407942, F_fool_loss: 0.047817875854671, predictor_y_loss: 0.15167953625321387, cycled_y_loss: 0.05681407205760479, D_Y_loss: 1.1048381578922273\n",
      "[78:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[78:END] Completed epoch in 704.7285678386688s\n",
      "[78:599] ep_loss_idt_x: 0.081 ep_G_fool_loss: 0.051 ep_predictor_x_loss: 0.114 ep_cycled_x_loss: 0.079 ep_D_X_loss: 1.168\n",
      "[78:599] ep_loss_idt_y: 0.056 ep_F_fool_loss: 0.052 ep_predictor_y_loss: 0.149 ep_cycled_y_loss: 0.059 ep_D_Y_loss: 1.100\n",
      "[78:END] Completed eval in 5.969035863876343s\n",
      "Updated G_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated F_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated D_X_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated D_Y_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated P_X_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "Updated P_Y_opt learning rate from 9.803921568627452e-05 to 9.411764705882353e-05\n",
      "[78:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[79:100] Took 117.98s\n",
      "[79:100] loss_idt_x: 0.07516849037259817, G_fool_loss: 0.051487161666154864, predictor_x_loss: 0.1178206355497241, cycled_x_loss: 0.07397446230053902, D_X_loss: 1.1877067077159882\n",
      "[79:100] loss_idt_y: 0.05311409171670675, F_fool_loss: 0.045192526020109654, predictor_y_loss: 0.14619766190648079, cycled_y_loss: 0.05618635907769203, D_Y_loss: 1.0995769912004472\n",
      "[79:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[79:200] Took 111.16s\n",
      "[79:200] loss_idt_x: 0.08233298715204, G_fool_loss: 0.0506938299536705, predictor_x_loss: 0.11001548655331135, cycled_x_loss: 0.07910938885062933, D_X_loss: 1.1710231685638428\n",
      "[79:200] loss_idt_y: 0.057223193924874065, F_fool_loss: 0.044720066599547866, predictor_y_loss: 0.14937375433743, cycled_y_loss: 0.05952230103313923, D_Y_loss: 1.0926392036676407\n",
      "[79:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[79:300] Took 111.67s\n",
      "[79:300] loss_idt_x: 0.07431833531707525, G_fool_loss: 0.05756936017423868, predictor_x_loss: 0.11178673774003983, cycled_x_loss: 0.07040665678679943, D_X_loss: 1.1683329880237578\n",
      "[79:300] loss_idt_y: 0.05366920538246631, F_fool_loss: 0.04504356503486633, predictor_y_loss: 0.14675263728946447, cycled_y_loss: 0.05638304688036442, D_Y_loss: 1.1089219754934312\n",
      "[79:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[79:400] Took 111.19s\n",
      "[79:400] loss_idt_x: 0.07895091112703084, G_fool_loss: 0.04831341102719307, predictor_x_loss: 0.11294594366103411, cycled_x_loss: 0.07786596029996871, D_X_loss: 1.1619986116886138\n",
      "[79:400] loss_idt_y: 0.05575311679393053, F_fool_loss: 0.044650104679167274, predictor_y_loss: 0.1514054448902607, cycled_y_loss: 0.057150723077356816, D_Y_loss: 1.1069609081745149\n",
      "[79:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[79:500] Took 121.09s\n",
      "[79:500] loss_idt_x: 0.07988365642726421, G_fool_loss: 0.04996370323002339, predictor_x_loss: 0.11468229252845048, cycled_x_loss: 0.07940009687095881, D_X_loss: 1.1606969082355498\n",
      "[79:500] loss_idt_y: 0.05479867614805698, F_fool_loss: 0.04445647545158863, predictor_y_loss: 0.13789070919156074, cycled_y_loss: 0.05683176405727863, D_Y_loss: 1.0850031250715255\n",
      "[79:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[79:END] Completed epoch in 704.0890650749207s\n",
      "[79:599] ep_loss_idt_x: 0.078 ep_G_fool_loss: 0.051 ep_predictor_x_loss: 0.113 ep_cycled_x_loss: 0.076 ep_D_X_loss: 1.167\n",
      "[79:599] ep_loss_idt_y: 0.055 ep_F_fool_loss: 0.045 ep_predictor_y_loss: 0.147 ep_cycled_y_loss: 0.057 ep_D_Y_loss: 1.097\n",
      "[79:END] Completed eval in 6.538847923278809s\n",
      "Updated G_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated F_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated D_X_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated D_Y_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated P_X_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "Updated P_Y_opt learning rate from 9.411764705882353e-05 to 9.019607843137255e-05\n",
      "[79:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[80:100] Took 127.68s\n",
      "[80:100] loss_idt_x: 0.08449634969234467, G_fool_loss: 0.05211355958133936, predictor_x_loss: 0.12202963892370462, cycled_x_loss: 0.08006558462977409, D_X_loss: 1.1823013651371002\n",
      "[80:100] loss_idt_y: 0.05305426828563213, F_fool_loss: 0.045780345909297464, predictor_y_loss: 0.14527640726417304, cycled_y_loss: 0.056570573449134826, D_Y_loss: 1.1064302325248718\n",
      "[80:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[80:200] Took 111.83s\n",
      "[80:200] loss_idt_x: 0.07198326110839844, G_fool_loss: 0.05078396789729595, predictor_x_loss: 0.11486493714153767, cycled_x_loss: 0.07034283116459847, D_X_loss: 1.1573502147197723\n",
      "[80:200] loss_idt_y: 0.05314277295023203, F_fool_loss: 0.044816577658057216, predictor_y_loss: 0.14176359254866838, cycled_y_loss: 0.0562817532941699, D_Y_loss: 1.1015117865800859\n",
      "[80:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[80:300] Took 111.86s\n",
      "[80:300] loss_idt_x: 0.07780760090798139, G_fool_loss: 0.05110238056629896, predictor_x_loss: 0.11724604815244674, cycled_x_loss: 0.07460322573781014, D_X_loss: 1.1551303273439408\n",
      "[80:300] loss_idt_y: 0.0505030432716012, F_fool_loss: 0.0445829713344574, predictor_y_loss: 0.1344842430949211, cycled_y_loss: 0.05305981274694204, D_Y_loss: 1.113809341788292\n",
      "[80:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[80:400] Took 113.32s\n",
      "[80:400] loss_idt_x: 0.07038657546043396, G_fool_loss: 0.05089434362947941, predictor_x_loss: 0.10264645762741566, cycled_x_loss: 0.07195067521184682, D_X_loss: 1.1712681514024734\n",
      "[80:400] loss_idt_y: 0.057709664441645145, F_fool_loss: 0.047538020126521585, predictor_y_loss: 0.13833686605095863, cycled_y_loss: 0.05972178399562836, D_Y_loss: 1.0934188950061798\n",
      "[80:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[80:500] Took 114.70s\n",
      "[80:500] loss_idt_x: 0.08161544248461723, G_fool_loss: 0.04939334832131863, predictor_x_loss: 0.11010577660053969, cycled_x_loss: 0.0787891511246562, D_X_loss: 1.1627948659658431\n",
      "[80:500] loss_idt_y: 0.05741482518613338, F_fool_loss: 0.04798922970890999, predictor_y_loss: 0.14465719126164914, cycled_y_loss: 0.05853205110877752, D_Y_loss: 1.1134830337762833\n",
      "[80:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[80:END] Completed epoch in 700.6246883869171s\n",
      "[80:599] ep_loss_idt_x: 0.077 ep_G_fool_loss: 0.051 ep_predictor_x_loss: 0.112 ep_cycled_x_loss: 0.075 ep_D_X_loss: 1.162\n",
      "[80:599] ep_loss_idt_y: 0.055 ep_F_fool_loss: 0.046 ep_predictor_y_loss: 0.141 ep_cycled_y_loss: 0.057 ep_D_Y_loss: 1.104\n",
      "[80:END] Completed eval in 6.245285987854004s\n",
      "Updated G_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated F_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated D_X_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated D_Y_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated P_X_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "Updated P_Y_opt learning rate from 9.019607843137255e-05 to 8.627450980392158e-05\n",
      "[80:END] Saving models and training information permanently\n",
      "[81:100] Took 117.30s\n",
      "[81:100] loss_idt_x: 0.08067677143961191, G_fool_loss: 0.051879477314651014, predictor_x_loss: 0.11474737077951432, cycled_x_loss: 0.077342878729105, D_X_loss: 1.1658783543109894\n",
      "[81:100] loss_idt_y: 0.057979370020329955, F_fool_loss: 0.04506922822445631, predictor_y_loss: 0.13716129951179026, cycled_y_loss: 0.057618611454963685, D_Y_loss: 1.110971949696541\n",
      "[81:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[81:200] Took 115.34s\n",
      "[81:200] loss_idt_x: 0.07627571292221547, G_fool_loss: 0.05019245322793722, predictor_x_loss: 0.10524245899170637, cycled_x_loss: 0.07519078880548477, D_X_loss: 1.158135062456131\n",
      "[81:200] loss_idt_y: 0.053559868521988394, F_fool_loss: 0.0467399512976408, predictor_y_loss: 0.134497039206326, cycled_y_loss: 0.05539989165961742, D_Y_loss: 1.0919717621803284\n",
      "[81:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[81:300] Took 127.57s\n",
      "[81:300] loss_idt_x: 0.07597017399966717, G_fool_loss: 0.04975132804363966, predictor_x_loss: 0.10921015847474337, cycled_x_loss: 0.07194189049303532, D_X_loss: 1.1618616461753846\n",
      "[81:300] loss_idt_y: 0.05410986490547657, F_fool_loss: 0.04423995364457369, predictor_y_loss: 0.14268070995807647, cycled_y_loss: 0.056242352090775966, D_Y_loss: 1.0956917452812194\n",
      "[81:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[81:400] Took 131.33s\n",
      "[81:400] loss_idt_x: 0.07130079042166472, G_fool_loss: 0.04948613539338112, predictor_x_loss: 0.11624301090836525, cycled_x_loss: 0.07105531830340624, D_X_loss: 1.1629121601581573\n",
      "[81:400] loss_idt_y: 0.048938224129378795, F_fool_loss: 0.04939199637621641, predictor_y_loss: 0.139659972935915, cycled_y_loss: 0.05154703851789236, D_Y_loss: 1.105757915377617\n",
      "[81:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[81:500] Took 117.14s\n",
      "[81:500] loss_idt_x: 0.0753982264176011, G_fool_loss: 0.047969071604311464, predictor_x_loss: 0.10901455029845238, cycled_x_loss: 0.07255150128155946, D_X_loss: 1.1626762008666993\n",
      "[81:500] loss_idt_y: 0.05157669464126229, F_fool_loss: 0.04648174107074737, predictor_y_loss: 0.14178107529878617, cycled_y_loss: 0.053722679689526556, D_Y_loss: 1.0996941620111464\n",
      "[81:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[81:END] Completed epoch in 760.7652530670166s\n",
      "[81:599] ep_loss_idt_x: 0.076 ep_G_fool_loss: 0.049 ep_predictor_x_loss: 0.111 ep_cycled_x_loss: 0.074 ep_D_X_loss: 1.159\n",
      "[81:599] ep_loss_idt_y: 0.053 ep_F_fool_loss: 0.046 ep_predictor_y_loss: 0.140 ep_cycled_y_loss: 0.055 ep_D_Y_loss: 1.101\n",
      "[81:END] Completed eval in 6.261933326721191s\n",
      "Updated G_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated F_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated D_X_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated D_Y_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated P_X_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "Updated P_Y_opt learning rate from 8.627450980392158e-05 to 8.23529411764706e-05\n",
      "[81:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[82:100] Took 154.92s\n",
      "[82:100] loss_idt_x: 0.07225314244627952, G_fool_loss: 0.05046054575592279, predictor_x_loss: 0.1106488173827529, cycled_x_loss: 0.06929474748671055, D_X_loss: 1.1701400703191758\n",
      "[82:100] loss_idt_y: 0.049249712526798245, F_fool_loss: 0.04696759913116694, predictor_y_loss: 0.14287387788295747, cycled_y_loss: 0.05131641913205385, D_Y_loss: 1.1068834948539734\n",
      "[82:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[82:200] Took 159.24s\n",
      "[82:200] loss_idt_x: 0.07889411654323339, G_fool_loss: 0.04863555423915386, predictor_x_loss: 0.1121382388100028, cycled_x_loss: 0.07580860111862421, D_X_loss: 1.1538208556175231\n",
      "[82:200] loss_idt_y: 0.05060349084436894, F_fool_loss: 0.044551568776369094, predictor_y_loss: 0.13702504135668278, cycled_y_loss: 0.05309477437287569, D_Y_loss: 1.105752587914467\n",
      "[82:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[82:300] Took 138.13s\n",
      "[82:300] loss_idt_x: 0.07908626291900873, G_fool_loss: 0.04818560633808375, predictor_x_loss: 0.11174006935209035, cycled_x_loss: 0.07608770754188299, D_X_loss: 1.1555009967088699\n",
      "[82:300] loss_idt_y: 0.049145778156816956, F_fool_loss: 0.04752057582139969, predictor_y_loss: 0.13826345663517714, cycled_y_loss: 0.0522096586599946, D_Y_loss: 1.1095505511760713\n",
      "[82:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[82:400] Took 174.48s\n",
      "[82:400] loss_idt_x: 0.07442065984010697, G_fool_loss: 0.04867741838097572, predictor_x_loss: 0.11204800277948379, cycled_x_loss: 0.06956203687936068, D_X_loss: 1.1577721154689788\n",
      "[82:400] loss_idt_y: 0.052404313329607245, F_fool_loss: 0.0496262351050973, predictor_y_loss: 0.1430121110379696, cycled_y_loss: 0.05624000005424023, D_Y_loss: 1.1041867524385451\n",
      "[82:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[82:500] Took 148.15s\n",
      "[82:500] loss_idt_x: 0.07012137919664382, G_fool_loss: 0.049016214087605474, predictor_x_loss: 0.10851704876869916, cycled_x_loss: 0.07037552930414677, D_X_loss: 1.1699792635440827\n",
      "[82:500] loss_idt_y: 0.05304733216762543, F_fool_loss: 0.046679623797535895, predictor_y_loss: 0.15310107205063106, cycled_y_loss: 0.0557538079097867, D_Y_loss: 1.1078925323486328\n",
      "[82:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[82:END] Completed epoch in 893.4884653091431s\n",
      "[82:599] ep_loss_idt_x: 0.075 ep_G_fool_loss: 0.049 ep_predictor_x_loss: 0.110 ep_cycled_x_loss: 0.072 ep_D_X_loss: 1.160\n",
      "[82:599] ep_loss_idt_y: 0.051 ep_F_fool_loss: 0.046 ep_predictor_y_loss: 0.143 ep_cycled_y_loss: 0.054 ep_D_Y_loss: 1.104\n",
      "[82:END] Completed eval in 6.157664775848389s\n",
      "Updated G_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated F_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated D_X_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated D_Y_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated P_X_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "Updated P_Y_opt learning rate from 8.23529411764706e-05 to 7.843137254901962e-05\n",
      "[82:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[83:100] Took 125.11s\n",
      "[83:100] loss_idt_x: 0.07098259557038546, G_fool_loss: 0.048512602113187316, predictor_x_loss: 0.11153145849704743, cycled_x_loss: 0.06998693395406008, D_X_loss: 1.1659785628318786\n",
      "[83:100] loss_idt_y: 0.05197806788608432, F_fool_loss: 0.04513476744294167, predictor_y_loss: 0.1386006709560752, cycled_y_loss: 0.054343585930764673, D_Y_loss: 1.1206399822235107\n",
      "[83:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[83:200] Took 132.21s\n",
      "[83:200] loss_idt_x: 0.07176436755806208, G_fool_loss: 0.04868159420788288, predictor_x_loss: 0.11012644998729229, cycled_x_loss: 0.07091404035687447, D_X_loss: 1.167869634628296\n",
      "[83:200] loss_idt_y: 0.05050537571310997, F_fool_loss: 0.04757168997079134, predictor_y_loss: 0.1436244975030422, cycled_y_loss: 0.0540156301856041, D_Y_loss: 1.0999600619077683\n",
      "[83:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[83:300] Took 137.82s\n",
      "[83:300] loss_idt_x: 0.07270240090787411, G_fool_loss: 0.046926789321005344, predictor_x_loss: 0.10734248198568822, cycled_x_loss: 0.07217505756765603, D_X_loss: 1.1671559619903564\n",
      "[83:300] loss_idt_y: 0.050945913102477786, F_fool_loss: 0.04511366069316864, predictor_y_loss: 0.1413816186785698, cycled_y_loss: 0.05207016535103321, D_Y_loss: 1.110829489827156\n",
      "[83:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[83:400] Took 128.47s\n",
      "[83:400] loss_idt_x: 0.07624066837131976, G_fool_loss: 0.051129059419035915, predictor_x_loss: 0.11136371113359927, cycled_x_loss: 0.06951173059642315, D_X_loss: 1.1652054286003113\n",
      "[83:400] loss_idt_y: 0.05073756340891123, F_fool_loss: 0.04350738782435656, predictor_y_loss: 0.15005088787525891, cycled_y_loss: 0.05287620309740305, D_Y_loss: 1.0962978345155716\n",
      "[83:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[83:500] Took 130.94s\n",
      "[83:500] loss_idt_x: 0.07177883718162775, G_fool_loss: 0.051469333656132224, predictor_x_loss: 0.1030258047580719, cycled_x_loss: 0.07037214081734419, D_X_loss: 1.1741886806488038\n",
      "[83:500] loss_idt_y: 0.048027317598462106, F_fool_loss: 0.046867656484246255, predictor_y_loss: 0.1328659289702773, cycled_y_loss: 0.05169483747333288, D_Y_loss: 1.0925212413072587\n",
      "[83:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[83:END] Completed epoch in 801.9934458732605s\n",
      "[83:599] ep_loss_idt_x: 0.073 ep_G_fool_loss: 0.049 ep_predictor_x_loss: 0.109 ep_cycled_x_loss: 0.071 ep_D_X_loss: 1.164\n",
      "[83:599] ep_loss_idt_y: 0.050 ep_F_fool_loss: 0.045 ep_predictor_y_loss: 0.140 ep_cycled_y_loss: 0.053 ep_D_Y_loss: 1.101\n",
      "[83:END] Completed eval in 6.154741525650024s\n",
      "Updated G_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated F_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated D_X_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated D_Y_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated P_X_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "Updated P_Y_opt learning rate from 7.843137254901962e-05 to 7.450980392156864e-05\n",
      "[83:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[84:100] Took 154.84s\n",
      "[84:100] loss_idt_x: 0.06726534947752953, G_fool_loss: 0.05017021797597408, predictor_x_loss: 0.11060557633638382, cycled_x_loss: 0.06750302001833916, D_X_loss: 1.178473938703537\n",
      "[84:100] loss_idt_y: 0.05020867425948381, F_fool_loss: 0.04780372004956007, predictor_y_loss: 0.14747964531183244, cycled_y_loss: 0.052783864811062814, D_Y_loss: 1.114712718129158\n",
      "[84:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[84:200] Took 129.92s\n",
      "[84:200] loss_idt_x: 0.0772642182931304, G_fool_loss: 0.05002278719097376, predictor_x_loss: 0.11069023672491313, cycled_x_loss: 0.07183705192059278, D_X_loss: 1.1618919956684113\n",
      "[84:200] loss_idt_y: 0.05480022672563791, F_fool_loss: 0.0437716057151556, predictor_y_loss: 0.13371578615158797, cycled_y_loss: 0.05568452723324299, D_Y_loss: 1.1037396317720414\n",
      "[84:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[84:300] Took 115.24s\n",
      "[84:300] loss_idt_x: 0.07010474301874638, G_fool_loss: 0.048276211097836495, predictor_x_loss: 0.10318096287548542, cycled_x_loss: 0.06878255549818277, D_X_loss: 1.1557197225093843\n",
      "[84:300] loss_idt_y: 0.04820435367524624, F_fool_loss: 0.0439034003764391, predictor_y_loss: 0.1323175871744752, cycled_y_loss: 0.05077274013310671, D_Y_loss: 1.1012566751241684\n",
      "[84:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[84:400] Took 115.10s\n",
      "[84:400] loss_idt_x: 0.07488566730171442, G_fool_loss: 0.04734591469168663, predictor_x_loss: 0.10104116495698691, cycled_x_loss: 0.07075538832694292, D_X_loss: 1.1587586390972138\n",
      "[84:400] loss_idt_y: 0.05205923022702336, F_fool_loss: 0.04632852878421545, predictor_y_loss: 0.1351692882925272, cycled_y_loss: 0.05355701614171267, D_Y_loss: 1.1029678094387054\n",
      "[84:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[84:500] Took 116.96s\n",
      "[84:500] loss_idt_x: 0.07110929373651743, G_fool_loss: 0.048065566830337046, predictor_x_loss: 0.10721881560981274, cycled_x_loss: 0.06832654528319836, D_X_loss: 1.1574282670021057\n",
      "[84:500] loss_idt_y: 0.051613392271101476, F_fool_loss: 0.04889898426830769, predictor_y_loss: 0.14559774622321128, cycled_y_loss: 0.05398557905107736, D_Y_loss: 1.1086256849765777\n",
      "[84:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[84:END] Completed epoch in 747.8075456619263s\n",
      "[84:599] ep_loss_idt_x: 0.072 ep_G_fool_loss: 0.049 ep_predictor_x_loss: 0.108 ep_cycled_x_loss: 0.070 ep_D_X_loss: 1.159\n",
      "[84:599] ep_loss_idt_y: 0.051 ep_F_fool_loss: 0.046 ep_predictor_y_loss: 0.138 ep_cycled_y_loss: 0.054 ep_D_Y_loss: 1.104\n",
      "[84:END] Completed eval in 6.174419641494751s\n",
      "Updated G_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated F_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated D_X_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated D_Y_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated P_X_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "Updated P_Y_opt learning rate from 7.450980392156864e-05 to 7.058823529411764e-05\n",
      "[84:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[85:100] Took 118.08s\n",
      "[85:100] loss_idt_x: 0.06933213844895363, G_fool_loss: 0.04844032138586044, predictor_x_loss: 0.10113546684384346, cycled_x_loss: 0.0653899396210909, D_X_loss: 1.1672967731952668\n",
      "[85:100] loss_idt_y: 0.050914885625243184, F_fool_loss: 0.044234524220228194, predictor_y_loss: 0.13898721035569905, cycled_y_loss: 0.052606684789061546, D_Y_loss: 1.1132173949480058\n",
      "[85:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[85:200] Took 113.24s\n",
      "[85:200] loss_idt_x: 0.07233274139463902, G_fool_loss: 0.04836700309067964, predictor_x_loss: 0.10866458244621753, cycled_x_loss: 0.06872924007475376, D_X_loss: 1.156834129691124\n",
      "[85:200] loss_idt_y: 0.04874557329341769, F_fool_loss: 0.04418189536780119, predictor_y_loss: 0.13079962082207203, cycled_y_loss: 0.05153773970901966, D_Y_loss: 1.1056163334846496\n",
      "[85:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[85:300] Took 113.20s\n",
      "[85:300] loss_idt_x: 0.06832600332796573, G_fool_loss: 0.04758463494479656, predictor_x_loss: 0.10765163753181696, cycled_x_loss: 0.06861541848629713, D_X_loss: 1.1609398198127747\n",
      "[85:300] loss_idt_y: 0.04888666829094291, F_fool_loss: 0.0439424255117774, predictor_y_loss: 0.13947578519582748, cycled_y_loss: 0.05172638025134802, D_Y_loss: 1.1024008297920227\n",
      "[85:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[85:400] Took 121.76s\n",
      "[85:400] loss_idt_x: 0.07404543839395046, G_fool_loss: 0.04672647003084421, predictor_x_loss: 0.10897635787725449, cycled_x_loss: 0.07168637160211802, D_X_loss: 1.1664533197879792\n",
      "[85:400] loss_idt_y: 0.050944662615656854, F_fool_loss: 0.04429761465638876, predictor_y_loss: 0.13195680130273105, cycled_y_loss: 0.052798752672970295, D_Y_loss: 1.105914426445961\n",
      "[85:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[85:500] Took 115.42s\n",
      "[85:500] loss_idt_x: 0.0672611340507865, G_fool_loss: 0.04750901244580746, predictor_x_loss: 0.10922305293381214, cycled_x_loss: 0.06537484899163246, D_X_loss: 1.1566480684280396\n",
      "[85:500] loss_idt_y: 0.04871259575709701, F_fool_loss: 0.04437189470976591, predictor_y_loss: 0.1404320200532675, cycled_y_loss: 0.0513396704941988, D_Y_loss: 1.1215835809707642\n",
      "[85:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[85:END] Completed epoch in 725.3287816047668s\n",
      "[85:599] ep_loss_idt_x: 0.071 ep_G_fool_loss: 0.047 ep_predictor_x_loss: 0.106 ep_cycled_x_loss: 0.068 ep_D_X_loss: 1.160\n",
      "[85:599] ep_loss_idt_y: 0.050 ep_F_fool_loss: 0.044 ep_predictor_y_loss: 0.137 ep_cycled_y_loss: 0.052 ep_D_Y_loss: 1.109\n",
      "[85:END] Completed eval in 6.265877962112427s\n",
      "Updated G_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated F_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated D_X_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated D_Y_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated P_X_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "Updated P_Y_opt learning rate from 7.058823529411764e-05 to 6.666666666666668e-05\n",
      "[85:END] Saving models and training information permanently\n",
      "[86:100] Took 130.35s\n",
      "[86:100] loss_idt_x: 0.06888130061328411, G_fool_loss: 0.04664598021656275, predictor_x_loss: 0.10898848980665207, cycled_x_loss: 0.06694532100111246, D_X_loss: 1.1696321475505829\n",
      "[86:100] loss_idt_y: 0.04652144350111485, F_fool_loss: 0.04581292167305946, predictor_y_loss: 0.1364392401278019, cycled_y_loss: 0.049165835753083226, D_Y_loss: 1.1178458857536315\n",
      "[86:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[86:200] Took 123.01s\n",
      "[86:200] loss_idt_x: 0.06914547778666019, G_fool_loss: 0.047508674189448354, predictor_x_loss: 0.09969919111579656, cycled_x_loss: 0.06711517684161664, D_X_loss: 1.163443089723587\n",
      "[86:200] loss_idt_y: 0.04603985439985991, F_fool_loss: 0.04329290043562651, predictor_y_loss: 0.13238931074738503, cycled_y_loss: 0.04908767972141504, D_Y_loss: 1.1118033415079116\n",
      "[86:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[86:300] Took 142.97s\n",
      "[86:300] loss_idt_x: 0.06980243448168039, G_fool_loss: 0.0462253475189209, predictor_x_loss: 0.11034241687506437, cycled_x_loss: 0.06745241586118937, D_X_loss: 1.1660768282413483\n",
      "[86:300] loss_idt_y: 0.051436379849910736, F_fool_loss: 0.04436201240867376, predictor_y_loss: 0.13955835685133933, cycled_y_loss: 0.05155980542302132, D_Y_loss: 1.1158605939149857\n",
      "[86:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[86:400] Took 151.12s\n",
      "[86:400] loss_idt_x: 0.06894263174384832, G_fool_loss: 0.046726149544119834, predictor_x_loss: 0.10437321998178958, cycled_x_loss: 0.06615973059087991, D_X_loss: 1.1653360986709596\n",
      "[86:400] loss_idt_y: 0.04873033251613378, F_fool_loss: 0.0473666038364172, predictor_y_loss: 0.13802962582558392, cycled_y_loss: 0.0504689347743988, D_Y_loss: 1.118254644870758\n",
      "[86:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[86:500] Took 128.94s\n",
      "[86:500] loss_idt_x: 0.076276675760746, G_fool_loss: 0.04619794279336929, predictor_x_loss: 0.11327315036207437, cycled_x_loss: 0.07222641356289387, D_X_loss: 1.1654377353191376\n",
      "[86:500] loss_idt_y: 0.05604405177757144, F_fool_loss: 0.043734379634261134, predictor_y_loss: 0.1349261089414358, cycled_y_loss: 0.05563313227146864, D_Y_loss: 1.1165412420034408\n",
      "[86:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[86:END] Completed epoch in 791.4146242141724s\n",
      "[86:599] ep_loss_idt_x: 0.070 ep_G_fool_loss: 0.047 ep_predictor_x_loss: 0.106 ep_cycled_x_loss: 0.068 ep_D_X_loss: 1.165\n",
      "[86:599] ep_loss_idt_y: 0.050 ep_F_fool_loss: 0.045 ep_predictor_y_loss: 0.135 ep_cycled_y_loss: 0.052 ep_D_Y_loss: 1.115\n",
      "[86:END] Completed eval in 6.361036777496338s\n",
      "Updated G_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated F_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated D_X_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated D_Y_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated P_X_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "Updated P_Y_opt learning rate from 6.666666666666668e-05 to 6.274509803921569e-05\n",
      "[86:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[87:100] Took 119.30s\n",
      "[87:100] loss_idt_x: 0.06950893510133029, G_fool_loss: 0.047754538655281065, predictor_x_loss: 0.11147057209163905, cycled_x_loss: 0.07065343163907528, D_X_loss: 1.180445783138275\n",
      "[87:100] loss_idt_y: 0.0538293874822557, F_fool_loss: 0.04611596133559942, predictor_y_loss: 0.1333653660491109, cycled_y_loss: 0.05457939367741346, D_Y_loss: 1.1145190274715424\n",
      "[87:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[87:200] Took 113.90s\n",
      "[87:200] loss_idt_x: 0.06992107283324003, G_fool_loss: 0.04712399251759052, predictor_x_loss: 0.10675116077065468, cycled_x_loss: 0.06958571091294288, D_X_loss: 1.164179350733757\n",
      "[87:200] loss_idt_y: 0.0525186862051487, F_fool_loss: 0.04368406735360622, predictor_y_loss: 0.12557913694530726, cycled_y_loss: 0.05142235293984413, D_Y_loss: 1.1088466304540634\n",
      "[87:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[87:300] Took 114.00s\n",
      "[87:300] loss_idt_x: 0.0705060661956668, G_fool_loss: 0.0468249961733818, predictor_x_loss: 0.10873685047030449, cycled_x_loss: 0.0670193687453866, D_X_loss: 1.1532290828227998\n",
      "[87:300] loss_idt_y: 0.04717563711106777, F_fool_loss: 0.043517102748155595, predictor_y_loss: 0.13655327077955007, cycled_y_loss: 0.048590272888541224, D_Y_loss: 1.106157357096672\n",
      "[87:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[87:400] Took 113.94s\n",
      "[87:400] loss_idt_x: 0.06605029333382845, G_fool_loss: 0.0475983452424407, predictor_x_loss: 0.09826502550393343, cycled_x_loss: 0.06411394104361534, D_X_loss: 1.1595126432180405\n",
      "[87:400] loss_idt_y: 0.04495909171178937, F_fool_loss: 0.04583730846643448, predictor_y_loss: 0.13798726595938204, cycled_y_loss: 0.04748052835464477, D_Y_loss: 1.1000733590126037\n",
      "[87:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[87:500] Took 113.98s\n",
      "[87:500] loss_idt_x: 0.06770054198801517, G_fool_loss: 0.047087348103523254, predictor_x_loss: 0.10787899695336818, cycled_x_loss: 0.06608428880572319, D_X_loss: 1.1608055186271669\n",
      "[87:500] loss_idt_y: 0.0471826109290123, F_fool_loss: 0.043159803338348866, predictor_y_loss: 0.13654859714210033, cycled_y_loss: 0.04885911125689745, D_Y_loss: 1.112913168668747\n",
      "[87:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[87:END] Completed epoch in 689.4917821884155s\n",
      "[87:599] ep_loss_idt_x: 0.069 ep_G_fool_loss: 0.047 ep_predictor_x_loss: 0.105 ep_cycled_x_loss: 0.067 ep_D_X_loss: 1.160\n",
      "[87:599] ep_loss_idt_y: 0.049 ep_F_fool_loss: 0.044 ep_predictor_y_loss: 0.134 ep_cycled_y_loss: 0.050 ep_D_Y_loss: 1.108\n",
      "[87:END] Completed eval in 6.232600688934326s\n",
      "Updated G_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated F_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated D_X_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated D_Y_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated P_X_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "Updated P_Y_opt learning rate from 6.274509803921569e-05 to 5.88235294117647e-05\n",
      "[87:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[88:100] Took 118.63s\n",
      "[88:100] loss_idt_x: 0.06609763767570258, G_fool_loss: 0.04615595385432243, predictor_x_loss: 0.10785541903227568, cycled_x_loss: 0.06371080443263054, D_X_loss: 1.1674072855710984\n",
      "[88:100] loss_idt_y: 0.054020845629274845, F_fool_loss: 0.04367646843194962, predictor_y_loss: 0.14049484461545944, cycled_y_loss: 0.05488714829087257, D_Y_loss: 1.124242640733719\n",
      "[88:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[88:200] Took 113.72s\n",
      "[88:200] loss_idt_x: 0.06889461170881987, G_fool_loss: 0.046749159842729565, predictor_x_loss: 0.10583606775850057, cycled_x_loss: 0.06632800456136465, D_X_loss: 1.158372849225998\n",
      "[88:200] loss_idt_y: 0.04627061910927296, F_fool_loss: 0.04380760222673416, predictor_y_loss: 0.1352675113081932, cycled_y_loss: 0.04762778528034687, D_Y_loss: 1.1055960243940353\n",
      "[88:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[88:300] Took 113.35s\n",
      "[88:300] loss_idt_x: 0.06808396894484758, G_fool_loss: 0.04563664212822914, predictor_x_loss: 0.09436963833868503, cycled_x_loss: 0.06529126491397619, D_X_loss: 1.1504499220848083\n",
      "[88:300] loss_idt_y: 0.04940990416333079, F_fool_loss: 0.04412147998809814, predictor_y_loss: 0.12710699744522572, cycled_y_loss: 0.049358221180737016, D_Y_loss: 1.114370287656784\n",
      "[88:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[88:400] Took 113.34s\n",
      "[88:400] loss_idt_x: 0.07150329068303109, G_fool_loss: 0.04740109231323004, predictor_x_loss: 0.1081990672275424, cycled_x_loss: 0.06718699522316456, D_X_loss: 1.1522144377231598\n",
      "[88:400] loss_idt_y: 0.04611100675538182, F_fool_loss: 0.043761553764343264, predictor_y_loss: 0.12458131782710552, cycled_y_loss: 0.0476377010717988, D_Y_loss: 1.108021878004074\n",
      "[88:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[88:500] Took 113.98s\n",
      "[88:500] loss_idt_x: 0.06751016106456519, G_fool_loss: 0.04741461876779795, predictor_x_loss: 0.10716683629900217, cycled_x_loss: 0.06376948487013578, D_X_loss: 1.157775890827179\n",
      "[88:500] loss_idt_y: 0.04561939472332597, F_fool_loss: 0.04285892676562071, predictor_y_loss: 0.13625273779034613, cycled_y_loss: 0.04695658750832081, D_Y_loss: 1.1011434799432755\n",
      "[88:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[88:END] Completed epoch in 687.2594287395477s\n",
      "[88:599] ep_loss_idt_x: 0.068 ep_G_fool_loss: 0.047 ep_predictor_x_loss: 0.103 ep_cycled_x_loss: 0.065 ep_D_X_loss: 1.155\n",
      "[88:599] ep_loss_idt_y: 0.048 ep_F_fool_loss: 0.043 ep_predictor_y_loss: 0.132 ep_cycled_y_loss: 0.049 ep_D_Y_loss: 1.109\n",
      "[88:END] Completed eval in 6.179023742675781s\n",
      "Updated G_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated F_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated D_X_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated D_Y_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated P_X_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "Updated P_Y_opt learning rate from 5.88235294117647e-05 to 5.490196078431373e-05\n",
      "[88:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[89:100] Took 116.20s\n",
      "[89:100] loss_idt_x: 0.071215308457613, G_fool_loss: 0.04684748977422714, predictor_x_loss: 0.11008817471563816, cycled_x_loss: 0.06535657208412886, D_X_loss: 1.1708816194534302\n",
      "[89:100] loss_idt_y: 0.047228881251066925, F_fool_loss: 0.04330300703644752, predictor_y_loss: 0.12390787921845912, cycled_y_loss: 0.049543410260230306, D_Y_loss: 1.1181459653377532\n",
      "[89:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[89:200] Took 114.98s\n",
      "[89:200] loss_idt_x: 0.06811825525015593, G_fool_loss: 0.04607906173914671, predictor_x_loss: 0.1033191055431962, cycled_x_loss: 0.06469528798013925, D_X_loss: 1.156523745059967\n",
      "[89:200] loss_idt_y: 0.04386409679427743, F_fool_loss: 0.04464194998145103, predictor_y_loss: 0.12517776120454072, cycled_y_loss: 0.045273352824151514, D_Y_loss: 1.1052966815233232\n",
      "[89:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[89:300] Took 111.68s\n",
      "[89:300] loss_idt_x: 0.0642495172470808, G_fool_loss: 0.046007373332977296, predictor_x_loss: 0.09802110873162746, cycled_x_loss: 0.06192732874304056, D_X_loss: 1.1539790642261505\n",
      "[89:300] loss_idt_y: 0.045183131005614996, F_fool_loss: 0.04350522972643375, predictor_y_loss: 0.1207144046202302, cycled_y_loss: 0.04625372156500816, D_Y_loss: 1.1187772715091706\n",
      "[89:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[89:400] Took 111.66s\n",
      "[89:400] loss_idt_x: 0.06526024103164672, G_fool_loss: 0.04656884741038084, predictor_x_loss: 0.10114829186350108, cycled_x_loss: 0.06179524712264538, D_X_loss: 1.1572975850105285\n",
      "[89:400] loss_idt_y: 0.04859591780230403, F_fool_loss: 0.043932194262742995, predictor_y_loss: 0.12444436434656382, cycled_y_loss: 0.049218597561120986, D_Y_loss: 1.1110250997543334\n",
      "[89:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[89:500] Took 111.66s\n",
      "[89:500] loss_idt_x: 0.07000288061797619, G_fool_loss: 0.04600158810615539, predictor_x_loss: 0.10192185826599598, cycled_x_loss: 0.06403449114412069, D_X_loss: 1.151629946231842\n",
      "[89:500] loss_idt_y: 0.04614332124590874, F_fool_loss: 0.04380254033952952, predictor_y_loss: 0.12703457929193973, cycled_y_loss: 0.04874548392370343, D_Y_loss: 1.1127847093343735\n",
      "[89:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[89:END] Completed epoch in 678.3117821216583s\n",
      "[89:599] ep_loss_idt_x: 0.067 ep_G_fool_loss: 0.046 ep_predictor_x_loss: 0.102 ep_cycled_x_loss: 0.063 ep_D_X_loss: 1.156\n",
      "[89:599] ep_loss_idt_y: 0.046 ep_F_fool_loss: 0.044 ep_predictor_y_loss: 0.125 ep_cycled_y_loss: 0.048 ep_D_Y_loss: 1.111\n",
      "[89:END] Completed eval in 6.180892705917358s\n",
      "Updated G_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated F_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated D_X_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated D_Y_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated P_X_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "Updated P_Y_opt learning rate from 5.490196078431373e-05 to 5.0980392156862745e-05\n",
      "[89:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[90:100] Took 113.21s\n",
      "[90:100] loss_idt_x: 0.06882301483303309, G_fool_loss: 0.04552522543817759, predictor_x_loss: 0.10470484253019094, cycled_x_loss: 0.06292776878923177, D_X_loss: 1.157977590560913\n",
      "[90:100] loss_idt_y: 0.04810418646782637, F_fool_loss: 0.043802559711039066, predictor_y_loss: 0.12724327586591244, cycled_y_loss: 0.05044192312285304, D_Y_loss: 1.1220251536369323\n",
      "[90:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[90:200] Took 108.52s\n",
      "[90:200] loss_idt_x: 0.06517560373991728, G_fool_loss: 0.045381427109241486, predictor_x_loss: 0.11216396037489176, cycled_x_loss: 0.06219129856675863, D_X_loss: 1.1582746529579162\n",
      "[90:200] loss_idt_y: 0.046225894819945094, F_fool_loss: 0.042625225707888605, predictor_y_loss: 0.12055176690220833, cycled_y_loss: 0.04764128359034658, D_Y_loss: 1.110753551721573\n",
      "[90:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[90:300] Took 108.23s\n",
      "[90:300] loss_idt_x: 0.06546263072639703, G_fool_loss: 0.04508590921759605, predictor_x_loss: 0.0975063431635499, cycled_x_loss: 0.06313145156949758, D_X_loss: 1.1556262636184693\n",
      "[90:300] loss_idt_y: 0.047061000876128675, F_fool_loss: 0.042384299747645855, predictor_y_loss: 0.12236966617405415, cycled_y_loss: 0.04924652609974146, D_Y_loss: 1.1053761863708496\n",
      "[90:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[90:400] Took 108.45s\n",
      "[90:400] loss_idt_x: 0.06603580046445132, G_fool_loss: 0.045796587094664575, predictor_x_loss: 0.10165213376283645, cycled_x_loss: 0.06359833672642708, D_X_loss: 1.153804785013199\n",
      "[90:400] loss_idt_y: 0.04578769028186798, F_fool_loss: 0.04446800254285335, predictor_y_loss: 0.12634043335914613, cycled_y_loss: 0.04708390539512038, D_Y_loss: 1.1085149788856505\n",
      "[90:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[90:500] Took 118.42s\n",
      "[90:500] loss_idt_x: 0.06622234083712102, G_fool_loss: 0.045897439643740656, predictor_x_loss: 0.09595636364072561, cycled_x_loss: 0.06195418063551188, D_X_loss: 1.1550770711898803\n",
      "[90:500] loss_idt_y: 0.04624982699751854, F_fool_loss: 0.04255922697484493, predictor_y_loss: 0.12496323198080063, cycled_y_loss: 0.04854254990816116, D_Y_loss: 1.1124759703874587\n",
      "[90:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[90:END] Completed epoch in 690.6661546230316s\n",
      "[90:599] ep_loss_idt_x: 0.066 ep_G_fool_loss: 0.046 ep_predictor_x_loss: 0.102 ep_cycled_x_loss: 0.062 ep_D_X_loss: 1.155\n",
      "[90:599] ep_loss_idt_y: 0.047 ep_F_fool_loss: 0.043 ep_predictor_y_loss: 0.124 ep_cycled_y_loss: 0.048 ep_D_Y_loss: 1.110\n",
      "[90:END] Completed eval in 6.62136435508728s\n",
      "Updated G_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated F_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated D_X_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated D_Y_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated P_X_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "Updated P_Y_opt learning rate from 5.0980392156862745e-05 to 4.7058823529411774e-05\n",
      "[90:END] Saving models and training information permanently\n",
      "[91:100] Took 144.67s\n",
      "[91:100] loss_idt_x: 0.0662002095580101, G_fool_loss: 0.046569255106151106, predictor_x_loss: 0.0992894933372736, cycled_x_loss: 0.06149664599448443, D_X_loss: 1.1627227699756622\n",
      "[91:100] loss_idt_y: 0.047415737733244895, F_fool_loss: 0.043010418750345704, predictor_y_loss: 0.1289595615491271, cycled_y_loss: 0.04919104989618063, D_Y_loss: 1.1113203179836273\n",
      "[91:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[91:200] Took 116.48s\n",
      "[91:200] loss_idt_x: 0.062175060771405694, G_fool_loss: 0.045464872866868976, predictor_x_loss: 0.09990973304957151, cycled_x_loss: 0.06110153082758188, D_X_loss: 1.1539001953601837\n",
      "[91:200] loss_idt_y: 0.04691808117553592, F_fool_loss: 0.042628483399748805, predictor_y_loss: 0.12420680552721024, cycled_y_loss: 0.048534003663808105, D_Y_loss: 1.1145237481594086\n",
      "[91:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[91:300] Took 115.10s\n",
      "[91:300] loss_idt_x: 0.06374554239213466, G_fool_loss: 0.045743106380105016, predictor_x_loss: 0.10699264615774155, cycled_x_loss: 0.06357663232833147, D_X_loss: 1.1553691613674164\n",
      "[91:300] loss_idt_y: 0.046241092067211866, F_fool_loss: 0.04288497339934111, predictor_y_loss: 0.12758293151855468, cycled_y_loss: 0.047498142272233965, D_Y_loss: 1.1109522181749343\n",
      "[91:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[91:400] Took 114.98s\n",
      "[91:400] loss_idt_x: 0.06217082004994154, G_fool_loss: 0.04536745678633451, predictor_x_loss: 0.09751366842538119, cycled_x_loss: 0.059016237668693065, D_X_loss: 1.1497844660282135\n",
      "[91:400] loss_idt_y: 0.04419676994904876, F_fool_loss: 0.04278395179659128, predictor_y_loss: 0.12295673318207263, cycled_y_loss: 0.044914067965000866, D_Y_loss: 1.1093287479877472\n",
      "[91:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[91:500] Took 114.91s\n",
      "[91:500] loss_idt_x: 0.0673249488696456, G_fool_loss: 0.04556380353868008, predictor_x_loss: 0.10157201372087002, cycled_x_loss: 0.0622657323628664, D_X_loss: 1.1505713629722596\n",
      "[91:500] loss_idt_y: 0.04579371714964509, F_fool_loss: 0.04228404931724072, predictor_y_loss: 0.12950881116092205, cycled_y_loss: 0.04600868016481399, D_Y_loss: 1.1065114521980286\n",
      "[91:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[91:END] Completed epoch in 724.2173578739166s\n",
      "[91:599] ep_loss_idt_x: 0.064 ep_G_fool_loss: 0.046 ep_predictor_x_loss: 0.101 ep_cycled_x_loss: 0.061 ep_D_X_loss: 1.153\n",
      "[91:599] ep_loss_idt_y: 0.046 ep_F_fool_loss: 0.043 ep_predictor_y_loss: 0.126 ep_cycled_y_loss: 0.047 ep_D_Y_loss: 1.107\n",
      "[91:END] Completed eval in 6.325173377990723s\n",
      "Updated G_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated F_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated D_X_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated D_Y_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated P_X_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "Updated P_Y_opt learning rate from 4.7058823529411774e-05 to 4.313725490196079e-05\n",
      "[91:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[92:100] Took 119.21s\n",
      "[92:100] loss_idt_x: 0.06189178351312876, G_fool_loss: 0.045762721933424476, predictor_x_loss: 0.09946156747639179, cycled_x_loss: 0.061107771173119545, D_X_loss: 1.1689606487751008\n",
      "[92:100] loss_idt_y: 0.04377315910533071, F_fool_loss: 0.04269606541842222, predictor_y_loss: 0.13143430542200804, cycled_y_loss: 0.0452431895211339, D_Y_loss: 1.124842596054077\n",
      "[92:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[92:200] Took 114.52s\n",
      "[92:200] loss_idt_x: 0.06340659331530332, G_fool_loss: 0.04544426437467337, predictor_x_loss: 0.10206018306314946, cycled_x_loss: 0.05942162226885557, D_X_loss: 1.1552294707298278\n",
      "[92:200] loss_idt_y: 0.04749823054298759, F_fool_loss: 0.04230592541396618, predictor_y_loss: 0.1251590449362993, cycled_y_loss: 0.04792438939213753, D_Y_loss: 1.1083978939056396\n",
      "[92:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[92:300] Took 115.29s\n",
      "[92:300] loss_idt_x: 0.06006607726216316, G_fool_loss: 0.04567051757127047, predictor_x_loss: 0.09653337072581053, cycled_x_loss: 0.0569393328204751, D_X_loss: 1.1587045657634736\n",
      "[92:300] loss_idt_y: 0.047780473232269284, F_fool_loss: 0.04247114710509777, predictor_y_loss: 0.1237004804611206, cycled_y_loss: 0.04784771839156747, D_Y_loss: 1.1083542770147323\n",
      "[92:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[92:400] Took 134.45s\n",
      "[92:400] loss_idt_x: 0.06354427058249712, G_fool_loss: 0.04560439758002758, predictor_x_loss: 0.10015643253922463, cycled_x_loss: 0.060904080606997014, D_X_loss: 1.1626082313060762\n",
      "[92:400] loss_idt_y: 0.04657832968980074, F_fool_loss: 0.04333414010703564, predictor_y_loss: 0.12433306369930505, cycled_y_loss: 0.048417313527315854, D_Y_loss: 1.1081826436519622\n",
      "[92:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[92:500] Took 148.65s\n",
      "[92:500] loss_idt_x: 0.07082828290760518, G_fool_loss: 0.044767689257860184, predictor_x_loss: 0.10100615352392196, cycled_x_loss: 0.06430587943643332, D_X_loss: 1.1538370966911315\n",
      "[92:500] loss_idt_y: 0.045614148918539286, F_fool_loss: 0.04272859871387482, predictor_y_loss: 0.13132743835449218, cycled_y_loss: 0.04733070503920317, D_Y_loss: 1.1156555432081223\n",
      "[92:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[92:END] Completed epoch in 770.9647407531738s\n",
      "[92:599] ep_loss_idt_x: 0.064 ep_G_fool_loss: 0.045 ep_predictor_x_loss: 0.100 ep_cycled_x_loss: 0.060 ep_D_X_loss: 1.156\n",
      "[92:599] ep_loss_idt_y: 0.046 ep_F_fool_loss: 0.043 ep_predictor_y_loss: 0.126 ep_cycled_y_loss: 0.047 ep_D_Y_loss: 1.109\n",
      "[92:END] Completed eval in 6.480855226516724s\n",
      "Updated G_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated F_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated D_X_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated D_Y_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated P_X_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "Updated P_Y_opt learning rate from 4.313725490196079e-05 to 3.92156862745098e-05\n",
      "[92:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[93:100] Took 119.81s\n",
      "[93:100] loss_idt_x: 0.06493066374212503, G_fool_loss: 0.04534181591123342, predictor_x_loss: 0.09772931829094887, cycled_x_loss: 0.0601060576364398, D_X_loss: 1.162523970603943\n",
      "[93:100] loss_idt_y: 0.04537304932251573, F_fool_loss: 0.04289845015853643, predictor_y_loss: 0.12796610459685326, cycled_y_loss: 0.045940007530152795, D_Y_loss: 1.1232327342033386\n",
      "[93:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[93:200] Took 114.69s\n",
      "[93:200] loss_idt_x: 0.056822377108037475, G_fool_loss: 0.045708868354558944, predictor_x_loss: 0.09729649305343628, cycled_x_loss: 0.05522822443395853, D_X_loss: 1.1604785776138307\n",
      "[93:200] loss_idt_y: 0.047614903505891565, F_fool_loss: 0.04215378925204277, predictor_y_loss: 0.1256152154132724, cycled_y_loss: 0.04821438506245613, D_Y_loss: 1.1036309897899628\n",
      "[93:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[93:300] Took 114.92s\n",
      "[93:300] loss_idt_x: 0.06163511339575052, G_fool_loss: 0.04459070414304733, predictor_x_loss: 0.09843993932008743, cycled_x_loss: 0.05940746877342463, D_X_loss: 1.1542872834205626\n",
      "[93:300] loss_idt_y: 0.043593860678374764, F_fool_loss: 0.04247613921761513, predictor_y_loss: 0.1311001303419471, cycled_y_loss: 0.04576373776420951, D_Y_loss: 1.1191060793399812\n",
      "[93:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[93:400] Took 114.83s\n",
      "[93:400] loss_idt_x: 0.06296213906258345, G_fool_loss: 0.04522528894245625, predictor_x_loss: 0.10098046828061343, cycled_x_loss: 0.05821134634315968, D_X_loss: 1.1559752988815308\n",
      "[93:400] loss_idt_y: 0.04361603694036603, F_fool_loss: 0.04185040667653084, predictor_y_loss: 0.11511193946003914, cycled_y_loss: 0.04543497536331415, D_Y_loss: 1.1095745086669921\n",
      "[93:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[93:500] Took 114.80s\n",
      "[93:500] loss_idt_x: 0.06269418496638536, G_fool_loss: 0.04516542624682188, predictor_x_loss: 0.09819305170327425, cycled_x_loss: 0.06065092824399471, D_X_loss: 1.1525701487064361\n",
      "[93:500] loss_idt_y: 0.04489201311022043, F_fool_loss: 0.042684285081923005, predictor_y_loss: 0.11520756967365742, cycled_y_loss: 0.04635859213769436, D_Y_loss: 1.115180459022522\n",
      "[93:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[93:END] Completed epoch in 694.3689572811127s\n",
      "[93:599] ep_loss_idt_x: 0.063 ep_G_fool_loss: 0.045 ep_predictor_x_loss: 0.099 ep_cycled_x_loss: 0.059 ep_D_X_loss: 1.154\n",
      "[93:599] ep_loss_idt_y: 0.045 ep_F_fool_loss: 0.042 ep_predictor_y_loss: 0.123 ep_cycled_y_loss: 0.046 ep_D_Y_loss: 1.113\n",
      "[93:END] Completed eval in 6.376011610031128s\n",
      "Updated G_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated F_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated D_X_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated D_Y_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated P_X_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "Updated P_Y_opt learning rate from 3.92156862745098e-05 to 3.5294117647058834e-05\n",
      "[93:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[94:100] Took 117.80s\n",
      "[94:100] loss_idt_x: 0.06150770209729672, G_fool_loss: 0.044913311190903187, predictor_x_loss: 0.09936344027519226, cycled_x_loss: 0.05967148270457983, D_X_loss: 1.158660957813263\n",
      "[94:100] loss_idt_y: 0.043635104410350324, F_fool_loss: 0.042391392439603805, predictor_y_loss: 0.12235594365745783, cycled_y_loss: 0.044452100060880184, D_Y_loss: 1.1258943259716034\n",
      "[94:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[94:200] Took 112.66s\n",
      "[94:200] loss_idt_x: 0.06431502547115088, G_fool_loss: 0.04499731730669737, predictor_x_loss: 0.09255317382514477, cycled_x_loss: 0.058242485634982584, D_X_loss: 1.1537291193008423\n",
      "[94:200] loss_idt_y: 0.04573183849453926, F_fool_loss: 0.041802261620759965, predictor_y_loss: 0.11776629716157913, cycled_y_loss: 0.04567646356299519, D_Y_loss: 1.114269362092018\n",
      "[94:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[94:300] Took 112.88s\n",
      "[94:300] loss_idt_x: 0.06479553803801537, G_fool_loss: 0.04489286541938782, predictor_x_loss: 0.10619044218212366, cycled_x_loss: 0.06022912677377462, D_X_loss: 1.1533672964572907\n",
      "[94:300] loss_idt_y: 0.044943204689770935, F_fool_loss: 0.04237031769007445, predictor_y_loss: 0.11925351031124592, cycled_y_loss: 0.045309971421957015, D_Y_loss: 1.1060890567302704\n",
      "[94:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[94:400] Took 112.62s\n",
      "[94:400] loss_idt_x: 0.06388302121311426, G_fool_loss: 0.044537470191717145, predictor_x_loss: 0.09671711821109057, cycled_x_loss: 0.059865111261606214, D_X_loss: 1.1542426645755768\n",
      "[94:400] loss_idt_y: 0.04685859706252813, F_fool_loss: 0.041983288042247296, predictor_y_loss: 0.12148722153156996, cycled_y_loss: 0.04758164202794433, D_Y_loss: 1.1127261054515838\n",
      "[94:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[94:500] Took 112.92s\n",
      "[94:500] loss_idt_x: 0.05695561736822128, G_fool_loss: 0.04463566429913044, predictor_x_loss: 0.09933549292385578, cycled_x_loss: 0.05505090963095426, D_X_loss: 1.161810939311981\n",
      "[94:500] loss_idt_y: 0.04319927655160427, F_fool_loss: 0.042435913793742654, predictor_y_loss: 0.12323715463280678, cycled_y_loss: 0.04442038746550679, D_Y_loss: 1.121817808151245\n",
      "[94:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[94:END] Completed epoch in 685.039222240448s\n",
      "[94:599] ep_loss_idt_x: 0.062 ep_G_fool_loss: 0.045 ep_predictor_x_loss: 0.098 ep_cycled_x_loss: 0.058 ep_D_X_loss: 1.154\n",
      "[94:599] ep_loss_idt_y: 0.045 ep_F_fool_loss: 0.042 ep_predictor_y_loss: 0.121 ep_cycled_y_loss: 0.045 ep_D_Y_loss: 1.114\n",
      "[94:END] Completed eval in 6.323877334594727s\n",
      "Updated G_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated F_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated D_X_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated D_Y_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated P_X_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "Updated P_Y_opt learning rate from 3.5294117647058834e-05 to 3.137254901960784e-05\n",
      "[94:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[95:100] Took 116.93s\n",
      "[95:100] loss_idt_x: 0.059614566918462515, G_fool_loss: 0.04504461593925953, predictor_x_loss: 0.10056856449693441, cycled_x_loss: 0.05624713905155659, D_X_loss: 1.1584469091892242\n",
      "[95:100] loss_idt_y: 0.042789432294666765, F_fool_loss: 0.04267272349447012, predictor_y_loss: 0.13131280966103076, cycled_y_loss: 0.0439253362827003, D_Y_loss: 1.129007387161255\n",
      "[95:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[95:200] Took 111.86s\n",
      "[95:200] loss_idt_x: 0.05968802219256759, G_fool_loss: 0.04486566003412008, predictor_x_loss: 0.09584345132112503, cycled_x_loss: 0.05779255606234074, D_X_loss: 1.1500155943632127\n",
      "[95:200] loss_idt_y: 0.04305251866579056, F_fool_loss: 0.043230551928281784, predictor_y_loss: 0.12155917607247829, cycled_y_loss: 0.043935010209679604, D_Y_loss: 1.111103971004486\n",
      "[95:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[95:300] Took 111.95s\n",
      "[95:300] loss_idt_x: 0.059386162981390954, G_fool_loss: 0.044580023624002936, predictor_x_loss: 0.09285255216062069, cycled_x_loss: 0.05632296528667211, D_X_loss: 1.1495868599414825\n",
      "[95:300] loss_idt_y: 0.043264913614839313, F_fool_loss: 0.042098595649003985, predictor_y_loss: 0.11551903393119574, cycled_y_loss: 0.04336276182904839, D_Y_loss: 1.11421162545681\n",
      "[95:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[95:400] Took 111.86s\n",
      "[95:400] loss_idt_x: 0.061800221465528014, G_fool_loss: 0.0442811019718647, predictor_x_loss: 0.09762434527277947, cycled_x_loss: 0.05688057318329811, D_X_loss: 1.1582315838336945\n",
      "[95:400] loss_idt_y: 0.04110147861763835, F_fool_loss: 0.04212864905595779, predictor_y_loss: 0.11491484671831131, cycled_y_loss: 0.04214597560465336, D_Y_loss: 1.111128250360489\n",
      "[95:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[95:500] Took 111.89s\n",
      "[95:500] loss_idt_x: 0.061108887158334256, G_fool_loss: 0.044496208131313324, predictor_x_loss: 0.09918223235756159, cycled_x_loss: 0.05672123949974775, D_X_loss: 1.1577899801731109\n",
      "[95:500] loss_idt_y: 0.04611845318228006, F_fool_loss: 0.04169399503618479, predictor_y_loss: 0.12875432591885327, cycled_y_loss: 0.046525275241583584, D_Y_loss: 1.1165517634153366\n",
      "[95:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[95:END] Completed epoch in 676.928060054779s\n",
      "[95:599] ep_loss_idt_x: 0.061 ep_G_fool_loss: 0.045 ep_predictor_x_loss: 0.097 ep_cycled_x_loss: 0.057 ep_D_X_loss: 1.154\n",
      "[95:599] ep_loss_idt_y: 0.043 ep_F_fool_loss: 0.042 ep_predictor_y_loss: 0.122 ep_cycled_y_loss: 0.044 ep_D_Y_loss: 1.114\n",
      "[95:END] Completed eval in 6.409220457077026s\n",
      "Updated G_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated F_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated D_X_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated D_Y_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated P_X_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "Updated P_Y_opt learning rate from 3.137254901960784e-05 to 2.7450980392156855e-05\n",
      "[95:END] Saving models and training information permanently\n",
      "[96:100] Took 112.69s\n",
      "[96:100] loss_idt_x: 0.06762734550982713, G_fool_loss: 0.044516500197350976, predictor_x_loss: 0.09648044850677252, cycled_x_loss: 0.06039679866284132, D_X_loss: 1.1613263273239136\n",
      "[96:100] loss_idt_y: 0.04469294618815184, F_fool_loss: 0.042366793155670164, predictor_y_loss: 0.12223203346133232, cycled_y_loss: 0.04515121586620808, D_Y_loss: 1.1298485505580902\n",
      "[96:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[96:200] Took 107.72s\n",
      "[96:200] loss_idt_x: 0.05849728491157293, G_fool_loss: 0.04387817069888115, predictor_x_loss: 0.09065842896699905, cycled_x_loss: 0.05552144072949886, D_X_loss: 1.1548216259479522\n",
      "[96:200] loss_idt_y: 0.04261454738676548, F_fool_loss: 0.0417171149328351, predictor_y_loss: 0.119092419706285, cycled_y_loss: 0.04300693266093731, D_Y_loss: 1.114877871274948\n",
      "[96:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[96:300] Took 112.90s\n",
      "[96:300] loss_idt_x: 0.062035969309508804, G_fool_loss: 0.04413810707628727, predictor_x_loss: 0.10339707899838686, cycled_x_loss: 0.057400135099887846, D_X_loss: 1.1488685190677643\n",
      "[96:300] loss_idt_y: 0.04503557220101356, F_fool_loss: 0.04178038455545902, predictor_y_loss: 0.121678536683321, cycled_y_loss: 0.04558686321601271, D_Y_loss: 1.120147944688797\n",
      "[96:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[96:400] Took 109.79s\n",
      "[96:400] loss_idt_x: 0.056924295388162134, G_fool_loss: 0.04417825751006603, predictor_x_loss: 0.09459343902766705, cycled_x_loss: 0.05459382083266973, D_X_loss: 1.155713061094284\n",
      "[96:400] loss_idt_y: 0.0419181645475328, F_fool_loss: 0.04149170722812414, predictor_y_loss: 0.12112385138869286, cycled_y_loss: 0.04376830270513892, D_Y_loss: 1.1200078403949738\n",
      "[96:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[96:500] Took 109.60s\n",
      "[96:500] loss_idt_x: 0.060014158003032204, G_fool_loss: 0.0437682069465518, predictor_x_loss: 0.1001513459160924, cycled_x_loss: 0.0566838052123785, D_X_loss: 1.1510214173793794\n",
      "[96:500] loss_idt_y: 0.04305617816746235, F_fool_loss: 0.041598415747284886, predictor_y_loss: 0.11884907454252243, cycled_y_loss: 0.04464889345690608, D_Y_loss: 1.121356873512268\n",
      "[96:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[96:END] Completed epoch in 662.8193891048431s\n",
      "[96:599] ep_loss_idt_x: 0.060 ep_G_fool_loss: 0.044 ep_predictor_x_loss: 0.097 ep_cycled_x_loss: 0.056 ep_D_X_loss: 1.152\n",
      "[96:599] ep_loss_idt_y: 0.043 ep_F_fool_loss: 0.042 ep_predictor_y_loss: 0.122 ep_cycled_y_loss: 0.044 ep_D_Y_loss: 1.118\n",
      "[96:END] Completed eval in 6.385799169540405s\n",
      "Updated G_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated F_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated D_X_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated D_Y_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated P_X_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "Updated P_Y_opt learning rate from 2.7450980392156855e-05 to 2.3529411764705887e-05\n",
      "[96:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[97:100] Took 113.71s\n",
      "[97:100] loss_idt_x: 0.060471593141555785, G_fool_loss: 0.04455677226185799, predictor_x_loss: 0.0999449285119772, cycled_x_loss: 0.05680512333288789, D_X_loss: 1.161274449825287\n",
      "[97:100] loss_idt_y: 0.04485288921743631, F_fool_loss: 0.04190540503710508, predictor_y_loss: 0.12336669526994229, cycled_y_loss: 0.04488492013886571, D_Y_loss: 1.128549154996872\n",
      "[97:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[97:200] Took 108.85s\n",
      "[97:200] loss_idt_x: 0.059421835727989675, G_fool_loss: 0.0441249955072999, predictor_x_loss: 0.09226621218025684, cycled_x_loss: 0.05582145396620035, D_X_loss: 1.1514493548870086\n",
      "[97:200] loss_idt_y: 0.04188307961449027, F_fool_loss: 0.04168477859348059, predictor_y_loss: 0.11843357224017381, cycled_y_loss: 0.04301243042573333, D_Y_loss: 1.1174321293830871\n",
      "[97:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[97:300] Took 108.57s\n",
      "[97:300] loss_idt_x: 0.05858593188226223, G_fool_loss: 0.04367824919521809, predictor_x_loss: 0.09707596383988858, cycled_x_loss: 0.05471193801611662, D_X_loss: 1.1505486965179443\n",
      "[97:300] loss_idt_y: 0.04245912604033947, F_fool_loss: 0.04159268546849489, predictor_y_loss: 0.11886670529842376, cycled_y_loss: 0.043312121480703354, D_Y_loss: 1.121276127099991\n",
      "[97:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[97:400] Took 108.80s\n",
      "[97:400] loss_idt_x: 0.05869774166494608, G_fool_loss: 0.04398650988936424, predictor_x_loss: 0.0959712690487504, cycled_x_loss: 0.05412826385349035, D_X_loss: 1.1465697646141053\n",
      "[97:400] loss_idt_y: 0.04373124394565821, F_fool_loss: 0.04209314785897732, predictor_y_loss: 0.12429655194282532, cycled_y_loss: 0.0438193104416132, D_Y_loss: 1.1201049721240997\n",
      "[97:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[97:500] Took 110.37s\n",
      "[97:500] loss_idt_x: 0.059220578260719775, G_fool_loss: 0.04392210237681866, predictor_x_loss: 0.09407931990921498, cycled_x_loss: 0.05527182910591364, D_X_loss: 1.1497838306427002\n",
      "[97:500] loss_idt_y: 0.044147528409957885, F_fool_loss: 0.04159332308918238, predictor_y_loss: 0.11624335587024688, cycled_y_loss: 0.044263470135629174, D_Y_loss: 1.1138059663772584\n",
      "[97:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[97:END] Completed epoch in 659.7753868103027s\n",
      "[97:599] ep_loss_idt_x: 0.059 ep_G_fool_loss: 0.044 ep_predictor_x_loss: 0.096 ep_cycled_x_loss: 0.055 ep_D_X_loss: 1.151\n",
      "[97:599] ep_loss_idt_y: 0.044 ep_F_fool_loss: 0.042 ep_predictor_y_loss: 0.120 ep_cycled_y_loss: 0.044 ep_D_Y_loss: 1.118\n",
      "[97:END] Completed eval in 6.416353225708008s\n",
      "Updated G_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated F_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated D_X_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated D_Y_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated P_X_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "Updated P_Y_opt learning rate from 2.3529411764705887e-05 to 1.96078431372549e-05\n",
      "[97:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[98:100] Took 115.83s\n",
      "[98:100] loss_idt_x: 0.05588512852787972, G_fool_loss: 0.044453667104244234, predictor_x_loss: 0.09387888994067907, cycled_x_loss: 0.05430011365562677, D_X_loss: 1.1663521230220795\n",
      "[98:100] loss_idt_y: 0.04251627204939723, F_fool_loss: 0.0418251296132803, predictor_y_loss: 0.11850621152669191, cycled_y_loss: 0.04290368488058448, D_Y_loss: 1.1236553061008454\n",
      "[98:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[98:200] Took 111.18s\n",
      "[98:200] loss_idt_x: 0.05785429015755653, G_fool_loss: 0.04376134667545557, predictor_x_loss: 0.09714478351175786, cycled_x_loss: 0.05301368637010455, D_X_loss: 1.1588967776298522\n",
      "[98:200] loss_idt_y: 0.0422238327562809, F_fool_loss: 0.04151771869510412, predictor_y_loss: 0.11796469796448945, cycled_y_loss: 0.042738525476306674, D_Y_loss: 1.1163441562652587\n",
      "[98:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[98:300] Took 156.28s\n",
      "[98:300] loss_idt_x: 0.05675831582397223, G_fool_loss: 0.04401865914463997, predictor_x_loss: 0.09908583737909794, cycled_x_loss: 0.054409882128238676, D_X_loss: 1.1548793888092042\n",
      "[98:300] loss_idt_y: 0.04056783365085721, F_fool_loss: 0.041427733674645424, predictor_y_loss: 0.11362682431936263, cycled_y_loss: 0.04102190328761935, D_Y_loss: 1.1182516360282897\n",
      "[98:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[98:400] Took 167.26s\n",
      "[98:400] loss_idt_x: 0.06120160229504108, G_fool_loss: 0.04386542521417141, predictor_x_loss: 0.0979392621666193, cycled_x_loss: 0.05613771408796311, D_X_loss: 1.1539074432849885\n",
      "[98:400] loss_idt_y: 0.04434329153969884, F_fool_loss: 0.041569995395839214, predictor_y_loss: 0.1155059326812625, cycled_y_loss: 0.044060232695192096, D_Y_loss: 1.1159891110658646\n",
      "[98:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[98:500] Took 128.52s\n",
      "[98:500] loss_idt_x: 0.05857541661709547, G_fool_loss: 0.04401689611375332, predictor_x_loss: 0.09383787151426076, cycled_x_loss: 0.05350729040801525, D_X_loss: 1.15726926445961\n",
      "[98:500] loss_idt_y: 0.04136524453759193, F_fool_loss: 0.041460099667310714, predictor_y_loss: 0.11840200405567884, cycled_y_loss: 0.04229885900393129, D_Y_loss: 1.1205166816711425\n",
      "[98:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[98:END] Completed epoch in 816.9337227344513s\n",
      "[98:599] ep_loss_idt_x: 0.059 ep_G_fool_loss: 0.044 ep_predictor_x_loss: 0.096 ep_cycled_x_loss: 0.054 ep_D_X_loss: 1.155\n",
      "[98:599] ep_loss_idt_y: 0.042 ep_F_fool_loss: 0.042 ep_predictor_y_loss: 0.116 ep_cycled_y_loss: 0.043 ep_D_Y_loss: 1.117\n",
      "[98:END] Completed eval in 6.71268105506897s\n",
      "Updated G_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated F_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated D_X_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated D_Y_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated P_X_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "Updated P_Y_opt learning rate from 1.96078431372549e-05 to 1.5686274509803935e-05\n",
      "[98:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[99:100] Took 127.61s\n",
      "[99:100] loss_idt_x: 0.05455483250319958, G_fool_loss: 0.044561289586126804, predictor_x_loss: 0.09320706710219383, cycled_x_loss: 0.052644738480448726, D_X_loss: 1.1657341289520264\n",
      "[99:100] loss_idt_y: 0.040484495218843224, F_fool_loss: 0.04195117235183716, predictor_y_loss: 0.1114834762364626, cycled_y_loss: 0.041014696583151815, D_Y_loss: 1.1242754673957824\n",
      "[99:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[99:200] Took 116.79s\n",
      "[99:200] loss_idt_x: 0.0549654371663928, G_fool_loss: 0.04342171661555767, predictor_x_loss: 0.096502953954041, cycled_x_loss: 0.052433599829673765, D_X_loss: 1.1545863497257232\n",
      "[99:200] loss_idt_y: 0.04174708174541593, F_fool_loss: 0.04157402906566858, predictor_y_loss: 0.11758287753909827, cycled_y_loss: 0.041996219903230665, D_Y_loss: 1.1260580968856813\n",
      "[99:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[99:300] Took 116.04s\n",
      "[99:300] loss_idt_x: 0.06345648799091577, G_fool_loss: 0.043898436799645425, predictor_x_loss: 0.0938884124159813, cycled_x_loss: 0.05506851952522993, D_X_loss: 1.1551058828830718\n",
      "[99:300] loss_idt_y: 0.04175786606967449, F_fool_loss: 0.04144716553390026, predictor_y_loss: 0.11235474854707718, cycled_y_loss: 0.04230404160916805, D_Y_loss: 1.1197367012500763\n",
      "[99:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[99:400] Took 116.00s\n",
      "[99:400] loss_idt_x: 0.05908644299954176, G_fool_loss: 0.04371512081474066, predictor_x_loss: 0.09268270265311003, cycled_x_loss: 0.055153234545141455, D_X_loss: 1.1559732949733734\n",
      "[99:400] loss_idt_y: 0.04143438896164298, F_fool_loss: 0.041346979700028895, predictor_y_loss: 0.10892074421048165, cycled_y_loss: 0.042138278111815454, D_Y_loss: 1.1141375613212585\n",
      "[99:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[99:500] Took 116.00s\n",
      "[99:500] loss_idt_x: 0.057721874304115774, G_fool_loss: 0.043981141448020934, predictor_x_loss: 0.09312991455197334, cycled_x_loss: 0.05236824968829751, D_X_loss: 1.1482156455516814\n",
      "[99:500] loss_idt_y: 0.043487588763237, F_fool_loss: 0.041393466219305994, predictor_y_loss: 0.1199588006734848, cycled_y_loss: 0.04333978898823261, D_Y_loss: 1.118102295398712\n",
      "[99:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[99:END] Completed epoch in 709.0649151802063s\n",
      "[99:599] ep_loss_idt_x: 0.058 ep_G_fool_loss: 0.044 ep_predictor_x_loss: 0.095 ep_cycled_x_loss: 0.054 ep_D_X_loss: 1.154\n",
      "[99:599] ep_loss_idt_y: 0.041 ep_F_fool_loss: 0.041 ep_predictor_y_loss: 0.114 ep_cycled_y_loss: 0.042 ep_D_Y_loss: 1.120\n",
      "[99:END] Completed eval in 6.702544450759888s\n",
      "Updated G_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated F_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated D_X_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated D_Y_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated P_X_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "Updated P_Y_opt learning rate from 1.5686274509803935e-05 to 1.1764705882352944e-05\n",
      "[99:END] Saving models and training information temporarily to latest and saving generators permanently\n",
      "[100:100] Took 117.20s\n",
      "[100:100] loss_idt_x: 0.06102607760578394, G_fool_loss: 0.04430164508521557, predictor_x_loss: 0.09629467416554689, cycled_x_loss: 0.05588091228157282, D_X_loss: 1.1565149450302123\n",
      "[100:100] loss_idt_y: 0.0397617557644844, F_fool_loss: 0.041880705207586286, predictor_y_loss: 0.11444872476160527, cycled_y_loss: 0.0401786333322525, D_Y_loss: 1.1271008002758025\n",
      "[100:100] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[100:200] Took 112.50s\n",
      "[100:200] loss_idt_x: 0.055208458825945855, G_fool_loss: 0.04397547964006662, predictor_x_loss: 0.09486157868057489, cycled_x_loss: 0.051726224888116124, D_X_loss: 1.1544365978240967\n",
      "[100:200] loss_idt_y: 0.04094930035993457, F_fool_loss: 0.0413903146982193, predictor_y_loss: 0.1106987415254116, cycled_y_loss: 0.041375321466475726, D_Y_loss: 1.1224853003025055\n",
      "[100:200] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[100:300] Took 112.27s\n",
      "[100:300] loss_idt_x: 0.06066363297402859, G_fool_loss: 0.04298057172447443, predictor_x_loss: 0.09285396125167608, cycled_x_loss: 0.05552862893790007, D_X_loss: 1.1522840881347656\n",
      "[100:300] loss_idt_y: 0.04049567403271794, F_fool_loss: 0.041383908912539485, predictor_y_loss: 0.11735608857125043, cycled_y_loss: 0.041082465201616285, D_Y_loss: 1.119502135515213\n",
      "[100:300] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[100:400] Took 112.38s\n",
      "[100:400] loss_idt_x: 0.0547726234793663, G_fool_loss: 0.04329878617078066, predictor_x_loss: 0.09581223983317613, cycled_x_loss: 0.05186970051378012, D_X_loss: 1.1548943769931794\n",
      "[100:400] loss_idt_y: 0.040395458322018386, F_fool_loss: 0.04116863034665585, predictor_y_loss: 0.1137007811665535, cycled_y_loss: 0.040744269955903294, D_Y_loss: 1.1192589974403382\n",
      "[100:400] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[100:500] Took 113.00s\n",
      "[100:500] loss_idt_x: 0.0552894913032651, G_fool_loss: 0.04320675864815712, predictor_x_loss: 0.0920334953069687, cycled_x_loss: 0.0526065094769001, D_X_loss: 1.149020298719406\n",
      "[100:500] loss_idt_y: 0.03997764965519309, F_fool_loss: 0.04160000830888748, predictor_y_loss: 0.11510404244065285, cycled_y_loss: 0.04047352481633425, D_Y_loss: 1.117641394138336\n",
      "[100:500] fake_X_buffer: 20, fake_Y_buffer: 20\n",
      "[100:END] Completed epoch in 694.1396555900574s\n",
      "[100:599] ep_loss_idt_x: 0.057 ep_G_fool_loss: 0.043 ep_predictor_x_loss: 0.095 ep_cycled_x_loss: 0.053 ep_D_X_loss: 1.150\n",
      "[100:599] ep_loss_idt_y: 0.041 ep_F_fool_loss: 0.041 ep_predictor_y_loss: 0.115 ep_cycled_y_loss: 0.041 ep_D_Y_loss: 1.121\n",
      "[100:END] Completed eval in 6.687170505523682s\n",
      "Updated G_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated F_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated D_X_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated D_Y_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated P_X_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "Updated P_Y_opt learning rate from 1.1764705882352944e-05 to 7.843137254901956e-06\n",
      "[100:END] Saving models and training information permanently\n"
     ]
    }
   ],
   "source": [
    "if cyclegan.start_epoch != 0:\n",
    "    print(f\"Resuming training from epoch {cyclegan.start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "if vis is not None:\n",
    "    loss_plot = MultiLinePlot(vis, \"Losses\", \"Epoch\", \"Loss\")\n",
    "\n",
    "for epoch in range(cyclegan.start_epoch + 1, epochs + 1):\n",
    "    cyclegan.G.train()\n",
    "    cyclegan.F.train()\n",
    "    \n",
    "    cyclegan.D_X.train()\n",
    "    cyclegan.D_Y.train()\n",
    "    \n",
    "    cyclegan.P_X.train()\n",
    "    cyclegan.P_Y.train()\n",
    "\n",
    "    batch_start_time = time.time()\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    cum_loss_idt_x = 0\n",
    "    cum_loss_idt_y = 0\n",
    "    cum_G_fool_loss = 0\n",
    "    cum_F_fool_loss = 0\n",
    "    cum_predictor_x_loss = 0\n",
    "    cum_predictor_y_loss = 0\n",
    "    cum_cycled_x_loss = 0\n",
    "    cum_cycled_y_loss = 0\n",
    "    cum_D_X_loss = 0\n",
    "    cum_D_Y_loss = 0\n",
    "    \n",
    "    ep_loss_idt_x = 0\n",
    "    ep_loss_idt_y = 0\n",
    "    ep_G_fool_loss = 0\n",
    "    ep_F_fool_loss = 0\n",
    "    ep_predictor_x_loss = 0\n",
    "    ep_predictor_y_loss = 0\n",
    "    ep_cycled_x_loss = 0\n",
    "    ep_cycled_y_loss = 0\n",
    "    ep_D_X_loss = 0\n",
    "    ep_D_Y_loss = 0\n",
    "    \n",
    "    for batch_no, ((x_0, x_1, x_2), (y_0, y_1, y_2)) in enumerate(dataloader):\n",
    "        # Load the sequence of frames to the GPU\n",
    "        x_0 = x_0.to(device)\n",
    "        x_1 = x_1.to(device)\n",
    "        x_2 = x_2.to(device)\n",
    "        \n",
    "        y_0 = y_0.to(device)\n",
    "        y_1 = y_1.to(device)\n",
    "        y_2 = y_2.to(device)\n",
    "        \n",
    "        # Firstly, generate fake images in domain Y using the x_t images\n",
    "        fake_y_0 = cyclegan.G(x_0)\n",
    "        fake_y_1 = cyclegan.G(x_1)\n",
    "        \n",
    "        # For the final frame we use the predictor model, we are doing this in domain Y space so use P_Y not P_X\n",
    "        fake_y_2 = cyclegan.P_Y(torch.cat((fake_y_0, fake_y_1), 1))\n",
    "        \n",
    "        # Then generate the fake images in domain X using the y_t images\n",
    "        fake_x_0 = cyclegan.F(y_0)\n",
    "        fake_x_1 = cyclegan.F(y_1)\n",
    "        # For the final frame we use the predictor model, we are doing this in domain X space so use P_X not P_Y\n",
    "        fake_x_2 = cyclegan.P_X(torch.cat((fake_x_0, fake_x_1), 1))\n",
    "        \n",
    "        ### GENERATOR TRAINING\n",
    "        \n",
    "        # Freeze discriminator weights\n",
    "        for param in cyclegan.D_X.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in cyclegan.D_Y.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Zero the gradients for the generators and predictors\n",
    "        cyclegan.G_opt.zero_grad()\n",
    "        cyclegan.F_opt.zero_grad()\n",
    "        cyclegan.P_X_opt.zero_grad()\n",
    "        cyclegan.P_Y_opt.zero_grad()\n",
    "        \n",
    "        # Calculate the identity loss, this tries to enforce that G(y) = I(y) = y i.e. the identity\n",
    "        idt_x_0 = cyclegan.F(x_0)\n",
    "        idt_x_1 = cyclegan.F(x_1)\n",
    "        loss_idt_x = cyclegan.identity_loss(idt_x_0, x_0) + cyclegan.identity_loss(idt_x_1, x_1)\n",
    "        \n",
    "        idt_y_0 = cyclegan.G(y_0)\n",
    "        idt_y_1 = cyclegan.G(y_1)\n",
    "        loss_idt_y = cyclegan.identity_loss(idt_y_0, y_0) + cyclegan.identity_loss(idt_y_1, y_1)\n",
    "        \n",
    "        # Now we try and fool the discriminators\n",
    "        # D_X tries to tell if an image is from X (1) or from F(Y) (0) so it takes input fake_x_t\n",
    "        # D_X is supposed to be 1 if the image is from X but here we are trying to get it to be 1 if it is from G(X) -> Y which is incorrect\n",
    "        G_fool_0 = cyclegan.D_Y(fake_y_0) \n",
    "        # We want to tell if fake_y_0 has fooled D_X, so we measure how far from the output 1 it is \n",
    "        G_fool_loss_0 = cyclegan.gan_loss(G_fool_0, generate_noisy_labels(G_fool_0.shape, True, device))\n",
    "        \n",
    "        G_fool_1 = cyclegan.D_Y(fake_y_1)\n",
    "        G_fool_loss_1 = cyclegan.gan_loss(G_fool_1, generate_noisy_labels(G_fool_1.shape, True, device))\n",
    "        \n",
    "        G_fool_2 = cyclegan.D_Y(fake_y_2)\n",
    "        G_fool_loss_2 = cyclegan.gan_loss(G_fool_2, generate_noisy_labels(G_fool_2.shape, True, device))\n",
    "        \n",
    "        G_fool_loss = G_fool_loss_0 + G_fool_loss_1 + G_fool_loss_2\n",
    "        \n",
    "        # D_Y tries to tell if an image is from Y (1) or from G(X) (0) so it takes input fake_y_t\n",
    "        F_fool_0 = cyclegan.D_X(fake_x_0)\n",
    "        # We want to tell if fake_x_0 has fooled D_Y, so we measure how far from the output 1 it is \n",
    "        F_fool_loss_0 = cyclegan.gan_loss(F_fool_0, generate_noisy_labels(F_fool_0.shape, True, device))\n",
    "        \n",
    "        F_fool_1 = cyclegan.D_X(fake_x_1)\n",
    "        F_fool_loss_1 = cyclegan.gan_loss(F_fool_1, generate_noisy_labels(F_fool_1.shape, True, device))\n",
    "        \n",
    "        F_fool_2 = cyclegan.D_X(fake_x_2)\n",
    "        F_fool_loss_2 = cyclegan.gan_loss(F_fool_2, generate_noisy_labels(F_fool_2.shape, True, device))\n",
    "        \n",
    "        F_fool_loss = F_fool_loss_0 + F_fool_loss_1 + F_fool_loss_2\n",
    "        \n",
    "        # Now we train the predictors on the real images using the recurrent loss\n",
    "        # x_2 first\n",
    "        predicted_x_2 = cyclegan.P_X(torch.cat((x_0, x_1), 1))\n",
    "        predicted_x_loss = cyclegan.recurrent_loss(predicted_x_2, x_2)\n",
    "        \n",
    "        # So recycled_x_2 = F(P_Y(G(x_0), G(x_1)))\n",
    "        recycled_x_2 = cyclegan.F(fake_y_2)\n",
    "        recycled_x_loss = cyclegan.recycle_loss(recycled_x_2, x_2)\n",
    "        \n",
    "        predictor_x_loss = predicted_x_loss + recycled_x_loss\n",
    "        \n",
    "        # now y_2\n",
    "        predicted_y_2 = cyclegan.P_Y(torch.cat((y_0, y_1), 1))\n",
    "        predicted_y_loss = cyclegan.recurrent_loss(predicted_y_2, y_2)\n",
    "        \n",
    "        # So recycled_y_2 = G(P_X(F(y_0), F(y_1)))\n",
    "        recycled_y_2 = cyclegan.G(fake_x_2)\n",
    "        recycled_y_loss = cyclegan.recycle_loss(recycled_y_2, y_2)\n",
    "        \n",
    "        predictor_y_loss = predicted_y_loss + recycled_y_loss\n",
    "        \n",
    "        # Now do the cycle loss\n",
    "        cycled_x_0 = cyclegan.F(fake_y_0)\n",
    "        cycled_loss_x_0 = cyclegan.cycle_loss(cycled_x_0, x_0)\n",
    "        \n",
    "        cycled_x_1 = cyclegan.F(fake_y_1)\n",
    "        cycled_loss_x_1 = cyclegan.cycle_loss(cycled_x_1, x_1)\n",
    "        \n",
    "        cycled_loss_x = cycled_loss_x_0 + cycled_loss_x_1\n",
    "        \n",
    "        cycled_y_0 = cyclegan.G(fake_x_0)\n",
    "        cycled_loss_y_0 = cyclegan.cycle_loss(cycled_y_0, y_0)\n",
    "        \n",
    "        cycled_y_1 = cyclegan.G(fake_x_1)\n",
    "        cycled_loss_y_1 = cyclegan.cycle_loss(cycled_y_1, y_1)\n",
    "        \n",
    "        cycled_loss_y = cycled_loss_y_0 + cycled_loss_y_1\n",
    "        \n",
    "        # Backpropagate and step the gradients\n",
    "        generator_loss = G_fool_loss + F_fool_loss + lambda_weight * (cycled_loss_x + cycled_loss_y + predictor_x_loss + predictor_y_loss + lambda_idt_X * loss_idt_x + lambda_idt_Y * loss_idt_y)\n",
    "        generator_loss.backward()\n",
    "        \n",
    "        cyclegan.G_opt.step()\n",
    "        cyclegan.F_opt.step()\n",
    "        cyclegan.P_X_opt.step()\n",
    "        cyclegan.P_Y_opt.step()\n",
    "        \n",
    "        del G_fool_0\n",
    "        del G_fool_1\n",
    "        del G_fool_2\n",
    "        del F_fool_0\n",
    "        del F_fool_1\n",
    "        del F_fool_2\n",
    "        \n",
    "        ### DISCRIMINATOR TRAINING\n",
    "        # Unfreeze discriminator weights\n",
    "        for param in cyclegan.D_X.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in cyclegan.D_Y.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Zero the gradients\n",
    "        cyclegan.D_X_opt.zero_grad()\n",
    "        cyclegan.D_Y_opt.zero_grad()\n",
    "        \n",
    "        D_X_loss_0 = get_discriminator_loss(x_0, fake_x_0, cyclegan.fake_X_buffer, cyclegan.D_X, cyclegan.gan_loss)\n",
    "        D_X_loss_1 = get_discriminator_loss(x_1, fake_x_1, cyclegan.fake_X_buffer, cyclegan.D_X, cyclegan.gan_loss)\n",
    "        D_X_loss_fake_pred = get_discriminator_loss(x_2, fake_x_2, cyclegan.fake_X_buffer, cyclegan.D_X, cyclegan.gan_loss)\n",
    "        D_X_loss_real_pred = get_discriminator_loss(x_2, predicted_x_2, cyclegan.fake_X_buffer, cyclegan.D_X, cyclegan.gan_loss)\n",
    "        D_X_loss = D_X_loss_0 + D_X_loss_1 + D_X_loss_fake_pred + D_X_loss_real_pred\n",
    "        \n",
    "        D_Y_loss_0 = get_discriminator_loss(y_0, fake_y_0, cyclegan.fake_Y_buffer, cyclegan.D_Y, cyclegan.gan_loss)\n",
    "        D_Y_loss_1 = get_discriminator_loss(y_1, fake_y_1, cyclegan.fake_Y_buffer, cyclegan.D_Y, cyclegan.gan_loss)\n",
    "        D_Y_loss_fake_pred = get_discriminator_loss(y_2, fake_y_2, cyclegan.fake_Y_buffer, cyclegan.D_Y, cyclegan.gan_loss)\n",
    "        D_Y_loss_real_pred = get_discriminator_loss(y_2, predicted_y_2, cyclegan.fake_Y_buffer, cyclegan.D_Y, cyclegan.gan_loss)\n",
    "        D_Y_loss = D_Y_loss_0 + D_Y_loss_1 + D_Y_loss_fake_pred + D_Y_loss_real_pred\n",
    "        \n",
    "        # Backpropagate and step the gradients\n",
    "        D_loss = D_X_loss + D_Y_loss\n",
    "        D_loss.backward()\n",
    "        \n",
    "        cyclegan.D_X_opt.step()\n",
    "        cyclegan.D_Y_opt.step()\n",
    "        \n",
    "        ### UPDATE POOLS\n",
    "        cyclegan.fake_X_buffer.add(fake_x_0.detach())\n",
    "        cyclegan.fake_X_buffer.add(fake_x_1.detach())\n",
    "        cyclegan.fake_X_buffer.add(fake_x_2.detach())\n",
    "        \n",
    "        cyclegan.fake_Y_buffer.add(fake_y_0.detach())\n",
    "        cyclegan.fake_Y_buffer.add(fake_y_1.detach())\n",
    "        cyclegan.fake_Y_buffer.add(fake_y_2.detach())\n",
    "        \n",
    "        ### TRACK LOSS\n",
    "        cum_loss_idt_x += loss_idt_x.item()\n",
    "        cum_loss_idt_y += loss_idt_y.item()\n",
    "        cum_G_fool_loss += G_fool_loss.item()\n",
    "        cum_F_fool_loss += F_fool_loss.item()\n",
    "        cum_predictor_x_loss += predictor_x_loss.item()\n",
    "        cum_predictor_y_loss += predictor_y_loss.item()\n",
    "        cum_cycled_x_loss += cycled_loss_x.item()\n",
    "        cum_cycled_y_loss += cycled_loss_y.item()\n",
    "        cum_D_X_loss += D_X_loss.item()\n",
    "        cum_D_Y_loss += D_Y_loss.item()\n",
    "        \n",
    "        ep_loss_idt_x += loss_idt_x.item()\n",
    "        ep_loss_idt_y += loss_idt_y.item()\n",
    "        ep_G_fool_loss += G_fool_loss.item()\n",
    "        ep_F_fool_loss += F_fool_loss.item()\n",
    "        ep_predictor_x_loss += predictor_x_loss.item()\n",
    "        ep_predictor_y_loss += predictor_y_loss.item()\n",
    "        ep_cycled_x_loss += cycled_loss_x.item()\n",
    "        ep_cycled_y_loss += cycled_loss_y.item()\n",
    "        ep_D_X_loss += D_X_loss.item()\n",
    "        ep_D_Y_loss += D_Y_loss.item()\n",
    "        \n",
    "        if epoch == 0 and batch_no < 55:\n",
    "            print(f\"[{epoch}:{batch_no}] fake_X_buffer: {len(cyclegan.fake_X_buffer)}, fake_Y_buffer: {len(cyclegan.fake_Y_buffer)}\")\n",
    "        \n",
    "        if batch_no % 100 == 0 and batch_no != 0: \n",
    "            duration = time.time() - batch_start_time\n",
    "            \n",
    "            updated_losses = {\n",
    "                \"loss_idt_x\": cum_loss_idt_x / 100,\n",
    "                \"loss_idt_y\": cum_loss_idt_y / 100,\n",
    "                \"G_fool_loss\": cum_G_fool_loss / 100,\n",
    "                \"F_fool_loss\": cum_F_fool_loss / 100,\n",
    "                \"predictor_x_loss\": cum_predictor_x_loss / 100,\n",
    "                \"predictor_y_loss\": cum_predictor_y_loss / 100,\n",
    "                \"cycled_x_loss\": cum_cycled_x_loss / 100,\n",
    "                \"cycled_y_loss\": cum_cycled_y_loss / 100,\n",
    "                \"D_X_loss\": cum_D_X_loss / 100,\n",
    "                \"D_Y_loss\": cum_D_Y_loss / 100\n",
    "            }\n",
    "            \n",
    "            x_loss_str = f\"[{epoch}:{batch_no}]\"\n",
    "            y_loss_str = f\"[{epoch}:{batch_no}]\"\n",
    "            \n",
    "            for i, (key, value) in enumerate(updated_losses.items()):\n",
    "                if i % 2 == 0:\n",
    "                    x_loss_str = f\"{x_loss_str} {key}: {value},\"\n",
    "                else:\n",
    "                    y_loss_str = f\"{y_loss_str} {key}: {value},\"\n",
    "            \n",
    "            x_loss_str = x_loss_str[:-1]\n",
    "            y_loss_str = y_loss_str[:-1]\n",
    "\n",
    "            print(f\"[{epoch}:{batch_no}] Took {duration:.2f}s\")\n",
    "            print(x_loss_str)\n",
    "            print(y_loss_str)\n",
    "            print(f\"[{epoch}:{batch_no}] fake_X_buffer: {len(cyclegan.fake_X_buffer)}, fake_Y_buffer: {len(cyclegan.fake_Y_buffer)}\")\n",
    "            \n",
    "            if vis is not None:\n",
    "                loss_plot.append_values(epoch + batch_no / len(dataloader), updated_losses)\n",
    "            \n",
    "            cum_loss_idt_x = 0\n",
    "            cum_loss_idt_y = 0\n",
    "            cum_G_fool_loss = 0\n",
    "            cum_F_fool_loss = 0\n",
    "            cum_predictor_x_loss = 0\n",
    "            cum_predictor_y_loss = 0\n",
    "            cum_cycled_x_loss = 0\n",
    "            cum_cycled_y_loss = 0\n",
    "            cum_D_X_loss = 0\n",
    "            cum_D_Y_loss = 0\n",
    "\n",
    "            batch_start_time = time.time()\n",
    "    \n",
    "    print(f\"[{epoch}:END] Completed epoch in {time.time() - epoch_start_time}s\")\n",
    "    \n",
    "    print(f\"[{epoch}:{batch_no}]\", \n",
    "          f\"ep_loss_idt_x: {ep_loss_idt_x / len(dataloader):.3f}\", \n",
    "          f\"ep_G_fool_loss: {ep_G_fool_loss / len(dataloader):.3f}\", \n",
    "          f\"ep_predictor_x_loss: {ep_predictor_x_loss / len(dataloader):.3f}\", \n",
    "          f\"ep_cycled_x_loss: {ep_cycled_x_loss / len(dataloader):.3f}\",\n",
    "          f\"ep_D_X_loss: {ep_D_X_loss / len(dataloader):.3f}\")\n",
    "    \n",
    "    print(f\"[{epoch}:{batch_no}]\", \n",
    "          f\"ep_loss_idt_y: {ep_loss_idt_y / len(dataloader):.3f}\", \n",
    "          f\"ep_F_fool_loss: {ep_F_fool_loss / len(dataloader):.3f}\", \n",
    "          f\"ep_predictor_y_loss: {ep_predictor_y_loss / len(dataloader):.3f}\", \n",
    "          f\"ep_cycled_y_loss: {ep_cycled_y_loss / len(dataloader):.3f}\",\n",
    "          f\"ep_D_Y_loss: {ep_D_Y_loss / len(dataloader):.3f}\")\n",
    "    \n",
    "    cyclegan.G.eval()\n",
    "    cyclegan.F.eval()\n",
    "    \n",
    "    if vis is not None:\n",
    "        eval_start_time = time.time()\n",
    "\n",
    "        G_eval_forward = cyclegan.apply(test_xs, x_to_y=True)\n",
    "        F_eval_forward = cyclegan.apply(test_ys, x_to_y=False)\n",
    "\n",
    "        G_rev = cyclegan.apply(G_eval_forward, x_to_y=False)\n",
    "        F_rev = cyclegan.apply(F_eval_forward, x_to_y=True)\n",
    "\n",
    "        G_eval_forward = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in G_eval_forward])\n",
    "        F_eval_forward = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in F_eval_forward])\n",
    "        G_rev = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in G_rev])\n",
    "        F_rev = torch.stack([revert_normalisation(x).permute(2, 0, 1) for x in F_rev])\n",
    "\n",
    "        G_eval_grid = torchvision.utils.make_grid(G_eval_forward, nrow=4)\n",
    "        F_eval_grid = torchvision.utils.make_grid(F_eval_forward, nrow=4)\n",
    "        G_rev_grid = torchvision.utils.make_grid(G_rev, nrow=4)\n",
    "        F_rev_grid = torchvision.utils.make_grid(F_rev, nrow=4)\n",
    "        \n",
    "        folder = f\"{cyclegan.save_folder}/{epoch}\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        \n",
    "        torchvision.utils.save_image(G_eval_grid, f\"{folder}/X_to_Y.png\")\n",
    "        torchvision.utils.save_image(F_eval_grid, f\"{folder}/Y_to_X.png\")\n",
    "        torchvision.utils.save_image(G_rev_grid, f\"{folder}/X_to_Y_to_X.png\")\n",
    "        torchvision.utils.save_image(F_rev_grid, f\"{folder}/Y_to_X_to_Y.png\")\n",
    "\n",
    "        vis.image(G_eval_grid, win=\"G_eval\", opts={\n",
    "            \"caption\": f\"X -> Y evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "\n",
    "        vis.image(F_eval_grid, win=\"F_eval\", opts={\n",
    "            \"caption\": f\"Y -> X evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "\n",
    "        vis.image(G_rev_grid, win=\"G_rev\", opts={\n",
    "            \"caption\": f\"X -> Y -> X evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "\n",
    "        vis.image(F_rev_grid, win=\"F_rev\", opts={\n",
    "            \"caption\": f\"Y -> X -> Y evaluation, epoch {epoch}\",\n",
    "            \"store_history\": True\n",
    "        })\n",
    "        \n",
    "        print(f\"[{epoch}:END] Completed eval in {time.time() - eval_start_time}s\")\n",
    "\n",
    "    cyclegan.G.train()\n",
    "    cyclegan.F.train()\n",
    "\n",
    "    cyclegan.step_learning_rates()\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"[{epoch}:END] Saving models and training information permanently\")\n",
    "        cyclegan.save(epoch, full_save=True)\n",
    "        cyclegan.save(epoch, full_save=True, folder=\"latest\")\n",
    "    else:\n",
    "        print(f\"[{epoch}:END] Saving models and training information temporarily to latest and saving generators permanently\")\n",
    "        cyclegan.save(epoch, full_save=True, folder=\"latest\")\n",
    "        cyclegan.save(epoch, full_save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d56c9-97ab-4aa0-bafa-b8bcd55b101b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Video Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a35e8cbb-55eb-48b5-9ff8-e81e531a622e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_time = \"1680898964.0020654\"\n",
    "model_parent_directory = f\"./runs/RecycleGAN/{model_time}\"\n",
    "epoch_directory = \"latest\"\n",
    "model_name = \"F.pth\" # F: Y -> X which is the style transfer we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dd980fe3-49a9-4dec-b0b2-9e3bfd6bb698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{model_parent_directory}/info_None.json\", \"r\") as fp:\n",
    "    model_info = json.load(fp)\n",
    "\n",
    "upsample_strategy = model_info[\"upsample_strategy\"]\n",
    "block_count = model_info[\"block_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "13896de5-0cac-4b68-8c59-2171870b0c41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Generator(block_count, upsample_strategy).to(device)\n",
    "model.load_state_dict(torch.load(f\"{model_parent_directory}/{epoch_directory}/{model_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "21ac2f86-ef4a-4b1d-80b1-1ef44178f954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_video_path = \"./original_data/Test/Test Movie.mp4\"\n",
    "output_video_path = f\"./video_transfer/recyclegan_{model_time}.mp4\"\n",
    "batch_size = 4\n",
    "\n",
    "os.makedirs(\"./video_transfer\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1f19d2b0-07b0-4ffd-b297-2273d9527fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232510dee47e471e8eda8e7f446a2adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_video(input_video_path, output_video_path, model, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec850d-97c4-4f2a-a950-c45cd4d37252",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Frame Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc93aff-fa22-41d2-81ff-c4a80b0de33e",
   "metadata": {},
   "source": [
    "To run this you may need to rename the 'Test Movie.mp4' to 'test_movie.mp4' to avoid issues with whitespace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d52d22c-6cc0-48ff-a315-c762b413b5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './original_data/Test/test_movie.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2022-12-02T16:48:53.000000Z\n",
      "  Duration: 00:01:05.80, start: 0.000000, bitrate: 427 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 480x360 [SAR 1:1 DAR 4:3], 424 kb/s, 25 fps, 25 tbr, 25k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:48:53.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffe45ffd60] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './video_transfer/frames/original/%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Video: mjpeg, yuvj420p(pc), 480x360 [SAR 1:1 DAR 4:3], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-12-02T16:48:53.000000Z\n",
      "      handler_name    : Alias Data Handler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1645 fps=234 q=2.0 Lsize=N/A time=00:01:05.80 bitrate=N/A speed=9.35x    \n",
      "video:36842kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './video_transfer/cyclegan_1680981254.7780375.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp41isom\n",
      "    creation_time   : 2023-04-10T14:41:09.000000Z\n",
      "  Duration: 00:01:05.80, start: 0.000000, bitrate: 4269 kb/s\n",
      "    Stream #0:0(und): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p, 480x360 [SAR 1:1 DAR 4:3], 4269 kb/s, 25 fps, 25 tbr, 25k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-04-10T14:41:09.000000Z\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffc9ee1720] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './video_transfer/frames/cyclegan/%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp41isom\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 480x360 [SAR 1:1 DAR 4:3], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-04-10T14:41:09.000000Z\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1645 fps=221 q=2.0 Lsize=N/A time=00:01:05.80 bitrate=N/A speed=8.83x    \n",
      "video:34029kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './video_transfer/recyclegan_1680898964.0020654.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp41isom\n",
      "    creation_time   : 2023-04-10T14:47:07.000000Z\n",
      "  Duration: 00:01:05.80, start: 0.000000, bitrate: 4277 kb/s\n",
      "    Stream #0:0(und): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p, 480x360 [SAR 1:1 DAR 4:3], 4276 kb/s, 25 fps, 25 tbr, 25k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-04-10T14:47:07.000000Z\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : AVC Coding\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x7fffdc246f80] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to './video_transfer/frames/recyclegan/%05d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp41isom\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 480x360 [SAR 1:1 DAR 4:3], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-04-10T14:47:07.000000Z\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame= 1645 fps=223 q=2.0 Lsize=N/A time=00:01:05.80 bitrate=N/A speed=8.91x    \n",
      "video:33510kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./video_transfer_frame_comparison.sh \"./original_data/Test/test_movie.mp4\" \"./video_transfer/cyclegan_1680981254.7780375.mp4\" \"./video_transfer/recyclegan_1680898964.0020654.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78896c-4e0d-49da-a540-7a145ed61871",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f18da-f3bb-4780-8664-652a7aa07c67",
   "metadata": {},
   "source": [
    "#### Segmentation Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a4e1c-9ab0-4c2a-85f4-51df965db759",
   "metadata": {},
   "source": [
    "I begin by cycling the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2417edc7-0dd0-4853-812d-2d9f0b4ccfad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_transfer_folder = \"./extracted_data/recyclegan_transferred\"\n",
    "test_input_folder = lambda base: f\"./extracted_data/recyclegan_training_data/{base}/Test\"\n",
    "\n",
    "model_parent_folder = \"./runs/RecycleGAN/1680898964.0020654\"\n",
    "game_to_movie_path = f\"{model_parent_folder}/latest/G.pth\"\n",
    "movie_to_game_path = f\"{model_parent_folder}/latest/F.pth\"\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "291a2e25-0071-49d9-9e1e-d12fe8552f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960eb3cc67274e45bab8307a8d28a072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f83c9aa62744e34a1bd902375671924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f\"{model_parent_folder}/info_None.json\", \"r\") as fp:\n",
    "    model_info = json.load(fp)\n",
    "\n",
    "upsample_strategy = model_info[\"upsample_strategy\"]\n",
    "block_count = model_info[\"block_count\"]\n",
    "\n",
    "for base in [\"Game\", \"Movie\"]:\n",
    "    other_domain = \"Movie\" if base == \"Game\" else \"Game\"\n",
    "    model_path =  game_to_movie_path if base == \"Game\" else movie_to_game_path\n",
    "    test_folder = test_input_folder(base)\n",
    "    transferred_folder = f\"{base_transfer_folder}/{base}_to_{other_domain}\"\n",
    "    \n",
    "    os.makedirs(transferred_folder)\n",
    "    \n",
    "    model = Generator(block_count, upsample_strategy).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    file_names = [file_name for file_name in os.listdir(test_folder) if file_name.endswith(\".jpg\")]\n",
    "    batch_count = len(file_names) // batch_size + 1\n",
    "    \n",
    "    for batch_no in tqdm(range(batch_count)):\n",
    "        selected_files = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            real_i = batch_size * batch_no + i\n",
    "            \n",
    "            if real_i >= len(file_names):\n",
    "                break\n",
    "            \n",
    "            selected_files.append(file_names[real_i])\n",
    "        \n",
    "        if len(selected_files) == 0:\n",
    "            break\n",
    "            \n",
    "        batch_images = [cv2.cvtColor(cv2.imread(f\"{test_folder}/{file_name}\"), cv2.COLOR_BGR2RGB) for file_name in selected_files]\n",
    "        transferred = transfer_style_to_batch(batch_images, model)\n",
    "        \n",
    "        for file_name, transferred_image in zip(selected_files, transferred):\n",
    "            cv2.imwrite(f\"{transferred_folder}/{''.join(file_name.split('.')[:-1])}_transferred.jpg\", cv2.cvtColor((transferred_image.numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "23def448-1850-4cba-960e-27514d53c30b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac640d03251485585ac3e0f4b77fa57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf86c6ef1d7f4045b1d2d0eacccfd3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f\"{model_parent_folder}/info_None.json\", \"r\") as fp:\n",
    "    model_info = json.load(fp)\n",
    "\n",
    "upsample_strategy = model_info[\"upsample_strategy\"]\n",
    "block_count = model_info[\"block_count\"]\n",
    "\n",
    "for base in [\"Game\", \"Movie\"]:\n",
    "    other_domain = \"Movie\" if base == \"Game\" else \"Game\"\n",
    "    model_path =  movie_to_game_path if base == \"Game\" else game_to_movie_path\n",
    "    test_folder = f\"{base_transfer_folder}/{base}_to_{other_domain}\"\n",
    "    transferred_folder = f\"{base_transfer_folder}/{base}_to_{other_domain}_to_{base}\"\n",
    "    \n",
    "    os.makedirs(transferred_folder)\n",
    "    \n",
    "    model = Generator(block_count, upsample_strategy).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    file_names = [file_name for file_name in os.listdir(test_folder) if file_name.endswith(\".jpg\")]\n",
    "    batch_count = len(file_names) // batch_size + 1\n",
    "    \n",
    "    for batch_no in tqdm(range(batch_count)):\n",
    "        selected_files = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            real_i = batch_size * batch_no + i\n",
    "            \n",
    "            if real_i >= len(file_names):\n",
    "                break\n",
    "            \n",
    "            selected_files.append(file_names[real_i])\n",
    "        \n",
    "        if len(selected_files) == 0:\n",
    "            break\n",
    "            \n",
    "        batch_images = [cv2.cvtColor(cv2.imread(f\"{test_folder}/{file_name}\"), cv2.COLOR_BGR2RGB) for file_name in selected_files]\n",
    "        transferred = transfer_style_to_batch(batch_images, model)\n",
    "        \n",
    "        for file_name, transferred_image in zip(selected_files, transferred):\n",
    "            cv2.imwrite(f\"{transferred_folder}/{''.join(file_name.split('.')[:-1])}_transferred.jpg\", cv2.cvtColor((transferred_image.numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5669605a-63c6-4d4a-87db-f51e4ada213c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_game_folder = \"./extracted_data/recyclegan_training_data/Game/Test\"\n",
    "cycled_game_folder = \"./extracted_data/recyclegan_transferred/Game_to_Movie_to_Game\"\n",
    "original_game_files = [f\"{original_game_folder}/{file_name}\" for file_name in os.listdir(original_game_folder) if file_name.endswith(\".jpg\")]\n",
    "cycled_game_files = [f\"{cycled_game_folder}/{file_name}\" for file_name in os.listdir(cycled_game_folder) if file_name.endswith(\".jpg\")]\n",
    "\n",
    "original_movie_folder = \"./extracted_data/recyclegan_training_data/Movie/Test\"\n",
    "cycled_movie_folder = \"./extracted_data/recyclegan_transferred/Movie_to_Game_to_Movie\"\n",
    "original_movie_files = [f\"{original_movie_folder}/{file_name}\" for file_name in os.listdir(original_movie_folder) if file_name.endswith(\".jpg\")]\n",
    "cycled_movie_files = [f\"{cycled_movie_folder}/{file_name}\" for file_name in os.listdir(cycled_movie_folder) if file_name.endswith(\".jpg\")]\n",
    "\n",
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "342e684c-7425-45c2-97d1-20cccd2cccb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskrcnn = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "maskrcnn.to(device).eval()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e69eb33-36c0-45ba-9c6c-5ee694ff6fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 91 COCO class names, directly from Semantic Segmentation Mask R-CNN.ipynb\n",
    "coco_names = ['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "af9149bd-b607-4338-96d2-6be530d09185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_segmentation_map(output, frame, threshold):\n",
    "    # Get the relevant model output on to the CPU in a usable format\n",
    "    scores = output[\"scores\"].detach().cpu().numpy()\n",
    "    boxes = output[\"boxes\"].detach().cpu().numpy().astype(int)\n",
    "    label_indices = output[\"labels\"].detach().cpu()\n",
    "    masks = (output[\"masks\"] > 0.5).detach().cpu()\n",
    "    \n",
    "    segmentation_maps = {label: np.zeros(frame.shape[:2]).astype(np.uint8) for label in coco_names[1:]}\n",
    "    \n",
    "    # Process each entry found by the model\n",
    "    for i, (confidence, box, label_idx, mask) in enumerate(zip(scores, boxes, label_indices, masks)):\n",
    "        label = coco_names[label_idx.item()]\n",
    "        \n",
    "        # The confidences are sorted high to low so stop once we're below the threshold\n",
    "        if confidence < threshold:\n",
    "            break\n",
    "        \n",
    "        segmentation_maps[label][(mask == 1).squeeze()] = 1\n",
    "    \n",
    "    return segmentation_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "44af4403-70e5-4024-a699-fa6a8c3ccf8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def measure_segmentation_map_similarity(original_files, cycled_files):\n",
    "    tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mean_accuracies = []\n",
    "    \n",
    "    for original_file_name, cycled_file_name in tqdm(zip(original_files, cycled_files), total=len(original_files)):\n",
    "        original_file = cv2.imread(original_file_name, cv2.IMREAD_COLOR)\n",
    "        cycled_file = cv2.imread(cycled_file_name, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if original_file.shape != cycled_file.shape:\n",
    "            original_file = cv2.cvtColor(original_file, cv2.COLOR_BGR2RGB)\n",
    "            original_file_pil = Image.fromarray(original_file).resize((256, 256))\n",
    "            original_file = np.asarray(original_file_pil)\n",
    "            original_file = cv2.cvtColor(original_file, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            cycled_file = cv2.cvtColor(cycled_file, cv2.COLOR_BGR2RGB)\n",
    "            cycled_file_pil = Image.fromarray(cycled_file).resize((256, 256))\n",
    "            cycled_file = np.asarray(cycled_file_pil)\n",
    "            cycled_file = cv2.cvtColor(cycled_file, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "        \n",
    "        maskrcnn_batch = torch.stack([tensor_transform(original_file), tensor_transform(cycled_file)]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = maskrcnn(maskrcnn_batch)\n",
    "            \n",
    "        original_seg_maps = retrieve_segmentation_map(outputs[0], original_file, threshold)\n",
    "        cycled_seg_maps = retrieve_segmentation_map(outputs[1], cycled_file, threshold)\n",
    "        \n",
    "        ins_accuracies = []\n",
    "        \n",
    "        for label in coco_names[1:]:\n",
    "            original_seg_map = original_seg_maps[label]\n",
    "            cycled_seg_map = cycled_seg_maps[label]\n",
    "            \n",
    "            assert original_seg_map.shape == cycled_seg_map.shape\n",
    "            \n",
    "            if not original_seg_map.any() and not cycled_seg_map.any():\n",
    "                continue\n",
    "            \n",
    "            correct_pixels = ((original_seg_map == 1) & (cycled_seg_map == 1)).sum()\n",
    "            total_pixels = (original_seg_map == 1).sum()\n",
    "            \n",
    "#             dupe_frame = original_file.copy()\n",
    "#             y = np.stack([original_seg_map, original_seg_map, original_seg_map], axis=2).astype(np.uint8)\n",
    "#             cv2.addWeighted(dupe_frame, 1.0, y * 200, 0.6, 0.0, dupe_frame)\n",
    "#             cv2.imwrite(f\"./test_{time.time()}_{label}_org.png\", dupe_frame)\n",
    "            \n",
    "#             dupe_frame = cycled_file.copy()\n",
    "#             y = np.stack([cycled_seg_map, cycled_seg_map, cycled_seg_map], axis=2).astype(np.uint8)\n",
    "#             cv2.addWeighted(dupe_frame, 1.0, y * 200, 0.6, 0.0, dupe_frame)\n",
    "#             cv2.imwrite(f\"./test_{time.time()}_{label}_cycled.png\", dupe_frame)\n",
    "            \n",
    "            if total_pixels == 0:\n",
    "                continue\n",
    "    \n",
    "            accuracy = correct_pixels / total_pixels\n",
    "            ins_accuracies.append(accuracy)\n",
    "            \n",
    "        if len(ins_accuracies) == 0:\n",
    "            continue\n",
    "        \n",
    "        mean_accuracy = sum(ins_accuracies) / len(ins_accuracies)\n",
    "        mean_accuracies.append(mean_accuracy)\n",
    "    \n",
    "    return sum(mean_accuracies) / len(mean_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7a4fdd25-ebc4-42f0-8cc0-ff0b72aa63ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bea62d8e6d84a8fa24f6b4abd2103f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game_fcn = measure_segmentation_map_similarity(original_game_files, cycled_game_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "97afa76f-e60e-4dfa-bfec-cd3117cc5e08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7096492848913747"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "06e7ba3f-cd11-470b-ba80-a62291547da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64cf57a32ba45e38de4ec6fa51f275a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_fcn = measure_segmentation_map_similarity(original_movie_files, cycled_movie_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fa367a8-7fc6-4f86-aa04-aa1753ae1337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5468722320982466"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6ba40-7099-44a7-b783-c681fb3927b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### FID and KID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2e5a543a-61bb-4790-92b0-3e81ff678cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute FID between two folders\n",
      "Found 470 images in the folder ./extracted_data/recyclegan_training_data/Movie/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Test :   0%|                                                                                | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "FID Test :   7%|                                                                   | 1/15 [00:00<00:03,  3.52it/s]\u001b[A\n",
      "FID Test :  13%|                                                              | 2/15 [00:00<00:04,  3.22it/s]\u001b[A\n",
      "FID Test :  20%|                                                         | 3/15 [00:00<00:03,  3.73it/s]\u001b[A\n",
      "FID Test :  27%|                                                    | 4/15 [00:01<00:02,  3.99it/s]\u001b[A\n",
      "FID Test :  33%|                                                | 5/15 [00:01<00:02,  4.14it/s]\u001b[A\n",
      "FID Test :  40%|                                           | 6/15 [00:01<00:02,  4.22it/s]\u001b[A\n",
      "FID Test :  47%|                                      | 7/15 [00:01<00:01,  4.24it/s]\u001b[A\n",
      "FID Test :  53%|                                 | 8/15 [00:01<00:01,  4.33it/s]\u001b[A\n",
      "FID Test :  60%|                            | 9/15 [00:02<00:01,  4.35it/s]\u001b[A\n",
      "FID Test :  67%|                       | 10/15 [00:02<00:01,  4.31it/s]\u001b[A\n",
      "FID Test :  73%|                   | 11/15 [00:02<00:00,  4.34it/s]\u001b[A\n",
      "FID Test :  80%|              | 12/15 [00:02<00:00,  4.34it/s]\u001b[A\n",
      "FID Test :  87%|         | 13/15 [00:03<00:00,  4.35it/s]\u001b[A\n",
      "FID Test :  93%|    | 14/15 [00:03<00:00,  4.43it/s]\u001b[A\n",
      "FID Test : 100%|| 15/15 [00:03<00:00,  4.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 490 images in the folder ./extracted_data/recyclegan_transferred/Game_to_Movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Game_to_Movie :   0%|                                                                       | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "FID Game_to_Movie :   6%|                                                           | 1/16 [00:00<00:04,  3.15it/s]\u001b[A\n",
      "FID Game_to_Movie :  12%|                                                       | 2/16 [00:00<00:04,  3.20it/s]\u001b[A\n",
      "FID Game_to_Movie :  19%|                                                   | 3/16 [00:00<00:03,  3.53it/s]\u001b[A\n",
      "FID Game_to_Movie :  25%|                                               | 4/16 [00:01<00:03,  3.44it/s]\u001b[A\n",
      "FID Game_to_Movie :  31%|                                           | 5/16 [00:01<00:03,  2.93it/s]\u001b[A\n",
      "FID Game_to_Movie :  38%|                                       | 6/16 [00:01<00:03,  3.16it/s]\u001b[A\n",
      "FID Game_to_Movie :  44%|                                   | 7/16 [00:02<00:02,  3.27it/s]\u001b[A\n",
      "FID Game_to_Movie :  50%|                               | 8/16 [00:02<00:02,  3.22it/s]\u001b[A\n",
      "FID Game_to_Movie :  56%|                           | 9/16 [00:02<00:02,  3.15it/s]\u001b[A\n",
      "FID Game_to_Movie :  62%|                       | 10/16 [00:03<00:01,  3.04it/s]\u001b[A\n",
      "FID Game_to_Movie :  69%|                   | 11/16 [00:03<00:01,  2.89it/s]\u001b[A\n",
      "FID Game_to_Movie :  75%|               | 12/16 [00:03<00:01,  2.95it/s]\u001b[A\n",
      "FID Game_to_Movie :  81%|           | 13/16 [00:04<00:00,  3.02it/s]\u001b[A\n",
      "FID Game_to_Movie :  88%|       | 14/16 [00:04<00:00,  3.05it/s]\u001b[A\n",
      "FID Game_to_Movie :  94%|   | 15/16 [00:04<00:00,  2.80it/s]\u001b[A\n",
      "FID Game_to_Movie : 100%|| 16/16 [00:05<00:00,  3.16it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_fid(test_input_folder(\"Movie\"), \"./extracted_data/recyclegan_transferred/Game_to_Movie\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a0944f6b-23d3-4e14-9bb8-9f4e26c309cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.33488812395717"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b1cfa395-86f6-48cc-8a67-b032c3003b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute KID between two folders\n",
      "Found 470 images in the folder ./extracted_data/recyclegan_training_data/Movie/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Test :   0%|                                                                                | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "KID Test :   7%|                                                                   | 1/15 [00:00<00:04,  3.32it/s]\u001b[A\n",
      "KID Test :  13%|                                                              | 2/15 [00:00<00:04,  3.14it/s]\u001b[A\n",
      "KID Test :  20%|                                                         | 3/15 [00:00<00:03,  3.68it/s]\u001b[A\n",
      "KID Test :  27%|                                                    | 4/15 [00:01<00:02,  3.95it/s]\u001b[A\n",
      "KID Test :  33%|                                                | 5/15 [00:01<00:02,  4.12it/s]\u001b[A\n",
      "KID Test :  40%|                                           | 6/15 [00:01<00:02,  4.21it/s]\u001b[A\n",
      "KID Test :  47%|                                      | 7/15 [00:01<00:01,  4.25it/s]\u001b[A\n",
      "KID Test :  53%|                                 | 8/15 [00:01<00:01,  4.34it/s]\u001b[A\n",
      "KID Test :  60%|                            | 9/15 [00:02<00:01,  4.36it/s]\u001b[A\n",
      "KID Test :  67%|                       | 10/15 [00:02<00:01,  4.35it/s]\u001b[A\n",
      "KID Test :  73%|                   | 11/15 [00:02<00:00,  4.36it/s]\u001b[A\n",
      "KID Test :  80%|              | 12/15 [00:02<00:00,  4.38it/s]\u001b[A\n",
      "KID Test :  87%|         | 13/15 [00:03<00:00,  4.41it/s]\u001b[A\n",
      "KID Test :  93%|    | 14/15 [00:03<00:00,  4.49it/s]\u001b[A\n",
      "KID Test : 100%|| 15/15 [00:03<00:00,  4.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 490 images in the folder ./extracted_data/recyclegan_transferred/Game_to_Movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Game_to_Movie :   0%|                                                                       | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "KID Game_to_Movie :   6%|                                                           | 1/16 [00:00<00:04,  3.21it/s]\u001b[A\n",
      "KID Game_to_Movie :  12%|                                                       | 2/16 [00:00<00:04,  3.24it/s]\u001b[A\n",
      "KID Game_to_Movie :  19%|                                                   | 3/16 [00:00<00:03,  3.57it/s]\u001b[A\n",
      "KID Game_to_Movie :  25%|                                               | 4/16 [00:01<00:03,  3.47it/s]\u001b[A\n",
      "KID Game_to_Movie :  31%|                                           | 5/16 [00:01<00:03,  2.97it/s]\u001b[A\n",
      "KID Game_to_Movie :  38%|                                       | 6/16 [00:01<00:03,  3.19it/s]\u001b[A\n",
      "KID Game_to_Movie :  44%|                                   | 7/16 [00:02<00:02,  3.31it/s]\u001b[A\n",
      "KID Game_to_Movie :  50%|                               | 8/16 [00:02<00:02,  3.26it/s]\u001b[A\n",
      "KID Game_to_Movie :  56%|                           | 9/16 [00:02<00:02,  3.18it/s]\u001b[A\n",
      "KID Game_to_Movie :  62%|                       | 10/16 [00:03<00:01,  3.07it/s]\u001b[A\n",
      "KID Game_to_Movie :  69%|                   | 11/16 [00:03<00:01,  2.93it/s]\u001b[A\n",
      "KID Game_to_Movie :  75%|               | 12/16 [00:03<00:01,  2.98it/s]\u001b[A\n",
      "KID Game_to_Movie :  81%|           | 13/16 [00:04<00:00,  3.04it/s]\u001b[A\n",
      "KID Game_to_Movie :  88%|       | 14/16 [00:04<00:00,  3.08it/s]\u001b[A\n",
      "KID Game_to_Movie :  94%|   | 15/16 [00:04<00:00,  2.87it/s]\u001b[A\n",
      "KID Game_to_Movie : 100%|| 16/16 [00:04<00:00,  3.21it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_kid(test_input_folder(\"Movie\"), \"./extracted_data/recyclegan_transferred/Game_to_Movie\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f75d3f99-924a-4b2b-8ba1-6cc11d73ee48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04133906387394656"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7196705e-c26e-4033-ae2d-cbd5bfdec7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute FID between two folders\n",
      "Found 490 images in the folder ./extracted_data/recyclegan_training_data/Game/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Test :   0%|                                                                                | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "FID Test :   6%|                                                                   | 1/16 [00:00<00:05,  2.67it/s]\u001b[A\n",
      "FID Test :  12%|                                                               | 2/16 [00:00<00:05,  2.54it/s]\u001b[A\n",
      "FID Test :  19%|                                                          | 3/16 [00:01<00:04,  3.06it/s]\u001b[A\n",
      "FID Test :  25%|                                                      | 4/16 [00:01<00:03,  3.17it/s]\u001b[A\n",
      "FID Test :  31%|                                                 | 5/16 [00:01<00:03,  2.86it/s]\u001b[A\n",
      "FID Test :  38%|                                             | 6/16 [00:02<00:03,  3.13it/s]\u001b[A\n",
      "FID Test :  44%|                                        | 7/16 [00:02<00:02,  3.27it/s]\u001b[A\n",
      "FID Test :  50%|                                    | 8/16 [00:02<00:02,  3.29it/s]\u001b[A\n",
      "FID Test :  56%|                               | 9/16 [00:02<00:02,  3.22it/s]\u001b[A\n",
      "FID Test :  62%|                          | 10/16 [00:03<00:01,  3.11it/s]\u001b[A\n",
      "FID Test :  69%|                      | 11/16 [00:03<00:01,  2.98it/s]\u001b[A\n",
      "FID Test :  75%|                 | 12/16 [00:03<00:01,  3.04it/s]\u001b[A\n",
      "FID Test :  81%|             | 13/16 [00:04<00:00,  3.10it/s]\u001b[A\n",
      "FID Test :  88%|        | 14/16 [00:04<00:00,  3.14it/s]\u001b[A\n",
      "FID Test :  94%|    | 15/16 [00:04<00:00,  2.92it/s]\u001b[A\n",
      "FID Test : 100%|| 16/16 [00:05<00:00,  3.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 470 images in the folder ./extracted_data/recyclegan_transferred/Movie_to_Game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "FID Movie_to_Game :   0%|                                                                       | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "FID Movie_to_Game :   7%|                                                          | 1/15 [00:00<00:03,  4.58it/s]\u001b[A\n",
      "FID Movie_to_Game :  13%|                                                      | 2/15 [00:00<00:02,  4.39it/s]\u001b[A\n",
      "FID Movie_to_Game :  20%|                                                  | 3/15 [00:00<00:02,  4.46it/s]\u001b[A\n",
      "FID Movie_to_Game :  27%|                                              | 4/15 [00:00<00:02,  4.44it/s]\u001b[A\n",
      "FID Movie_to_Game :  33%|                                          | 5/15 [00:01<00:02,  4.33it/s]\u001b[A\n",
      "FID Movie_to_Game :  40%|                                     | 6/15 [00:01<00:02,  4.32it/s]\u001b[A\n",
      "FID Movie_to_Game :  47%|                                 | 7/15 [00:01<00:01,  4.28it/s]\u001b[A\n",
      "FID Movie_to_Game :  53%|                             | 8/15 [00:01<00:01,  4.36it/s]\u001b[A\n",
      "FID Movie_to_Game :  60%|                         | 9/15 [00:02<00:01,  4.34it/s]\u001b[A\n",
      "FID Movie_to_Game :  67%|                    | 10/15 [00:02<00:01,  4.32it/s]\u001b[A\n",
      "FID Movie_to_Game :  73%|                | 11/15 [00:02<00:00,  4.32it/s]\u001b[A\n",
      "FID Movie_to_Game :  80%|            | 12/15 [00:02<00:00,  4.32it/s]\u001b[A\n",
      "FID Movie_to_Game :  87%|        | 13/15 [00:02<00:00,  4.37it/s]\u001b[A\n",
      "FID Movie_to_Game :  93%|    | 14/15 [00:03<00:00,  4.41it/s]\u001b[A\n",
      "FID Movie_to_Game : 100%|| 15/15 [00:03<00:00,  4.45it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_fid(test_input_folder(\"Game\"), \"./extracted_data/recyclegan_transferred/Movie_to_Game\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fe31fa99-dbe6-4c81-b638-ef08d2a9f028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178.9576746667507"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ee355e4b-473a-4ce3-a983-961a6613572a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute KID between two folders\n",
      "Found 490 images in the folder ./extracted_data/recyclegan_training_data/Game/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Test :   0%|                                                                                | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "KID Test :   6%|                                                                   | 1/16 [00:00<00:05,  2.67it/s]\u001b[A\n",
      "KID Test :  12%|                                                               | 2/16 [00:00<00:05,  2.54it/s]\u001b[A\n",
      "KID Test :  19%|                                                          | 3/16 [00:01<00:04,  3.06it/s]\u001b[A\n",
      "KID Test :  25%|                                                      | 4/16 [00:01<00:03,  3.19it/s]\u001b[A\n",
      "KID Test :  31%|                                                 | 5/16 [00:01<00:03,  2.86it/s]\u001b[A\n",
      "KID Test :  38%|                                             | 6/16 [00:01<00:03,  3.13it/s]\u001b[A\n",
      "KID Test :  44%|                                        | 7/16 [00:02<00:02,  3.27it/s]\u001b[A\n",
      "KID Test :  50%|                                    | 8/16 [00:02<00:02,  3.29it/s]\u001b[A\n",
      "KID Test :  56%|                               | 9/16 [00:02<00:02,  3.23it/s]\u001b[A\n",
      "KID Test :  62%|                          | 10/16 [00:03<00:01,  3.11it/s]\u001b[A\n",
      "KID Test :  69%|                      | 11/16 [00:03<00:01,  2.97it/s]\u001b[A\n",
      "KID Test :  75%|                 | 12/16 [00:03<00:01,  3.03it/s]\u001b[A\n",
      "KID Test :  81%|             | 13/16 [00:04<00:00,  3.10it/s]\u001b[A\n",
      "KID Test :  88%|        | 14/16 [00:04<00:00,  3.13it/s]\u001b[A\n",
      "KID Test :  94%|    | 15/16 [00:04<00:00,  2.92it/s]\u001b[A\n",
      "KID Test : 100%|| 16/16 [00:05<00:00,  3.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 470 images in the folder ./extracted_data/recyclegan_transferred/Movie_to_Game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KID Movie_to_Game :   0%|                                                                       | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "KID Movie_to_Game :   7%|                                                          | 1/15 [00:00<00:03,  4.66it/s]\u001b[A\n",
      "KID Movie_to_Game :  13%|                                                      | 2/15 [00:00<00:02,  4.60it/s]\u001b[A\n",
      "KID Movie_to_Game :  20%|                                                  | 3/15 [00:00<00:02,  4.63it/s]\u001b[A\n",
      "KID Movie_to_Game :  27%|                                              | 4/15 [00:00<00:02,  4.56it/s]\u001b[A\n",
      "KID Movie_to_Game :  33%|                                          | 5/15 [00:01<00:02,  4.49it/s]\u001b[A\n",
      "KID Movie_to_Game :  40%|                                     | 6/15 [00:01<00:02,  4.46it/s]\u001b[A\n",
      "KID Movie_to_Game :  47%|                                 | 7/15 [00:01<00:01,  4.41it/s]\u001b[A\n",
      "KID Movie_to_Game :  53%|                             | 8/15 [00:01<00:01,  4.46it/s]\u001b[A\n",
      "KID Movie_to_Game :  60%|                         | 9/15 [00:02<00:01,  4.43it/s]\u001b[A\n",
      "KID Movie_to_Game :  67%|                    | 10/15 [00:02<00:01,  4.39it/s]\u001b[A\n",
      "KID Movie_to_Game :  73%|                | 11/15 [00:02<00:00,  4.39it/s]\u001b[A\n",
      "KID Movie_to_Game :  80%|            | 12/15 [00:02<00:00,  4.40it/s]\u001b[A\n",
      "KID Movie_to_Game :  87%|        | 13/15 [00:02<00:00,  4.44it/s]\u001b[A\n",
      "KID Movie_to_Game :  93%|    | 14/15 [00:03<00:00,  4.48it/s]\u001b[A\n",
      "KID Movie_to_Game : 100%|| 15/15 [00:03<00:00,  4.55it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "score = fid.compute_kid(test_input_folder(\"Game\"), \"./extracted_data/recyclegan_transferred/Movie_to_Game\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "91a98ad0-f82e-40d0-a236-76c43a5e67b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04826035881512055"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
